[
    {
        "description": "Count the number of files in your home directory that were modified in the last 7 days and have a \".txt\" extension. You should exclude directories from the count.",
        "explanation": "To solve this problem, you can use the `find` command to search for files in your home directory. The `-mtime` option allows you to filter files based on their modification time, and `-type f` ensures only regular files are counted (excluding directories).\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/experiment -type f -name \"*.txt\" -mtime -7 | wc -l\n```",
        "create": {
            "init": "# Create some sample .txt files with different modification dates\nmkdir -p ~/experiment\ntouch ~/experiment/file1.txt\ntouch ~/experiment/file2.txt\ntouch ~/experiment/file3.txt\n\n# Modify the timestamp of file1.txt to be 8 days old\ntouch -d \"$(date --date='8 days ago')\" ~/experiment/file1.txt\n\n# Modify the timestamp of file2.txt and file3.txt to be within the last 7 days\ntouch -d \"$(date --date='3 days ago')\" ~/experiment/file2.txt\ntouch -d \"$(date --date='5 days ago')\" ~/experiment/file3.txt\n\n# Ensure there are no directories among these files."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/experiment -type f -name \"*.txt\" -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that were modified in the last 7 days and have a size greater than 100KB.",
        "explanation": "To solve this problem, you can use the `find` command to search for files in your home directory. You will need to specify conditions such as modification time (using `-mtime`) and file size (using `-size`). The result of the command should be filtered to count only those files meeting both criteria.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind $HOME -type f -mtime -7 -size +100k | wc -l\n```",
        "create": {
            "init": "# There is no initialization needed for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find $HOME -type f -mtime -7 -size +100k | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days. Exclude directories from this count.",
        "explanation": "To solve this problem, you need to use the `find` command to search for files in your home directory (`~/`) that have been modified within the last 7 days. The `-type f` option will help you filter out only regular files and exclude directories. After filtering, you can use `wc -l` to count the number of lines (i.e., files) returned by the `find` command.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required for this task as it operates on existing files and directories in the student's home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and have a size greater than 1MB.",
        "explanation": "To solve this problem, you can use the `find` command to filter files based on their modification time and size. The `-mtime` option allows you to specify files modified within a certain number of days, while `-size` helps filter files by size. You can count the number of matching files using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# This script does not require any specific initialization."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in the `/home/student/documents` directory that contain the word \"Linux\".",
        "explanation": "To solve this problem, you need to iterate over each `.txt` file in the specified directory, read its contents, and count the lines containing the word \"Linux\". You can use `grep` to search for lines containing \"Linux\" and `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'Linux' /home/student/documents/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho -e \"This is a Linux file.\\nIt contains multiple lines about Linux.\" > /home/student/documents/file1.txt\necho -e \"Another file mentioning Linux.\\nAgain, Linux is great!\" > /home/student/documents/file2.txt\necho -e \"No mention of Linux here.\" > /home/student/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'Linux' /home/student/documents/*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and are larger than 1MB.",
        "explanation": "To solve this problem, you need to first identify files in your home directory that have been modified within the last week. You can use the `find` command with `-mtime` parameter to filter out these files based on their modification time. Then, you'll filter these results further by file size using the `-size` parameter. Finally, count the number of such files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "Identify and count the number of files in your home directory that were modified in the last 7 days and have a file size greater than 1MB.",
        "explanation": "To solve this problem, you can use the `find` command, which is useful for searching files with specific criteria. You should filter the files based on their modification time using the `-mtime` option and size using the `-size` option. Combine these options to count only those files that satisfy both conditions.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# Create sample files with varying modification dates and sizes in the student's home directory.\nmkdir -p ~/test_files\ntouch ~/test_files/file1.txt\ntouch ~/test_files/file2.txt\ndd if=/dev/zero of=~/test_files/bigfile1.bin bs=1024k count=2 # Create a big file (2MB)\ndd if=/dev/zero of=~/test_files/bigfile2.bin bs=1024k count=1 # Create a big file (1MB)\n\n# Modify timestamps for testing purposes\ntouch -d \"3 days ago\" ~/test_files/file1.txt \ntouch -d \"8 days ago\" ~/test_files/file2.txt \ntouch -d \"5 days ago\" ~/test_files/bigfile1.bin \ntouch -d \"10 days ago\" ~/test_files/bigfile2.bin"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all `.log` files located in the `/var/log/myapp/` directory, and then output the sum.",
        "explanation": "To solve this problem, you will need to use tools like `grep` to search for occurrences of the word \"error\" within each `.log` file and `wc -l` to count the number of lines matched by `grep`. You might also need to use loops or other bash utilities to iterate over multiple files in a specified directory.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Iterate over each .log file and count lines containing 'error'\ntotal_errors=0\nfor logfile in /var/log/myapp/*.log; do\n  errors_in_file=$(grep -i 'error' \"$logfile\" | wc -l)\n  total_errors=$((total_errors + errors_in_file))\ndone\n\n# Output the total count of 'error' lines across all log files\necho $total_errors\n```",
        "create": {
            "init": "# Create a sample directory with log files containing various messages\nmkdir -p /var/log/myapp/\necho -e \"This is a message\\nHere is an error\\nAnother line\" > /var/log/myapp/app1.log\necho -e \"Error occurred here\\nNo errors here\\nYet another error\" > /var/log/myapp/app2.log\necho -e \"All clear\\nError found\\nSome other text\" > /var/log/myapp/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Iterate over each .log file and count lines containing 'error'\ntotal_errors=0\nfor logfile in /var/log/myapp/*.log; do\n  errors_in_file=$(grep -i 'error' \"$logfile\" | wc -l)\n  total_errors=$((total_errors + errors_in_file))\ndone\n\n# Output the total count of 'error' lines across all log files\necho $total_errors"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in the `/home/student/documents` directory that contain the word \"Linux\". You should ignore case sensitivity when searching for the word.",
        "explanation": "To solve this problem, you can use a combination of `grep` to search for occurrences of \"Linux\" (ignoring case) and `wc -l` to count lines. The `grep` command with `-i` flag will help you find occurrences of \"Linux\" without worrying about case sensitivity. You would first list all `.txt` files in the specified directory, perform a search on each file using `grep`, and finally sum up the line counts using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'Linux' /home/student/documents/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho -e \"This is a Linux tutorial.\\nWelcome to Linux world.\" > /home/student/documents/file1.txt\necho -e \"LINUX is powerful.\\nOperating system: linux.\" > /home/student/documents/file2.txt\necho -e \"No mention here.\" > /home/student/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'Linux' /home/student/documents/*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of files in the `/var/log` directory that have been modified in the last 7 days and whose size is greater than 1MB.",
        "explanation": "To solve this problem, you need to list all files in the `/var/log` directory and filter them based on their modification time and size. You can use `find` command with `-mtime`, `-size`, and `-type` options to achieve this. The `-mtime -7` option will filter files modified within the last 7 days, `-size +1M` will filter files larger than 1MB, and `-type f` ensures only regular files are considered. Finally, count the number of results using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization is required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "In your home directory, count the total number of lines across all text files (*.txt) that contain the word \"Linux\" (case-sensitive). Assume there are no subdirectories in your home directory.",
        "explanation": "To solve this problem, you can use a combination of `grep` to filter lines containing the word \"Linux\" and `wc -l` to count these lines. You should iterate over each text file in your home directory.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\ngrep -h 'Linux' ~/*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample text files in the student's home directory\necho -e \"Linux is great\\nI love using Linux\\nOperating systems are fun\" > ~/file1.txt\necho -e \"Linux kernel\\nJust another line\\nNot about Linux\" > ~/file2.txt\necho -e \"This is not about Linux\\nAnother line\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\ngrep -h 'Linux' ~/*.txt | wc -l"
        }
    },
    {
        "description": "You need to determine the total number of lines across all `.txt` files within a directory named `documents` in your home directory, and only count lines that contain the word \"Linux\". Assume the `documents` directory contains multiple `.txt` files with varying content.",
        "explanation": "To solve this problem, you will need to use a combination of shell commands to search through each `.txt` file in the `documents` directory, filter lines containing the word \"Linux\", and count those lines. Commands such as `grep`, `find`, `xargs`, or loops can be useful for this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"Linux\" ~/documents/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/documents\necho -e \"Linux is great\\nI love Linux\\nThis is another line\" > ~/documents/file1.txt\necho -e \"No Linux here\\nJust some text\" > ~/documents/file2.txt\necho -e \"Linux again\\nAnd more Linux\" > ~/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"Linux\" ~/documents/*.txt | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing multiple log files with the extension \".log\". Each log file contains timestamps in the format \"YYYY-MM-DD HH:MM:SS\" followed by a message. Your task is to find out how many unique dates (YYYY-MM-DD) appear across all the log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to extract the date part from each timestamp in every log file, collect these dates, and then count how many of them are unique. You can use tools like `grep`, `awk`, and `sort` with `uniq` to achieve this. First, use `grep` or `awk` to extract the date portion from each line of all log files combined. Then sort these dates and use `uniq` to filter out duplicates before counting them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir logs\necho -e \"2023-10-01 12:00:01 First log message\\n2023-10-01 13:30:22 Another message\\n2023-10-02 09:15:45 Morning update\" > logs/log1.log\necho -e \"2023-10-02 11:05:33 Second day entry\\n2023-10-03 18:45:11 Evening news\\n2023-10-03 21:21:00 Late night info\" > logs/log2.log\necho -e \"2023-10-01 08:55:12 Early bird note\\n2023-10-04 20:00:00 End of day review\" > logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all \".log\" files located within the \"/var/logs\" directory and its subdirectories.",
        "explanation": "To solve this problem, you should use a combination of `find`, `grep`, and `wc` commands. First, use the `find` command to locate all \".log\" files within the specified directory. Then, use `grep` to search for lines containing the word \"error\". Finally, count those lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Find all .log files and count lines containing 'error'\nfind /var/logs -type f -name \"*.log\" -exec grep -i \"error\" {} + | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create a sample directory structure with .log files\nmkdir -p /var/logs/{app1,app2}\necho -e \"This is an info\\nThis is an error\\nAnother error line\" > /var/logs/app1/system.log\necho -e \"No errors here\\nYet another error\\nError again\" > /var/logs/app2/application.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Find all .log files and count lines containing 'error'\nfind /var/logs -type f -name \"*.log\" -exec grep -i \"error\" {} + | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a file named `server_logs.txt` which contains logs from multiple servers with entries formatted as \"Timestamp - ServerID - ErrorCode\". Count how many unique `ErrorCode` entries are present in the file.",
        "explanation": "To solve this problem, you will need to extract the `ErrorCode` part of each log entry from the `server_logs.txt` file. You can use tools like `awk` or `cut` to isolate the error codes. Once you've extracted them, you can use utilities such as `sort`, `uniq`, or other text processing commands to find and count the number of unique error codes.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract and count unique error codes from server_logs.txt\n\n# Extract ErrorCodes using awk (assuming they are the third field)\nawk '{print $NF}' ~/server_logs.txt | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample server_logs.txt file with some log entries\ncat <<EOL > ~/server_logs.txt\n2023-10-01 12:00:00 - Server1 - E404\n2023-10-01 12:05:00 - Server2 - E500\n2023-10-01 12:10:00 - Server1 - E404\n2023-10-01 12:15:00 - Server3 - E503\n2023-10-01 12:20:00 - Server4 - E503\n2023-10-01 12:25:00 - Server2 - E500\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract and count unique error codes from server_logs.txt\n\n# Extract ErrorCodes using awk (assuming they are the third field)\nawk '{print $NF}' ~/server_logs.txt | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing multiple log files with the extension \".log\". Each log file contains timestamped entries, and you need to count the total number of unique IP addresses that have accessed the system across all log files. Ensure that each IP address is counted only once, even if it appears in multiple files or multiple times within the same file.",
        "explanation": "To solve this problem, you need to read through each log file in the \"logs\" directory, extract all IP addresses, and then determine how many unique IP addresses exist. A good approach is to use tools like `grep` to search for IP address patterns and `sort` combined with `uniq` to filter out duplicates. The final step is to count these unique entries using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '([0-9]{1,3}\\.){3}[0-9]{1,3}' logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p logs\necho \"2023-10-01 12:00:00 192.168.1.1 Accessed /index.html\" > logs/access1.log\necho \"2023-10-01 12:05:00 192.168.1.2 Accessed /about.html\" >> logs/access1.log\necho \"2023-10-01 12:10:00 192.168.1.1 Accessed /contact.html\" >> logs/access1.log\necho \"2023-10-02 13:00:00 192.168.2.3 Accessed /index.html\" > logs/access2.log\necho \"2023-10-02 13:05:00 192.168.2.4 Accessed /about.html\" >> logs/access2.log\necho \"2023-10-02 13:10:00 192.168.2.3 Accessed /contact.html\" >> logs/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '([0-9]{1,3}\\.){3}[0-9]{1,3}' logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in your home directory, excluding any lines that contain the word \"error\".",
        "explanation": "To solve this problem, you need to list all `.txt` files in your home directory and use a combination of `grep` and `wc` commands. First, use `grep` to exclude lines containing \"error\", then count the remaining lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use grep to filter out lines containing 'error' and wc to count remaining lines.\ngrep -v 'error' ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample .txt files with some content for testing.\necho -e \"This is a test.\\nNo errors here.\" > ~/file1.txt\necho -e \"Another line.\\nError: something went wrong.\" > ~/file2.txt\necho -e \"Everything is fine.\\nAll good.\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use grep to filter out lines containing 'error' and wc to count remaining lines.\ngrep -v 'error' ~/file*.txt | wc -l"
        }
    },
    {
        "description": "Count how many files in your home directory have been modified in the last 7 days and contain the word \"error\" in their content.",
        "explanation": "To solve this problem, you need to use several Linux utilities. First, find the files that were modified within the last 7 days using `find` with the `-mtime` option. Then filter these files by checking if they contain the word \"error\" using `grep`. Finally, count these files using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 -exec grep -l \"error\" {} \\; | wc -l\n```",
        "create": {
            "init": "# No initialization is required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 -exec grep -l \"error\" {} \\; | wc -l"
        }
    },
    {
        "description": "In your home directory, you need to count the number of files that have been modified in the last 7 days and whose file size is greater than 500KB. Please provide the count as the final answer.",
        "explanation": "To solve this problem, you can use the `find` command with appropriate options to filter files based on their modification time and size. The `-mtime` option allows you to specify files modified within a certain number of days, while `-size` helps filter based on file size. Once filtered, use `wc -l` to count these files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Using find command to filter required files and counting them.\nfind ~ -type f -mtime -7 -size +500k | wc -l\n```",
        "create": {
            "init": "# Creating example files in the home directory for testing purposes\ntouch ~/file1.txt\ntouch ~/file2.txt\ntouch ~/file3.txt\n\n# Modifying timestamps of some files to simulate last 7 days modification\ntouch -d '5 days ago' ~/file1.txt\ntouch -d '10 days ago' ~/file2.txt\n\n# Adding content to make file sizes different\ndd if=/dev/zero of=~/file1.txt bs=1024 count=600 # 600KB\ndd if=/dev/zero of=~/file2.txt bs=1024 count=200 # 200KB\ndd if=/dev/zero of=~/file3.txt bs=1024 count=800 # 800KB"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Using find command to filter required files and counting them.\nfind ~ -type f -mtime -7 -size +500k | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" containing multiple log files. Each log file is in the format \"log_YYYYMMDD.txt\", where YYYYMMDD represents the date the log was created. Count how many unique IP addresses accessed the system in the month of January 2023. Assume that each line in a log file contains an IP address followed by other information. You should only consider logs from January 2023.",
        "explanation": "To solve this problem, you need to filter out files with names containing \"202301\" as they represent logs from January 2023. Extract IP addresses from these files, store them in a list or set, and count the number of unique IP addresses. You can use tools like `grep`, `awk`, or `sed` to extract IPs and `sort` with `uniq` to determine uniqueness.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -hEo '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' log_files/log_202301*.txt | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p log_files\necho -e \"192.168.1.1 some other info\\n192.168.1.2 more info\" > log_files/log_20230101.txt\necho -e \"192.168.1.2 some other info\\n192.168.1.3 more info\" > log_files/log_20230102.txt\necho -e \"192.168.1.4 some other info\\n192.168.1.5 more info\" > log_files/log_20230201.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -hEo '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' log_files/log_202301*.txt | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count how many files in your home directory have been modified in the last 7 days and are larger than 1MB.",
        "explanation": "To solve this problem, you can use the `find` command to filter files based on their modification time and size. The `-mtime` option allows you to specify the number of days since a file was last modified, and the `-size` option helps to filter files based on their size. Combine these options with appropriate conditions to count the files that meet both criteria.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution using find command\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution using find command\nfind ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "In your home directory, find all files with a \".txt\" extension and count the number of lines in each file. Then, filter out files containing less than 10 lines and sum up the line counts of the remaining files. You should provide the total line count as your answer.",
        "explanation": "To solve this problem, you need to interact with the shell multiple times. First, list all \".txt\" files in your home directory using `find`. Then, use `wc -l` to count the lines in each file. Next, filter out files having fewer than 10 lines using `awk` or similar tools. Finally, use `awk` or `paste` with `bc` to sum up the line counts of the filtered files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files and count lines; filter and sum up those with >= 10 lines.\nfind ~ -maxdepth 1 -type f -name \"*.txt\" | while read file; do wc -l \"$file\"; done | awk '$1 >= 10 {sum += $1} END {print sum}'\n```",
        "create": {
            "init": "# Create some sample .txt files in the student's home directory for testing\necho -e \"Line1\\nLine2\\nLine3\\nLine4\\nLine5\\nLine6\\nLine7\\nLine8\\nLine9\" > ~/file1.txt\necho -e \"Line1\\nLine2\\nLine3\" > ~/file2.txt\necho -e \"Line1\\nLine2\\nLine3\\nLine4\\nLine5\" > ~/file3.txt\necho -e \"This is a test file with more than ten lines.\\nIt contains multiple lines.\\nLet's see how it works.\\nAre you ready?\\nHere we go!\\nAnother line.\\nKeep going!\\nAlmost there.\\nJust one more.\\nFinally!\" > ~/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files and count lines; filter and sum up those with >= 10 lines.\nfind ~ -maxdepth 1 -type f -name \"*.txt\" | while read file; do wc -l \"$file\"; done | awk '$1 >= 10 {sum += $1} END {print sum}'"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files located in the `/home/student/documents` directory, including subdirectories. You should exclude empty lines from the count.",
        "explanation": "To solve this problem, you need to search for all `.txt` files within the specified directory and its subdirectories using a command like `find`. Then, for each file found, use a tool such as `grep` or `awk` to filter out empty lines and count the remaining ones. Finally, sum up these counts to get the total number of non-empty lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -name \"*.txt\" | xargs grep -v '^$' | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents/subdir1\nmkdir -p /home/student/documents/subdir2\n\necho -e \"Hello World\\nThis is a test file.\\n\\nAnother line.\" > /home/student/documents/file1.txt\necho -e \"\\nLine 1\\nLine 2\" > /home/student/documents/subdir1/file2.txt\necho -e \"Just one line\" > /home/student/documents/subdir2/file3.txt\necho -e \"\\n\\n\\n\" > /home/student/documents/subdir2/empty_lines.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -name \"*.txt\" | xargs grep -v '^$' | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and contain the word \"TODO\" within their contents.",
        "explanation": "To solve this problem, you will need to first identify files that have been modified within the last 7 days. You can use the `find` command with appropriate options to filter these files. Then, you need to search for the word \"TODO\" within those files using `grep`. Finally, count how many such files exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 | xargs grep -l \"TODO\" | wc -l\n```",
        "create": {
            "init": "# Create some sample files in student's home directory\nmkdir -p ~/experiment_files\necho \"This is a TODO item.\" > ~/experiment_files/file1.txt\necho \"Nothing here.\" > ~/experiment_files/file2.txt\necho \"Another TODO item.\" > ~/experiment_files/file3.txt\n\n# Modify file1.txt and file3.txt to simulate recent changes\ntouch -m -d \"$(date -d '-3 days')\" ~/experiment_files/file1.txt\ntouch -m -d \"$(date -d '-8 days')\" ~/experiment_files/file2.txt\ntouch -m -d \"$(date)\" ~/experiment_files/file3.txt\n\n# Move these sample files to home directory for students' access.\nmv ~/experiment_files/* ~/\nrm -r ~/experiment_files"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 | xargs grep -l \"TODO\" | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all \".log\" files located within the \"/var/logs\" directory and its subdirectories. Assume each file is no larger than 50MB.",
        "explanation": "To solve this problem, you need to recursively search through all subdirectories in \"/var/logs\" for files with a \".log\" extension and count the occurrences of the word \"error\". You can use utilities like `find`, `grep`, and `wc` to achieve this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files under /var/logs, search for 'error', then count lines\nfind /var/logs -type f -name \"*.log\" | xargs grep -i \"error\" | wc -l\n```",
        "create": {
            "init": "# Create /var/logs directory and some sample log files\nmkdir -p /var/logs/subdir1\nmkdir -p /var/logs/subdir2\n\n# Create sample log files with random content including some lines with \"error\"\necho -e \"This is a test log\\nError occurred here\\nAnother line\\nError again\" > /var/logs/test1.log\necho -e \"No error here\\nYet another line\\nRandom error message\" > /var/logs/test2.log\necho -e \"Subdirectory log file\\nError found\\nNo more errors\" > /var/logs/subdir1/subtest1.log\necho -e \"All good here\\nJust an error line\\nMore text without error\" > /var/logs/subdir2/subtest2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files under /var/logs, search for 'error', then count lines\nfind /var/logs -type f -name \"*.log\" | xargs grep -i \"error\" | wc -l"
        }
    },
    {
        "description": "Find and count the number of files within your home directory that have been modified in the last 7 days and whose names contain the word \"report\". The count should only include regular files, excluding directories or other types of files.",
        "explanation": "To solve this problem, you can use the `find` command with options to filter by modification time and filename pattern. The `-type f` option will ensure only regular files are included. Use the `-mtime` option to find files modified within a specific number of days, along with the `-name` option to search for filenames containing \"report\".\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script: Count the number of relevant files using find command\nfind ~ -type f -name '*report*' -mtime -7 | wc -l\n```",
        "create": {
            "init": "# Create sample files in the home directory for testing\nmkdir -p ~/test_reports/\ntouch ~/test_reports/report1.txt\ntouch ~/test_reports/report2.txt\ntouch ~/test_reports/old_report3.txt\n\n# Modify file timestamps to simulate recent changes\ntouch -m -d '2 days ago' ~/test_reports/report1.txt\ntouch -m -d '8 days ago' ~/test_reports/old_report3.txt\n\n# Create some non-report related files\ntouch ~/test_reports/random_file.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script: Count the number of relevant files using find command\nfind ~ -type f -name '*report*' -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all text files located within the directory `/home/student/documents`, excluding empty lines and lines that contain only whitespace characters. You must use a combination of bash utilities to achieve this.",
        "explanation": "To solve this problem, you need to navigate through the specified directory and list all text files. Then, use utilities like `grep` to filter out empty lines and lines that only contain whitespace. Finally, use `wc -l` to count the remaining lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -v '^\\s*$' /home/student/documents/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho \"This is a line.\" > /home/student/documents/file1.txt\necho \"\" >> /home/student/documents/file1.txt\necho \"   \" >> /home/student/documents/file1.txt\necho \"Another line here.\" >> /home/student/documents/file1.txt\n\necho \"Text file with content.\" > /home/student/documents/file2.txt\necho \"\" >> /home/student/documents/file2.txt\necho \"Yet another meaningful line.\" >> /home/student/documents/file2.txt\n\ntouch /home/student/documents/empty_file.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -v '^\\s*$' /home/student/documents/*.txt | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains timestamped entries, and your task is to determine which log file has the most recent entry. You should output the name of this file without its path or extension.",
        "explanation": "To solve this problem, you need to iterate over all the \".log\" files in the \"logs\" directory, extract the last timestamp from each file, compare these timestamps across files, and identify which file contains the most recent timestamp. You can use utilities like `grep`, `sort`, and `awk` to process and compare timestamps.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all log files in the logs directory.\ncd ~/logs\n\n# Find out which log file has the most recent timestamp.\nrecent_file=$(for logfile in *.log; do \n    last_entry=$(tail -n1 \"$logfile\")\n    echo \"$last_entry $logfile\"\ndone | sort | tail -n1 | awk '{print $NF}' | sed 's/\\.log//')\n\n# Output only the name of the most recent log file without path or extension.\necho \"$recent_file\"\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 10:00:00 Log entry 1\\n2023-01-02 11:00:00 Log entry 2\" > ~/logs/file1.log\necho -e \"2023-01-03 09:30:00 Log entry A\\n2023-01-03 10:30:00 Log entry B\" > ~/logs/file2.log\necho -e \"2023-01-02 08:15:00 Log start\\n2023-01-04 12:45:00 Log end\" > ~/logs/file3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "# List all log files in the logs directory.\ncd ~/logs\n\n# Find out which log file has the most recent timestamp.\nrecent_file=$(for logfile in *.log; do \n    last_entry=$(tail -n1 \"$logfile\")\n    echo \"$last_entry $logfile\"\ndone | sort | tail -n1 | awk '{print $NF}' | sed 's/\\.log//')\n\n# Output only the name of the most recent log file without path or extension.\necho \"$recent_file\""
        }
    },
    {
        "description": "Determine the total disk usage of all text files (*.txt) located within a specific directory named \"documents\" and its subdirectories, excluding hidden files. You should report the size in human-readable format (e.g., KB, MB).",
        "explanation": "To solve this problem, you can use the `find` command to locate all non-hidden text files in the \"documents\" directory and its subdirectories. The `du` command will help you calculate their sizes, and using options like `-h` will display these sizes in a human-readable format. Remember that hidden files start with a dot (.), so you need to exclude them using appropriate flags or conditions.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/documents -type f -name \"*.txt\" ! -path '*/.*' -exec du -ch {} + | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p ~/documents/subdir1 ~/documents/subdir2\necho \"Sample text file 1\" > ~/documents/file1.txt\necho \"Sample text file 2\" > ~/documents/subdir1/file2.txt\necho \"Sample text file 3\" > ~/documents/subdir2/file3.txt\necho \"Hidden file content\" > ~/documents/.hiddenfile.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "find ~/documents -type f -name \"*.txt\" ! -path '*/.*' -exec du -ch {} + | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files. Each file records system events with each line starting with a timestamp in the format `[YYYY-MM-DD HH:MM:SS]`. Count how many lines have a timestamp that falls within the date range from `2023-01-01` to `2023-12-31`, inclusive, and output this number.",
        "explanation": "To solve the problem, you need to iterate over each file in the \"logs\" directory and read each line. Extract the date portion of the timestamp and check if it falls within the specified range. If it does, count that line. You can use tools like `grep` or `awk` for pattern matching and processing.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h -o '^\\[2023-[0][1]-.*\\|^\\[[2][0][2][3]-' ~/logs/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat > ~/logs/log1.txt <<EOL\n[2023-01-10 10:00:00] Event A occurred\n[2024-01-10 11:00:00] Event B occurred\n[2023-06-15 09:30:45] Event C occurred\nEOL\n\ncat > ~/logs/log2.txt <<EOL\n[2022-12-31 08:22:33] Event D occurred\n[2023-07-20 14:45:55] Event E occurred\n[2023-12-31 23:59:59] Event F occurred\nEOL\n\ncat > ~/logs/log3.txt <<EOL\n[2025-01-01 00:00:01] Event G occurred\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h -o '^\\[2023-[0][1]-.*\\|^\\[[2][0][2][3]-' ~/logs/*.txt | wc -l"
        }
    },
    {
        "description": "Count the total number of words across all `.txt` files in your home directory that contain the word \"Linux\" at least once.",
        "explanation": "To solve this problem, you need to search through each `.txt` file in your home directory, identify those containing the word \"Linux\", and count all the words in those specific files. You can use utilities like `grep` to find relevant files and `wc` to count words.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all .txt files containing the word 'Linux' and count their words.\ngrep -l 'Linux' ~/*.txt | xargs wc -w | tail -n 1 | awk '{print $1}'\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create some sample .txt files in the home directory\necho \"Linux operating system is popular.\" > ~/file1.txt\necho \"This is a text file without any keyword.\" > ~/file2.txt\necho \"Learning Linux is fun and educational.\" > ~/file3.txt\necho \"Another random text file.\" > ~/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all .txt files containing the word 'Linux' and count their words.\ngrep -l 'Linux' ~/*.txt | xargs wc -w | tail -n 1 | awk '{print $1}'"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines in all `.txt` files located in your home directory and its subdirectories that contain the word \"Linux\". Ignore case sensitivity when searching for the word.",
        "explanation": "To solve this problem, you need to search through all `.txt` files in your home directory and its subdirectories. You can use the `find` command to locate these files and then use `grep` to filter lines containing the word \"Linux\", ignoring case sensitivity. Finally, count these lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files and count lines containing 'Linux' (case-insensitive)\nfind ~ -type f -name \"*.txt\" | xargs grep -i 'Linux' | wc -l\n```",
        "create": {
            "init": "# Create a few sample text files in the home directory and subdirectories\nmkdir -p ~/testdir/subdir\necho -e \"This is a Linux test file.\\nAnother line.\" > ~/testdir/file1.txt\necho -e \"This file talks about LINUX systems.\\nAnd more content.\" > ~/testdir/file2.txt\necho -e \"No related content here.\" > ~/file3.txt\necho -e \"Learning linux is fun.\\nAnother Linux mention.\" > ~/testdir/subdir/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files and count lines containing 'Linux' (case-insensitive)\nfind ~ -type f -name \"*.txt\" | xargs grep -i 'Linux' | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains various lines of text, some of which are error messages prefixed by the string \"ERROR:\". Count the total number of error messages across all log files within this directory.",
        "explanation": "To solve this problem, you need to iterate through each file in the \"logs\" directory that has a \".log\" extension and count lines starting with \"ERROR:\". You can use tools like `grep` to filter these lines and `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"^ERROR:\" ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: System started\\nERROR: Failed to load module\\nINFO: Operation successful\" > ~/logs/system1.log\necho -e \"ERROR: Network timeout\\nINFO: Connection established\\nERROR: Disk full\" > ~/logs/system2.log\necho -e \"INFO: User login\\nERROR: Access denied\\nINFO: Process completed\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"^ERROR:\" ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all \".txt\" files located in your home directory and its subdirectories that contain the word \"Linux\". Ignore case sensitivity.",
        "explanation": "To solve this problem, you can use the `grep` command with options to perform a case-insensitive search and count matching lines across multiple files. You might need to use `find` to locate all \".txt\" files recursively and then pipe them into `xargs` to process each file using `grep`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use find to locate all .txt files, then grep through them for case-insensitive matches of \"Linux\"\nfind ~ -type f -name \"*.txt\" | xargs grep -i \"Linux\" | wc -l\n```",
        "create": {
            "init": "# Create some example .txt files with various content in the home directory and subdirectories\nmkdir -p ~/testdir/subdir\necho -e \"This is a Linux tutorial.\\nLearning Linux is fun!\" > ~/testdir/linux_tutorial.txt\necho -e \"Operating systems include Windows, MacOS, and Linux.\\nLinux distributions are diverse.\" > ~/testdir/subdir/os_info.txt\necho -e \"UNIX is different from Linux.\\nHowever, Linux has UNIX-like features.\" > ~/unix_vs_linux.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use find to locate all .txt files, then grep through them for case-insensitive matches of \"Linux\"\nfind ~ -type f -name \"*.txt\" | xargs grep -i \"Linux\" | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and have a \".txt\" extension.",
        "explanation": "To solve this problem, you need to list all the files in your home directory, filter those with a \".txt\" extension, and then check their last modification date. You can use the `find` command with appropriate options to achieve this task. The `-mtime` option helps you filter files modified within a certain number of days.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -name \"*.txt\" -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -name \"*.txt\" -mtime -7 | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Each log file contains timestamps in the format \"YYYY-MM-DD HH:MM:SS\" and various messages. Determine how many distinct days are represented across all log files combined.",
        "explanation": "To solve this problem, you need to extract dates from each timestamp found in the log files, then count how many unique dates appear across all files. You can use tools such as `grep`, `awk`, and `sort` to process and filter the data.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 10:00:00 Log started\\n2023-01-02 11:00:00 Action performed\\n2023-01-02 12:30:45 Another action\" > ~/logs/log1.log\necho -e \"2023-01-03 08:15:20 Initializing\\n2023-01-03 09:45:30 Running task\\n2023-01-04 14:20:00 Finished task\" > ~/logs/log2.log\necho -e \"2023-01-05 16:00:00 Log started\\n2023-01-06 17:05:50 Error detected\\n2023-01-06 18:25:10 Recovery action\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of unique IP addresses found in all `.log` files located in the `/var/logs` directory, and print the result.",
        "explanation": "To solve this problem, you need to extract IP addresses from each `.log` file in the `/var/logs` directory. You can achieve this by using tools like `grep` with a regex pattern to find IP addresses and then use `sort` and `uniq` to count only unique ones.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use grep with regex to find all IP address patterns, sort them, and get unique counts.\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' /var/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create the /var/logs directory if it doesn't exist\nmkdir -p /var/logs\n\n# Create sample log files with random IP addresses\necho \"192.168.1.1 - Access successful\" >> /var/logs/access.log\necho \"192.168.1.2 - Access denied\" >> /var/logs/access.log\necho \"10.0.0.1 - Connection timeout\" >> /var/logs/error.log\necho \"192.168.1.1 - Access successful\" >> /var/logs/error.log\necho \"172.16.0.5 - Connection reset\" >> /var/logs/system.log\n\n# Add more entries to ensure complexity and uniqueness testing\nfor i in {3..10}; do echo \"192.168.$i.$((RANDOM%255)) - Random message\" >> /var/logs/random$i.log; done"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use grep with regex to find all IP address patterns, sort them, and get unique counts.\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' /var/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that were modified in the last 7 days and have a \".txt\" extension.",
        "explanation": "To solve this problem, you can use the `find` command. You will need to specify your home directory, use the `-type f` option to ensure you are counting files only, and apply the `-mtime -7` option to filter files modified in the last 7 days. Additionally, use the `-name \"*.txt\"` pattern to match only files with a \".txt\" extension. Finally, pipe the output of `find` into `wc -l` to count the number of matched files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files in home directory modified in last 7 days and count them.\nfind ~ -type f -mtime -7 -name \"*.txt\" | wc -l\n```",
        "create": {
            "init": "# Create sample .txt files with varying modification dates in the student's home directory for testing.\ntouch ~/file1.txt\ntouch ~/file2.txt\ntouch ~/file3.txt\n\n# Modify timestamps so some are within last 7 days and others are not\ntouch -d \"2 days ago\" ~/file1.txt\ntouch -d \"8 days ago\" ~/file2.txt\ntouch -d \"4 days ago\" ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files in home directory modified in last 7 days and count them.\nfind ~ -type f -mtime -7 -name \"*.txt\" | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with extension \".log\". Each log file contains lines in the format: \"YYYY-MM-DD HH:MM:SS - LogLevel - Message\". Count how many times the log level \"ERROR\" appears across all the log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and use a combination of commands to search for occurrences of the word \"ERROR\" in all files ending with \".log\". You can use `grep` to search for patterns within files. The `-r` option allows recursive searching through directories, and `-c` counts matches per file. Summing up these counts will give you the total number of \"ERROR\" occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep -r 'ERROR' *.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 - INFO - This is an info message\\n2023-10-01 12:05:00 - ERROR - An error occurred\\n2023-10-01 12:10:00 - WARNING - A warning sign\\n2023-10-01 12:15:00 - ERROR - Another error occurred\" > ~/logs/log1.log\necho -e \"2023-10-02 09:00:00 - INFO - Starting process\\n2023-10-02 09:05:00 - ERROR - Failed to start process\\n2023-10-02 09:10:00 - INFO - Process started successfully\" > ~/logs/log2.log\necho -e \"2023-10-03 14:30:00 - ERROR - Error initializing module\\n2023-10-03 14:35:00 - DEBUG - Debugging information here\\n2023-10-03 14:40:00 - ERROR - Fatal error encountered\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep -r 'ERROR' *.log | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all text files in your home directory that contain the word \"error\", case-insensitively.",
        "explanation": "To solve this problem, you need to explore all text files within your home directory and count occurrences of the word \"error\" regardless of its case. You may use utilities like `grep` with appropriate options for case-insensitive searches and line counts.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use grep to search for 'error' case-insensitively and count lines across all text files.\ngrep -i 'error' ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Create some sample text files with various content in the home directory.\necho -e \"Error in line one\\nThis is fine\\nERROR occurred again\" > ~/file1.txt\necho -e \"No issues here\\nSomething went wrong\\nAn error is possible\" > ~/file2.txt\necho -e \"Check this out\\nEverything OK\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use grep to search for 'error' case-insensitively and count lines across all text files.\ngrep -i 'error' ~/file*.txt | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden directory called `.myconfig` containing several configuration files with a `.conf` extension. Your task is to count how many unique lines exist across all `.conf` files within this directory, ignoring case and leading/trailing whitespace.",
        "explanation": "To solve this problem, you need to:\n1. Locate all the `.conf` files in the `.myconfig` hidden directory.\n2. Read through the contents of these files.\n3. Normalize each line by converting it to lowercase and trimming any leading or trailing whitespace.\n4. Store the normalized lines in a set to automatically filter duplicates.\n5. Count the number of unique entries in this set.\n\nYou may find utilities like `find`, `cat`, `tr`, `sed`, and `awk` useful for processing file contents and manipulating text.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/'.myconfig' -type f -name '*.conf' -exec cat {} + | \\\ntr '[:upper:]' '[:lower:]' | sed 's/^[ \\t]*//;s/[ \\t]*$//' | \\\nsort -u | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/'.myconfig'\necho \" Line One \" > ~/.myconfig/file1.conf\necho \"line two\" >> ~/.myconfig/file1.conf\necho \"line three\" >> ~/.myconfig/file1.conf\n\necho \"LINE ONE\" > ~/.myconfig/file2.conf\necho \"line Two  \" >> ~/.myconfig/file2.conf\necho \"Line Four\" >> ~/.myconfig/file2.conf\n\n# Additional configuration files can be added here if needed"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/'.myconfig' -type f -name '*.conf' -exec cat {} + | \\\ntr '[:upper:]' '[:lower:]' | sed 's/^[ \\t]*//;s/[ \\t]*$//' | \\\nsort -u | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"log_files\" containing several log files with a \".log\" extension. Your task is to determine the total number of unique IP addresses that have accessed the server, as logged in these files. Each line in a log file represents one access and starts with an IP address followed by a space. Count the total number of unique IP addresses across all \".log\" files within the \"log_files\" directory.",
        "explanation": "To solve this problem, you need to:\n1. List all \".log\" files in the \"log_files\" directory.\n2. Extract the IP addresses from each file.\n3. Use a tool like `sort` or `awk` combined with `uniq` to count only distinct IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat log_files/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p log_files\necho -e \"192.168.1.1 UserX\\n10.0.0.2 UserY\\n192.168.1.1 UserZ\" > log_files/access1.log\necho -e \"10.0.0.2 UserA\\n172.16.0.3 UserB\\n192.168.1.4 UserC\" > log_files/access2.log\necho -e \"192.168.1.5 UserD\\n172.16.0.3 UserE\\n10.0.0.2 UserF\" > log_files/access3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat log_files/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory called \"logs\" in your home directory that contains multiple log files with the extension \".log\". Each log file records different types of events, and each event is logged as a single line starting with a timestamp followed by the event type and message. Your task is to identify the most frequently occurring event type across all log files in the \"logs\" directory and determine how many times this event type occurs. Report the event type and its frequency as your answer.",
        "explanation": "To solve this problem, you need to first list all the log files within the \"logs\" directory. Then, for each file, extract all lines that contain event types. You should then aggregate these events across all files and count their occurrences. Finally, determine which event type occurs most frequently and report its name along with its frequency.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the logs directory\ncd ~/logs\n\n# List all .log files and extract event types with their counts\ngrep -hEo 'INFO|ERROR|WARN' *.log | sort | uniq -c | sort -nr | head -n1 | awk '{print $2, $1}'\n```",
        "create": {
            "init": "# Create logs directory\nmkdir -p ~/logs\n\n# Create sample log files\necho -e \"2023-10-01 12:00:00 INFO User login\\n2023-10-01 12:05:00 ERROR Failed login\\n2023-10-01 12:10:00 WARN Password attempt\\n2023-10-01 12:15:00 INFO User logout\" > ~/logs/log1.log\necho -e \"2023-10-02 09:00:00 INFO Scheduled job start\\n2023-10-02 09:05:00 ERROR Disk full\\n2023-10-02 09:07:00 INFO Scheduled job end\\n2023-10-02 09:15:00 WARN Low memory\" > ~/logs/log2.log\necho -e \"2023-10-03 14:20:00 ERROR Network failure\\n2023-10-03 14:25:00 INFO System rebooted\\n2023-10-03 14:30:00 WARN CPU high usage\\n2023-10-03 14:35:00 ERROR Out of memory\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "# Navigate to the logs directory\ncd ~/logs\n\n# List all .log files and extract event types with their counts\ngrep -hEo 'INFO|ERROR|WARN' *.log | sort | uniq -c | sort -nr | head -n1 | awk '{print $2, $1}'"
        }
    },
    {
        "description": "In your home directory, there are several text files with random content. Your task is to find the total number of unique words across all these text files. You should ignore case sensitivity (i.e., 'Word' and 'word' should be considered the same) and exclude any punctuation from the words.",
        "explanation": "To solve this problem, you need to read each file in your home directory, process the text to normalize case and remove punctuation, split the text into words, and count the unique words across all files. You can use utilities like `find` to locate files, `tr` or `sed` to remove punctuation, `awk` or `grep` for word extraction, and sort/uniq for counting unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/text_files -type f -exec cat {} + | tr '[:upper:]' '[:lower:]' | tr -d '[:punct:]' | tr ' ' '\\n' | grep -v '^$' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/text_files\necho \"Hello world! This is an example.\" > ~/text_files/file1.txt\necho \"Another example; with words: hello World.\" > ~/text_files/file2.txt\necho \"The quick brown fox jumps over the lazy dog.\" > ~/text_files/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/text_files -type f -exec cat {} + | tr '[:upper:]' '[:lower:]' | tr -d '[:punct:]' | tr ' ' '\\n' | grep -v '^$' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In the current directory, there are multiple text files containing log entries with various timestamps. Your task is to find out how many log entries occurred in the last 24 hours from the current system time. Assume all timestamps in the logs are in the format \"YYYY-MM-DD HH:MM:SS\". You need to count only unique log entries by their timestamp.",
        "explanation": "To solve this problem, you will need to:\n1. Identify and extract timestamps from each log file.\n2. Convert these timestamps into a comparable format using the `date` command.\n3. Compare each timestamp against the current system time minus 24 hours.\n4. Use a method to ensure that each timestamp is counted only once, even if it appears in multiple files or multiple times within a file.\n\nYou may find utilities such as `awk`, `grep`, `sort`, `uniq`, and `date` helpful for this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Get current date minus 24 hours as a reference point\nreference_time=$(date --date=\"yesterday\" +\"%Y-%m-%d %H:%M:%S\")\n\n# Extract unique timestamps from all logs and filter those within last 24 hours\ncat *.txt | awk '{print $1, $2}' | sort | uniq | while read timestamp; do \n    if [[ \"$timestamp\" > \"$reference_time\" ]]; then\n        echo \"$timestamp\"\n    fi\ndone | wc -l\n```",
        "create": {
            "init": "# Create sample log files with timestamps\necho -e \"2023-10-10 12:00:00 Log entry one\\n2023-10-11 13:30:00 Log entry two\\n2023-10-12 15:45:00 Log entry three\" > log1.txt\necho -e \"2023-10-11 22:00:00 Log entry four\\n2023-10-12 14:30:00 Log entry five\\n2023-10-12 16:45:00 Log entry six\" > log2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Get current date minus 24 hours as a reference point\nreference_time=$(date --date=\"yesterday\" +\"%Y-%m-%d %H:%M:%S\")\n\n# Extract unique timestamps from all logs and filter those within last 24 hours\ncat *.txt | awk '{print $1, $2}' | sort | uniq | while read timestamp; do \n    if [[ \"$timestamp\" > \"$reference_time\" ]]; then\n        echo \"$timestamp\"\n    fi\ndone | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with names starting with \"access_log\". Each line in these files contains a timestamp and an HTTP status code. Count how many requests resulted in a 404 error across all the files, and provide the total count.",
        "explanation": "To solve this problem, you should navigate to the \"logs\" directory and use tools like `grep` to filter out lines containing the 404 status code from each file. You can then use `wc -l` to count these lines, summing up the counts for all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '404' ~/logs/access_log*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01T12:00:00 200\\n2023-10-01T12:05:00 404\\n2023-10-01T12:10:00 404\" > ~/logs/access_log1.txt\necho -e \"2023-09-30T11:00:00 200\\n2023-09-30T11:05:00 404\" > ~/logs/access_log2.txt\necho -e \"2023-09-29T10:15:00 500\\n2023-09-29T10:20:00 200\\n2023-09-29T10:25:00 404\" > ~/logs/access_log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '404' ~/logs/access_log*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"ERROR\" in all \".log\" files within the \"/var/logs/\" directory. Assume that some of these files could be compressed with gzip, and you need to handle both compressed and uncompressed log files.",
        "explanation": "To solve this problem, you should first list all \".log\" files in the \"/var/logs/\" directory, including those with a \".gz\" extension. Use utilities like `find` to discover files and `zgrep` or `grep` to count occurrences of \"ERROR\". You will need to differentiate handling between regular and gzipped log files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log and .log.gz files in /var/logs/\nfiles=$(find /var/logs/ -type f \\( -name \"*.log\" -o -name \"*.log.gz\" \\))\n\n# Initialize a counter variable\nerror_count=0\n\n# Iterate over each file found\nfor file in $files; do\n    if [[ $file == *.gz ]]; then\n        # Use zgrep for gzipped files\n        error_count=$((error_count + $(zgrep -c 'ERROR' \"$file\")))\n    else\n        # Use grep for regular log files\n        error_count=$((error_count + $(grep -c 'ERROR' \"$file\")))\n    fi\ndone\n\n# Output the total count of ERROR lines across all logs.\necho $error_count\n```",
        "create": {
            "init": "mkdir -p /var/logs/\necho -e \"INFO: System started\\nERROR: Disk not found\\nINFO: Network initialized\" > /var/logs/system.log\necho -e \"WARNING: Low memory\\nERROR: Out of memory\\nINFO: Memory check passed\" > /var/logs/memory.log\ngzip -c /var/logs/system.log > /var/logs/system.log.gz\ngzip -c /var/logs/memory.log > /var/logs/memory.log.gz"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log and .log.gz files in /var/logs/\nfiles=$(find /var/logs/ -type f \\( -name \"*.log\" -o -name \"*.log.gz\" \\))\n\n# Initialize a counter variable\nerror_count=0\n\n# Iterate over each file found\nfor file in $files; do\n    if [[ $file == *.gz ]]; then\n        # Use zgrep for gzipped files\n        error_count=$((error_count + $(zgrep -c 'ERROR' \"$file\")))\n    else\n        # Use grep for regular log files\n        error_count=$((error_count + $(grep -c 'ERROR' \"$file\")))\n    fi\ndone\n\n# Output the total count of ERROR lines across all logs.\necho $error_count"
        }
    },
    {
        "description": "Identify and count all the unique IP addresses that have accessed the server, using log files stored in `/var/log/apache2`, and output the number of unique IP addresses. Assume the log files are named `access.log`.",
        "explanation": "To solve this problem, you need to extract all IP addresses from the `access.log` file using tools like `awk` or `grep`. Then, utilize commands such as `sort` and `uniq` to filter out duplicate IP addresses, allowing you to count only the unique ones.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract IPs, sort them and find unique ones, then count them.\nawk '{print $1}' /var/log/apache2/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample access.log with some dummy data\nmkdir -p /var/log/apache2\ncat << EOF > /var/log/apache2/access.log\n192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \"GET / HTTP/1.0\" 200 1043\n192.168.1.2 - - [10/Oct/2023:14:00:01 +0000] \"GET /about.html HTTP/1.0\" 200 2048\n192.168.1.3 - - [10/Oct/2023:14:05:12 +0000] \"POST /login HTTP/1.0\" 404 312\n192.168.1.1 - - [10/Oct/2023:15:20:36 +0000] \"GET /contact.html HTTP/1.0\" 200 1234\nEOF"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract IPs, sort them and find unique ones, then count them.\nawk '{print $1}' /var/log/apache2/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Find the total number of lines containing the word \"error\" in all `.log` files located in the `/var/logs` directory. You must ensure the search is case-insensitive.",
        "explanation": "To solve this problem, you need to use the `grep` command with its case-insensitive option `-i` to search for occurrences of \"error\" in each `.log` file within the `/var/logs` directory. You can combine this with `wc -l` to count the number of matching lines across all files. The command might look like `grep -i error /var/logs/*.log | wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i error /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs\necho -e \"This is a test log\\nError found\\nAnother line\\nno issues\" > /var/logs/test1.log\necho -e \"Everything is fine\\nERROR detected\\nJust an info\\nNo error here\" > /var/logs/test2.log\necho -e \"Warning: something happened\\nerror occurred again\\nall good\" > /var/logs/test3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i error /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all \".txt\" files in the \"/home/student/documents\" directory, but only include lines that contain the word \"Linux\". You must not use any temporary files during your process.",
        "explanation": "To solve this problem, you need to find all \".txt\" files in the specified directory using a command like `find`. Then, for each file found, use `grep` to filter lines containing the word \"Linux\". Finally, use `wc -l` to count these filtered lines and sum them up across all files. You can accomplish this with pipes and command substitutions.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -name \"*.txt\" | xargs grep 'Linux' | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho -e \"Linux is great\\nI love Linux\\nOperating Systems are fun\" > /home/student/documents/file1.txt\necho -e \"Hello World\\nLinux tutorial\\nBash scripting\" > /home/student/documents/file2.txt\necho -e \"Learn Linux\\nShell commands are powerful\" > /home/student/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -name \"*.txt\" | xargs grep 'Linux' | wc -l"
        }
    },
    {
        "description": "Find the total number of lines that contain the word \"error\" in all `.log` files located in the directory `/var/logs`, and output this number.",
        "explanation": "To solve the problem, you need to count lines containing the word \"error\" across multiple log files. You can use tools like `grep` to search for occurrences of \"error\" and then `wc -l` to count the lines. A combination of these commands using pipes will allow you to achieve the desired result.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count lines containing \"error\" in all .log files within /var/logs directory.\ngrep -i 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "# Create /var/logs directory if it doesn't exist\nmkdir -p /var/logs\n\n# Populate with sample log files\necho -e \"This is a test\\nThere has been an error\\nAll systems go\\nAnother error occurred\" > /var/logs/system.log\necho -e \"Starting up\\nError detected\\nShutdown complete\\nError found again\" > /var/logs/application.log\necho -e \"No issues here\\nJust running smoothly\\nOops, an error!\" > /var/logs/user.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count lines containing \"error\" in all .log files within /var/logs directory.\ngrep -i 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "You have been provided with a directory named \"logs\" in your home directory, which contains multiple log files with the extension \".log\". Each log file may contain error messages that include the word \"ERROR\" followed by a timestamp and an error message. Your task is to find the most recent error message across all log files and print only the timestamp of that error. Assume all timestamps are in the format YYYY-MM-DD HH:MM:SS.",
        "explanation": "To solve this problem, iterate through each \".log\" file in the \"logs\" directory and search for lines containing the word \"ERROR\". Extract the timestamp from each of these lines and keep track of the most recent one encountered. Once you've checked all lines in all files, output only the most recent timestamp found.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h \"ERROR\" ~/logs/*.log | awk '{print $2, $3}' | sort | tail -n1\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO 2023-10-01 12:00:00 Some info message\\nERROR 2023-10-01 12:10:00 First error\\nINFO 2023-10-01 12:20:00 Another info\\nERROR 2023-10-01 12:30:00 Second error\" > ~/logs/log1.log\necho -e \"INFO 2023-10-02 14:00:00 Some info message\\nERROR 2023-10-02 14:15:00 Third error\\nINFO 2023-10-02 14:25:00 Another info\\nERROR 2023-10-02 14:45:00 Fourth error\" > ~/logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "grep -h \"ERROR\" ~/logs/*.log | awk '{print $2, $3}' | sort | tail -n1"
        }
    },
    {
        "description": "You are tasked with finding the total number of bytes used by all text files (.txt) that contain the word \"Linux\" in their content, within a specific directory named \"data_files\". You should count only files directly in this directory (non-recursively).",
        "explanation": "To solve this problem, you need to use several bash utilities. First, use `grep` to search for files containing the word \"Linux\" and then use `wc -c` to count the bytes in those files. Finally, sum the results using `awk` or similar tools.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files containing the word 'Linux'\nmatching_files=$(grep -l 'Linux' data_files/*.txt)\n\n# Initialize total byte counter\ntotal_bytes=0\n\n# Loop through each matching file and add its byte size to total_bytes\nfor file in $matching_files; do\n    bytes=$(wc -c < \"$file\")\n    total_bytes=$((total_bytes + bytes))\ndone\n\n# Output the total byte count as result for evaluation purposes.\necho $total_bytes\n```",
        "create": {
            "init": "# Create a directory named data_files\nmkdir -p data_files\n\n# Create some text files with varying content\necho \"This file talks about Linux.\" > data_files/file1.txt\necho \"This file does not mention anything.\" > data_files/file2.txt\necho \"Linux is great for operating systems study.\" > data_files/file3.txt\necho \"Just another file without Linux keyword.\" > data_files/file4.txt\n\n# Add some additional non-txt files to verify selection criteria works correctly.\necho \"This won't be counted as it's not a .txt file.\" > data_files/file5.md"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files containing the word 'Linux'\nmatching_files=$(grep -l 'Linux' data_files/*.txt)\n\n# Initialize total byte counter\ntotal_bytes=0\n\n# Loop through each matching file and add its byte size to total_bytes\nfor file in $matching_files; do\n    bytes=$(wc -c < \"$file\")\n    total_bytes=$((total_bytes + bytes))\ndone\n\n# Output the total byte count as result for evaluation purposes.\necho $total_bytes"
        }
    },
    {
        "description": "You have a directory named `project_logs` in your home directory that contains multiple log files, each with a `.log` extension. Each log file records system events with timestamps. Your task is to find out which log file contains the most occurrences of the word \"ERROR\" and report the name of that file.",
        "explanation": "To solve this problem, you should iterate through all `.log` files in the `project_logs` directory and count how many times the word \"ERROR\" appears in each file. You can use utilities like `grep` to filter lines containing \"ERROR\" and `wc -l` to count them. After counting, compare the counts from all files and determine which file has the highest count.\n\nYou can use this command pattern to perform the task:\n\n```bash\nmax_errors=0\nfile_with_max_errors=\"\"\n\nfor logfile in ~/project_logs/*.log; do\n    error_count=$(grep -c \"ERROR\" \"$logfile\")\n    if (( error_count > max_errors )); then\n        max_errors=$error_count\n        file_with_max_errors=$(basename \"$logfile\")\n    fi\ndone\n\necho $file_with_max_errors\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho \"2023-10-01 12:00:00 INFO Start process\" > ~/project_logs/log1.log\necho \"2023-10-01 12:05:00 ERROR Something went wrong\" >> ~/project_logs/log1.log\necho \"2023-10-01 12:10:00 ERROR Another error occurred\" >> ~/project_logs/log1.log\n\necho \"2023-10-02 13:00:00 INFO Start process\" > ~/project_logs/log2.log\necho \"2023-10-02 13:05:00 WARNING Low disk space\" >> ~/project_logs/log2.log\necho \"2023-10-02 13:15:00 ERROR Disk space critically low\" >> ~/project_logs/log2.log\n\necho \"2023-10-03 14:00:00 INFO Start process\" > ~/project_logs/log3.log\necho \"2023-10-03 14:25:00 ERROR Unexpected shutdown\" >> ~/project_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "max_errors=0\nfile_with_max_errors=\"\"\n\nfor logfile in ~/project_logs/*.log; do\n    error_count=$(grep -c \"ERROR\" \"$logfile\")\n    if (( error_count > max_errors )); then\n        max_errors=$error_count\n        file_with_max_errors=$(basename \"$logfile\")\n    fi\ndone\n\necho $file_with_max_errors"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and whose size is greater than 1MB.",
        "explanation": "To solve the problem, you can use a combination of `find` command with appropriate options to filter files based on modification time and size. The `-mtime` option can be used to find files modified within the last 7 days, and `-size` option can be used to find files larger than 1MB. You can then count these files using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization necessary as students will work with their own home directories."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "You need to count the number of lines in all `.txt` files within your home directory that contain the word \"Linux\". Ignore case when counting occurrences.",
        "explanation": "To solve this problem, you can use the `grep` command with the `-i` option to ignore case while searching for occurrences of \"Linux\". You will then count the lines using `wc -l`. Ensure you're checking every `.txt` file present in your home directory.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find and count lines containing 'Linux' or 'linux'\ngrep -i 'Linux' ~/sample_texts/*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample .txt files with varying content\nmkdir -p ~/sample_texts\necho -e \"This is a Linux example.\\nSome other text.\" > ~/sample_texts/file1.txt\necho -e \"Another line.\\nlinux is here.\" > ~/sample_texts/file2.txt\necho -e \"No mention of OS here.\\nJust plain text.\" > ~/sample_texts/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find and count lines containing 'Linux' or 'linux'\ngrep -i 'Linux' ~/sample_texts/*.txt | wc -l"
        }
    },
    {
        "description": "In your home directory, you have a folder named \"logs\" containing multiple log files (e.g., log1.txt, log2.txt, etc.). Each log file contains lines with timestamps and error messages. Your task is to find the total number of unique error messages across all files in the \"logs\" directory that occurred in the month of September 2023. You need to consider only lines starting with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Please output just the count of these unique error messages.",
        "explanation": "To solve this problem, you should first list all files in the \"logs\" directory. Then, for each file, filter out lines containing timestamps from September 2023. Extract unique error messages that follow these timestamps and keep a running list of them across all files. Finally, count and output the number of unique error messages found.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -name \"*.txt\" | xargs grep \"^2023\\-09.*Error:\" | cut -d':' -f2 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/log1.txt\n2023-09-01 10:00:00 Error: Failed to connect to database\n2023-09-02 11:30:45 Warning: Low disk space\n2023-09-15 14:22:01 Error: Timeout occurred during operation\n2023-08-25 09:15:12 Error: Network unreachable\nEOL\n\ncat <<EOL > ~/logs/log2.txt\n2023-09-10 12:00:00 Error: Failed to connect to database\n2023-09-12 13:45:30 Critical: System overheating detected\n2023-09-20 16:40:50 Error: Timeout occurred during operation\nEOL\n\ncat <<EOL > ~/logs/log3.txt\n2023-07-05 18:30:20 Info: System rebooted successfully\n2023-09-25 19:15::55 Critical Failure on disk drive detected!\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -name \"*.txt\" | xargs grep \"^2023\\-09.*Error:\" | cut -d':' -f2 | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with examining the system logs on your Ubuntu machine to determine how many unique IP addresses have attempted to access the system in the last 24 hours. The log file you need to analyze is located at `/var/log/auth.log`. You should consider only the entries that contain \"Failed password\" as these indicate failed login attempts. Provide the count of unique IP addresses from these entries.",
        "explanation": "To solve this problem, you can use tools such as `grep` to filter log entries containing \"Failed password\", and then use `awk` or `sed` to extract the IP address from each relevant entry. After extracting all IP addresses, you can sort them and use `uniq` to find unique instances. Finally, count these unique instances using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Extract failed login attempts and corresponding IPs, then count unique ones.\ngrep \"Failed password\" /var/log/auth.log | awk '{print $11}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Initialize a sample auth.log file for testing\necho \"\" > /var/log/auth.log\necho \"Oct 10 10:00:00 ubuntu sshd[12345]: Failed password for invalid user root from 192.168.1.1 port 22 ssh2\" >> /var/log/auth.log\necho \"Oct 10 11:00:00 ubuntu sshd[12346]: Failed password for invalid user admin from 192.168.1.2 port 22 ssh2\" >> /var/log/auth.log\necho \"Oct 10 12:00:00 ubuntu sshd[12347]: Failed password for invalid user guest from 192.168.1.3 port 22 ssh2\" >> /var/log/auth.log\necho \"Oct 10 13:00:00 ubuntu sshd[12348]: Failed password for invalid user root from 192.168.1.4 port 22 ssh2\" >> /var/log/auth.log\necho \"Oct 10 14:00:00 ubuntu sshd[12349]: Failed password for invalid user user from 192.168.1.3 port 22 ssh2\" >> /var/log/auth.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Extract failed login attempts and corresponding IPs, then count unique ones.\ngrep \"Failed password\" /var/log/auth.log | awk '{print $11}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count how many files in the `/var/log` directory contain the string \"error\" at least once.",
        "explanation": "To solve this problem, you need to search through all the files in the `/var/log` directory and check if they contain the word \"error\". You can use utilities such as `grep` to search for strings within files, and `wc -l` to count lines. Combining these tools will help you determine how many files meet the criteria.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find and count number of files containing \"error\"\ngrep -lR \"error\" /var/log | wc -l\n```",
        "create": {
            "init": "# No initialization is needed for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find and count number of files containing \"error\"\ngrep -lR \"error\" /var/log | wc -l"
        }
    },
    {
        "description": "Count the total number of files, excluding directories, in your home directory and all its subdirectories that have been modified in the last 7 days.",
        "explanation": "To solve this problem, you need to recursively search through your home directory and its subdirectories. You can use the `find` command with appropriate options to filter out directories and find files based on their modification time. The `-type f` option helps in selecting only files, and `-mtime -7` filters for those modified within the last 7 days. Finally, use `wc -l` to count the number of lines returned by `find`, which corresponds to the number of files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You are tasked with organizing and analyzing a directory of text files named \"logs\" located in your home directory. Each file is named in the format \"log_YYYYMMDD.txt\" where YYYYMMDD represents the date of the log. Your goal is to find out how many unique IP addresses have accessed the server on the most recent date available in these log files. Each line in a log file represents an access entry and starts with an IP address.",
        "explanation": "To solve this problem, you need to first determine which log file corresponds to the most recent date by examining their filenames. Once identified, open this file and extract all unique IP addresses from it. Count these unique addresses to get your answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find the most recent file based on date in filename\nrecent_file=$(ls ~/logs | sort | tail -n 1)\n\n# Extract unique IPs from that file and count them\nunique_ips_count=$(awk '{print $1}' ~/logs/$recent_file | sort | uniq | wc -l)\n\n# Output the count of unique IP addresses\necho $unique_ips_count\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \\\"GET / HTTP/1.1\\\" 200 4982\\n192.168.1.2 - - [10/Oct/2023:14:00:01 +0000] \\\"GET /about HTTP/1.1\\\" 200 2346\" > ~/logs/log_20231010.txt\necho -e \"192.168.1.3 - - [11/Oct/2023:09:15:23 +0000] \\\"GET /contact HTTP/1.1\\\" 404 721\\n192.168.1.4 - - [11/Oct/2023:09:45:03 +0000] \\\"POST /login HTTP/1.1\\\" 500 4025\\n192.168.1.3 - - [11/Oct/2023:09:50:12 +0000] \\\"GET /home HTTP/1.1\\\" 200 1024\" > ~/logs/log_20231011.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find the most recent file based on date in filename\nrecent_file=$(ls ~/logs | sort | tail -n 1)\n\n# Extract unique IPs from that file and count them\nunique_ips_count=$(awk '{print $1}' ~/logs/$recent_file | sort | uniq | wc -l)\n\n# Output the count of unique IP addresses\necho $unique_ips_count"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory, which contains multiple log files with various extensions. Your task is to count the total number of lines in all `.log` files within this directory. Note that the `.log` files might be nested inside subdirectories of \"logfiles\". You should find a way to efficiently count these lines without manually opening each file.",
        "explanation": "To solve this problem, you can use the `find` command to locate all `.log` files within the \"logfiles\" directory and its subdirectories. Then, you can use `xargs` along with `wc -l` to count the total number of lines across all found files. This approach leverages shell utilities to automate what would otherwise be a time-consuming manual process.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files and count their total lines\nfind ~/logfiles -type f -name \"*.log\" | xargs wc -l | tail -n1 | awk '{print $1}'\n```",
        "create": {
            "init": "# Create directories and files for testing\nmkdir -p ~/logfiles/subdir1 ~/logfiles/subdir2\necho -e \"Line 1\\nLine 2\\nLine 3\" > ~/logfiles/file1.log\necho -e \"Line 1\\nLine 2\" > ~/logfiles/subdir1/file2.log\necho -e \"Line 1\\nLine 2\\nLine 3\\nLine 4\" > ~/logfiles/subdir2/file3.log\necho -e \"Not a .log file content\" > ~/logfiles/subdir2/ignore.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files and count their total lines\nfind ~/logfiles -type f -name \"*.log\" | xargs wc -l | tail -n1 | awk '{print $1}'"
        }
    },
    {
        "description": "Count the number of files with the \".txt\" extension in your home directory that have been modified in the last 5 days.",
        "explanation": "To solve this problem, you can use the 'find' command to search for files in your home directory with the \".txt\" extension and filter those modified within the last 5 days using the '-mtime' flag. You should then count these files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script to count .txt files modified within last 5 days.\nfind ~ -name \"*.txt\" -mtime -5 | wc -l\n```",
        "create": {
            "init": "# Create some .txt files in student's home directory\ncd ~\ntouch file1.txt file2.txt file3.txt file4.txt outdated_file.txt\n# Modify timestamps to simulate last modification dates\ntouch -m -d \"3 days ago\" file1.txt\ntouch -m -d \"1 day ago\" file2.txt\ntouch -m -d \"6 days ago\" outdated_file.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script to count .txt files modified within last 5 days.\nfind ~ -name \"*.txt\" -mtime -5 | wc -l"
        }
    },
    {
        "description": "Find the total number of lines containing the word \"error\" across all `.log` files in your home directory. You should exclude lines where \"error\" is part of another word (e.g., \"errors\").",
        "explanation": "To solve this problem, you will need to search through all `.log` files in your home directory using a combination of shell commands. Start by listing all `.log` files, then use `grep` with appropriate options to ensure the word \"error\" is matched as a whole word and not as part of another word. Finally, count the occurrences across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files and count lines containing 'error' as a whole word.\ngrep -w 'error' ~/file*.log | wc -l\n```",
        "create": {
            "init": "# Create example .log files in the user's home directory\necho -e \"This is an error\\nNo errors here\\nAnother error line\" > ~/file1.log\necho -e \"Error occurred\\nAn error and more\\nErrors everywhere\" > ~/file2.log\necho -e \"Random text\\nNothing wrong here\\nJust an error again\" > ~/file3.log\necho -e \"A final error\\nFinal errors line\\nIgnore these errors\" > ~/file4.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files and count lines containing 'error' as a whole word.\ngrep -w 'error' ~/file*.log | wc -l"
        }
    },
    {
        "description": "Find and count the number of lines in all text files within the \"documents\" directory in your home directory that contain the word \"Linux\", case-insensitively.",
        "explanation": "To solve this problem, you need to search for the term \"Linux\" in all text files (.txt) within the specified directory. You can use `grep` with the `-i` flag for case-insensitive search and then count the number of lines using `wc -l`. Ensure you handle multiple files and aggregate counts properly.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'Linux' ~/documents/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/documents\necho -e \"Introduction to Linux\\nOperating Systems Overview\" > ~/documents/file1.txt\necho -e \"Linux is a powerful OS\\nBasics of Shell Scripting\" > ~/documents/file2.txt\necho -e \"Python Programming\\nAdvanced Linux Commands\" > ~/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'Linux' ~/documents/*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all log files within the directory \"/var/logs\". Log files have a \".log\" extension.",
        "explanation": "To solve this problem, you need to navigate to the \"/var/logs\" directory and search through all files with a \".log\" extension. Use tools such as `grep` to filter lines containing the word \"error\", and then count those lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use grep to find lines containing 'error' and wc -l to count them across all .log files in /var/logs\ngrep 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "# Create /var/logs directory and sample log files\nmkdir -p /var/logs\n\n# Create sample log files with various contents\necho -e \"info: system started\\nerror: disk not found\\ninfo: network connected\" > /var/logs/system.log\necho -e \"warning: low memory\\nerror: failed login attempt\\ninfo: user logged in\" > /var/logs/security.log\necho -e \"error: connection lost\\ninfo: connection restored\\nwarning: high CPU usage\" > /var/logs/network.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use grep to find lines containing 'error' and wc -l to count them across all .log files in /var/logs\ngrep 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "You need to determine how many lines contain the word \"ERROR\" in all .log files within the /var/logs directory, and the output should be the total count of such lines. Ensure that you do not include any subdirectories in your search.",
        "explanation": "To solve this problem, you can use grep to search through each .log file in the specified directory for lines containing \"ERROR\". Use wc -l to count these lines. You can combine these commands with xargs or a loop to iterate over all relevant files and sum up the counts.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h \"ERROR\" /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "# Create /var/logs directory and sample log files for testing\nmkdir -p /var/logs\necho -e \"INFO: All systems go\\nERROR: Failed to start service\\nINFO: Service started\\nERROR: Out of memory\" > /var/logs/system.log\necho -e \"DEBUG: Starting process\\nINFO: Process running smoothly\\nERROR: Unable to allocate resource\\nWARNING: Low disk space\" > /var/logs/resource.log\necho -e \"INFO: User logged in\\nINFO: User logged out\\nERROR: Connection timeout\" > /var/logs/network.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h \"ERROR\" /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing system logs to determine the total number of failed login attempts. In your home directory, there is a file named `auth.log` that contains log entries related to authentication. Count the number of lines in this file that contain the phrase \"Failed password\".",
        "explanation": "To solve this problem, you need to search through the `auth.log` file for lines that specifically contain the phrase \"Failed password\", which indicates a failed login attempt. You can use tools like `grep` to filter out these lines and then use `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count the number of failed login attempts in auth.log\ngrep \"Failed password\" ~/auth.log | wc -l\n```",
        "create": {
            "init": "# Create a sample auth.log file with various log entries\ncat <<EOL > ~/auth.log\nJan 10 10:00:01 ubuntu sshd[12345]: Failed password for invalid user from 192.168.0.1 port 22 ssh2\nJan 10 10:05:01 ubuntu sshd[12346]: Failed password for root from 192.168.0.2 port 22 ssh2\nJan 10 11:00:01 ubuntu sshd[12347]: Accepted password for user1 from 192.168.0.3 port 22 ssh2\nJan 10 12:00:01 ubuntu sshd[12348]: Failed password for user1 from 192.168.0.4 port 22 ssh2\nJan 10 13:00:01 ubuntu sshd[12349]: Connection closed by authenticating user root [preauth]\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count the number of failed login attempts in auth.log\ngrep \"Failed password\" ~/auth.log | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and have a \".log\" extension.",
        "explanation": "To solve this problem, you can use the `find` command to search for files within your home directory. You will need to use options such as `-mtime` to filter files based on their modification time and `-name` to filter files by their extension. The result will be a count of all `.log` files that have been modified within the last week.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind \"$HOME\" -type f -name \"*.log\" -mtime -7 | wc -l\n```",
        "create": {
            "init": "# Create some example log files with various modification dates\nmkdir -p \"$HOME/logs\"\ntouch \"$HOME/logs/file1.log\" \"$HOME/logs/file2.log\"\nsleep 1\ntouch \"$HOME/logs/file3.log\"\n# Modify one file to set its timestamp back by 8 days\ntouch -d \"$(date -d '8 days ago')\" \"$HOME/logs/file1.log\""
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find \"$HOME\" -type f -name \"*.log\" -mtime -7 | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory containing multiple text files with log entries. Each entry in these log files starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique days (YYYY-MM-DD) have log entries and return that number.",
        "explanation": "To solve this problem, navigate to the \"logfiles\" directory. You need to extract all unique dates from the timestamps across all files. First, concatenate all files together, then use a command to extract the date portion of each timestamp, filter for unique dates, and finally count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logfiles\ncat *.txt | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-03-01 12:00:01 Log entry 1\\n2023-03-01 13:45:23 Log entry 2\\n2023-03-02 09:30:10 Log entry 3\" > ~/logfiles/log1.txt\necho -e \"2023-03-02 15:15:15 Log entry 4\\n2023-03-03 16:45:00 Log entry 5\\n2023-03-01 17:20:30 Log entry 6\" > ~/logfiles/log2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logfiles\ncat *.txt | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there are multiple text files with varying extensions (e.g., .txt, .log, .md). Your task is to count the total number of lines across all these text files that contain the word \"error\" (case-insensitive). Additionally, ensure that empty lines are not included in this count.",
        "explanation": "To solve this problem, you need to search through each text file in your home directory for lines containing the word \"error\". Use grep with the -i option to make the search case-insensitive. You'll also need to filter out empty lines. Finally, sum up the counts from all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script.\ncd ~\ngrep -i 'error' *.txt *.log *.md | grep -v '^$' | wc -l\n```",
        "create": {
            "init": "# Create sample text files in the student's home directory for testing.\ncd ~\necho -e \"This is a test.\\nError found here.\\nAnother line.\" > file1.txt\necho -e \"No issues here.\\n\\nError detected.\\nYet another error.\" > file2.log\necho -e \"All clear.\\nLooks good.\" > file3.md\necho -e \"\\n\\nERROR occurred again.\" > file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script.\ncd ~\ngrep -i 'error' *.txt *.log *.md | grep -v '^$' | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"project_logs\" in your home directory, which contains multiple text files. Each file logs events with timestamps in the format \"YYYY-MM-DD HH:MM:SS - Event Description\". Your task is to count how many events occurred on the date \"2023-01-15\", and obtain the total number of such events across all files.",
        "explanation": "To solve this problem, you will need to search through each file in the \"project_logs\" directory to find lines that match the date pattern \"2023-01-15\". You can use tools like `grep` to filter these lines and then use `wc -l` to count them. Summing up these counts from all files gives you the final answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '2023-01-15' ~/project_logs/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"2023-01-15 09:00:00 - User login\\n2023-01-16 10:30:00 - File uploaded\" > ~/project_logs/log1.txt\necho -e \"2023-01-15 14:30:00 - Error detected\\n2023-02-17 08:45:00 - System reboot\" > ~/project_logs/log2.txt\necho -e \"2023-03-12 11:20:00 - Update installed\\n2023-01-15 19:45:00 - Service restarted\" > ~/project_logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '2023-01-15' ~/project_logs/*.txt | wc -l"
        }
    },
    {
        "description": "In your home directory, there are multiple text files with random names. Each file contains words separated by spaces and new lines. Your task is to find the word that appears the most across all these files combined, and output that word along with its frequency in the format \"word:frequency\". Assume all words are case-sensitive.",
        "explanation": "To solve this problem, you need to read all text files in your home directory, count the occurrences of each word across all files, and determine which word has the highest frequency. You can use tools like `cat`, `tr`, `sort`, `uniq`, and `awk` to process the text data.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Combine all text files into one stream\ncat ~/file*.txt | \\\n# Replace new lines with spaces to handle words properly\ntr '\\n' ' ' | \\\n# Break down into individual words (assuming space as delimiter)\ntr ' ' '\\n' | \\\n# Sort words for counting them easily with uniq\nsort | \\\n# Count occurrences of each word\nuniq -c | \\\n# Sort based on frequency in descending order and get the most frequent one \nsort -nr | \\\n# Use awk to format the output as required (\"word:frequency\")\nawk '{print $2\":\"$1}' | head -n 1\n```",
        "create": {
            "init": "# Create sample text files in the home directory for testing\necho -e \"apple orange banana\\napple grape\" > ~/file1.txt\necho -e \"banana apple orange\\norange\" > ~/file2.txt\necho -e \"grape apple\\nbanana\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "# Combine all text files into one stream\ncat ~/file*.txt | \\\n# Replace new lines with spaces to handle words properly\ntr '\\n' ' ' | \\\n# Break down into individual words (assuming space as delimiter)\ntr ' ' '\\n' | \\\n# Sort words for counting them easily with uniq\nsort | \\\n# Count occurrences of each word\nuniq -c | \\\n# Sort based on frequency in descending order and get the most frequent one \nsort -nr | \\\n# Use awk to format the output as required (\"word:frequency\")\nawk '{print $2\":\"$1}' | head -n 1"
        }
    },
    {
        "description": "In your Linux environment, there is a directory named \"project_logs\" containing various log files with the \".log\" extension. Each log file contains timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique days are covered by all the timestamps across all log files in the \"project_logs\" directory. Count only the unique dates irrespective of the time.",
        "explanation": "To solve this problem, you need to extract all timestamps from each \".log\" file in the \"project_logs\" directory. You can use commands like `grep` to search for timestamps and then use tools like `awk` or `cut` to extract just the date part (first 10 characters). After extracting dates, store them in a list and use a command like `sort | uniq` to filter out duplicates, finally counting how many unique dates exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind project_logs -name \"*.log\" -exec grep -oE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' {} \\; | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p project_logs\necho -e \"2023-01-01 08:21:00\\n2023-01-02 09:22:00\\n2023-01-01 12:30:00\" > project_logs/log1.log\necho -e \"2023-01-03 10:45:00\\n2023-01-02 11:50:00\\n2023-01-04 15:25:00\" > project_logs/log2.log\necho -e \"2023-01-05 16:35:00\\n2023-01-03 17:45:00\\n2023-01-06 18:55:00\" > project_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find project_logs -name \"*.log\" -exec grep -oE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' {} \\; | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that were modified in the last 7 days and have a '.txt' extension. You must exclude directories from this count.",
        "explanation": "To solve this problem, you can use the `find` command to search for files within your home directory. You'll need to filter files based on their modification time using the `-mtime` option and exclude directories using the `-type f` option. Finally, apply a filter for files with a '.txt' extension using the `-name` option. Count the number of results returned by this command.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -name \"*.txt\" | wc -l\n```",
        "create": {
            "init": "# Initialization script: No specific initialization required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -name \"*.txt\" | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains various log files with a \".log\" extension. Each log file contains timestamps and corresponding event messages. Your task is to find out how many unique days have events recorded across all these log files. Assume that each timestamp is formatted as \"YYYY-MM-DD HH:MM:SS\". You must count only the unique dates (YYYY-MM-DD) present in any of the logs.",
        "explanation": "To solve this problem, you need to extract the date part from each line in every \".log\" file within the \"logs\" directory. You can use tools like `grep` or `awk` to filter out and process the date part of each timestamp. After extracting the dates, you should store them in a list and use utilities like `sort` and `uniq` to determine the number of unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract all dates from .log files in ~/logs directory.\ngrep -hoE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-11-01 12:00:00 Event A\\n2023-11-01 13:30:00 Event B\\n2023-11-02 14:45:00 Event C\" > ~/logs/system.log\necho -e \"2023-11-02 09:15:00 Event D\\n2023-11-03 16:20:00 Event E\\n2023-11-03 18:30:00 Event F\" > ~/logs/application.log\necho -e \"2023-11-01 07:50:00 Event G\\n2023-11-04 10:05:00 Event H\" > ~/logs/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract all dates from .log files in ~/logs directory.\ngrep -hoE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, count the number of files (not directories) that were modified in the last 7 days and have a size greater than 1MB.",
        "explanation": "To solve this problem, you need to use the `find` command to search for files within your home directory. You can specify conditions such as modification time and file size using `-mtime` and `-size` options respectively. Remember to exclude directories from your count.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# Create sample files in the student's home directory for testing\ntouch ~/file1.txt\ntouch ~/file2.txt\ntouch ~/file3.txt\n\n# Modify some files to change their timestamps\necho \"Sample content\" > ~/file1.txt\necho \"Sample content\" > ~/file2.txt\n\n# Set file sizes and modification times\ndd if=/dev/zero of=~/largefile1 bs=1024 count=2048  # 2MB file\ndd if=/dev/zero of=~/largefile2 bs=1024 count=512   # 0.5MB file\n\ntouch -m -d '3 days ago' ~/largefile1\ntouch -m -d '10 days ago' ~/largefile2\n\nmkdir ~/sampledir  # Create a directory which should not be counted as a file."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "Determine the total size of all files in your home directory that were modified in the last 7 days and have a \".log\" extension. The result should be presented as a human-readable size.",
        "explanation": "To solve this problem, you need to perform several steps: \n1. Navigate to your home directory.\n2. Use the `find` command to list all \".log\" files modified within the last 7 days.\n3. Pipe the output of `find` into `xargs` or directly use `du` to calculate the size of these files.\n4. Use options such as `-h` with `du` for human-readable format or convert it manually if needed.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~\nfind . -name \"*.log\" -mtime -7 -exec du -ch {} + | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "# Create a few sample log files in the home directory with different modification times\ncd ~\ntouch -t 202310010000 example1.log\ntouch -t 202310050000 example2.log\ntouch -t 202309250000 example3.log\necho \"Log file content\" > example1.log\necho \"Log file content\" > example2.log\necho \"Log file content\" > example3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "cd ~\nfind . -name \"*.log\" -mtime -7 -exec du -ch {} + | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory that contains multiple log files with various extensions. Count how many lines contain the word \"ERROR\" across all `.log` files and output the total number.",
        "explanation": "To solve this problem, you need to navigate to the \"log_files\" directory and use tools like `grep` to search for the word \"ERROR\" in each `.log` file. You can then use `wc -l` to count these occurrences and sum them up to get the total number of lines containing \"ERROR\".\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/log_files\ngrep -h ERROR *.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nINFO: Reboot scheduled\" > ~/log_files/system.log\necho -e \"WARNING: High memory usage\\nERROR: Network timeout\\nINFO: Update complete\" > ~/log_files/network.log\necho -e \"INFO: Backup successful\\nERROR: Permission denied\\nWARNING: CPU temperature high\" > ~/log_files/security.log\ntouch ~/log_files/empty.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/log_files\ngrep -h ERROR *.log | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that were modified in the last 7 days and have a file size greater than 1MB.",
        "explanation": "To solve this problem, you need to use several Linux commands together. First, use `find` to locate files modified within the last 7 days and with sizes greater than 1MB. Then, pipe the results to `wc -l` to count the number of matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization required as students will work with their own home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all text files (.txt) in your home directory, including those within subdirectories. You should ensure that hidden files (those starting with a dot) are also included in your count.",
        "explanation": "To solve this problem, you need to search through your home directory and all its subdirectories for files ending with the \".txt\" extension. You can use the `find` command to locate these files and then use `wc -l` to count the number of lines in each file. Summing these counts will give you the total number of lines across all text files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files in home directory including hidden ones, and count their lines \nfind ~ -type f -name \"*.txt\" -exec wc -l {} + | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "# Create some sample text files and directories\nmkdir -p ~/test_dir/sub_dir\necho -e \"Hello\\nWorld\\nThis is a test.\" > ~/test_file1.txt\necho -e \"Another test file.\\nWith some more lines.\" > ~/test_dir/test_file2.txt\necho -e \"Hidden file\\nTest content.\" > ~/.hidden_test_file.txt\necho -e \"Subdirectory file\\nLine one.\\nLine two.\" > ~/test_dir/sub_dir/test_file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files in home directory including hidden ones, and count their lines \nfind ~ -type f -name \"*.txt\" -exec wc -l {} + | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days, excluding hidden files and directories.",
        "explanation": "To solve this problem, you need to use the `find` command to search for files in your home directory. Use the `-type f` option to ensure only regular files are counted. The `-mtime -7` option will help you filter files that have been modified within the last 7 days. You should also use appropriate options to exclude hidden files and directories.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 ! -path '*/.*' | wc -l\n```",
        "create": {
            "init": "# No initialization required as students will work with their existing home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 ! -path '*/.*' | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"logs\" containing multiple log files with the extension \".log\". Each file contains timestamped logs from a server in the format \"[YYYY-MM-DD HH:MM:SS] Event message\". Your task is to find out how many unique dates are recorded across all log files. Consider only distinct dates from the timestamps.",
        "explanation": "To solve this problem, you need to extract the date portion from each line of the log files and identify unique dates. You can use tools like `cat`, `grep`, or `awk` to extract the date part, and then use `sort` and `uniq` to count how many distinct dates exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"[2023-10-01 12:00:00] Server started\\n[2023-10-01 12:30:00] User logged in\\n[2023-10-02 13:00:00] Data backup completed\" > ~/logs/server1.log\necho -e \"[2023-10-02 14:15:00] Connection established\\n[2023-10-03 09:45:00] System updated\" > ~/logs/server2.log\necho -e \"[2023-10-03 10:15:00] New session created\\n[2023-10-04 11:25:00] Error detected\" > ~/logs/server3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"Linux\" in all `.txt` files within your home directory and its subdirectories. Ignore case sensitivity.",
        "explanation": "To solve this problem, you can use the `grep` command with the `-i` option to ignore case and search for the word \"Linux\" across multiple files. You need to include options to count occurrences and handle recursive directory searching. You can combine these capabilities using pipes or command substitutions to get a total line count.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use grep recursively and capture lines with 'Linux', then count them.\ngrep -ri 'Linux' ~ --include \\*.txt | wc -l\n```",
        "create": {
            "init": "# Create some sample text files with various contents\nmkdir -p ~/testdir/subdir\necho -e \"This is a Linux system.\\nLearning Linux is fun.\" > ~/testdir/file1.txt\necho -e \"LINUX commands are powerful.\\nOpen source Linux.\" > ~/testdir/subdir/file2.txt\necho -e \"No mention of linux here.\" > ~/testdir/subdir/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use grep recursively and capture lines with 'Linux', then count them.\ngrep -ri 'Linux' ~ --include \\*.txt | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory containing multiple log files with the extension \".log\". Each log file contains various entries in the format: `YYYY-MM-DD ERROR/WARNING/INFO Message`. Your task is to determine how many \"ERROR\" entries occurred on the specific date \"2023-03-15\" across all these log files.",
        "explanation": "To solve this problem, you need to navigate through the \"logfiles\" directory and process each \".log\" file. You will filter out lines containing \"ERROR\" entries specifically for the date \"2023-03-15\", then count these filtered lines to get the total number of errors on that day.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '2023-03-' ~/logfiles/*.log | grep 'ERROR' | grep '2023\\-03\\-15' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-03-15 ERROR Disk full\\n2023-03-15 INFO System rebooted\\n2023-03-14 WARNING High memory usage\\n2023-03-15 ERROR Network failure\" > ~/logfiles/log1.log\necho -e \"2023-03-13 INFO User login\\n2023-03-15 ERROR Application crash\\n2023-03-16 INFO Scheduled backup completed\\n2023-03-15 WARNING Low disk space\" > ~/logfiles/log2.log\necho -e \"2023-02-28 INFO Monthly report generated\\n2023-03-15 ERROR Unauthorized access detected\\n2023-03-15 ERROR Service timeout\" > ~/logfiles/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '2023-03-' ~/logfiles/*.log | grep 'ERROR' | grep '2023\\-03\\-15' | wc -l"
        }
    },
    {
        "description": "Count the number of files and directories in your home directory that have been modified in the last 7 days.",
        "explanation": "To solve this problem, you can use the `find` command with appropriate options to filter out files and directories based on their modification time. The `-mtime` option allows you to specify the number of days ago a file was modified. You can use `-type f` for files and `-type d` for directories, then count them using the `wc -l` command.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -mtime -7 \\( -type f -o -type d \\) | wc -l\n```",
        "create": {
            "init": "# No initialization is needed for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -mtime -7 \\( -type f -o -type d \\) | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple log files with a \".log\" extension. These logs contain various messages, some of which are error messages starting with the string \"ERROR:\". Your task is to count the total number of unique error messages across all log files. Consider only the part of the message after \"ERROR:\" as significant for uniqueness.",
        "explanation": "To solve this problem, you need to search through each file in the \"log_files\" directory for lines that start with \"ERROR:\". Extract the part of each line following \"ERROR:\" and track these messages to determine how many unique ones exist. You may find it helpful to use tools such as `grep` to filter lines, `awk` or `sed` for text processing, and `sort` combined with `uniq` to find unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h '^ERROR:' ~/log_files/*.log | sed 's/^ERROR://' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\ncat > ~/log_files/file1.log << EOL\nINFO: This is an information message.\nERROR: Disk space low.\nWARNING: High memory usage.\nERROR: Disk space low.\nEOL\n\ncat > ~/log_files/file2.log << EOL\nINFO: System rebooted successfully.\nERROR: Network interface down.\nERROR: Disk space low.\nEOL\n\ncat > ~/log_files/file3.log << EOL\nERROR: Unreachable host detected.\nWARNING: CPU temperature high.\nINFO: Backup completed successfully.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h '^ERROR:' ~/log_files/*.log | sed 's/^ERROR://' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have been provided with a directory named \"log_analysis\" that contains multiple text files ending with \".log\". Each log file records various events, and each event is timestamped. Your task is to identify the most recent event timestamp across all log files in the \"log_analysis\" directory and return it in the format \"YYYY-MM-DD HH:MM:SS\".",
        "explanation": "To solve this problem, you need to iterate through each \".log\" file in the \"log_analysis\" directory, extract all timestamps, and determine which one is the most recent. You can use tools like `grep` to extract timestamps and `sort` to find the latest one. Remember that timestamps are usually formatted as \"YYYY-MM-DD HH:MM:SS\", so ensure your regular expression matches this format.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all timestamps and determine the most recent one.\ngrep -hoE '[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}' log_analysis/*.log | sort | tail -n1\n```",
        "create": {
            "init": "mkdir -p log_analysis\necho -e \"2023-10-01 12:00:00 Event A\\n2023-10-02 14:30:00 Event B\\n2023-09-30 16:00:00 Event C\" > log_analysis/log1.log\necho -e \"2023-10-01 18:45:00 Event D\\n2023-10-03 09:15:00 Event E\\n2023-09-28 19:30:00 Event F\" > log_analysis/log2.log\necho -e \"2023-09-29 08:20:00 Event G\\n2023-10-02 22:45:00 Event H\\n2023-10-03 11:05:00 Event I\" > log_analysis/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "# Find all timestamps and determine the most recent one.\ngrep -hoE '[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}' log_analysis/*.log | sort | tail -n1"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all text files located within the \"/var/logs/\" directory and its subdirectories. Assume that there are no symbolic links in this directory.",
        "explanation": "To solve this problem, you can use the `find` command to locate all text files within the specified directory and its subdirectories. Then, use `grep` to search for occurrences of the word \"error\" and count these lines using `wc -l`. You may need to combine these commands using pipes.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/logs/ -type f -name \"*.txt\" -exec grep -i \"error\" {} \\; | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\nmkdir -p /var/logs/subdir1 /var/logs/subdir2\necho -e \"This is an error\\nNo error here\\nAnother error line\" > /var/logs/file1.txt\necho -e \"Error occurred\\nStill running smoothly\" > /var/logs/subdir1/file2.txt\necho -e \"System error detected\\nAll systems go\\nMinor error\" > /var/logs/subdir2/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/logs/ -type f -name \"*.txt\" -exec grep -i \"error\" {} \\; | wc -l"
        }
    },
    {
        "description": "You need to find and count all the files in your home directory that were modified in the last 7 days, and then output the total count.",
        "explanation": "To solve this problem, you can use the `find` command with appropriate options to filter files based on their modification time. The `-mtime` option allows you to specify the number of days since a file was last modified. Use `find $HOME -type f -mtime -7` to list files modified in the last 7 days, and pipe the output to `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind $HOME -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization script is required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find $HOME -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You need to count the number of unique IP addresses found in the log file located at `/var/log/access.log`. The log file contains lines with IP addresses, and you must ensure that your count only includes unique instances. Note: The log file may contain other text, but the IP addresses are always at the beginning of each line.",
        "explanation": "To solve this problem, you can use a combination of `awk` to extract the first column (IP address) from each line, `sort` to arrange them in order, and `uniq` to filter out duplicate entries. Finally, use `wc -l` to count the number of unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{print $1}' /var/log/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create a sample access log for testing\necho -e \"192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \\\"GET / HTTP/1.1\\\" 200 1024\\n192.168.1.2 - - [10/Oct/2023:13:56:36 +0000] \\\"POST /login HTTP/1.1\\\" 200 2048\\n192.168.1.3 - - [10/Oct/2023:13:57:36 +0000] \\\"GET /home HTTP/1.1\\\" 404 512\\n192.168.1.2 - - [10/Oct/2023:13:58:36 +0000] \\\"GET /dashboard HTTP/1.1\\\" 200 3072\\n192.168.1.4 - - [10/Oct/2023:14:00:36 +0000] \\\"GET /profile HTTP/1.1\\\" 200 4096\" > /var/log/access.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{print $1}' /var/log/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, you will find a directory named \"logs\" containing multiple log files with a \".log\" extension. Each log file contains timestamped entries in the format \"YYYY-MM-DD HH:MM:SS - Message\". Your task is to determine how many unique days (in the format YYYY-MM-DD) appear across all log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to extract the date part of each entry from all \".log\" files within the \"logs\" directory. First, use `find` or `ls` to list all \".log\" files. Then, use tools like `cat`, `awk`, or `grep` to extract and sort these dates. Finally, use `uniq` to filter out duplicate dates and count how many unique dates appear.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all .log files in logs directory\nfind ~/logs/ -name \"*.log\" |\n\n# Concatenate all log files content together\nxargs cat |\n\n# Extract only the date part of each entry\nawk '{print $1}' |\n\n# Sort dates and filter out duplicates using uniq, then count them.\nsort | uniq | wc -l\n```",
        "create": {
            "init": "# Create logs directory and sample log files with timestamped entries\nmkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 - Start\\n2023-10-01 12:05:00 - Processed\\n2023-10-02 14:00:00 - End\" > ~/logs/log1.log\necho -e \"2023-10-02 09:30:00 - Init\\n2023-10-03 11:45:00 - Running\\n2023-10-03 17:20:00 - Completed\" > ~/logs/log2.log\necho -e \"2023-10-01 08:25:00 - Begin\\n2023-10-04 18:40:00 - Checkpoint\\n2023-10-04 19:15:00 - Finish\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# List all .log files in logs directory\nfind ~/logs/ -name \"*.log\" |\n\n# Concatenate all log files content together\nxargs cat |\n\n# Extract only the date part of each entry\nawk '{print $1}' |\n\n# Sort dates and filter out duplicates using uniq, then count them.\nsort | uniq | wc -l"
        }
    },
    {
        "description": "List all files in the directory `/var/log` that have been modified within the last 7 days and contain the string \"error\" in their contents. Count how many such files exist.",
        "explanation": "To solve this problem, you can use a combination of `find`, `grep`, and `wc`. First, use `find` to list files in `/var/log` that have been modified within the last 7 days. Then, use `grep` to filter these files for those containing the string \"error\". Finally, use `wc -l` to count how many such files exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -mtime -7 -exec grep -l \"error\" {} + | wc -l\n```",
        "create": {
            "init": "# No initialization is required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -mtime -7 -exec grep -l \"error\" {} + | wc -l"
        }
    },
    {
        "description": "Count the number of unique words across all text files in the \"documents\" directory, ignoring case sensitivity and punctuation.",
        "explanation": "To solve this problem, you need to iterate over all text files in the \"documents\" directory, process each file to remove punctuation, convert text to lowercase, and then count unique words. You can use utilities like `find`, `tr`, `sed`, and `awk` to manipulate and process the text files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Find all .txt files in the 'documents' directory.\nfind documents -type f -name \"*.txt\" | while read file; do \n  # Process each file: remove punctuation, convert to lowercase, split into words.\n  tr -d '[:punct:]' < \"$file\" | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n'\ndone | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create a 'documents' directory\nmkdir -p documents\n\n# Create sample text files with varying content\necho \"This is a sample document. It contains some words!\" > documents/doc1.txt\necho \"Another example document; it has different words.\" > documents/doc2.txt\necho \"Document three: Sample content again!\" > documents/doc3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Find all .txt files in the 'documents' directory.\nfind documents -type f -name \"*.txt\" | while read file; do \n  # Process each file: remove punctuation, convert to lowercase, split into words.\n  tr -d '[:punct:]' < \"$file\" | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n'\ndone | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"log_files\" in your home directory that contains multiple text files with server log entries. Each log entry in these files contains a timestamp, an error level (INFO, WARNING, ERROR), and a message. Your task is to count the total number of \"ERROR\" entries across all files in the \"log_files\" directory.",
        "explanation": "To solve this problem, you need to navigate to the \"log_files\" directory and search through each file for lines that contain the word \"ERROR\". You can use tools like `grep` to filter these lines and then count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-10-01 12:00:00 INFO Server started\\n2023-10-01 12:05:00 ERROR Failed to connect\\n2023-10-01 12:10:00 WARNING High memory usage\\n2023-10-01 12:15:00 ERROR Disk full\" > ~/log_files/server1.log\necho -e \"2023-10-02 14:00:00 INFO Connection established\\n2023-10-02 14:05:00 ERROR Timeout occurred\\n2023-10-02 14:10:00 INFO Data received\" > ~/log_files/server2.log\necho -e \"2023-10-03 16:30:00 WARNING CPU load high\\n2023-10-03 16:35:00 ERROR Network unreachable\\n2023-10-03 16:40:00 ERROR File not found\" > ~/log_files/server3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "You are required to find the total disk usage of all the text files (.txt) in your home directory and its subdirectories. The result should be a human-readable size, such as 1K, 2M, etc.",
        "explanation": "To solve this problem, you can use the `find` command to locate all `.txt` files in your home directory and its subdirectories. Then, use the `du` (disk usage) command with appropriate options to calculate their total disk usage in a human-readable format. The `-h` option in `du` will help you get the size in a readable format like 1K, 2M etc. Combining these commands with pipes will give you the desired result.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files and calculate their total disk usage.\nfind ~ -name \"*.txt\" -exec du -ch {} + | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "# Create some .txt files with random content and sizes for testing\nmkdir -p ~/test_dir/subdir1\nmkdir -p ~/test_dir/subdir2\n\necho \"Hello World!\" > ~/test_dir/file1.txt\nhead -c 1024 </dev/urandom > ~/test_dir/subdir1/file2.txt\nhead -c 2048 </dev/urandom > ~/test_dir/subdir2/file3.txt\n\n# Create some non-txt files to ensure they are not included in the count\necho \"This is a test.\" > ~/test_dir/file4.md\nhead -c 512 </dev/urandom > ~/test_dir/subdir1/file5.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "# Find all .txt files and calculate their total disk usage.\nfind ~ -name \"*.txt\" -exec du -ch {} + | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "Calculate the total size of all executable files in your home directory that were last modified more than 7 days ago.",
        "explanation": "To solve this problem, you need to find executable files in your home directory using `find`, filter them based on their modification time with the `-mtime` option, and then calculate their total size using `du` or other similar tools. You can use the `-executable` flag with `find` to ensure that only executable files are considered.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all executable files older than 7 days and calculate their total size in human-readable format.\ntotal_size=$(find ~ -type f -executable -mtime +7 -exec du -ch {} + | grep total$ | awk '{print $1}')\necho $total_size\n```",
        "create": {
            "init": "# Create some sample files in the home directory for testing\nmkdir -p ~/test_dir\ntouch ~/test_dir/file1.txt\nchmod +x ~/test_dir/file1.txt # Make it executable\n\ntouch ~/test_dir/file2.sh\nchmod +x ~/test_dir/file2.sh # Make it executable\n\necho \"Hello World\" > ~/test_dir/file3.py\nchmod +x ~/test_dir/file3.py # Make it executable\n\n# Set modification times to be older than 7 days for testing purposes\ntouch -d '10 days ago' ~/test_dir/file1.txt\ntouch -d '10 days ago' ~/test_dir/file2.sh\n\n# Set modification time to today for one file so it's not counted\ntouch -d 'today' ~/test_dir/file3.py"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "# Find all executable files older than 7 days and calculate their total size in human-readable format.\ntotal_size=$(find ~ -type f -executable -mtime +7 -exec du -ch {} + | grep total$ | awk '{print $1}')\necho $total_size"
        }
    },
    {
        "description": "Count the number of lines in all text files (*.txt) within your home directory that contain the word \"Linux\" (case-sensitive). Additionally, only consider files modified in the last 7 days.",
        "explanation": "To solve this problem, you need to identify all text files within the home directory. Use `find` to filter for files modified in the last 7 days and ending with `.txt`. Then use `grep` to count occurrences of \"Linux\" in each file. Sum these counts to get the final result.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files modified in the last 7 days and count lines containing 'Linux'\nfind ~ -name \"*.txt\" -mtime -7 | xargs grep -c 'Linux' | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "# Create some sample text files in the user's home directory for testing\necho \"This is a Linux tutorial.\" > ~/file1.txt\necho \"Learning Linux commands.\" > ~/file2.txt\necho \"The history of Linux is interesting.\" > ~/file3.txt\n# Modify dates for testing purposes, where file1.txt and file2.txt are modified within 7 days\ntouch -d '2 days ago' ~/file1.txt\ntouch -d '4 days ago' ~/file2.txt\ntouch -d '9 days ago' ~/file3.txt # This file should not be counted as it was modified more than 7 days ago."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files modified in the last 7 days and count lines containing 'Linux'\nfind ~ -name \"*.txt\" -mtime -7 | xargs grep -c 'Linux' | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "Find and count the number of files in your home directory that have been modified in the last 7 days and are larger than 1MB.",
        "explanation": "To solve this problem, you can use a combination of `find`, `-mtime`, and `-size` commands. The `find` command is useful for searching files based on different criteria such as modification time and file size. Use `-mtime -7` to filter files modified in the last 7 days and `-size +1M` to filter files larger than 1MB.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization script required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "In your home directory, there are several log files named `access.log.1`, `access.log.2`, ..., `access.log.n`. Each file contains multiple lines of web server access logs in the common log format. Your task is to count how many times the IP address `192.168.1.100` has accessed the server across all these log files.",
        "explanation": "To solve this problem, you need to search through all the provided log files for occurrences of the IP address `192.168.1.100`. You can use tools like `grep` to find occurrences of this IP address and then use `wc -l` to count the number of lines that contain this IP address.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Count occurrences of '192.168.1.100' in all access logs in home directory\ngrep '192\\.168\\.1\\.100' ~/access.log.* | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create sample log files in the home directory for testing\necho -e \"192.168.1.100 - - [10/Oct/2023:13:55:36 +0000] \\\"GET /index.html HTTP/1.0\\\" 200 2326\\n192.168.2.101 - - [10/Oct/2023:13:55:37 +0000] \\\"POST /form HTTP/1.0\\\" 404 299\" > ~/access.log.1\necho -e \"172.16.0.5 - - [10/Oct/2023:14:00:01 +0000] \\\"GET /about.html HTTP/1.0\\\" 200 1234\\n192.168.1.100 - - [10/Oct/2023:14:00:02 +0000] \\\"GET /contact.html HTTP/1.0\\\" 200 5678\" > ~/access.log.2\necho -e \"192.168.x.x - - [10/Oct/2023:14:05:00 +0000] \\\"GET /home.html HTTP/1.x\\\" 500\\n192.xx.xxx.xx.xxxx\" > ~/access.log.n"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Count occurrences of '192.168.1.100' in all access logs in home directory\ngrep '192\\.168\\.1\\.100' ~/access.log.* | wc -l"
        }
    },
    {
        "description": "You need to determine how many lines in the file \"logs.txt\" contain the word \"ERROR\". The file is located in your home directory.",
        "explanation": "To solve this problem, you can use tools like `grep` to search for the word \"ERROR\" within the file and then use `wc -l` to count the number of lines that contain this word.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count lines containing 'ERROR'\ngrep -c 'ERROR' ~/logs.txt\n```",
        "create": {
            "init": "# Create a test file with some log entries\ncat <<EOT > ~/logs.txt\nINFO: This is an information message.\nERROR: An error has occurred.\nWARNING: This is a warning message.\nERROR: Another error encountered.\nINFO: All systems are operational.\nEOT"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count lines containing 'ERROR'\ngrep -c 'ERROR' ~/logs.txt"
        }
    },
    {
        "description": "Find the total number of lines across all `.txt` files in your home directory that contain the word \"Linux\", regardless of case.",
        "explanation": "You can solve this problem by using a combination of shell commands. Start by searching for all `.txt` files in your home directory, then use `grep` with the `-i` flag to perform a case-insensitive search for the word \"Linux\". Finally, count the number of lines returned from this search.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\ngrep -i 'linux' ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample .txt files in the home directory for testing\necho -e \"Linux is great.\\nUbuntu is a Linux distro.\" > ~/file1.txt\necho -e \"I love using Linux.\\nLINUX is powerful.\" > ~/file2.txt\necho -e \"This file mentions nothing about Linux.\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\ngrep -i 'linux' ~/file*.txt | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all '.txt' files located within the 'documents' directory and its subdirectories, ensuring you do not include any empty lines in your count.",
        "explanation": "To solve this problem, you need to traverse through the 'documents' directory and its subdirectories to locate all '.txt' files. You can use `find` command to simplify locating these files. Then, utilize tools like `grep` or `awk` to filter out empty lines while counting.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind documents -type f -name '*.txt' | xargs grep -v '^$' | wc -l\n```",
        "create": {
            "init": "mkdir -p documents/subdir1 documents/subdir2\necho -e \"Hello World\\n\\nThis is a test file.\\n\" > documents/file1.txt\necho -e \"\\nAnother file with some text.\\nAnd another line.\" > documents/subdir1/file2.txt\necho -e \"Text file in another subdirectory.\\n\\nLast non-empty line.\" > documents/subdir2/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find documents -type f -name '*.txt' | xargs grep -v '^$' | wc -l"
        }
    },
    {
        "description": "Count the number of files in the directory `/var/log` that have been modified in the last 7 days.",
        "explanation": "To solve this problem, you need to interact with the shell to list files in `/var/log`, filter out those modified in the last 7 days, and count them. You can use utilities like `find` with `-mtime` option to help achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization needed for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the string \"ERROR\" across all text files in your home directory. The search should be case-insensitive.",
        "explanation": "To solve this problem, you need to use a combination of `grep` and `wc` commands. The `grep` command can be used with the `-i` option to perform a case-insensitive search for the term \"ERROR\". You can use wildcards to specify that all `.txt` files in your home directory should be searched. Finally, pipe the output of `grep` into `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i \"ERROR\" ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample text files with varying content in the user's home directory.\necho -e \"This is an error.\\nAll is well.\" > ~/file1.txt\necho -e \"Something went wrong.\\nERROR detected!\" > ~/file2.txt\necho -e \"Error here.\\nAnother line.\" > ~/file3.txt\necho -e \"No issues.\\nerror found.\" > ~/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i \"ERROR\" ~/file*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all text files located within the directory \"/home/student/documents\" that contain the word \"Linux\", regardless of case sensitivity.",
        "explanation": "To solve this problem, you need to search for the word \"Linux\" in each text file within the specified directory. Using tools like `grep` with case-insensitive options will help you to find occurrences of \"Linux\". You can use `wc -l` to count the lines containing matches found by `grep`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'linux' /home/student/documents/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho -e \"This is a Linux tutorial.\\nWelcome to Ubuntu.\" > /home/student/documents/file1.txt\necho -e \"Learn linux commands.\\nMastering Linux is fun.\" > /home/student/documents/file2.txt\necho -e \"Operating systems are crucial.\" > /home/student/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'linux' /home/student/documents/*.txt | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" containing multiple log files with extensions \".log\". Count and return the number of lines in all the .log files combined that contain the word \"ERROR\".",
        "explanation": "To solve this problem, you need to iterate through each file in the \"log_files\" directory that has a \".log\" extension. For each file, use tools like `grep` to filter out lines containing the word \"ERROR\". Then, count these lines using `wc -l`, and finally sum up the counts from all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h \"ERROR\" log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p log_files\necho -e \"INFO: All systems operational\\nERROR: Failed to connect to server\\nINFO: Connection successful\" > log_files/server.log\necho -e \"WARNING: Disk space low\\nERROR: Out of memory\\nINFO: Memory allocation successful\" > log_files/memory.log\necho -e \"INFO: User login successful\\nERROR: Permission denied\\nINFO: Logout successful\" > log_files/auth.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h \"ERROR\" log_files/*.log | wc -l"
        }
    },
    {
        "description": "Determine the total number of lines containing the word \"error\" across all `.log` files in the `/var/logs` directory. You may not use any third-party utilities or packages.",
        "explanation": "To solve this problem, you will need to iterate over each `.log` file within the `/var/logs` directory and count how many lines contain the word \"error\". You can achieve this using a combination of bash commands such as `grep` for pattern searching and `wc -l` for counting lines. You may need to ensure that your command handles multiple files and aggregates their counts appropriately.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Count total number of lines containing 'error' across all .log files in /var/logs\ngrep -i 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Creating /var/logs directory if it doesn't exist\nmkdir -p /var/logs\n\n# Creating sample .log files with some content\necho -e \"This is an error\\nEverything is fine\\nAnother error found\" > /var/logs/app1.log\necho -e \"No issues here\\nError detected\\nAll good\" > /var/logs/app2.log\necho -e \"Error, something went wrong\\nNo error here\\nYet another error\" > /var/logs/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Count total number of lines containing 'error' across all .log files in /var/logs\ngrep -i 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing various log files with random names. Count the total number of lines across all \".log\" files in this directory that contain the word \"ERROR\", case-insensitively.",
        "explanation": "To solve this problem, you need to list all \".log\" files in the \"logs\" directory, search for lines containing the word \"ERROR\" (in any case) within these files, and count those lines. You can use tools like `find`, `grep`, and `wc` in combination to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -name \"*.log\" | xargs grep -i 'ERROR' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"This is a test log.\\nERROR found here.\\nAnother error line.\\nerror again.\" > ~/logs/test1.log\necho -e \"No errors here.\\nJust some info.\" > ~/logs/test2.log\necho -e \"Here's an error line!\\nAnd another ERROR\\nFinal error statement.\" > ~/logs/test3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -name \"*.log\" | xargs grep -i 'ERROR' | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in the `/var/logs/` directory that contain the word \"error\". You should consider files only in the specified directory, not in any subdirectories.",
        "explanation": "To solve this problem, you need to filter lines containing the word \"error\" from each `.txt` file in the `/var/logs/` directory and count them. You can use tools like `grep` to find matching lines and `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' /var/logs/*.txt | wc -l\n```",
        "create": {
            "init": "# Creating /var/logs directory and some sample text files\nmkdir -p /var/logs/\necho -e \"This is a test log\\nAn error occurred\\nAnother line\" > /var/logs/file1.txt\necho -e \"Error found here\\nNo issues\\nError again\" > /var/logs/file2.txt\necho -e \"Everything is fine\\nError detected\" > /var/logs/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' /var/logs/*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of files (excluding directories) in your home directory that contain the string \"TODO\" anywhere in their contents. This should include hidden files as well.",
        "explanation": "To solve this problem, you need to search through all the files in your home directory, including hidden ones, and check for the presence of the string \"TODO\". You can use tools like `grep` to search for strings within files and `find` to list all files excluding directories. Combining these utilities will help you count the occurrences efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all files (excluding directories) in the home directory and subdirectories\n# Use grep to search for the string \"TODO\" within each file\n# Count how many such files exist\n\nfind ~/ -type f -exec grep -l \"TODO\" {} + | wc -l\n```",
        "create": {
            "init": "# No initialization is required as students will be using their own home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all files (excluding directories) in the home directory and subdirectories\n# Use grep to search for the string \"TODO\" within each file\n# Count how many such files exist\n\nfind ~/ -type f -exec grep -l \"TODO\" {} + | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory. This directory contains multiple log files with a \".log\" extension. Your task is to count the total number of lines across all log files that contain the word \"ERROR\". Ignore case while searching for the word \"ERROR\".",
        "explanation": "To solve this problem, you need to navigate to the \"log_files\" directory and search for all files with the \".log\" extension. You can use tools like `grep` with the `-i` option to ignore case sensitivity and count lines containing \"ERROR\". The `wc -l` command will be helpful in counting these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Navigate to the log_files directory \ncd ~/log_files\n\n# Count all lines containing 'ERROR', ignoring case, across all .log files\ngrep -i 'ERROR' *.log | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create a directory called log_files in the home directory\nmkdir -p ~/log_files\n\n# Create sample log files with some content\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nWarning: CPU usage high\" > ~/log_files/system1.log\necho -e \"error: Network connection lost\\nINFO: Backup completed\\nERROR: Memory leak detected\" > ~/log_files/system2.log\necho -e \"INFO: User login successful\\nerror: Unauthorized access attempt\\nWARNING: Firewall breach\" > ~/log_files/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Navigate to the log_files directory \ncd ~/log_files\n\n# Count all lines containing 'ERROR', ignoring case, across all .log files\ngrep -i 'ERROR' *.log | wc -l"
        }
    },
    {
        "description": "Count the total number of files (not directories) in your home directory and all its subdirectories, but exclude any files within directories named \"backup\" from the count.",
        "explanation": "To solve this problem, you need to recursively list all files in your home directory while excluding those within \"backup\" directories. You can achieve this using the `find` command with appropriate flags to exclude certain paths. The `-type f` option will help you target only files, and `-prune` can be used to skip over \"backup\" directories.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\nfind ~ -type d -name 'backup' -prune -o -type f -print | wc -l\n```",
        "create": {
            "init": "# No initialization required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\nfind ~ -type d -name 'backup' -prune -o -type f -print | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"projects\" containing multiple subdirectories, each representing a separate project. Each project subdirectory contains several files of varying types and sizes. Your task is to determine the total size of all \".log\" files across all project subdirectories. Provide the answer in human-readable form (e.g., KB, MB).",
        "explanation": "To solve this problem, you should navigate through each subdirectory in the \"projects\" folder and identify all files with the \".log\" extension. You can use utilities like `find` to locate these files and then use `du` or similar commands to calculate their cumulative size. Finally, convert this size into a human-readable format.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all .log files in 'projects' directory and calculate total size in human-readable format\nfind ~/projects -type f -name \"*.log\" -exec du -ch {} + | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create the projects directory\nmkdir -p ~/projects/project1\nmkdir -p ~/projects/project2\nmkdir -p ~/projects/project3\n\n# Create some random .log files with different sizes\ndd if=/dev/zero of=~/projects/project1/app.log bs=512 count=20\ndd if=/dev/zero of=~/projects/project1/error.log bs=512 count=30\n\ndd if=/dev/zero of=~/projects/project2/server.log bs=1024 count=5\ndd if=/dev/zero of=~/projects/project2/access.log bs=1024 count=10\n\ndd if=/dev/zero of=~/projects/project3/debug.log bs=256 count=40"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all .log files in 'projects' directory and calculate total size in human-readable format\nfind ~/projects -type f -name \"*.log\" -exec du -ch {} + | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days.",
        "explanation": "To solve this problem, you can use the `find` command with the `-mtime` option to filter files based on their modification time. The `-type f` option ensures that only regular files are counted, excluding directories or special files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Using the find command to count files modified in the last 7 days.\nfind ~/ -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization needed, as students will work with their own home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Using the find command to count files modified in the last 7 days.\nfind ~/ -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden directory named `.project_files` containing several text files. Count how many lines contain the word \"error\" across all files within this hidden directory.",
        "explanation": "To solve this problem, you need to locate the hidden `.project_files` directory in your home directory and use commands like `grep` to search for the word \"error\" in all text files within that directory. You can use `grep -c` to count the occurrences per file and then sum them up.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -roh 'error' ~/.project_files | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_files\necho -e \"This is a test line.\\nAn error occurred.\\nAnother line without an error.\" > ~/project_files/file1.txt\necho -e \"Error found here.\\nNo issues here.\" > ~/project_files/file2.txt\necho -e \"Nothing wrong here.\\nYet another error line.\" > ~/project_files/file3.txt\nmv ~/project_files ~/.project_files  # Make it a hidden directory"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -roh 'error' ~/.project_files | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with a \".log\" extension. Each log file contains timestamps and error messages. Your task is to find the most frequently occurring error message across all these log files.",
        "explanation": "To solve this problem, you need to perform the following steps:\n1. List all the \".log\" files in the \"logs\" directory.\n2. Extract all error messages from each file (ignoring timestamps).\n3. Count the frequency of each error message.\n4. Identify and output the most frequently occurring error message.\n\nHints:\n- Use `grep` or `awk` to extract error messages.\n- Use `sort` and `uniq -c` to count occurrences.\n- Use `sort -nr` to sort by frequency in descending order.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Combine all errors from log files into one list, stripping timestamps\ngrep 'Error:' ~/logs/*.log | awk '{$1=$2=\"\"; print $0}' | sort | uniq -c | sort -nr | head -n 1 | awk '{$1=\"\"; print $0}'\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create logs directory\nmkdir -p ~/logs\n\n# Generate sample log files with timestamps and random errors\necho -e \"2023-10-01 12:00:00 Error: File not found\\n2023-10-01 12:01:00 Error: Network timeout\\n2023-10-01 12:02:00 Error: File not found\" > ~/logs/log1.log\necho -e \"2023-10-02 13:00:00 Error: Disk full\\n2023-10-02 13:01:00 Error: File not found\\n2023-10-02 13:02:00 Error: Disk full\" > ~/logs/log2.log\necho -e \"2023-10-03 14:00:00 Error: Network timeout\\n2023-10-03 14:01:00 Error: File not found\\n2023-10-03 14:02:00 Error: File not found\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Combine all errors from log files into one list, stripping timestamps\ngrep 'Error:' ~/logs/*.log | awk '{$1=$2=\"\"; print $0}' | sort | uniq -c | sort -nr | head -n 1 | awk '{$1=\"\"; print $0}'"
        }
    },
    {
        "description": "Count how many files in your home directory have a \".txt\" extension and were modified in the last seven days.",
        "explanation": "To solve this problem, you need to search for files with a \".txt\" extension within your home directory. You can use the `find` command to filter files based on their modification time using the `-mtime` option. Specifically, use `-mtime -7` to find files modified in the last seven days.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# The example solution script that counts .txt files modified in the last seven days.\nfind ~/test_directory -name \"*.txt\" -mtime -7 | wc -l\n```",
        "create": {
            "init": "# This script initializes the environment by creating some .txt files\n# in the student's home directory with various modification times.\nmkdir -p ~/test_directory\ntouch ~/test_directory/file1.txt ~/test_directory/file2.txt \n# Modify file1.txt to change its modification date to within last 7 days\ntouch -d '2 days ago' ~/test_directory/file1.txt\n# Modify file2.txt to change its modification date to older than 7 days\ntouch -d '10 days ago' ~/test_directory/file2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# The example solution script that counts .txt files modified in the last seven days.\nfind ~/test_directory -name \"*.txt\" -mtime -7 | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory containing multiple log files. Some of these files contain the word \"ERROR\". Count how many lines contain the word \"ERROR\" across all files in the \"log_files\" directory.",
        "explanation": "To solve this problem, you need to iterate over each file in the \"log_files\" directory, search for lines containing the word \"ERROR\", and count them. You can use tools like `grep` to find matching lines and `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/log_files | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"INFO: System started\\nERROR: Disk failure\\nINFO: Task completed\" > ~/log_files/log1.txt\necho -e \"WARNING: Low memory\\nERROR: Network issue\\nERROR: Timeout occurred\" > ~/log_files/log2.txt\necho -e \"INFO: User login\\nINFO: File accessed\\nERROR: Unauthorized access attempt\" > ~/log_files/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/log_files | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all `.txt` files located in the `texts` directory within your home directory, excluding any empty lines.",
        "explanation": "To solve this problem, you need to navigate to the `texts` directory in your home directory and use tools like `find` to locate all `.txt` files. Next, use `grep` or `awk` to exclude empty lines and count the remaining lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/texts -type f -name \"*.txt\" | xargs grep -v '^$' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/texts\necho \"Hello world\" > ~/texts/file1.txt\necho \"\" > ~/texts/file2.txt\necho \"This is a test\" > ~/texts/file3.txt\necho \"Another line\" > ~/texts/file4.txt\necho \"\" >> ~/texts/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/texts -type f -name \"*.txt\" | xargs grep -v '^$' | wc -l"
        }
    },
    {
        "description": "Count the total number of words across all text files in your home directory, excluding any files that begin with \"temp_\". You must also exclude any hidden files (those starting with a dot).",
        "explanation": "To solve this problem, you can use a combination of `find`, `grep`, and `wc` commands. First, use `find` to list all non-hidden text files in your home directory that do not start with \"temp_\". Then, use `xargs` to pass these filenames to `grep` which will count the words using `wc -w`. Finally, sum up the word counts from each file.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all non-hidden text files excluding those starting with 'temp_' and count their words.\nfind ~/test_text_files -type f ! -name \".hidden*\" ! -name \"temp_*\" | xargs grep -h . | wc -w\n```",
        "create": {
            "init": "# Create sample text files in the user's home directory\nmkdir -p ~/test_text_files\n\necho \"This is a sample file with several words.\" > ~/test_text_files/sample1.txt\necho \"Another example text file.\" > ~/test_text_files/sample2.txt\necho \"Yet another file containing different words.\" > ~/test_text_files/sample3.txt\n\n# Hidden and temp files should not be counted\necho \"This hidden file should not be counted.\" > ~/test_text_files/.hiddenfile.txt\necho \"Temporary file content that shouldn't be included.\" > ~/test_text_files/temp_file.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all non-hidden text files excluding those starting with 'temp_' and count their words.\nfind ~/test_text_files -type f ! -name \".hidden*\" ! -name \"temp_*\" | xargs grep -h . | wc -w"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all \".log\" files within the \"logs\" directory located in your home directory.",
        "explanation": "To solve this problem, you need to use shell commands to navigate into the \"logs\" directory and search through all \".log\" files for occurrences of the word \"error\". You can use tools like `grep` to filter these lines and `wc` to count them. Remember that you should only count lines where \"error\" appears, not just files that contain it.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"This is an info message\\nThis is an error message\\nAnother error occurred\\nInfo again\" > ~/logs/app1.log\necho -e \"Error found\\nNothing wrong here\\nYet another error line\\nFinal info line\" > ~/logs/app2.log\necho -e \"Random text\\nMore random stuff\\nNo errors here\" > ~/logs/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files located in your home directory, ignoring any empty lines.",
        "explanation": "To solve this problem, you should use a combination of shell commands to navigate to your home directory, find all `.txt` files, and then read their contents to count the non-empty lines. You can use tools like `find` to locate files, and `grep` or `awk` to filter out empty lines while counting.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script that counts non-empty lines in all .txt files in the home directory.\nfind ~ -name \"*.txt\" -exec grep -v '^$' {} \\; | wc -l\n```",
        "create": {
            "init": "# Create sample .txt files with varying number of lines in the user's home directory for testing purposes.\necho -e \"Line 1\\nLine 2\\n\\nLine 4\" > ~/file1.txt\necho -e \"\\n\\nLine A\\nLine B\" > ~/file2.txt\necho -e \"Hello World\\n\\nLinux OS\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script that counts non-empty lines in all .txt files in the home directory.\nfind ~ -name \"*.txt\" -exec grep -v '^$' {} \\; | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" which contains multiple text files with various system log entries. Your task is to count the number of occurrences of the word \"error\" across all files in the \"logs\" directory, regardless of case sensitivity.",
        "explanation": "To solve this problem, you need to use several shell utilities. First, you can concatenate all files in the \"logs\" directory using `cat`. Then, you can use `grep` with the `-i` flag for case-insensitive search to find lines containing the word \"error\". Finally, use `wc -l` to count these occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat logs/* | grep -i error | wc -l\n```",
        "create": {
            "init": "mkdir logs\necho -e \"Info: system started\\nError: failed to load module\\nWarning: low memory\" > logs/log1.txt\necho -e \"Error: disk not found\\nInfo: operation successful\\nerror: network timeout\" > logs/log2.txt\necho -e \"warning: high cpu usage\\ninfo: backup complete\\nERROR: unauthorized access\" > logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat logs/* | grep -i error | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all \".log\" files within the \"/var/logs/\" directory, excluding any files that are empty.",
        "explanation": "To solve this problem, you need to navigate to the \"/var/logs/\" directory and use a combination of bash utilities such as `find`, `grep`, and `wc` to count the lines. First, use `find` to list all \".log\" files that are non-empty. Then, use `grep` with the pattern \"error\" across these files to filter relevant lines. Finally, pipe the output to `wc -l` to count the number of matched lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all non-empty .log files and count lines containing 'error'\nfind /var/logs/ -type f -name \"*.log\" ! -size 0 | xargs grep -i \"error\" | wc -l\n```",
        "create": {
            "init": "# Create /var/logs directory\nmkdir -p /var/logs\n\n# Create some log files with content\necho -e \"error: failed connection\\ninfo: connection established\\nwarning: retrying...\" > /var/logs/system.log\necho -e \"info: user logged in\\nerror: disk full\\ninfo: disk cleaned\" > /var/logs/user.log\necho -e \"\" > /var/logs/empty.log # Empty file should be excluded\n\n# Additional non-error logs\necho -e \"info: process started\\nwarning: low memory\" > /var/logs/process.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all non-empty .log files and count lines containing 'error'\nfind /var/logs/ -type f -name \"*.log\" ! -size 0 | xargs grep -i \"error\" | wc -l"
        }
    },
    {
        "description": "Determine the total number of lines contained within all \".txt\" files located in your home directory, but exclude any lines that contain only whitespace.",
        "explanation": "To solve this problem, you need to iterate over all \".txt\" files in your home directory, count the total number of non-whitespace lines in each file, and finally sum these counts. You can use utilities like `find`, `grep`, and `wc` to accomplish this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files in the home directory, count non-whitespace lines and sum them up.\nfind ~ -type f -name \"*.txt\" | xargs grep -v '^\\s*$' | wc -l\n```",
        "create": {
            "init": "# Create sample .txt files containing various lines including whitespace\nmkdir -p ~/example_directory\necho -e \"Line 1\\nLine 2\\n \\nLine 3\" > ~/example_directory/file1.txt\necho -e \"\\n\\nWhitespace only line\\nAnother line\" > ~/example_directory/file2.txt\necho -e \"Non-empty line\\n \\nAnother non-empty line\" > ~/example_directory/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files in the home directory, count non-whitespace lines and sum them up.\nfind ~ -type f -name \"*.txt\" | xargs grep -v '^\\s*$' | wc -l"
        }
    },
    {
        "description": "You are tasked with finding out which user has the largest number of files in their home directory. Traverse through each user's home directory located under `/home` and count the number of files (not directories) each user owns. You should ignore hidden files (those starting with a dot). Determine the username of the user with the most files.",
        "explanation": "To solve this problem, you need to iterate over each directory inside `/home`, which corresponds to a user's home directory. For each home directory, count all non-hidden regular files. Use tools like `find` to locate files and `wc -l` to count them, ignoring directories and hidden files. Compare counts across users to find the one with the highest number of files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example script to find which user has the most number of regular non-hidden files\n\nmax_files=0\nuser_with_max=\"\"\n\nfor dir in /home/*; do\n    if [ -d \"$dir\" ]; then\n        user=$(basename \"$dir\")\n        file_count=$(find \"$dir\" -maxdepth 1 -type f ! -name '.*' | wc -l)\n        \n        if [ \"$file_count\" -gt \"$max_files\" ]; then\n            max_files=$file_count\n            user_with_max=$user\n        fi\n    fi\ndone\n\necho \"$user_with_max\"\n```",
        "create": {
            "init": "# Create sample user directories and files for testing\nmkdir -p /home/user1 /home/user2 /home/user3\n\n# Create some test files in each user's home directory\ntouch /home/user1/file1.txt /home/user1/file2.txt\ntouch /home/user2/file1.txt /home/user2/file2.txt /home/user2/file3.txt\ntouch /home/user3/file1.txt\n\n# Ensure no hidden files are created for simplicity"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "# Example script to find which user has the most number of regular non-hidden files\n\nmax_files=0\nuser_with_max=\"\"\n\nfor dir in /home/*; do\n    if [ -d \"$dir\" ]; then\n        user=$(basename \"$dir\")\n        file_count=$(find \"$dir\" -maxdepth 1 -type f ! -name '.*' | wc -l)\n        \n        if [ \"$file_count\" -gt \"$max_files\" ]; then\n            max_files=$file_count\n            user_with_max=$user\n        fi\n    fi\ndone\n\necho \"$user_with_max\""
        }
    },
    {
        "description": "Count the total number of files in the `/var/log` directory that have been modified in the last 7 days, excluding directories and symbolic links.",
        "explanation": "To solve this problem, you can use the `find` command to search for files in `/var/log` that have been modified within the last 7 days. Use the `-type f` flag to exclude directories and symbolic links from your count.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required for this task"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all `.log` files located in the `/var/log/experiments/` directory. Ensure that you only count lines from files modified within the last 7 days.",
        "explanation": "To solve this problem, you'll need to first list all `.log` files in the `/var/log/experiments/` directory. Next, filter these files to only include those modified within the last 7 days using `find`. Then use `grep` to search for lines containing the word \"error\" and count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files modified within the last 7 days and count lines with 'error'\nfind /var/log/experiments/*.log -mtime -7 -exec grep -i \"error\" {} \\; | wc -l\n```",
        "create": {
            "init": "# Create a directory for log files\nmkdir -p /var/log/experiments/\n\n# Create log files with various modification dates\ntouch /var/log/experiments/app1.log\ntouch /var/log/experiments/app2.log\ntouch /var/log/experiments/app3.log\n\n# Modify some of them to simulate activity within the last 7 days\necho \"This is an error message\" >> /var/log/experiments/app1.log\necho \"Everything is fine\" >> /var/log/experiments/app2.log\necho \"Error: Something went wrong\" >> /var/log/experiments/app3.log\n\n# Adjust modification times (setting app1 and app3 within last 7 days)\ntouch -d '2 days ago' /var/log/experiments/app1.log\ntouch -d '10 days ago' /var/log/experiments/app2.log\ntouch -d '5 days ago' /var/log/experiments/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files modified within the last 7 days and count lines with 'error'\nfind /var/log/experiments/*.log -mtime -7 -exec grep -i \"error\" {} \\; | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in the `/home/student/documents` directory, excluding any lines that contain the word \"error\".",
        "explanation": "To solve this problem, you need to use a combination of utilities such as `grep`, `wc`, and potentially others. You can achieve this by first filtering out lines containing \"error\" using `grep -v`, then counting the remaining lines using `wc -l`. It requires iterating over multiple files, so utilizing loops or find commands may be necessary.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all .txt files and count lines excluding those containing 'error'\nfind /home/student/documents -type f -name \"*.txt\" | xargs grep -v 'error' | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create the directory if it doesn't exist\nmkdir -p /home/student/documents\n\n# Create example .txt files with various contents\necho -e \"This is a test file.\\nNo errors here.\\nAll good.\" > /home/student/documents/file1.txt\necho -e \"Another file.\\nOops, an error occurred.\\nLet's fix it.\" > /home/student/documents/file2.txt\necho -e \"Final check.\\nEverything is fine.\\nNo mistakes.\" > /home/student/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all .txt files and count lines excluding those containing 'error'\nfind /home/student/documents -type f -name \"*.txt\" | xargs grep -v 'error' | wc -l"
        }
    },
    {
        "description": "Count the number of unique IP addresses that have accessed the web server from the log file located at `/var/log/apache2/access.log`. Assume that each entry in the log file starts with an IP address and is space-separated.",
        "explanation": "To solve this problem, you need to extract IP addresses from each line of the log file and count the number of unique IPs. You can use utilities like `awk` or `cut` to isolate the IP address from each line, and then use `sort` and `uniq` to get a count of unique addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{print $1}' /var/log/apache2/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a mock access log file with simulated entries.\nmkdir -p /var/log/apache2\ncat <<EOT > /var/log/apache2/access.log\n192.168.1.1 - - [10/Oct/2023:14:00:00 +0000] \"GET /index.html HTTP/1.1\" 200 2326\n192.168.1.2 - - [10/Oct/2023:14:02:00 +0000] \"POST /form HTTP/1.1\" 404 512\n192.168.1.3 - - [10/Oct/2023:14:03:00 +0000] \"GET /image.png HTTP/1.1\" 200 1024\n192.168.1.4 - - [10/Oct/2023:14:04:00 +0000] \"PUT /upload HTTP/1.1\" 201 3456\n192.168.1.2 - - [10/Oct/2023:14:05:00 +0000] \"GET /contact.html HTTP/1.1\" 200 789\n192.168.1.5 - - [10/Oct/2023:14:06:00 +0000] \"DELETE /remove HTTP/1.0\" 204 -\n192.168.1.4 - - [10/Oct/2023:14:07:00 +0000] \"GET /home.html HTTP/2\" 200 2345\nEOT"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{print $1}' /var/log/apache2/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing various .log files. Some of these files are larger than 1MB, while others are smaller. Count how many .log files are larger than 1MB and output the count.",
        "explanation": "To solve this problem, you need to use the `find` command to locate all .log files within the \"log_files\" directory that exceed a size of 1MB. You can apply the `-size` option with `+1M` to filter out files larger than 1MB. Then, use `wc -l` to count the number of matching lines returned by `find`, which corresponds to the number of .log files meeting the criteria.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find and count .log files larger than 1MB in log_files directory\nfind ~/log_files -type f -name \"*.log\" -size +1M | wc -l\n```",
        "create": {
            "init": "# Create log_files directory and generate sample log files\nmkdir -p ~/log_files\n# Create sample log files with varying sizes\nfallocate -l 500K ~/log_files/small1.log\nfallocate -l 2M ~/log_files/large1.log\nfallocate -l 3M ~/log_files/large2.log\nfallocate -l 200K ~/log_files/small2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find and count .log files larger than 1MB in log_files directory\nfind ~/log_files -type f -name \"*.log\" -size +1M | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" located in your home directory containing multiple log files with \".log\" extension. Count the total number of lines containing the word \"ERROR\" across all log files in this directory.",
        "explanation": "To solve this problem, you need to search through each log file in the \"log_files\" directory and count the lines that contain the word \"ERROR\". You can use utilities such as `grep` to filter these lines and `wc` to count them. Ensure that you are searching only within files with \".log\" extensions.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Use grep to find lines containing 'ERROR' and wc to count them across all .log files\ngrep -r 'ERROR' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create a directory named 'log_files' in the home directory\nmkdir -p ~/log_files\n\n# Create sample log files with some content\necho -e \"INFO: System started\\nERROR: Missing file\\nINFO: User logged in\\nERROR: Disk full\" > ~/log_files/system.log\necho -e \"DEBUG: Variable initialized\\nERROR: Network down\\nDEBUG: Connection established\\nINFO: Shutdown initiated\" > ~/log_files/network.log\necho -e \"WARNING: Low memory\\nINFO: Process completed successfully\\nERROR: Unauthorized access attempt\\nINFO: Backup completed\" > ~/log_files/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Use grep to find lines containing 'ERROR' and wc to count them across all .log files\ngrep -r 'ERROR' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "Count the number of files in the `/var/log` directory that have been modified in the last 7 days. You should exclude directories from your count.",
        "explanation": "To solve this problem, you need to utilize the `find` command with appropriate options to filter files based on their modification time and exclude directories. Use `-type f` to ensure only files are counted, and `-mtime -7` to find files modified within the last 7 days.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization is required."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory which contains multiple log files with the \".log\" extension. Each log file consists of multiple lines, and each line has a timestamp followed by a log message. You need to count the total number of unique error messages across all log files within this directory. An error message is identified by any line containing the word \"ERROR\". Ignore case while counting unique messages.",
        "explanation": "To solve this problem, you should first navigate to the \"log_files\" directory. Then, use a combination of bash commands to extract lines containing the word \"ERROR\", ignoring case sensitivity. After extracting these lines, filter out only the unique messages (excluding timestamps). You can achieve this through text processing utilities like `grep`, `cut`, `sort`, and `uniq`. Finally, count these unique messages.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/log_files\ngrep -i 'ERROR' *.log | cut -d' ' -f4- | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\ncat <<EOL > ~/log_files/log1.log\n2023-10-01 12:00:01 ERROR Disk full on /dev/sda1\n2023-10-01 12:05:01 WARNING High memory usage detected\n2023-10-01 12:10:01 ERROR Disk full on /dev/sda1\nEOL\n\ncat <<EOL > ~/log_files/log2.log\n2023-10-02 13:00:01 INFO Backup completed successfully\n2023-10-02 13:05:01 ERROR Network connection lost\n2023-10-02 13:10:01 ERROR Disk full on /dev/sda1\nEOL\n\ncat <<EOL > ~/log_files/log3.log\n2023-10-03 14:00:01 ERROR Network connection lost\n2023-10-03 14:05:01 WARNING CPU temperature high\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/log_files\ngrep -i 'ERROR' *.log | cut -d' ' -f4- | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a large directory structure within your home directory named `project_files`. Your task is to find and count all the files that have been modified in the last 7 days and have a file size greater than 1MB. Output just the number of such files.",
        "explanation": "To solve this problem, you need to use the `find` command to search through the `project_files` directory. You will use options like `-mtime -7` to filter files modified within the last 7 days, and `-size +1M` to filter files with sizes greater than 1MB. Combining these filters with logical operators, you can count the matching files using additional commands like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/project_files -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_files\n\n# Create some test files with varying modification times and sizes\ntouch ~/project_files/file1.txt\ndd if=/dev/zero of=~/project_files/file2.txt bs=1024 count=1024  # exactly 1MB\n\n# Modify file time to be older than 7 days\ntouch -d '10 days ago' ~/project_files/file2.txt\n\n# Create more recent files\ndd if=/dev/zero of=~/project_files/recent_large_file.txt bs=1024 count=1500 # >1MB\ntouch ~/project_files/recent_small_file.txt\n\n# Modify time for recent_large_file to be within last week\ntouch -d '3 days ago' ~/project_files/recent_large_file.txt\n\n# Ensure some small file is also recent but less than 1MB\ntouch -d '2 days ago' ~/project_files/recent_small_file.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/project_files -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing various log files. Each file has a naming convention of \"log-YYYY-MM-DD.txt\". Your task is to count the total number of lines across all log files that contain the word \"ERROR\" and were modified within the last 7 days.",
        "explanation": "To solve this problem, you need to use several bash utilities. First, you should identify the log files modified within the last 7 days using `find`. Then, for each file identified, use `grep` to filter out lines containing the word \"ERROR\". Finally, use `wc -l` to count these lines across all identified files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -mtime -7 | xargs grep 'ERROR' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ntouch ~/logs/log-2023-10-01.txt\necho -e \"INFO: System started\\nERROR: Disk full\\nINFO: Reboot required\" >> ~/logs/log-2023-10-01.txt\ntouch ~/logs/log-2023-10-03.txt\necho -e \"ERROR: Network unreachable\\nINFO: Update complete\\nERROR: Disk full\" >> ~/logs/log-2023-10-03.txt\ntouch ~/logs/log-2023-10-05.txt\necho -e \"INFO: User login\\nERROR: File not found\\nERROR: Permission denied\" >> ~/logs/log-2023-10-05.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -mtime -7 | xargs grep 'ERROR' | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"system_logs\" in your home directory, which contains multiple log files with the extension \".log\". Each log file has entries formatted as \"YYYY-MM-DD HH:MM:SS [LEVEL] message\", where LEVEL can be INFO, WARNING, or ERROR. Your task is to count the total number of ERROR entries across all log files and output this number.",
        "explanation": "To solve this problem, you need to navigate to the \"system_logs\" directory and use tools like `grep` to filter out lines containing \"[ERROR]\" from each log file. You can then use `wc -l` to count the number of these lines. Combining these results will give you the total count of ERROR entries across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/system_logs\ngrep \"\\[ERROR\\]\" *.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/system_logs\necho -e \"2023-10-01 10:00:00 [INFO] Start process\\n2023-10-01 11:00:00 [ERROR] Process failed\\n2023-10-01 12:00:00 [WARNING] Low memory\" > ~/system_logs/log1.log\necho -e \"2023-10-02 09:30:00 [INFO] Initialize system\\n2023-10-02 09:45:00 [ERROR] System crash\\n2023-10-02 10:15:00 [INFO] Restart system\" > ~/system_logs/log2.log\necho -e \"2023-10-03 14:20:00 [ERROR] Network unreachable\\n2023-10-03 15:40:00 [INFO] Network restored\" > ~/system_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/system_logs\ngrep \"\\[ERROR\\]\" *.log | wc -l"
        }
    },
    {
        "description": "Count how many files in your home directory have been modified in the last 7 days and have a \".txt\" extension.",
        "explanation": "To solve this problem, you need to use the `find` command to search for files in your home directory that match the criteria: modification within the last 7 days and with a \".txt\" extension. The `-mtime` option can be used to specify files modified within a certain number of days, and `-name` can filter by extension. Count the results using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -name \"*.txt\" -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -name \"*.txt\" -mtime -7 | wc -l"
        }
    },
    {
        "description": "You need to find the total size of all text files (with the extension `.txt`) in your home directory and its subdirectories that contain the word \"Linux\" at least once. Display the size in a human-readable format.",
        "explanation": "To solve this problem, you can use a combination of `find`, `grep`, and `du` commands. First, use `find` to locate all `.txt` files in your home directory and its subdirectories. Then, use `grep` with the `-l` option to filter out files that contain the word \"Linux\". Finally, calculate the total size of these files using `du -ch` and extract the final summary line for a human-readable format.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find .txt files containing 'Linux' and calculate their total size.\ntotal_size=$(find ~ -type f -name \"*.txt\" -exec grep -l 'Linux' {} + | xargs du -ch | grep total$ | awk '{print $1}')\necho $total_size\n```",
        "create": {
            "init": "#!/bin/bash\n# Creating some directories and text files for testing\n\nmkdir -p ~/testdir/subdir1 ~/testdir/subdir2\n\necho \"This is a test file mentioning Linux.\" > ~/testdir/file1.txt\necho \"Another file talking about Linux.\" > ~/testdir/file2.txt\necho \"A file with no mention of the key term.\" > ~/testdir/subdir1/file3.txt\necho \"Linux is mentioned here as well.\" > ~/testdir/subdir1/file4.txt\necho \"Just some random text.\" > ~/testdir/subdir2/file5.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find .txt files containing 'Linux' and calculate their total size.\ntotal_size=$(find ~ -type f -name \"*.txt\" -exec grep -l 'Linux' {} + | xargs du -ch | grep total$ | awk '{print $1}')\necho $total_size"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing various log files with a \".log\" extension. Your task is to find out how many distinct IP addresses have made requests on the server, by checking all files in this directory. Assume that each line of a log file contains an IP address at the start of the line, followed by other request details. Count and report the number of unique IP addresses across all these log files.",
        "explanation": "To solve this problem, you should navigate to the \"logs\" directory and extract IP addresses from each log file. You can use tools like `awk` or `cut` to extract the first field (IP address) from each line. Use `sort` and `uniq` commands to filter out duplicate IPs and then count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ncat *.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 RequestA\\n192.168.1.2 RequestB\\n192.168.1.3 RequestC\\n192.168.1.1 RequestD\" > ~/logs/access1.log\necho -e \"192.168.1.4 RequestE\\n192.168.1.5 RequestF\\n192.168.1.2 RequestG\\n192.168.1.6 RequestH\" > ~/logs/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ncat *.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines across all text files in a directory named \"documents\" located in your home directory. The directory may contain subdirectories, and you should only count lines from files that have a \".txt\" extension. Assume that no symbolic links are involved.",
        "explanation": "To solve this problem, you can use the `find` command to search for all \".txt\" files within the \"documents\" directory and its subdirectories. Then, use `xargs` to pass these files to `wc -l`, which will count the lines in each file. Finally, sum up all the individual line counts to get the total number of lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/documents -type f -name \"*.txt\" | xargs wc -l | grep total | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p ~/documents/subdir1\nmkdir -p ~/documents/subdir2\necho -e \"Line 1\\nLine 2\\nLine 3\" > ~/documents/file1.txt\necho -e \"Line A\\nLine B\" > ~/documents/subdir1/file2.txt\necho -e \"Content X\\nContent Y\\nContent Z\\nContent W\" > ~/documents/subdir2/file3.txt\ntouch ~/documents/ignore.me"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/documents -type f -name \"*.txt\" | xargs wc -l | grep total | awk '{print $1}'"
        }
    },
    {
        "description": "Count the total number of lines in all `.txt` files located within the `/home/student/documents` directory and its subdirectories. Ignore any files that have the word \"draft\" in their name.",
        "explanation": "To solve this problem, you should use a combination of shell commands to search for `.txt` files within the specified directory and its subdirectories, excluding those containing \"draft\" in their name. Use `find` to locate relevant files, `grep` or `wc -l` to count lines, and pipe outputs as needed.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -name \"*.txt\" ! -name \"*draft*\" | xargs wc -l | grep total | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p /home/student/documents/subdir1\nmkdir -p /home/student/documents/subdir2\n\necho -e \"Line 1\\nLine 2\\nLine 3\" > /home/student/documents/file1.txt\necho -e \"Line A\\nLine B\\nLine C\\nLine D\" > /home/student/documents/file_draft.txt\necho -e \"Hello World\" > /home/student/documents/subdir1/file2.txt\necho -e \"First Line\\nSecond Line\" > /home/student/documents/subdir2/file3_draft.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -name \"*.txt\" ! -name \"*draft*\" | xargs wc -l | grep total | awk '{print $1}'"
        }
    },
    {
        "description": "Find out how many lines contain the word \"error\" in all \".log\" files located within the \"/var/logs\" directory. Assume that you do not have access to subdirectories.",
        "explanation": "The task requires using grep or similar tools to search for occurrences of the word \"error\" in log files. You can use wildcards to specify all \".log\" files within the specified directory. The output should be a single integer representing the number of lines containing the word \"error\".\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count lines containing 'error' in '.log' files within '/var/logs'\ngrep -i 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "# Create /var/logs directory and sample log files for testing\nmkdir -p /var/logs\necho -e \"This is an error line.\\nThis is another line.\" > /var/logs/system.log\necho -e \"No errors here.\\nYet another error found.\" > /var/logs/app.log\necho -e \"Error detected.\\nEverything looks fine.\" > /var/logs/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count lines containing 'error' in '.log' files within '/var/logs'\ngrep -i 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there are several text files with various extensions. Count how many lines contain the word \"Linux\" across all files with a \".txt\" extension.",
        "explanation": "To solve this problem, you need to list all \".txt\" files in your home directory and use tools like `grep` or `awk` to search for the word \"Linux\". You can use `wc -l` to count the number of lines that match the criteria.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files and count lines containing 'Linux'\ngrep -i 'Linux' ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Create some sample text files in the home directory\necho -e \"Linux is an open-source operating system kernel.\\nMany distributions use Linux as their base.\" > ~/file1.txt\necho -e \"This file is about Linux.\\nLinux powers many servers.\" > ~/file2.txt\necho -e \"Just a random note.\\nNothing about Linux here.\" > ~/file3.txt\necho -e \"Another unrelated file content.\" > ~/file4.md"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files and count lines containing 'Linux'\ngrep -i 'Linux' ~/file*.txt | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"data_logs\" in your home directory containing multiple log files with various extensions such as .log, .txt, and .out. Each file contains lines of text including timestamps and messages. Your task is to count the total number of unique error messages (lines containing the word \"ERROR\") across all files in this directory. Ignore case sensitivity when identifying \"ERROR\".",
        "explanation": "To solve this problem, you need to traverse through all the files in the \"data_logs\" directory and search for lines containing the word \"ERROR\" irrespective of its case. You can use `grep` with appropriate options to achieve this. After extracting all error lines, you need to ensure that only unique entries are counted, which can be done using commands like `sort` and `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i \"error\" ~/data_logs/* | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/data_logs\necho -e \"INFO: System started\\nERROR: Disk not found\\nWARNING: Low memory\\nERROR: Disk not found\" > ~/data_logs/system.log\necho -e \"Error: Network down\\nINFO: Connection established\\nError: Network down\" > ~/data_logs/network.txt\necho -e \"error: file missing\\ninfo: update complete\\nWARNING: High CPU usage\" > ~/data_logs/application.out"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i \"error\" ~/data_logs/* | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines that contain the word \"Linux\" in all text files within a directory named \"logs\" located in your home directory. These text files can have extensions \".txt\", \".log\", or \".md\". Assume the word \"Linux\" is case-sensitive, and you should only count lines where it appears as a whole word.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and search through each file with the specified extensions for lines containing the word \"Linux\". Use tools like `grep` for pattern matching and counting occurrences. You may find `find`, `xargs`, or loops helpful for processing multiple files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep -w 'Linux' *.txt *.log *.md | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"This is a test.\\nLinux is great.\\nI love Linux.\" > ~/logs/file1.txt\necho -e \"Another file.\\nNo mention here.\" > ~/logs/file2.log\necho -e \"Markdown file.\\nLinux is everywhere.\\nEven here: Linux.\" > ~/logs/file3.md"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep -w 'Linux' *.txt *.log *.md | wc -l"
        }
    },
    {
        "description": "You need to find the total disk space used by all \".log\" files in the \"/var/log\" directory and its subdirectories on your Linux system, and display the result in human-readable format.",
        "explanation": "To solve this problem, you can use the `find` command to locate all \".log\" files within the \"/var/log\" directory and its subdirectories. Then, use `du` to calculate their sizes and sum them up. Finally, display the total size using a format that is easy to read with human-friendly units like KB, MB, or GB.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -name \"*.log\" -exec du -ch {} + | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "# No initialization required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "find /var/log -type f -name \"*.log\" -exec du -ch {} + | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "Count the number of lines in all `.log` files within the `/var/log/` directory that contain the word \"error\" (case-insensitive) and were modified in the last 7 days.",
        "explanation": "To solve this problem, you need to perform several steps: \n1. Navigate to the `/var/log/` directory.\n2. Use `find` to list all `.log` files modified within the last 7 days.\n3. Use `grep` with a case-insensitive search for \"error\" in these files.\n4. Count the number of lines that match using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd /var/log/\nfind . -name \"*.log\" -mtime -7 -exec grep -i \"error\" {} \\; | wc -l\n```",
        "create": {
            "init": "# No initialization required as we are using existing system log files"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd /var/log/\nfind . -name \"*.log\" -mtime -7 -exec grep -i \"error\" {} \\; | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"ERROR\" in all \".log\" files located in the \"/var/logs\" directory, and ensure that the search is case-insensitive.",
        "explanation": "You need to use a combination of `grep` with appropriate options to perform a case-insensitive search for the word \"ERROR\" in all \".log\" files within the specified directory. The `-i` option will help you achieve case insensitivity, and `-r` can be used if you want to search recursively. Finally, count the total number of matched lines using tools like `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "# Create /var/logs directory\nmkdir -p /var/logs\n\n# Generate some log files with content\necho -e \"INFO: This is an info message\\nERROR: Something went wrong\\nerror: Another issue occurred\" > /var/logs/app.log\necho -e \"DEBUG: Debugging\\nWARNING: Be cautious\\nerror: Yet another problem\\nINFO: Information here\" > /var/logs/system.log\necho -e \"ERROR: Critical failure\\nINFO: All systems operational\\ndebugging information\" > /var/logs/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "Find the number of files that have been modified in the last 7 days within the 'logs' directory located in your home directory. You should only count regular files, not directories or symbolic links.",
        "explanation": "To solve this problem, you need to use the `find` command with appropriate options to filter files based on their modification time. The `-type f` option ensures that only regular files are considered, while `-mtime -7` helps filter files modified in the last 7 days. You can use the `wc -l` command to count the number of lines returned by `find`, which corresponds to the number of matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ntouch ~/logs/file1.txt\ntouch ~/logs/file2.txt\ntouch ~/logs/file3.txt\ntouch ~/logs/old_file.txt\n# Set modification time of some files manually for testing purpose.\ntouch -d \"8 days ago\" ~/logs/old_file.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count how many files in your home directory have the \".txt\" extension and contain the word \"Linux\" within them. Ensure your search includes subdirectories as well.",
        "explanation": "To solve this problem, you need to navigate through your home directory and its subdirectories, identify files with a \".txt\" extension, and check if they contain the word \"Linux\". You can use tools like `find`, `grep`, and `wc` to achieve this. First, use `find` to list all \".txt\" files recursively. Then, for each file, use `grep` to search for the word \"Linux\". Finally, count the number of files that match these criteria using `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files in home directory containing the word 'Linux'\nfind ~ -type f -name \"*.txt\" -exec grep -l \"Linux\" {} \\; | wc -l\n```",
        "create": {
            "init": "# Create some sample directories and text files in the user's home directory\nmkdir -p ~/testdir/subdir\necho \"This is a Linux text file.\" > ~/testdir/file1.txt\necho \"Just another text file.\" > ~/testdir/subdir/file2.txt\necho \"This mentions Linux.\" > ~/testdir/subdir/file3.txt\necho \"No mention here.\" > ~/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files in home directory containing the word 'Linux'\nfind ~ -type f -name \"*.txt\" -exec grep -l \"Linux\" {} \\; | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Your task is to count how many unique IP addresses accessed your server, as recorded in these log files. Assume that each line in the log files contains an IP address at the beginning of the line.",
        "explanation": "To solve this problem, you need to read all \".log\" files within the \"logs\" directory, extract IP addresses from each line, and then determine the count of unique IP addresses across all files. You can use tools like `grep` to filter out lines containing IPs and `awk` or `cut` to extract them. Finally, you can use `sort` and `uniq` to find unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"192.168.1.1 some message here\" > ~/logs/access1.log\necho \"192.168.1.2 another message here\" >> ~/logs/access1.log\necho \"192.168.1.3 yet another message here\" >> ~/logs/access1.log\necho \"192.168.1.2 repeated access message here\" > ~/logs/access2.log\necho \"192.168.1.4 new access message here\" >> ~/logs/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all text files located in the current directory and its subdirectories that contain the word \"Linux\".",
        "explanation": "To solve this problem, you should use a combination of bash commands such as `find`, `grep`, and `wc`. First, use `find` to identify all text files within the current directory and its subdirectories. Then, use `grep` to search for lines containing the word \"Linux\" in each file found. Finally, use `wc -l` to count those lines. Be sure to handle cases where there might be no matching files gracefully.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use find to locate all .txt files and grep to filter lines containing 'Linux'\nfind . -type f -name \"*.txt\" | xargs grep -i \"Linux\" | wc -l\n```",
        "create": {
            "init": "# Create sample directories and text files with varying content\nmkdir -p dir1 dir2/dir3\n\necho -e \"This is a Linux tutorial.\\nWelcome to Linux.\" > dir1/file1.txt\necho -e \"Learning operating systems is fun.\\nLinux is powerful.\" > dir2/file2.txt\necho -e \"Linux command line tools are useful.\\nAnother line without keyword.\" > dir2/dir3/file3.txt\necho -e \"No mention of Linux here.\\nJust random text.\" > dir2/dir3/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use find to locate all .txt files and grep to filter lines containing 'Linux'\nfind . -type f -name \"*.txt\" | xargs grep -i \"Linux\" | wc -l"
        }
    },
    {
        "description": "In your home directory, you have two files: \"access.log\" and \"error.log\". Both files contain log entries with timestamps. Count the number of log entries in \"access.log\" that occurred after the last entry in \"error.log\".",
        "explanation": "To solve this problem, first extract the timestamp from the last entry of \"error.log\". Then, filter out and count all entries in \"access.log\" whose timestamps are greater than this extracted timestamp.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract the last timestamp from error.log\nlast_error_timestamp=$(tail -n 1 ~/error.log | awk '{print $1}')\n\n# Count entries in access.log that occurred after this timestamp\nawk -v last_time=\"$last_error_timestamp\" '$1 > last_time' ~/access.log | wc -l\n```",
        "create": {
            "init": "# Create sample log files with timestamps\ncat << EOF > ~/access.log\n2023-10-01T12:01:00 Access successful\n2023-10-02T14:23:00 Access successful\n2023-10-03T16:45:00 Access failed\nEOF\n\ncat << EOF > ~/error.log\n2023-10-01T12:05:00 Error occurred\n2023-10-02T15:30:00 Error resolved\nEOF"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract the last timestamp from error.log\nlast_error_timestamp=$(tail -n 1 ~/error.log | awk '{print $1}')\n\n# Count entries in access.log that occurred after this timestamp\nawk -v last_time=\"$last_error_timestamp\" '$1 > last_time' ~/access.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a text file named \"log.txt\" that contains various log entries with timestamps. Your task is to count how many log entries were recorded on Mondays and output the result as an integer.",
        "explanation": "To solve this problem, you need to filter out log entries from \"log.txt\" that correspond to Mondays. Typically, log files have timestamps with a recognizable format (e.g., \"YYYY-MM-DD HH:MM:SS\"). You can use the `grep` command to identify lines containing dates corresponding to Mondays by leveraging `date` utility functions or regular expressions for filtering.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\n# Count entries for Mondays in the provided log file\n\n# Assume each line starts with a date in YYYY-MM-DD format.\ngrep -E '^2023-(10-(02|09|16))' ~/log.txt | wc -l\n```",
        "create": {
            "init": "# Create a sample log file with timestamps\necho -e \"2023-10-02 08:00:00 Log entry one\\n2023-10-03 09:15:00 Log entry two\\n2023-10-09 12:30:00 Log entry three\\n2023-10-16 14:45:00 Log entry four\" > ~/log.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\n# Count entries for Mondays in the provided log file\n\n# Assume each line starts with a date in YYYY-MM-DD format.\ngrep -E '^2023-(10-(02|09|16))' ~/log.txt | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all text files (.txt) in your home directory, including those within subdirectories.",
        "explanation": "To solve this problem, you need to use a combination of find and wc commands. First, utilize the find command to locate all .txt files in your home directory and its subdirectories. Then, pipe the output to wc -l to count the total number of lines in these files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files in the home directory and its subdirectories, then count their total lines.\nfind ~ -type f -name \"*.txt\" -exec cat {} + | wc -l\n```",
        "create": {
            "init": "# Create some sample text files with various line counts in the home directory and subdirectories\nmkdir -p ~/test_dir/sub_dir1\nmkdir -p ~/test_dir/sub_dir2\n\necho -e \"Line 1\\nLine 2\\nLine 3\" > ~/test_file1.txt\necho -e \"Hello\\nWorld\" > ~/test_file2.txt\necho -e \"Sample text\" > ~/test_dir/sub_dir1/sample1.txt\necho -e \"Another example\\nWith multiple lines\\nEnd here\" > ~/test_dir/sub_dir2/sample2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files in the home directory and its subdirectories, then count their total lines.\nfind ~ -type f -name \"*.txt\" -exec cat {} + | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory, which contains multiple \".log\" files. Count the total number of lines across all \".log\" files that contain the word \"ERROR\".",
        "explanation": "To solve this problem, you need to search through each \".log\" file in the \"log_files\" directory for lines that include the word \"ERROR\". You can use tools such as `grep` to filter these lines and then count them using `wc -l`. Ensure you are evaluating all files within the directory.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"INFO: System running\\nERROR: Disk space low\\nINFO: Update complete\" > ~/log_files/system.log\necho -e \"INFO: User login\\nERROR: Network down\\nERROR: File not found\" > ~/log_files/user_activity.log\necho -e \"WARNING: High CPU usage\\nINFO: Backup started\\nERROR: Backup failed\" > ~/log_files/server.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all `.txt` files located within the `/home/student/documents/` directory and its subdirectories that contain the word \"Linux\" (case-sensitive). You should also ignore empty lines while counting.",
        "explanation": "To solve this problem, you can use a combination of `find`, `grep`, and `wc`. The `find` command can help locate all `.txt` files within the specified directory, including subdirectories. The `grep` command can be used to search for lines containing the word \"Linux\" while ignoring empty lines. Finally, `wc -l` can be used to count these lines. You might need to pipe outputs between these commands.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents/ -type f -name \"*.txt\" | xargs grep -h \"Linux\" | grep \".\" | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents/subdir1\nmkdir -p /home/student/documents/subdir2\n\necho -e \"This is a test file.\\nLinux is powerful.\\n\\nAnother line.\" > /home/student/documents/file1.txt\necho -e \"Exploring Linux.\\n\\nNothing here.\" > /home/student/documents/subdir1/file2.txt\necho -e \"\\nJust some text.\\nLinux again.\" > /home/student/documents/subdir2/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents/ -type f -name \"*.txt\" | xargs grep -h \"Linux\" | grep \".\" | wc -l"
        }
    },
    {
        "description": "You need to find out how many JPEG images are present in your home directory and all its subdirectories, which were modified within the last 7 days. Provide the count of such files.",
        "explanation": "To solve this problem, you can use the `find` command to search for files with a `.jpg` or `.jpeg` extension in your home directory and its subdirectories. You will need to filter these files based on their modification time using the `-mtime` option. Specifically, you want files that have been modified within the last 7 days. Once you have this list, count the number of files using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use find to locate JPEG images modified in the last 7 days and count them.\nfind ~ -type f \\( -iname \"*.jpg\" -o -iname \"*.jpeg\" \\) -mtime -7 | wc -l\n```",
        "create": {
            "init": "# Create some dummy JPEG image files in the home directory and modify their timestamps\ntouch ~/image1.jpg ~/image2.jpeg ~/old_image.jpg\n# Modify timestamps to simulate recent changes\ntouch -d \"5 days ago\" ~/image1.jpg\ntouch -d \"6 days ago\" ~/image2.jpeg\n# Set an older timestamp for one image to ensure it does not count\ntouch -d \"15 days ago\" ~/old_image.jpg"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use find to locate JPEG images modified in the last 7 days and count them.\nfind ~ -type f \\( -iname \"*.jpg\" -o -iname \"*.jpeg\" \\) -mtime -7 | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a file named \"server_logs.txt\" containing server access logs. Each line in the file represents an access attempt, formatted as \"IP_ADDRESS TIMESTAMP URL STATUS_CODE\". Your task is to find out how many unique IP addresses accessed URLs with a status code of \"200\" between the hours of 14:00 and 16:00.",
        "explanation": "To solve this problem, you can use tools such as `grep` or `awk` to filter lines based on the status code and time range. Then, use `cut` or `awk` again to extract IP addresses from filtered lines. Finally, employ `sort` and `uniq` to count unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '200' ~/server_logs.txt | awk '$2 >= \"14:\" && $2 <= \"16:\" {print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "cat <<EOL > ~/server_logs.txt\n192.168.1.1 14:05 /index.html 200\n192.168.1.2 15:35 /about.html 404\n10.0.0.5 14:55 /contact.html 200\n172.16.0.3 13:45 /home.html 200\n192.168.1.1 14:20 /index.html 500\n10.0.0.5 15:05 /products.html 200\n172.16.0.3 16:10 /services.html 200\n192.168.1.4 15:45 /faq.html 200\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '200' ~/server_logs.txt | awk '$2 >= \"14:\" && $2 <= \"16:\" {print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Find and count the number of files in your home directory that have been modified in the last 7 days and are larger than 1MB. You need to exclude hidden files and directories from this count.",
        "explanation": "To solve this problem, you can use the `find` command with appropriate options to filter files based on modification time and size. The `-mtime` option allows filtering files modified within a certain number of days, while `-size` filters by file size. Use `-type f` to ensure only regular files are counted, excluding directories. Hidden files can be excluded using the pattern for visible filenames (those not starting with a dot).\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 -size +1M ! -path '*/.*' | wc -l\n```",
        "create": {
            "init": "# No specific initialization required. The task uses existing files in the home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 -size +1M ! -path '*/.*' | wc -l"
        }
    },
    {
        "description": "Find the total number of lines across all text files in the \"documents\" directory, excluding those containing the word \"error\".",
        "explanation": "To solve this problem, you need to first identify all text files within the \"documents\" directory. Then, for each file, count its lines while excluding any line that contains the word \"error\". You can use utilities like `grep`, `wc`, and loops to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ntotal_lines=0\nfor file in documents/*.txt; do\n  lines=$(grep -v 'error' \"$file\" | wc -l)\n  total_lines=$((total_lines + lines))\ndone\necho $total_lines\n```",
        "create": {
            "init": "mkdir -p documents\necho -e \"This is a sample line.\\nThis line contains error.\\nAnother regular line.\" > documents/file1.txt\necho -e \"Error found here.\\nNo issues found here.\\nYet another error.\" > documents/file2.txt\necho -e \"Everything is fine.\\nThis one has no errors.\\nGood to go.\" > documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "total_lines=0\nfor file in documents/*.txt; do\n  lines=$(grep -v 'error' \"$file\" | wc -l)\n  total_lines=$((total_lines + lines))\ndone\necho $total_lines"
        }
    },
    {
        "description": "In your home directory, count the number of files that contain the word \"TODO\" in their content and are larger than 100KB in size. You should only consider regular files and ignore directories or symbolic links.",
        "explanation": "To solve this problem, you need to traverse through all files in your home directory, check if the content contains the word \"TODO\", and filter out those which have a size greater than 100KB. Tools like `grep`, `find`, and `wc` can be helpful for this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f ! -name '.*' -size +100k | xargs grep -l 'TODO' | wc -l\n```",
        "create": {
            "init": "# Create some sample files for testing\nmkdir -p ~/test_dir\necho \"This file contains TODO\" > ~/test_dir/file1.txt\necho \"No TODO here\" > ~/test_dir/file2.txt\ntruncate -s 150K ~/test_dir/file3.txt\necho \"TODO is present here\" > ~/test_dir/file4.txt\n\n# Create large file with TODO\necho \"This is a large file with a TODO\" > ~/test_dir/large_todo_file.txt\ntruncate -s 200K ~/test_dir/large_todo_file.txt\n\n# Symbolic link (should be ignored)\nln -s ~/test_dir/file1.txt ~/home/symlink_to_file1\n\n# Move test files to home directory for the experiment\nmv ~/test_dir/* ~/\nrm -r ~/test_dir/"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f ! -name '.*' -size +100k | xargs grep -l 'TODO' | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.logfile` containing various log entries. Each entry starts with a timestamp followed by an error level and a message. Your task is to count how many \"ERROR\" level entries occurred in the last 24 hours.",
        "explanation": "To solve this problem, you need to filter the log entries based on the current date minus one day and count the number of lines that contain the \"ERROR\" level. You can use utilities like `grep`, `awk`, and `date` to achieve this. Start by fetching the current date minus one day using `date` and then filter entries with timestamps within that range.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Get current date minus one day in YYYY-MM-DD format\nyesterday=$(date -d '1 day ago' '+%Y-%m-%d')\n\n# Count how many \"ERROR\" entries occurred after yesterday's midnight (i.e., last 24 hours)\ngrep \"^$yesterday\" ~/.logfile | grep \"ERROR\" | wc -l\n```",
        "create": {
            "init": "# Create a hidden logfile with sample data\ncat <<EOL > ~/.logfile\n2023-10-01T12:00:00 ERROR Failed to connect to server\n2023-10-01T13:00:00 INFO Connection established\n2023-10-02T14:00:00 ERROR Timeout occurred during request\n2023-10-02T15:00:00 WARNING High memory usage detected\n2023-10-03T16:00:00 ERROR Disk space low on server\n2023-10-03T17:59:59 INFO Server reboot completed successfully\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Get current date minus one day in YYYY-MM-DD format\nyesterday=$(date -d '1 day ago' '+%Y-%m-%d')\n\n# Count how many \"ERROR\" entries occurred after yesterday's midnight (i.e., last 24 hours)\ngrep \"^$yesterday\" ~/.logfile | grep \"ERROR\" | wc -l"
        }
    },
    {
        "description": "You need to find the total number of files in your home directory that have been modified within the last 7 days.",
        "explanation": "To solve this problem, you can use the `find` command to search for files in your home directory that have been modified in the last 7 days. The command should filter out directories and only count regular files using appropriate flags.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No specific initialization required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "Find and count the number of files larger than 1MB in your home directory that have been modified in the last 7 days.",
        "explanation": "You can use the `find` command to search for files based on size and modification time. The `-size +1M` option will help you filter files larger than 1MB, while the `-mtime -7` option will help you find files modified within the last 7 days. Finally, use `wc -l` to count these files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -size +1M -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No specific initialization required"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -size +1M -mtime -7 | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory, which contains several text files with various log entries. Each log entry contains a timestamp, log level (INFO, WARNING, ERROR), and a message. Your task is to determine how many ERROR level logs occurred in the last 24 hours from the current time.",
        "explanation": "To solve this problem, you need to:\n1. Identify all the files in the \"logs\" directory.\n2. Extract log entries with the ERROR level.\n3. Filter these entries based on their timestamps to only include those from the last 24 hours.\n4. Count the filtered ERROR logs.\n\nHints:\n- Use `find` or `ls` to list files in the \"logs\" directory.\n- Use `grep` or `awk` to filter lines containing \"ERROR\".\n- Convert timestamps using `date` for comparison purposes.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Assume today's date is October 4th, and current time is around noon.\nfind ~/logs -type f -exec grep 'ERROR' {} + | awk '$1 >= strftime(\"%Y-%m-%d\", systime() - 86400)' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 INFO Start process\\n2023-10-02 14:30:00 ERROR Failed to connect\\n2023-10-03 16:45:00 WARNING Low memory\\n2023-10-03 18:00:00 ERROR Disk full\" > ~/logs/log1.txt\necho -e \"2023-10-04 09:20:00 INFO User login\\n2023-10-04 11:15:00 ERROR Network timeout\\n2023-10-04 13:40:00 INFO Process completed\" > ~/logs/log2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Assume today's date is October 4th, and current time is around noon.\nfind ~/logs -type f -exec grep 'ERROR' {} + | awk '$1 >= strftime(\"%Y-%m-%d\", systime() - 86400)' | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing numerous log files with the extension \".log\". Each log file contains multiple lines, and some lines include the word \"ERROR\". Your task is to count the total number of lines across all log files that contain the word \"ERROR\". Ensure you navigate through each file in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to iterate over each file within the \"logs\" directory and use a tool like `grep` to filter lines containing the word \"ERROR\". Then, you can use `wc -l` to count these lines. Summing up these counts will give you the total number of error lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -name \"*.log\" | xargs grep -c 'ERROR' | awk -F: '{sum += $2} END {print sum}'\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO Start process\\nERROR Failed to start\\nINFO Process ended\" > ~/logs/log1.log\necho -e \"DEBUG Initializing\\nERROR Connection lost\\nERROR Timeout reached\" > ~/logs/log2.log\necho -e \"INFO Job scheduled\\nWARNING Low memory\\nDEBUG Execution successful\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -name \"*.log\" | xargs grep -c 'ERROR' | awk -F: '{sum += $2} END {print sum}'"
        }
    },
    {
        "description": "You are given a directory named \"project_logs\" containing multiple log files with various timestamps in their filenames (e.g., log_20231001.txt, log_20230930.txt). Your task is to find and count the number of unique IP addresses that accessed the system on October 1st, 2023. The format of an access log entry is: \"IP_ADDRESS - TIMESTAMP - ACTION\". Assume all relevant log files are in the current directory.",
        "explanation": "To solve this problem, you need to:\n1. Identify and select the specific file(s) for October 1st, 2023.\n2. Extract only the IP addresses from these files.\n3. Count the number of unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^[0-9]\\+\\.[0-9]\\+\\.[0-9]\\+\\.[0-9]\\+' project_logs/log_20231001.txt | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p project_logs\necho -e \"192.168.1.1 - 2023-10-01 10:00:00 - LOGIN\\n192.168.1.2 - 2023-10-01 11:00:00 - LOGOUT\\n192.168.1.1 - 2023-10-01 12:00:00 - LOGIN\" > project_logs/log_20231001.txt\necho -e \"192.168.1.3 - 2023-09-30 09:00:00 - LOGIN\\n192.168.1.4 - 2023-09-30 10:30:00 - LOGOUT\" > project_logs/log_20230930.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^[0-9]\\+\\.[0-9]\\+\\.[0-9]\\+\\.[0-9]\\+' project_logs/log_20231001.txt | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days, excluding directories and symbolic links.",
        "explanation": "To solve this problem, you can use the `find` command to search for files in your home directory that meet the criteria. Use options to exclude directories and symbolic links, and specify a time condition to filter files modified within the last 7 days. The `wc -l` command can be used to count the number of matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization is required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You are given a directory named `logfiles` in your home directory, containing multiple log files with a `.log` extension. Each log file contains timestamped entries of server activities. Your task is to find out how many lines in total contain the word \"ERROR\" across all the log files. You must use shell commands to achieve this.",
        "explanation": "To solve this problem, you will need to navigate to the `logfiles` directory and use a combination of shell commands to count occurrences of the word \"ERROR\" in each file. A useful approach would be using tools like `grep` to search for \"ERROR\" and then pipe the results into `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Change directory into 'logfiles'\ncd ~/logfiles\n\n# Use grep to find all lines containing \"ERROR\", then count them using wc\ngrep -r \"ERROR\" ./*.log | wc -l\n```",
        "create": {
            "init": "# Create a directory named 'logfiles' in the user's home directory\nmkdir -p ~/logfiles\n\n# Generate sample log files with random content including some lines with \"ERROR\"\necho -e \"2023-10-01 08:00:00 INFO Server started\\n2023-10-01 08:05:00 ERROR Failed to connect\\n2023-10-01 08:10:00 INFO Connection successful\" > ~/logfiles/server1.log\necho -e \"2023-10-02 09:00:00 ERROR Disk full\\n2023-10-02 09:05:00 INFO Cleanup started\\n2023-10-02 09:15:00 ERROR Cleanup failed\" > ~/logfiles/server2.log\necho -e \"2023-10-03 07:50:00 INFO Backup initiated\\n2023-10-03 07:55:00 ERROR Backup failed\\n2023-10-03 08:00:00 INFO Backup completed successfully\" > ~/logfiles/server3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Change directory into 'logfiles'\ncd ~/logfiles\n\n# Use grep to find all lines containing \"ERROR\", then count them using wc\ngrep -r \"ERROR\" ./*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_files\" which contains multiple files of various types. Your task is to find the total number of lines across all text files (.txt) within this directory that contain the word \"error\". Note: Consider only lines where \"error\" appears as a whole word, case-insensitively.",
        "explanation": "To solve this problem, you need to perform several steps:\n1. Use `find` to list all .txt files in the \"project_files\" directory.\n2. Use `grep` with the `-i`, `-w`, and `-o` options to search for occurrences of the word \"error\" in each text file found.\n3. Count the number of matching lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind project_files -type f -name \"*.txt\" | xargs grep -i -w 'error' | wc -l\n```",
        "create": {
            "init": "mkdir -p project_files\necho -e \"This is a test file.\\nError: Something went wrong.\\nAll systems operational.\" > project_files/file1.txt\necho -e \"No errors here.\\nERROR found in logs.\\nThis is another line.\" > project_files/file2.txt\necho -e \"An error occurred.\\nThis line does not contain it.\\nYet another error message.\" > project_files/file3.txt\ntouch project_files/empty.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find project_files -type f -name \"*.txt\" | xargs grep -i -w 'error' | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that are larger than 1MB and contain the word \"report\" in their filename. Use a combination of find, grep, and other necessary commands to achieve this.",
        "explanation": "To solve this problem, you need to navigate through your home directory and find all files with sizes greater than 1MB. You can use the `find` command with the `-size` option to filter out these files. Then, use `grep` to filter filenames containing the word \"report\". Finally, count these filtered files using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script that provides the correct answer.\nfind ~ -type f -size +1M -name \"*report*\" | wc -l\n```",
        "create": {
            "init": "# This script creates some test files in the student's home directory for testing purposes.\nmkdir -p ~/test_directory\ndd if=/dev/zero of=~/test_directory/report1.txt bs=2M count=1\ndd if=/dev/zero of=~/test_directory/report2.txt bs=3M count=1\ndd if=/dev/zero of=~/test_directory/document.txt bs=4M count=1\ntouch ~/test_directory/small_report.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script that provides the correct answer.\nfind ~ -type f -size +1M -name \"*report*\" | wc -l"
        }
    },
    {
        "description": "Find the total number of lines that contain the word \"error\" in all \".log\" files within a directory named \"logs\" located in your home directory. The search should be case-insensitive.",
        "explanation": "To solve this problem, you need to use the `grep` command with appropriate options to perform a case-insensitive search for the word \"error\". You will then count how many lines contain this word across all \".log\" files in the specified directory.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"This is an error.\\nNo issues here.\\nERROR found.\" > ~/logs/file1.log\necho -e \"Everything is fine.\\nAnother ERROR occurred.\\nMore errors.\" > ~/logs/file2.log\necho -e \"No problems detected.\\nError log entry.\" > ~/logs/file3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that are larger than 1MB and have been modified in the last 7 days.",
        "explanation": "You can use the `find` command to search for files based on size and modification time. The `-size` flag allows you to specify the file size, and `-mtime` lets you find files modified within a certain number of days. Combine these flags with logical operators to meet both conditions.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -size +1M -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization needed as students will use their own home directories."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -size +1M -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and contain the word \"Linux\" in their content.",
        "explanation": "To solve this problem, you can use a combination of `find` to search for files modified within the last 7 days and `grep` to filter out files containing the word \"Linux\". The find command can help locate files based on modification time, while grep will search through file contents. You can use piping and command substitution to count the results.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count the number of qualifying files using find and grep.\nfind ~ -maxdepth 1 -type f -mtime -7 -exec grep -l \"Linux\" {} \\; | wc -l\n```",
        "create": {
            "init": "# Create some sample files in the home directory for testing.\nmkdir -p ~/test_files\necho \"This is a Linux file.\" > ~/test_files/file1.txt\necho \"Another Linux example.\" > ~/test_files/file2.txt\necho \"No keyword here.\" > ~/test_files/file3.txt\n\n# Modify timestamps to simulate recent changes.\ntouch -d '2 days ago' ~/test_files/file1.txt\ntouch -d '10 days ago' ~/test_files/file2.txt\ntouch -d '5 days ago' ~/test_files/file3.txt\n\n# Move test files to home directory for student interaction.\nmv ~/test_files/* ~/\nrm -r ~/test_files"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count the number of qualifying files using find and grep.\nfind ~ -maxdepth 1 -type f -mtime -7 -exec grep -l \"Linux\" {} \\; | wc -l"
        }
    },
    {
        "description": "Count the total number of files in your home directory that have been modified in the last 7 days.",
        "explanation": "To solve this problem, you need to use the `find` command to search your home directory for files that were modified within the last 7 days. You can utilize the `-mtime` option with `find`, which allows you to specify the modification time criteria. Combine this with `wc -l` to count the number of files returned by `find`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization needed, as students already have a home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all text files within the \"documents\" directory whose names contain the word \"report\".",
        "explanation": "To solve this problem, you need to navigate through the \"documents\" directory and search for files with names containing the word \"report\". You can use utilities such as `find` to locate these files and then use `wc -l` to count the lines in each file. Summing up these line counts will give you the total number of lines across all relevant files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind documents -type f -name \"*report*\" | xargs wc -l | grep total | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p documents\necho -e \"This is a test report.\\nIt contains multiple lines.\" > documents/report1.txt\necho -e \"Another report here.\\nWith more content.\" > documents/report2.txt\necho -e \"Not a report file.\" > documents/other.txt\ntouch documents/report3.txt # Empty file for complexity"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find documents -type f -name \"*report*\" | xargs wc -l | grep total | awk '{print $1}'"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in your home directory that contain the word \"error\" (case-insensitive).",
        "explanation": "To solve this problem, you can use tools like `grep` to search for lines containing the word \"error\" in a case-insensitive manner and then count them across all `.txt` files in your home directory. You can use `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\ngrep -i 'error' ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Create some example .txt files in the student's home directory\necho -e \"This is an error\\nLine two\\nAnother error here\" > ~/file1.txt\necho -e \"No errors here\\nJust text\" > ~/file2.txt\necho -e \"ERROR: Something went wrong\\nNormal line\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\ngrep -i 'error' ~/file*.txt | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing various log files with extensions \".log\". Count the total number of lines that contain the word \"ERROR\" in all \".log\" files within this directory. Assume that each line can contain multiple instances of the word \"ERROR\", but you should count only the lines where it appears at least once.",
        "explanation": "To solve this problem, you need to search for the word \"ERROR\" in each \".log\" file within the \"logs\" directory. You can use tools like `grep` to filter lines containing \"ERROR\" and then count these lines using `wc -l`. The command `grep -c ERROR filename.log` will directly give you the count of lines containing the word \"ERROR\". Iterate through all \".log\" files and sum up their counts.\n\nYou can use this command pattern to perform the task:\n\n```bash\ntotal_error_lines=0\nfor logfile in ~/logs/*.log; do\n  error_count=$(grep -c ERROR \"$logfile\")\n  total_error_lines=$((total_error_lines + error_count))\ndone\necho $total_error_lines\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO Starting process\\nERROR Failed to start\\nINFO Process running\\nERROR Stopped unexpectedly\" > ~/logs/app1.log\necho -e \"DEBUG Initializing\\nINFO Loaded config\\nERROR Invalid input\\nWARN Low disk space\\nERROR Disk full\" > ~/logs/app2.log\necho -e \"INFO Connection established\\nDEBUG Data received\\nWARN Timeout occurred\\nINFO Connection closed\" > ~/logs/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "total_error_lines=0\nfor logfile in ~/logs/*.log; do\n  error_count=$(grep -c ERROR \"$logfile\")\n  total_error_lines=$((total_error_lines + error_count))\ndone\necho $total_error_lines"
        }
    },
    {
        "description": "You are tasked with analyzing a directory called \"project_logs\" in your home directory. Within this directory, there are multiple log files named sequentially from \"log1.txt\" to \"log10.txt\". Each file contains lines of text where each line starts with a date in the format YYYY-MM-DD followed by a space and then an error message. Your task is to determine how many unique dates have error messages across all files.",
        "explanation": "To solve this problem, you need to extract the date from each line in all the log files and compile a list of unique dates. You can use tools like `cat` to concatenate all the files, `cut` or `awk` to extract the dates, and `sort` along with `uniq` to count unique occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/project_logs/log*.txt | cut -d' ' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\nfor i in {1..10}; do\n    echo -e \"2023-01-0$i Error: Something went wrong\\n2023-01-0$((i+1)) Error: Another issue\" > ~/project_logs/log$i.txt\ndone"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/project_logs/log*.txt | cut -d' ' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a file named `system_logs.txt` containing various log entries. Count how many times the word \"ERROR\" appears in this file, but only consider those lines where the error message starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\".",
        "explanation": "To solve this problem, you need to filter out lines that start with a timestamp and contain the word \"ERROR\". You can use tools like `grep`, `awk`, or `sed` to match lines with the correct format and count occurrences of \"ERROR\".\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -E '^([0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}) ERROR' ~/system_logs.txt | wc -l\n```",
        "create": {
            "init": "echo -e \"2023-10-01 12:30:45 ERROR Disk full\\n2023-10-01 12:31:00 INFO System rebooted\\n2023-10-01 12:32:00 ERROR Network issue\\nInvalid log entry\\n2023-10-01 12:33:45 ERROR Disk failure\" > ~/system_logs.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -E '^([0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}) ERROR' ~/system_logs.txt | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_files\" in your home directory containing various files. Your task is to identify and count the number of unique file extensions present in this directory. You should consider only files (ignore directories) and exclude hidden files (those starting with a dot).",
        "explanation": "To solve this problem, you can use the `find` command to list all non-hidden files in the \"project_files\" directory, then use utilities like `awk`, `sed`, or `cut` to extract file extensions. Finally, utilize `sort` and `uniq` to count the unique extensions. Remember that some files might not have an extension.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all non-hidden files in the project_files directory,\n# extract their extensions, sort them uniquely and count.\nfind ~/project_files -maxdepth 1 -type f ! -name '.*' | \\\nawk -F. '/\\./ {print $NF}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_files\ntouch ~/project_files/file1.txt\ntouch ~/project_files/file2.md\ntouch ~/project_files/file3.txt\ntouch ~/project_files/README\ntouch ~/project_files/.hiddenfile\ntouch ~/project_files/script.sh"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all non-hidden files in the project_files directory,\n# extract their extensions, sort them uniquely and count.\nfind ~/project_files -maxdepth 1 -type f ! -name '.*' | \\\nawk -F. '/\\./ {print $NF}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files. Each log file is named in the format \"log-yyyy-mm-dd.txt\" and contains various system events. You need to count the total number of unique error messages across all these log files. Each error message starts with the prefix \"ERROR:\". Ignore case distinctions when counting unique errors.",
        "explanation": "To solve this problem, you can use a combination of `grep` to extract lines containing \"ERROR:\", `awk` or `sed` to format and clean up each error message, and `sort | uniq` to count distinct errors ignoring case. \n\n1. Use `grep -i \"ERROR:\"` to extract all lines with errors from the log files.\n2. Use `sed` or `awk` to isolate the error message text following the \"ERROR:\" prefix.\n3. Convert all messages to a common case (lowercase or uppercase) using tools like `tr`.\n4. Use `sort | uniq` to find unique messages and then count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Extract all ERROR lines from logs, isolate the error messages,\n# convert them to lower case, sort them uniquely, and count them.\ngrep -i \"ERROR:\" ~/logs/*.txt \\\n    | sed 's/.*ERROR://' \\\n    | tr '[:upper:]' '[:lower:]' \\\n    | sort \\\n    | uniq \\\n    | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\nmkdir -p ~/logs\ncat <<EOL > ~/logs/log-2023-10-01.txt\nINFO: System booted successfully\nERROR: Invalid user input detected\nWARNING: Low disk space on /dev/sda1\nERROR: Network timeout occurred\nEOL\n\ncat <<EOL > ~/logs/log-2023-10-02.txt\nINFO: Scheduled backup completed successfully\nERROR: Network timeout occurred\nINFO: User logged in successfully\nERROR: Invalid user input detected\nEOL\n\ncat <<EOL > ~/logs/log-2023-10-03.txt\nWARNING: High memory usage detected\nERROR: Disk write failure at sector 2048\nINFO: System shutdown initiated by admin\nerror: network timeout occurred  # Intentional lowercase for testing case insensitivity \nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Extract all ERROR lines from logs, isolate the error messages,\n# convert them to lower case, sort them uniquely, and count them.\ngrep -i \"ERROR:\" ~/logs/*.txt \\\n    | sed 's/.*ERROR://' \\\n    | tr '[:upper:]' '[:lower:]' \\\n    | sort \\\n    | uniq \\\n    | wc -l"
        }
    },
    {
        "description": "You have a directory named \"project_logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains timestamps and error messages. Your task is to find out how many unique error messages occurred between 2 PM and 3 PM across all log files.",
        "explanation": "To solve the problem, you need to perform several steps:\n1. Navigate to the \"project_logs\" directory.\n2. Use a command to filter out lines from all \".log\" files that contain timestamps between 14:00:00 (2 PM) and 14:59:59 (3 PM).\n3. Extract the error messages from these lines.\n4. Sort and remove duplicates to count the number of unique error messages.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/project_logs\ngrep -hE '^[0-9]{4}-[0-9]{2}-[0-9]{2} 14:[0-5][0-9]:[0-5][0-9]' *.log | cut -d' ' -f4- | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"2023-11-01 13:45:00 Error: Disk not found\\n2023-11-01 14:10:23 Error: Network timeout\\n2023-11-01 14:15:45 Error: Disk not found\\n2023-11-01 15:05:12 Error: Memory leak\" > ~/project_logs/log1.log\necho -e \"2023-11-01 14:35:00 Error: CPU overload\\n2023-11-01 14:50:30 Error: Network timeout\\n2023-11-01 16:05:10 Error: Unauthorized access\" > ~/project_logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/project_logs\ngrep -hE '^[0-9]{4}-[0-9]{2}-[0-9]{2} 14:[0-5][0-9]:[0-5][0-9]' *.log | cut -d' ' -f4- | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"project_logs\" containing multiple log files with the \".log\" extension. Each log file consists of lines recording various events with timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique dates (in YYYY-MM-DD format) are present across all log files in this directory.",
        "explanation": "To solve this problem, you need to iterate over each log file in the \"project_logs\" directory and extract the date portion from each timestamp. You can use tools like `awk` or `cut` to extract the date, and then utilize `sort` and `uniq` to determine the number of unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind project_logs -name \"*.log\" -exec cat {} + | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p project_logs\ncat > project_logs/log1.log <<EOL\n2023-10-01 12:34:56 Event1\n2023-10-02 13:45:20 Event2\n2023-10-01 14:15:30 Event3\nEOL\n\ncat > project_logs/log2.log <<EOL\n2023-10-02 09:30:00 Event4\n2023-10-03 11:11:11 Event5\n2023-10-04 15:00:00 Event6\nEOL\n\ncat > project_logs/log3.log <<EOL\n2023-10-03 08:20:20 Event7\n2023-10-05 22:45:55 Event8\n2023-10-04 18:25:35 Event9\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find project_logs -name \"*.log\" -exec cat {} + | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified within the last 7 days and have a file size greater than 1MB.",
        "explanation": "To solve this problem, you can use the `find` command to search for files in your home directory that meet the specified criteria. The `-mtime` option can be used to filter files modified within the last 7 days, and the `-size` option can be used to filter files larger than 1MB. You will need to count these files using additional command-line tools like `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example script that solves the problem using shell commands.\nfind ~ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# Create some sample files with different modification times and sizes in the student's home directory\nmkdir -p ~/test_files\ntouch ~/test_files/file1.txt\ntouch ~/test_files/file2.txt\ndd if=/dev/zero of=~/test_files/file3.txt bs=2M count=1 # creates a file with size of 2MB\n\n# Modify file timestamps for testing purposes\ntouch -d \"3 days ago\" ~/test_files/file1.txt\ntouch -d \"10 days ago\" ~/test_files/file2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example script that solves the problem using shell commands.\nfind ~ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "Identify the total number of lines containing the word \"error\" in all `.log` files within a directory named `/var/logs`. You should only count lines where \"error\" appears as a standalone word (case insensitive).",
        "explanation": "To solve this problem, you can use tools such as `grep` to search for the word \"error\" in all `.log` files. The `-w` option in `grep` will help ensure that only standalone occurrences of \"error\" are matched. Additionally, the `-i` option can be used for case-insensitive matching. You might also need to use `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -iw 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs\necho -e \"Error: Something went wrong\\nSome other log line\\nerror occurred again\\nAnother error here\" > /var/logs/system.log\necho -e \"An error was detected\\nNo issues here\\nWarning: Check this out\\nEnd of log file\" > /var/logs/application.log\necho -e \"Errors everywhere\\nCritical Error happening now\\nAll is well\\nJust an error test\" > /var/logs/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -iw 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there are multiple directories containing text files. These directories are named in the format \"projectX\" where X is a number. Each text file contains various lines of text. Your task is to find the total number of lines across all these text files that contain the word \"error\". Ignore case when searching for the word \"error\".",
        "explanation": "To solve this problem, you need to navigate through each \"projectX\" directory in your home directory and search for files that contain lines with the word \"error\". You can use utilities like `find` to locate these files and `grep` with appropriate flags to count matching lines while ignoring case sensitivity.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/project* -type f -exec grep -i 'error' {} + | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project1 ~/project2 ~/project3\necho -e \"This is an Error line.\\nAnother line.\" > ~/project1/file1.txt\necho -e \"No issues here.\\nJust an error.\" > ~/project2/file2.txt\necho -e \"Everything seems fine.\\nERROR detected!\" > ~/project3/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/project* -type f -exec grep -i 'error' {} + | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all `.log` files within the `/var/log` directory that contain the word \"error\". You should only count lines from files that were modified in the last 7 days.",
        "explanation": "To solve this problem, you need to first identify all `.log` files in the `/var/log` directory. Then, filter these files to include only those modified within the last 7 days. Finally, search through these filtered files for lines containing the word \"error\" and count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log/test_logs -name \"*.log\" -mtime -7 | xargs grep -i \"error\" | wc -l\n```",
        "create": {
            "init": "# Create a sample log file structure for testing\nmkdir -p /var/log/test_logs\necho -e \"This is an error\\nNo issues here\" > /var/log/test_logs/system.log\necho -e \"Another error occurred\\nAll good\" > /var/log/test_logs/application.log\n\n# Update modification time to ensure they fall within criteria\ntouch -m -d \"$(date)\" /var/log/test_logs/system.log\ntouch -m -d \"$(date)\" /var/log/test_logs/application.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log/test_logs -name \"*.log\" -mtime -7 | xargs grep -i \"error\" | wc -l"
        }
    },
    {
        "description": "Count the number of text files in your home directory that contain the word \"Linux\" at least twice, and output this count.",
        "explanation": "To solve this problem, you first need to search for all text files in your home directory. You can use the `find` command with appropriate options to filter out text files. Next, you should use `grep` to search within these files for occurrences of the word \"Linux\". The `-c` option will help count the number of times \"Linux\" appears in each file. You need to then filter out files where this count is at least two and finally sum up these counts.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all text files and count occurrences of 'Linux'\ncount=0\nfor file in $(find ~ -name \"*.txt\"); do\n  if [ $(grep -c \"Linux\" \"$file\") -ge 2 ]; then\n    ((count++))\n  fi\ndone\n\n# Output the final count which matches integer-match evaluation type requirements.\necho $count\n```",
        "create": {
            "init": "# Create sample text files in the student's home directory\necho -e \"Welcome to Linux.\\nLinux is awesome.\" > ~/file1.txt\necho -e \"This is a test file.\\nNothing about Linux here.\" > ~/file2.txt\necho -e \"Linux is great.\\nI love Linux!\" > ~/file3.txt\necho -e \"Just another line.\\nAnd another.\" > ~/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all text files and count occurrences of 'Linux'\ncount=0\nfor file in $(find ~ -name \"*.txt\"); do\n  if [ $(grep -c \"Linux\" \"$file\") -ge 2 ]; then\n    ((count++))\n  fi\ndone\n\n# Output the final count which matches integer-match evaluation type requirements.\necho $count"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple text files. Each file contains log entries with timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to count how many log entries occurred between the hours of 9 AM and 5 PM (inclusive) across all files. Assume logs are in UTC.",
        "explanation": "To solve this problem, you need to iterate over each file in the \"logs\" directory, extract timestamps from the log entries, and count those that fall within the specified time range (09:00:00 to 17:00:00). You can use tools like `grep`, `awk`, or `sed` to filter and process the timestamps efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -exec awk '$2 >= \"09:00:00\" && $2 <= \"17:00:00\"' {} + | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 08:45:23 Log entry 1\\n2023-10-01 09:15:42 Log entry 2\\n2023-10-01 14:30:29 Log entry 3\\n2023-10-01 18:05:12 Log entry 4\" > ~/logs/log1.txt\necho -e \"2023-10-02 11:22:33 Log entry a\\n2023-10-02 16:45:55 Log entry b\\n2023-10-02 19:30:01 Log entry c\" > ~/logs/log2.txt\necho -e \"2023-10-03 07:59:59 Log entry x\\n2023-10-03 12:00:00 Log entry y\\n2023-10-03 16:59:59 Log entry z\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -exec awk '$2 >= \"09:00:00\" && $2 <= \"17:00:00\"' {} + | wc -l"
        }
    },
    {
        "description": "You need to determine the total number of unique IP addresses that have accessed a web server by inspecting all the log files in the `/var/log/apache2` directory, and ensure you exclude any access from local IP addresses (i.e., those starting with `192.168`).",
        "explanation": "To solve this problem, you should first locate all relevant log files in the `/var/log/apache2` directory. Use tools like `grep` to extract IP addresses from these logs, then filter out those starting with `192.168`. Finally, use `sort` and `uniq` to count the number of unique non-local IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract IPs from all logs, exclude local IPs, sort them uniquely and count\ngrep -hEo '^[^ ]+' /var/log/apache2/access.log* | grep -v '^192\\.168' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create some sample Apache log files for testing\nmkdir -p /var/log/apache2\necho -e \"192.168.1.1 - - [12/Oct/2023:06:25:24 +0000] \\\"GET /index.html HTTP/1.1\\\" 200 2326\\n203.0.113.5 - - [12/Oct/2023:07:25:24 +0000] \\\"GET /about.html HTTP/1.1\\\" 200 1024\\n198.51.100.7 - - [12/Oct/2023:08:25:24 +0000] \\\"POST /form_submit HTTP/1.1\\\" 404 512\" > /var/log/apache2/access.log\necho -e \"203.0.113.5 - - [13/Oct/2023:09:30:24 +0000] \\\"GET /contact.html HTTP/1.1\\\" 200 2048\\n192.168.1.2 - - [13/Oct/2023:10:30:24 +0000] \\\"GET /home.html HTTP/1.1\\\" 200 3072\" > /var/log/apache2/access.log-20231013"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract IPs from all logs, exclude local IPs, sort them uniquely and count\ngrep -hEo '^[^ ]+' /var/log/apache2/access.log* | grep -v '^192\\.168' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all `.txt` files located within the \"documents\" directory and its subdirectories, but only include lines that contain the word \"Linux\".",
        "explanation": "To solve this problem, you need to search through all `.txt` files in the \"documents\" directory and recursively in its subdirectories. Use tools like `find` to locate these files and `grep` to filter lines containing the word \"Linux\". You can then use `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count lines containing 'Linux' in all .txt files within 'documents' directory and subdirectories.\nfind documents -type f -name \"*.txt\" | xargs grep -i \"Linux\" | wc -l\n```",
        "create": {
            "init": "# Create a directory named 'documents' and populate it with sample .txt files\nmkdir -p documents/subdir1 documents/subdir2\n\necho -e \"Linux is great\\nOperating systems\\nLinux again\" > documents/file1.txt\necho -e \"Another line\\nNot Linux\\nYet another Linux line\" > documents/subdir1/file2.txt\necho -e \"Just a line here\\nMore Linux stuff\" > documents/subdir2/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count lines containing 'Linux' in all .txt files within 'documents' directory and subdirectories.\nfind documents -type f -name \"*.txt\" | xargs grep -i \"Linux\" | wc -l"
        }
    },
    {
        "description": "In your home directory, you have several text files with various extensions. Count how many of these text files contain the word \"Linux\" and output only the count.",
        "explanation": "To solve this problem, you can use tools like `grep` to search for the word \"Linux\" within files and `wc` to count the number of lines containing matches. You can leverage the `find` command to locate all text files based on extension and use pipes to combine these operations effectively.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use find, grep, and wc to count occurrences of 'Linux' in text files in home directory.\nfind ~ -type f \\( -name \"*.txt\" -o -name \"*.md\" \\) | xargs grep -l \"Linux\" | wc -l\n```",
        "create": {
            "init": "# Create sample text files in the home directory\ncd ~\necho \"This file mentions Linux.\" > file1.txt\necho \"No mention here.\" > file2.txt\necho \"Linux is great!\" > file3.txt\necho \"Another line without mention.\" > file4.log\necho \"Yet another line mentioning Linux.\" > file5.md"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use find, grep, and wc to count occurrences of 'Linux' in text files in home directory.\nfind ~ -type f \\( -name \"*.txt\" -o -name \"*.md\" \\) | xargs grep -l \"Linux\" | wc -l"
        }
    },
    {
        "description": "Find and count the number of unique IP addresses that have accessed a web server, by analyzing the access.log file located in your home directory. Ignore lines that do not contain valid IP addresses.",
        "explanation": "To solve this problem, you need to analyze the access.log file to extract valid IP addresses. You can use tools such as grep or awk to filter out lines containing valid IPs (usually in the format xxx.xxx.xxx.xxx), sort them uniquely using sort and uniq commands, and finally count them using wc -l.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract valid IP addresses from access.log, sort uniquely, and count them.\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create an example access.log file in the student's home directory\ncat <<EOF > ~/access.log\n192.168.0.1 - - [10/Oct/2023:13:55:36 +0000] \"GET /index.html HTTP/1.1\" 200 1234\n192.168.0.2 - - [10/Oct/2023:14:02:01 +0000] \"POST /submit-form HTTP/1.1\" 404 567\ninvalid-entry - - [10/Oct/2023:14:05:20 +0000] \"GET /home HTTP/1.1\" 200 2345\n192.168.0.1 - - [10/Oct/2023:14:12:45 +0000] \"GET /contact HTTP/1.1\" 200 8765\n255.255.255.255 - - [10/Oct/2023:14:19:08 +0000] \"GET /download HTTP/1.1\" 403 1234\nEOF"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract valid IP addresses from access.log, sort uniquely, and count them.\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and whose size exceeds 1MB.",
        "explanation": "To solve this problem, you can use the `find` command which is very powerful for filtering files based on various criteria. You need to specify your home directory as the search location, and then use options like `-mtime` to filter files modified within a certain timeframe, and `-size` to filter those larger than a specified size. The result can be fed into `wc -l` to count the number of matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization needed as students will work with their existing home directories."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "You need to find all files with the \".log\" extension in the \"/var/log\" directory that have been modified in the last 7 days, and count how many such files exist.",
        "explanation": "To solve this problem, you can use the \"find\" command to search for files with a \".log\" extension in the specified directory that have been modified within the last 7 days. The \"-mtime\" option can be used for this purpose. You can then use \"wc -l\" to count the number of lines outputted by \"find,\" which corresponds to the number of matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -name \"*.log\" -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization is required as /var/log is a standard directory on Linux systems containing log files."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -name \"*.log\" -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count how many files in your home directory are larger than 1MB and have been modified in the last 7 days.",
        "explanation": "To solve this problem, you can use the `find` command to search for files in your home directory that meet the size and modification time criteria. The `-size` option allows you to specify file size, and the `-mtime` option allows you to specify modification time. You should combine these options with logical operators to filter out the desired files, and then use `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -size +1M -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -size +1M -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that contain the word \"error\" in their filenames, ignoring case sensitivity.",
        "explanation": "To solve this problem, you need to list all files in your home directory and use a command to filter those whose names contain the word \"error\" regardless of case. You can use utilities like `ls`, `grep`, or `find` combined with appropriate flags for case-insensitive search.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the home directory\ncd ~\n\n# Find and count files containing 'error' in their filenames, case insensitive\nfind . -type f -iname \"*error*\" | wc -l\n```",
        "create": {
            "init": "# No initialization required for this problem"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to the home directory\ncd ~\n\n# Find and count files containing 'error' in their filenames, case insensitive\nfind . -type f -iname \"*error*\" | wc -l"
        }
    },
    {
        "description": "You are given a directory called \"logs\" in your home directory, which contains multiple log files with a \".log\" extension. Each file consists of entries with timestamps and various log levels such as INFO, WARN, and ERROR. Your task is to determine how many unique ERROR messages occurred on the most recent date present in these log files.",
        "explanation": "To solve this problem, you need to first identify the most recent date across all log files. Then, filter out entries from that date that contain the ERROR level. Finally, extract the unique ERROR messages and count them. Consider using tools like `grep`, `awk`, `sort`, `uniq`, and `date` to aid your process.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find the most recent date from all logs\nmost_recent_date=$(grep -hoP '\\d{4}-\\d{2}-\\d{2}' ~/logs/*.log | sort | uniq | tail -n1)\n\n# Extract unique ERROR messages from the most recent date\nunique_errors=$(grep \"$most_recent_date.*ERROR\" ~/logs/*.log | awk '{$1=$2=\"\"; print $0}' | sort | uniq)\n\n# Count the number of unique errors\necho \"$unique_errors\" | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 10:00:00 INFO Starting process\\n2023-10-02 12:00:00 WARN Disk space low\\n2023-10-03 14:30:00 ERROR Connection failed\\n2023-10-03 15:30:00 ERROR Connection failed\\n2023-10-03 17:45:00 INFO Process completed\" > ~/logs/system1.log\necho -e \"2023-10-02 09:15:00 INFO User login\\n2023-10-02 11:45:00 ERROR Timeout occurred\\n2023-10-03 13:05:00 WARN Memory usage high\\n2023-10-03 16:50:00 ERROR Disk error detected\" > ~/logs/system2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find the most recent date from all logs\nmost_recent_date=$(grep -hoP '\\d{4}-\\d{2}-\\d{2}' ~/logs/*.log | sort | uniq | tail -n1)\n\n# Extract unique ERROR messages from the most recent date\nunique_errors=$(grep \"$most_recent_date.*ERROR\" ~/logs/*.log | awk '{$1=$2=\"\"; print $0}' | sort | uniq)\n\n# Count the number of unique errors\necho \"$unique_errors\" | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that were modified in the last 7 days and have a size greater than 1MB.",
        "explanation": "To solve this problem, you need to list all files in your home directory, filter out those modified within the last 7 days using the `find` command with the `-mtime` option, then further filter them by size using the `-size` option. Finally, count the resulting files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization script is required for this task as it utilizes existing user data."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all \".log\" files located within the \"/var/log/\" directory and its subdirectories that contain the string \"error\".",
        "explanation": "To solve this problem, you need to search recursively through the \"/var/log/\" directory for files ending with \".log\". Then, filter out lines containing the string \"error\" from these files and count them. You can use tools like `find`, `grep`, and `wc` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log/ -type f -name \"*.log\" -exec grep -i error {} \\; | wc -l\n```",
        "create": {
            "init": "# No initialization required since we are using existing log files on the system."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log/ -type f -name \"*.log\" -exec grep -i error {} \\; | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines across all `.txt` files located in a directory called `data` within your home directory. You should only count lines in files that have been modified within the last 7 days.",
        "explanation": "To solve this problem, you need to use a combination of file management and text processing utilities available in Linux. First, identify `.txt` files in the `data` directory that were modified within the last 7 days using `find`. Then, use `wc -l` to count lines for each selected file and sum up these counts to get the total number of lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/data -name \"*.txt\" -mtime -7 | xargs wc -l | tail -n 1 | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p ~/data\ntouch ~/data/file1.txt ~/data/file2.txt ~/data/file3.txt\necho \"Line 1\" > ~/data/file1.txt\necho -e \"Line 1\\nLine 2\" > ~/data/file2.txt\necho -e \"Line 1\\nLine 2\\nLine 3\" > ~/data/file3.txt\n# Modify timestamps for testing:\ntouch -d \"8 days ago\" ~/data/file1.txt\ntouch -d \"today\" ~/data/file2.txt\ntouch -d \"today\" ~/data/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/data -name \"*.txt\" -mtime -7 | xargs wc -l | tail -n 1 | awk '{print $1}'"
        }
    },
    {
        "description": "Find and count the number of unique extensions of files located in the directory \"/home/student/documents\" that have been modified in the last 7 days.",
        "explanation": "To solve this problem, you should use a combination of 'find' to locate files modified in the last 7 days, 'awk' or 'sed' to extract file extensions, and 'sort' followed by 'uniq' to get unique extensions. Finally, you can use 'wc -l' to count these unique extensions.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -mtime -7 | sed -n 's/.*\\.//p' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\ntouch /home/student/documents/file1.txt\ntouch /home/student/documents/file2.doc\ntouch /home/student/documents/file3.pdf\ntouch /home/student/documents/file4.txt\nsleep 1 # Ensures subsequent files have different timestamps\ntouch /home/student/documents/oldfile.log # This file has an older timestamp\n\n# Modify timestamps to simulate recent modifications (except oldfile.log)\nfind /home/student/documents -type f ! -name \"oldfile.log\" -exec touch {} \\;"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -mtime -7 | sed -n 's/.*\\.//p' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days, and whose size is greater than 1MB.",
        "explanation": "To solve this problem, you need to first navigate to your home directory. Then, use the `find` command to search for files that match the criteria: modified within the last 7 days and have a size greater than 1MB. The `-mtime` option allows you to filter files based on their modification time, and `-size` can be used to specify file size. Finally, count the number of files that meet these conditions using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~\nfind . -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~\nfind . -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that were modified in the last 24 hours.",
        "explanation": "To solve this problem, you can use the `find` command with appropriate options to filter files based on their modification time. Specifically, you can use the `-mtime` option with a value of 0 to find files modified within the last day. Combine this with `wc -l` to count the number of such files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -1 | wc -l\n```",
        "create": {
            "init": "# This script creates some test files in the home directory for demonstration.\ntouch ~/test_file_1\ntouch ~/test_file_2\nsleep 2\ntouch ~/recent_file_3"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -1 | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory that contains multiple log files with the \".log\" extension. Each file records various events of a system, and every line in a log file starts with a timestamp in the format \"[YYYY-MM-DD HH:MM:SS]\". Your task is to find out how many unique days are there across all the log files. Assume each day is represented by \"YYYY-MM-DD\".",
        "explanation": "To solve this problem, you need to extract the date portion from each line of all log files in the \"logs\" directory, store them uniquely, and then count how many unique dates exist. You can use utilities such as `grep`, `cut`, `sort`, and `uniq` to accomplish this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep -ho \"^\\[[0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\}\" *.log | cut -d'[' -f2 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"[2023-01-01 09:00:00] Event1\" > ~/logs/log1.log\necho \"[2023-01-02 10:00:00] Event2\" >> ~/logs/log1.log\necho \"[2023-01-02 11:30:00] Event3\" >> ~/logs/log1.log\necho \"[2023-01-03 12:45:00] Event4\" > ~/logs/log2.log\necho \"[2023-01-03 13:15:00] Event5\" >> ~/logs/log2.log\necho \"[2023-01-04 14:20:00] Event6\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep -ho \"^\\[[0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\}\" *.log | cut -d'[' -f2 | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and have a '.txt' extension.",
        "explanation": "To solve this problem, you can use the `find` command to locate files with specific criteria. Utilize the `-mtime` option to filter files modified within a certain number of days and the `-name` option to filter for files with a '.txt' extension.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script to count .txt files modified in the last 7 days in home directory.\nfind ~ -type f -name \"*.txt\" -mtime -7 | wc -l\n```",
        "create": {
            "init": "# Create sample text files for testing\nmkdir -p ~/test_files\ntouch ~/test_files/file1.txt ~/test_files/file2.txt\nsleep 1\ntouch ~/test_files/file3.txt ~/test_files/file4.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script to count .txt files modified in the last 7 days in home directory.\nfind ~ -type f -name \"*.txt\" -mtime -7 | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory, which contains multiple log files with the \".log\" extension. Each log file consists of multiple lines, and each line starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to count how many unique dates (in YYYY-MM-DD format) are present across all the log files within the \"logs\" directory.",
        "explanation": "To solve this problem, you need to extract the date part from each line of every \".log\" file in the \"logs\" directory. Then, you should collect all unique dates and count them. You can use utilities like `grep`, `awk`, `sort`, and `uniq` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -hoE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-09-15 10:00:01 Log entry one\\n2023-09-16 11:30:45 Log entry two\\n2023-09-17 12:45:22 Log entry three\\n2023-09-15 13:05:33 Log entry four\" > ~/logs/log1.log\necho -e \"2023-09-18 14:15:54 Log entry five\\n2023-09-16 15:20:10 Log entry six\\n2023-09-19 16:25:40 Log entry seven\\n2023-09-17 17:30:55 Log entry eight\" > ~/logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -hoE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to find the total number of lines containing the word \"error\" across all log files in the directory \"/var/logs\". The word \"error\" should be case-insensitive.",
        "explanation": "To solve this problem, you will need to use a combination of commands that can search for text within files and count occurrences. You can use `grep` with the `-i` flag to perform a case-insensitive search, and then pipe the results to `wc -l` to count the number of lines that contain \"error\".\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Search for 'error' in all logs and count occurrences\ngrep -i 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "# Create a directory for logs\nmkdir -p /var/logs\n\n# Create sample log files with content\necho -e \"Error: Disk full\\nWarning: High Memory Usage\\nERROR: Network down\\nInfo: Scheduled reboot\" > /var/logs/system.log\necho -e \"Fatal Error: Application crash\\nINFO: Backup completed\\nError: Unauthorized access attempt\" > /var/logs/application.log\necho -e \"Debug: Initializing module\\nCritical Error detected\\nwarning: deprecated API usage\" > /var/logs/debug.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Search for 'error' in all logs and count occurrences\ngrep -i 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing multiple log files with random names. Each file logs events with timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique days have logged events across all these files. You should perform all operations using shell commands.",
        "explanation": "To solve this problem, you need to extract the date portion from each timestamp in the logs, collect all unique dates, and count them. Consider using `cat` to concatenate files, `awk` or `cut` to extract dates, `sort` and `uniq` to filter unique entries, and finally `wc -l` to count the number of unique lines (dates).\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Combine all log files into one stream\ncat logs/* | \n# Extract only the dates (first field)\nawk '{print $1}' |\n# Sort the dates\nsort |\n# Filter out duplicate dates\nuniq |\n# Count the number of unique lines (dates)\nwc -l\n```",
        "create": {
            "init": "mkdir logs\necho -e \"2023-10-01 12:00:00 Event1\\n2023-10-02 13:00:00 Event2\" > logs/log1.txt\necho -e \"2023-10-01 14:00:00 Event3\\n2023-10-03 15:00:00 Event4\" > logs/log2.txt\necho -e \"2023-10-02 16:00:00 Event5\\n2023-10-04 17:00:00 Event6\" > logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Combine all log files into one stream\ncat logs/* | \n# Extract only the dates (first field)\nawk '{print $1}' |\n# Sort the dates\nsort |\n# Filter out duplicate dates\nuniq |\n# Count the number of unique lines (dates)\nwc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"project_data\" in your home directory, containing numerous text files and subdirectories. Some files are compressed with the '.gz' extension. Your task is to determine the total number of unique words across all uncompressed text files directly within this directory (not in subdirectories). Assume a word is any sequence of characters separated by whitespace.",
        "explanation": "To solve this problem, you need to perform several operations: \n1. List all uncompressed text files in the \"project_data\" directory.\n2. Concatenate their contents.\n3. Extract words and count unique ones.\n\nHere are some hints:\n- Use `ls` to list files.\n- Use `cat` or similar command to combine file contents.\n- Use tools like `tr`, `sort`, and `uniq` to process and count unique words.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all uncompressed .txt files in project_data\nfiles=$(find ~/project_data -maxdepth 1 -type f ! -name '*.gz')\n\n# Concatenate their contents, extract words, sort them uniquely, and count them\ncat $files | tr -cs '[:alnum:]' '[\\n*]' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_data\necho \"Hello world\" > ~/project_data/file1.txt\necho \"Linux operating system\" > ~/project_data/file2.txt\necho \"Hello Linux\" > ~/project_data/file3.txt\necho \"compressed content that should not be read\" | gzip > ~/project_data/compressed.gz"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# List all uncompressed .txt files in project_data\nfiles=$(find ~/project_data -maxdepth 1 -type f ! -name '*.gz')\n\n# Concatenate their contents, extract words, sort them uniquely, and count them\ncat $files | tr -cs '[:alnum:]' '[\\n*]' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing several compressed log files (.gz). Count the total number of unique IP addresses found across all these log files, assuming each line in the log files follows the format \"IP_ADDRESS - - [DATE] \"REQUEST\" STATUS_CODE SIZE\".",
        "explanation": "To solve this problem, you need to extract and count unique IP addresses from multiple compressed log files. You can use tools like `zcat` or `gunzip` to decompress the files on-the-fly and process them using text-processing utilities such as `awk`, `sort`, and `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Decompress logs and extract IP addresses, then compute unique count\nzcat ~/logs/*.gz | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a 'logs' directory in the home directory\nmkdir -p ~/logs\n\n# Create sample compressed log files with dummy data\necho -e \"192.168.0.1 - - [01/Oct/2023:12:00:00 +0000] \\\"GET /index.html HTTP/1.1\\\" 200 1024\\n\\\n192.168.0.2 - - [01/Oct/2023:12:05:00 +0000] \\\"GET /about.html HTTP/1.1\\\" 200 2048\\n\\\n192.168.0.1 - - [01/Oct/2023:12:10:00 +0000] \\\"POST /form HTTP/1.1\\\" 404 512\" | gzip > ~/logs/logfile1.gz\n\necho -e \"192.168.0.3 - - [01/Oct/2023:13:00:00 +0000] \\\"GET /contact.html HTTP/1.1\\\" 200 1024\\n\\\n192.168.0.2 - - [01/Oct/2023:13:05:00 +0000] \\\"GET /services.html HTTP/1.1\\\" 200 2048\\n\\\n192.168.0.4 - - [01/Oct/2023:13:10:00 +0000] \\\"POST /submit HTTP/1.1\\\" 404 512\" | gzip > ~/logs/logfile2.gz"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Decompress logs and extract IP addresses, then compute unique count\nzcat ~/logs/*.gz | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_logs\" in your home directory that contains multiple log files with the \".log\" extension. Each file logs activities with timestamps, user actions, and status messages. Your task is to find out how many unique error messages (lines containing the word \"ERROR\") are present across all log files in this directory.",
        "explanation": "To solve this problem, you need to list all log files in the \"project_logs\" directory and search for lines containing the word \"ERROR\". Then, extract these lines and filter them to find unique error messages. You can use a combination of commands like `grep`, `sort`, `uniq`, and `wc` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR' ~/project_logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"2023-10-01 12:00:00 INFO Starting process\\n2023-10-01 12:01:00 ERROR Connection failed\\n2023-10-01 12:02:00 ERROR Timeout occurred\" > ~/project_logs/log1.log\necho -e \"2023-10-02 13:00:00 INFO Process running\\n2023-10-02 13:05:00 ERROR Connection failed\\n2023-10-02 13:06:00 INFO Process completed\" > ~/project_logs/log2.log\necho -e \"2023-10-03 14:00:00 ERROR Disk full\\n2023-10-03 14:01:00 INFO Cleanup started\\n2023-10-03 14:02:00 ERROR Timeout occurred\" > ~/project_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR' ~/project_logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of unique IP addresses that have accessed a web server, using the log file `access.log` located in your home directory. The log file follows the common format where each line starts with an IP address.",
        "explanation": "To solve this problem, you need to read through each line of the `access.log` file and extract the IP addresses. Then, you can use tools like `awk` or `cut` to isolate these IPs. Finally, use `sort` and `uniq` to count how many unique IP addresses are present.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract the first column (IP addresses) using awk, sort them and filter unique ones, then count them.\nawk '{print $1}' ~/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample access.log file with some repeated and some unique IP addresses.\ncat > ~/access.log << 'EOF'\n192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \"GET /index.html HTTP/1.1\" 200 1043\n192.168.1.2 - - [10/Oct/2023:13:55:37 +0000] \"POST /submit HTTP/1.1\" 404 221\n192.168.1.3 - - [10/Oct/2023:13:55:38 +0000] \"GET /home.html HTTP/1.1\" 200 532\n192.168.1.2 - - [10/Oct/2023:13:55:39 +0000] \"GET /about.html HTTP/1.1\" 200 1234\n192.168.1.4 - - [10/Oct/2023:13:55:40 +0000] \"GET /contact.html HTTP/1.1\" 304 -\n192.168.1.5 - - [10/Oct/2023:13:55:41 +0000] \"POST /upload HTTP/2\" 201 -\nEOF"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract the first column (IP addresses) using awk, sort them and filter unique ones, then count them.\nawk '{print $1}' ~/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory on the Linux system, there are multiple text files with random data. Your task is to count and output the total number of lines that contain the word \"Linux\" across all text files in this directory. You should ignore case sensitivity when counting occurrences of \"Linux\".",
        "explanation": "To solve this problem, you need to iterate over each text file in your home directory and search for lines containing the word \"Linux\", disregarding letter case. The `grep` command can be used with the `-i` option to perform a case-insensitive search, and the `-c` option can count occurrences within each file. Summing these counts will give you the total number of lines containing \"Linux\".\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count lines containing 'Linux' (case-insensitive) across all text files.\ngrep -i 'linux' ~/*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample text files in the student's home directory.\necho -e \"Welcome to Linux\\nThis is a test file.\\nLINUX is popular.\" > ~/file1.txt\necho -e \"Another line about linux.\\nLearning Linux is fun!\" > ~/file2.txt\necho -e \"No mention here.\\nJust some random text.\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count lines containing 'Linux' (case-insensitive) across all text files.\ngrep -i 'linux' ~/*.txt | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory, which contains multiple text files with server logs. Each log entry is a single line and follows the format: \"[timestamp] [log_level] [message]\". Your task is to count the number of log entries that have the log level \"ERROR\". Note that log levels such as \"INFO\", \"DEBUG\", and \"WARN\" may also be present in the files. You need to find all files recursively in this directory and count the total number of \"ERROR\" entries.",
        "explanation": "To solve this problem, you can use the `find` command to locate all text files within the \"log_files\" directory. Then, use `grep` with appropriate options to search for lines containing \"ERROR\". Finally, utilize `wc -l` to count these lines across all files. The pipeline of commands will help you aggregate results from multiple files efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/log_files -type f -name \"*.log\" -exec grep -h 'ERROR' {} + | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files/subdir\necho -e \"[2023-10-01 12:00:00] INFO Starting service\\n[2023-10-01 12:05:00] ERROR Failed to connect\\n[2023-10-01 12:10:00] DEBUG Connection retry\" > ~/log_files/server1.log\necho -e \"[2023-10-01 13:00:00] WARN Low memory\\n[2023-10-01 13:05:00] ERROR Disk full\\n[2023-10-01 13:15:00] ERROR Timeout reached\" > ~/log_files/subdir/server2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/log_files -type f -name \"*.log\" -exec grep -h 'ERROR' {} + | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing log files in the `/var/log/myapp/` directory. Your goal is to find out how many unique IP addresses have accessed the application in the last 24 hours. The log files are named in the format `access-YYYYMMDD.log`. Assume today is 2023-10-15, so you should focus on the file `access-20231014.log`. You need to filter out only IPv4 addresses.",
        "explanation": "To solve this problem, you can use tools like `grep` to extract IP addresses from the log file, followed by `awk` or `sed` to ensure only valid IPv4 addresses are considered. Use `sort` and `uniq` to count distinct entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '([0-9]{1,3}\\.){3}[0-9]{1,3}' /var/log/myapp/access-20231014.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/log/myapp/\ncat <<EOL > /var/log/myapp/access-20231014.log\n192.168.1.1 - - [14/Oct/2023:10:00:00 +0000] \"GET /index.html HTTP/1.1\" 200 2326\n192.168.1.2 - - [14/Oct/2023:11:00:00 +0000] \"POST /form.html HTTP/1.1\" 404 7210\n10.0.0.5 - - [14/Oct/2023:12:30:00 +0000] \"GET /home.html HTTP/1.1\" 200 1456\n192.168.1.1 - - [14/Oct/2023:13:45:00 +0000] \"GET /about.html HTTP/1.1\" 200 980\n172.16.254.3 - - [14/Oct/2023:15:20:00 +0000] \"GET /contact.html HTTP/1.1\" 503 2145\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '([0-9]{1,3}\\.){3}[0-9]{1,3}' /var/log/myapp/access-20231014.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all text files (*.txt) located in your home directory and its subdirectories. Ensure you include hidden directories and files in your count.",
        "explanation": "To solve the problem, you can use the `find` command to search for all `.txt` files in the home directory recursively, including hidden files and directories. Then, use a combination of `xargs` with `wc -l` to count the lines in each file and sum them up to get the total number of lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files, including hidden ones, and count their lines.\nfind ~ \\( -type d -name '.*' \\) , \\( -type f -name '*.txt' \\) | xargs wc -l | tail -n 1 | awk '{print $1}'\n```",
        "create": {
            "init": "# Create some sample text files with various numbers of lines.\nmkdir -p ~/testdir/subdir\necho -e \"Line 1\\nLine 2\\nLine 3\" > ~/testdir/file1.txt\necho -e \"Line 1\\nLine 2\" > ~/testdir/file2.txt\necho -e \"This is a single line.\" > ~/testdir/subdir/file3.txt\nmkdir -p ~/.hidden-dir\necho -e \"Hidden Line 1\\nHidden Line 2\" > ~/.hidden-dir/hiddenfile.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files, including hidden ones, and count their lines.\nfind ~ \\( -type d -name '.*' \\) , \\( -type f -name '*.txt' \\) | xargs wc -l | tail -n 1 | awk '{print $1}'"
        }
    },
    {
        "description": "In your home directory, there is a file named `log.txt` which contains multiple lines of log entries with timestamps. Each line follows the format \"YYYY-MM-DD HH:MM:SS - Log message\". Your task is to count how many log entries occurred on February 29th during leap years between 2000 and 2020.",
        "explanation": "To solve this problem, you need to identify leap years between 2000 and 2020 by checking if the year is divisible by 4, but not divisible by 100 unless it is divisible by 400. Then filter out log entries with dates matching February 29th in those years. Count the number of such entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script to count log entries on Feb. 29 during leap years from log.txt file\n\n# Get all lines from Feb.29 between years (leap years)\ngrep -E '^(2000|2004|2008|2012|2020)-02-29' ~/log.txt | wc -l\n```",
        "create": {
            "init": "# Create a sample log.txt file in the home directory\ncat > ~/log.txt <<EOL\n2000-02-29 12:00:00 - Event A\n2004-02-29 15:45:00 - Event B\n2008-02-28 09:30:00 - Event C\n2012-02-29 18:20:00 - Event D\n2016-03-01 14:15:00 - Event E\n2020-02-29 07:10:00 - Event F\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script to count log entries on Feb. 29 during leap years from log.txt file\n\n# Get all lines from Feb.29 between years (leap years)\ngrep -E '^(2000|2004|2008|2012|2020)-02-29' ~/log.txt | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all text files in your home directory, excluding any lines that contain the word \"error\".",
        "explanation": "To solve this problem, you need to search through all text files in your home directory and count the lines. You should use tools like `find`, `grep`, and `wc`. First, locate all `.txt` files using `find`. Then use `grep` to exclude lines containing \"error\". Finally, count the remaining lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files in the home directory, exclude lines containing 'error', and count remaining lines.\nfind ~ -maxdepth 1 -name \"*.txt\" -exec grep -v 'error' {} \\; | wc -l\n```",
        "create": {
            "init": "# Create sample text files with random content in the user's home directory\necho -e \"This is a test file.\\nIt has some content.\\nNo error here.\" > ~/file1.txt\necho -e \"Another file.\\nIt mentions error once.\\nThen it ends.\" > ~/file2.txt\necho -e \"Just a regular line.\\nAnd another one.\\nNo errors at all.\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files in the home directory, exclude lines containing 'error', and count remaining lines.\nfind ~ -maxdepth 1 -name \"*.txt\" -exec grep -v 'error' {} \\; | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all `.txt` files located in your home directory that contain the word \"Linux\". You should exclude any hidden files (those starting with a dot) from your count.",
        "explanation": "To solve this problem, you can use a combination of `grep` and `wc` commands. First, use `grep` to search for the word \"Linux\" within all non-hidden `.txt` files in your home directory. Then, use `wc -l` to count the number of lines returned by `grep`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script showing how to solve the problem\ngrep -h \"Linux\" ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Creating sample .txt files in the student's home directory for testing\necho -e \"This is a line about Linux.\\nAnother line.\" > ~/file1.txt\necho -e \"Linux is great.\\nI love Ubuntu.\" > ~/file2.txt\necho -e \"Hidden Linux line.\" > ~/.hidden_file.txt\necho -e \"No mention of OS here.\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script showing how to solve the problem\ngrep -h \"Linux\" ~/file*.txt | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named `log_files` containing multiple `.log` files. Each log file contains timestamps followed by event messages. Your task is to find out the number of unique error messages (lines containing the word \"ERROR\") across all these log files. Provide only the count of unique error messages as your answer.",
        "explanation": "To solve this problem, you need to search through all `.log` files in the `log_files` directory, extract lines containing the word \"ERROR\", and then determine the number of unique error messages. You can use utilities like `grep` to filter out error lines, `sort`, and `uniq` to find unique entries, and `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"ERROR\" log_files/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p log_files\ncat <<EOL > log_files/system1.log\n2023-10-01 10:00:00 INFO Starting system check\n2023-10-01 10:05:00 ERROR Disk full\n2023-10-01 10:06:00 ERROR Network timeout\n2023-10-01 11:00:00 INFO System check complete\nEOL\n\ncat <<EOL > log_files/system2.log\n2023-10-02 09:30:00 ERROR Disk full\n2023-10-02 09:45:00 WARN Low memory\n2023-10-02 09:50:00 ERROR Network timeout\n2023-10-02 09:55:00 ERROR CPU overload\nEOL\n\ncat <<EOL > log_files/system3.log\n2023-10-03 14:20:00 INFO Backup started\n2023-10-03 14:25:00 ERROR Disk full\n2023-10-03 14:30:00 INFO Backup complete\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"ERROR\" log_files/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "There are several text files in your home directory, each containing multiple lines of text. Your task is to determine the total number of unique words across all these files. Words should be considered case-insensitively, and punctuation should be ignored.",
        "explanation": "To solve this problem, you need to read all the text files in your home directory. Use tools like `tr` to translate uppercase letters to lowercase and remove punctuation. Then, use `sort` and `uniq` to filter out duplicate words and count the number of unique words.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Read all text files in the home directory and process them\ncat ~/file*.txt | tr '[:upper:]' '[:lower:]' | tr -d '[:punct:]' | tr ' ' '\\n' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create sample text files in the user's home directory\necho -e \"Hello World!\\nThis is a test.\" > ~/file1.txt\necho -e \"Another line here.\\nHELLO again!\" > ~/file2.txt\necho -e \"Test line with: punctuation.\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Read all text files in the home directory and process them\ncat ~/file*.txt | tr '[:upper:]' '[:lower:]' | tr -d '[:punct:]' | tr ' ' '\\n' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to count the total number of lines across all \".txt\" files located in the \"/var/logs\" directory and its subdirectories. However, only consider files modified within the last 7 days.",
        "explanation": "To solve this problem, you can use the `find` command to search for \".txt\" files within the specified directory and filter them by modification time using `-mtime` option. Then, use `xargs` with `wc -l` to count the total number of lines in these files. The `find` command's `-mtime -7` option will help you filter files modified in the last 7 days.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/logs -type f -name \"*.txt\" -mtime -7 | xargs wc -l | tail -n 1 | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p /var/logs/subdir1 /var/logs/subdir2\necho \"Line 1\" > /var/logs/file1.txt\necho \"Line 2\" >> /var/logs/file1.txt\necho \"Another line\" > /var/logs/subdir1/file2.txt\necho \"More content here\" > /var/logs/subdir2/file3.txt\n\n# Update file modification times to ensure they are within last 7 days.\ntouch -d '5 days ago' /var/logs/file1.txt\ntouch -d '3 days ago' /var/logs/subdir1/file2.txt\ntouch -d '8 days ago' /var/logs/subdir2/file3.txt # This file should not be included."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/logs -type f -name \"*.txt\" -mtime -7 | xargs wc -l | tail -n 1 | awk '{print $1}'"
        }
    },
    {
        "description": "You are tasked with finding the total size of all '.log' files within a directory named 'logs' in your home directory, including all its subdirectories. You need to provide the size in a human-readable format (e.g., KB, MB).",
        "explanation": "To solve this problem, you can use the `find` command to locate all '.log' files within the 'logs' directory and its subdirectories. Then, use the `du` (disk usage) command with appropriate options to calculate the total size in a human-readable format.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\n\n# Find all .log files in 'logs' directory and subdirectories, then calculate their total size\nfind ~/logs -type f -name \"*.log\" -exec du -ch {} + | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "# Create 'logs' directory and subdirectories\nmkdir -p ~/logs/subdir1 ~/logs/subdir2\n\n# Create dummy '.log' files with different sizes\ndd if=/dev/zero of=~/logs/access.log bs=1024 count=50   # 50KB file\ndd if=/dev/zero of=~/logs/error.log bs=1024 count=100   # 100KB file\ndd if=/dev/zero of=~/logs/subdir1/debug.log bs=1024 count=150 # 150KB file\ndd if=/dev/zero of=~/logs/subdir2/event.log bs=1024 count=200 # 200KB file"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "# Example solution script\n\n# Find all .log files in 'logs' directory and subdirectories, then calculate their total size\nfind ~/logs -type f -name \"*.log\" -exec du -ch {} + | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "Count the number of .txt files in the /tmp/test directory that contain the word \"Linux\" at least once.",
        "explanation": "To solve this problem, you need to search through all .txt files in the /tmp/test directory and count how many of these files contain the word \"Linux\". You can utilize tools like `grep` to find occurrences of \"Linux\" in each file and `wc` to count the matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -l \"Linux\" /tmp/test/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /tmp/test\necho \"Welcome to Linux.\" > /tmp/test/file1.txt\necho \"This is a test.\" > /tmp/test/file2.txt\necho \"Learning Linux is fun!\" > /tmp/test/file3.txt\necho \"Another file without the keyword.\" > /tmp/test/file4.txt\ntouch /tmp/test/file5.txt  # empty file"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -l \"Linux\" /tmp/test/*.txt | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all \".log\" files located within the \"/var/logs\" directory and its subdirectories.",
        "explanation": "To solve this problem, you need to search through each \".log\" file in the \"/var/logs\" directory and its subdirectories. Use a combination of `find` to locate all \".log\" files and `grep` to count lines containing the word \"error\". Finally, sum up these counts to get the total number of occurrences across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Find all .log files and count lines containing 'error'\ntotal_error_lines=$(find /var/logs -type f -name \"*.log\" -exec grep -i 'error' {} \\; | wc -l)\necho $total_error_lines\n```",
        "create": {
            "init": "#!/bin/bash\n# Create example log files with some 'error' entries for testing.\nmkdir -p /var/logs/subdir1 /var/logs/subdir2\n\necho -e \"Info: System started\\nError: Failed to connect\\nWarning: Low disk space\" > /var/logs/app1.log\necho -e \"Error: Timeout occurred\\nInfo: User login\\nError: Disk error detected\" > /var/logs/subdir1/app2.log\necho -e \"Warning: High memory usage\\nInfo: Backup completed\\nError: Network unreachable\" > /var/logs/subdir2/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Find all .log files and count lines containing 'error'\ntotal_error_lines=$(find /var/logs -type f -name \"*.log\" -exec grep -i 'error' {} \\; | wc -l)\necho $total_error_lines"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and have a \".txt\" extension. Ensure you exclude directories from this count.",
        "explanation": "To solve this problem, you can use the `find` command to search for files with the \".txt\" extension in your home directory. Use the `-mtime` option to filter files modified within the last 7 days, and employ `-type f` to ensure only regular files are counted (excluding directories). Finally, use `wc -l` to count the matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -name \"*.txt\" -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required as students will use their own home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -name \"*.txt\" -mtime -7 | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a file named \"user_data.csv\" containing multiple columns including \"username\", \"email\", and \"last_login\". Count how many unique email domains are present in the \"email\" column.",
        "explanation": "To solve this problem, you need to extract the domain part from the email addresses listed in the \"user_data.csv\" file. You can do this by using text processing tools like `cut`, `awk`, or `sed` to isolate the domain part after the '@' character. Then, use `sort` to sort these domains followed by `uniq` to count how many unique domains exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk -F',' 'NR>1 {split($2,a,\"@\"); print a[2]}' ~/user_data.csv | sort | uniq | wc -l\n```",
        "create": {
            "init": "echo -e \"username,email,last_login\\njohn_doe,john@example.com,2023-10-01\\njane_smith,jane@sample.org,2023-09-12\\nbob_brown,bob@example.com,2023-10-05\\nalice_green,alice@another.net,2023-08-30\" > ~/user_data.csv"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk -F',' 'NR>1 {split($2,a,\"@\"); print a[2]}' ~/user_data.csv | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all \".txt\" files in your home directory that contain the word \"Linux\", ignoring case sensitivity.",
        "explanation": "To solve this problem, you need to search for the term \"Linux\" within all \".txt\" files located in your home directory. You can use tools such as `grep` with options to allow case-insensitive searching and line counting. Remember to consider only those lines where \"Linux\" appears, regardless of its letter case.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script to count lines containing 'Linux' ignoring case sensitivity\ngrep -i 'linux' ~/sample*.txt | wc -l\n```",
        "create": {
            "init": "# Create some sample .txt files in the user's home directory for testing\necho -e \"This is a Linux tutorial\\nWelcome to Linux\\nOperating systems are crucial.\" > ~/sample1.txt\necho -e \"Understanding linux commands\\nLearn about Ubuntu\\nUsing bash shell.\" > ~/sample2.txt\necho -e \"Exploring file system\\nlinux is versatile\\nPractice makes perfect.\" > ~/sample3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script to count lines containing 'Linux' ignoring case sensitivity\ngrep -i 'linux' ~/sample*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that were modified in the last 7 days and have a \".log\" extension.",
        "explanation": "To solve this problem, you need to list files in your home directory, filter those with a \".log\" extension, check their modification date, and count only those modified within the last 7 days. You can use utilities like `find` with appropriate flags for filtering based on modification time and file extension.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Command to find all .log files modified within the last 7 days in the home directory.\nfind ~ -name \"*.log\" -mtime -7 | wc -l\n```",
        "create": {
            "init": "# Create some test log files in the home directory\ntouch ~/test1.log\ntouch ~/test2.log\ntouch ~/test3.txt\n\n# Modify some log files to set their modification dates to be within the last 7 days\ntouch -d \"2 days ago\" ~/recent1.log\ntouch -d \"5 days ago\" ~/recent2.log\n\n# Modify a log file to set its modification date beyond 7 days ago\ntouch -d \"10 days ago\" ~/old.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Command to find all .log files modified within the last 7 days in the home directory.\nfind ~ -name \"*.log\" -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" across all `.log` files in your home directory and its subdirectories, ignoring case sensitivity.",
        "explanation": "To solve this problem, you can use the `grep` command with recursive search enabled and case-insensitive option. You will need to filter the results to count only the lines that contain the word \"error\". Make sure to include all `.log` files within your home directory and any subdirectories.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example script to count lines containing 'error' in .log files, case insensitive.\ngrep -iR 'error' ~/ --include='*.log' | wc -l\n```",
        "create": {
            "init": "# This script initializes log files in the user's home directory for testing purposes.\nmkdir -p ~/logs/subdir\necho -e \"This is a test.\\nError occurred.\\nAnother line.\" > ~/logs/test1.log\necho -e \"No issues here.\\nAn error found.\" > ~/logs/test2.log\necho -e \"ERROR: Something happened.\\nAll good.\" > ~/logs/subdir/test3.log\necho -e \"Just a warning.\\nerror detected again.\" > ~/logs/subdir/test4.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example script to count lines containing 'error' in .log files, case insensitive.\ngrep -iR 'error' ~/ --include='*.log' | wc -l"
        }
    },
    {
        "description": "Create a directory named \"logs\" in your home directory. Inside this directory, there are several log files with names in the format \"log_YYYYMMDD.txt\". Your task is to find out how many lines contain the word \"ERROR\" across all these log files. Ensure you use the command-line utilities to process the files directly.",
        "explanation": "To solve this problem, navigate to the \"logs\" directory in your home folder using `cd ~/logs`. You can use the `grep` command to search for occurrences of the word \"ERROR\" across all text files, and then count them using `wc -l`. The command `grep -i 'ERROR' log_*.txt | wc -l` will help you achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'ERROR' ~/logs/log_*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: Everything is fine\\nERROR: Something went wrong\\nINFO: All systems go\\nERROR: Failed to start service\" > ~/logs/log_20230101.txt\necho -e \"DEBUG: Starting process\\nINFO: Process started\\nERROR: Process failed\\nDEBUG: Process ended\" > ~/logs/log_20230102.txt\necho -e \"INFO: System check passed\\nDEBUG: Running diagnostics\\nERROR: Diagnostics failed\\nINFO: Reboot required\" > ~/logs/log_20230103.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'ERROR' ~/logs/log_*.txt | wc -l"
        }
    },
    {
        "description": "You have been provided with a directory named \"logs\" in your home directory, which contains multiple text files with log entries. Each log file is named in the format \"log_YYYYMMDD.txt\" (e.g., log_20231015.txt). Your task is to identify the day with the highest number of error entries across all files. An error entry is any line that contains the word \"ERROR\". You should output the date in YYYY-MM-DD format.",
        "explanation": "To solve this problem, you need to iterate through each file in the \"logs\" directory, count how many lines contain the word \"ERROR\", and keep track of which date has the highest count. Use tools like `grep` to search for \"ERROR\" entries and `awk` or `sed` to manage and process data efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\nmax_errors=0\nmax_error_date=\"\"\nfor file in ~/logs/log_*.txt; do\n    errors=$(grep -c 'ERROR' \"$file\")\n    if [ \"$errors\" -gt \"$max_errors\" ]; then\n        max_errors=$errors\n        max_error_date=$(basename \"$file\" | sed 's/log_\\([0-9]\\+\\)\\.txt/\\1/' | awk '{print substr($0,1,4)\"-\"substr($0,5,2)\"-\"substr($0,7,2)}')\n    fi\ndone\necho $max_error_date  # Outputs 2023-10-13 since it has 2 error entries.\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: System running\\nERROR: Failed to load module\\nINFO: Update complete\" > ~/logs/log_20231012.txt\necho -e \"INFO: Boot sequence start\\nINFO: Boot sequence end\\nERROR: Connection timeout\\nERROR: Disk full\" > ~/logs/log_20231013.txt\necho -e \"WARNING: High memory usage\\nINFO: User login successful\\nERROR: Service unavailable\" > ~/logs/log_20231014.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "max_errors=0\nmax_error_date=\"\"\nfor file in ~/logs/log_*.txt; do\n    errors=$(grep -c 'ERROR' \"$file\")\n    if [ \"$errors\" -gt \"$max_errors\" ]; then\n        max_errors=$errors\n        max_error_date=$(basename \"$file\" | sed 's/log_\\([0-9]\\+\\)\\.txt/\\1/' | awk '{print substr($0,1,4)\"-\"substr($0,5,2)\"-\"substr($0,7,2)}')\n    fi\ndone\necho $max_error_date  # Outputs 2023-10-13 since it has 2 error entries."
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing multiple log files with various extensions (.log, .txt, .dat). Count the total number of lines across all files that contain the word \"ERROR\".",
        "explanation": "To solve this problem, you need to iterate through each file in the \"logs\" directory and search for lines containing the word \"ERROR\". You can use tools like `grep` to filter out these lines and `wc -l` to count them. The sum of these counts across all files will be your answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -rh 'ERROR' logs | wc -l\n```",
        "create": {
            "init": "mkdir logs\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nINFO: Backup completed\" > logs/system.log\necho -e \"DEBUG: Starting process\\nERROR: Invalid input\\nINFO: Process ended\" > logs/app.txt\necho -e \"ERROR: Connection lost\\nINFO: Reconnecting\\nDEBUG: Connection established\" > logs/network.dat"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -rh 'ERROR' logs | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.system_logs`. Your task is to count the number of unique IP addresses that appear in this file. Assume each line in the file contains a log entry and the IP address is always the first element on each line, separated by spaces.",
        "explanation": "To solve this problem, you need to read through the `.system_logs` file and extract all unique IP addresses. You can use tools like `awk` or `cut` to extract the first field (the IP address) from each line, and then use `sort` and `uniq` to count distinct IPs.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extracting unique IP addresses from the .system_logs file and counting them.\nawk '{print $1}' ~/.system_logs | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a hidden file .system_logs in the home directory with some sample log entries\ncat <<EOL > ~/.system_logs\n192.168.0.1 User logged in\n192.168.0.2 User logged out\n192.168.0.1 File accessed\n10.0.0.1 User logged in\n172.16.0.5 Server error occurred\n192.168.0.2 File accessed\n10.0.0.1 File uploaded\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extracting unique IP addresses from the .system_logs file and counting them.\nawk '{print $1}' ~/.system_logs | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing multiple text files with system log entries. Your task is to determine how many unique IP addresses have unsuccessfully attempted to access the system by counting distinct IP addresses associated with entries that contain the word \"FAILED\". Only consider log files ending with \".log\" extension.",
        "explanation": "To solve this problem, you need to perform the following steps:\n1. Navigate to the \"logs\" directory.\n2. Use a command like `grep` to search for lines containing the word \"FAILED\" in all \".log\" files.\n3. Extract IP addresses from these lines. Assume IP addresses are in standard IPv4 format (e.g., 192.168.1.1).\n4. Use `sort` and `uniq` commands to count the number of distinct IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the 'logs' directory.\ncd logs\n\n# Search for 'FAILED' entries in .log files, extract IPs, sort them, and get unique counts.\ngrep \"FAILED\" *.log | grep -oE \"([0-9]{1,3}\\.){3}[0-9]{1,3}\" | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p logs\ncat <<EOL > logs/access1.log\n192.168.0.1 - FAILED login attempt\n10.0.0.2 - SUCCESSFUL login attempt\n172.16.0.3 - FAILED login attempt\n192.168.0.1 - FAILED login attempt\nEOL\n\ncat <<EOL > logs/access2.log\n10.0.0.5 - FAILED login attempt\n172.16.0.3 - FAILED login attempt\n192.168.X.X - malformed entry\nEOL\n\ntouch logs/empty.log # An empty log file for edge case testing."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to the 'logs' directory.\ncd logs\n\n# Search for 'FAILED' entries in .log files, extract IPs, sort them, and get unique counts.\ngrep \"FAILED\" *.log | grep -oE \"([0-9]{1,3}\\.){3}[0-9]{1,3}\" | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory. This directory contains multiple log files with the extension \".log\". Each log file may contain multiple lines, where each line starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique days (in the format \"YYYY-MM-DD\") have logged events across all these files. Note that you need to consider only the date part for uniqueness and ignore the time.",
        "explanation": "To solve this problem, you need to extract the date from each line of every log file in the \"logs\" directory. Then, store these dates in a temporary list and finally determine how many unique dates are present. You can use tools like `cat`, `awk`, `sort`, and `uniq` to accomplish this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 Process started\\n2023-10-01 12:30:00 Process ended\" > ~/logs/log1.log\necho -e \"2023-10-02 08:00:00 User login\\n2023-10-02 17:00:00 User logout\" > ~/logs/log2.log\necho -e \"2023-10-03 09:15:00 System update\\n2023-10-01 14:45:00 System check\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines that contain the word \"error\" in all \".log\" files within the \"/var/logs\" directory on your system.",
        "explanation": "To solve this problem, you need to search through all \".log\" files in the \"/var/logs\" directory and count how many lines in each file contain the word \"error\". You can use tools like `grep` to filter lines containing \"error\" and then `wc -l` to count those lines. Additionally, ensure you handle file permissions correctly, as some logs might require elevated privileges to access.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count lines containing 'error' in each .log file within /var/logs and sum them up\ngrep -i 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "# Create a directory /var/logs if it does not exist and generate sample log files for students\nmkdir -p /var/logs\n\n# Create sample .log files with varying content\necho -e \"This is a sample log.\\nAn error occurred.\\nEverything is fine.\" > /var/logs/sample1.log\necho -e \"No issues here.\\nAnother error found.\\nError: something went wrong.\" > /var/logs/sample2.log\necho -e \"Error detected.\\nAll systems go.\\nYet another error.\" > /var/logs/sample3.log\n\n# Ensure proper permissions are set for students to read these files\nchmod 644 /var/logs/*.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count lines containing 'error' in each .log file within /var/logs and sum them up\ngrep -i 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "Find the total number of lines containing the word \"error\" in all `.log` files located in the `/var/log` directory and its subdirectories. You are not allowed to use `grep`.",
        "explanation": "You can use a combination of `find`, `xargs`, and `awk` commands to traverse through directories, locate `.log` files, and count the occurrences of lines containing the word \"error\".\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -name \"*.log\" | xargs awk '/error/ {count++} END {print count}'\n```",
        "create": {
            "init": "# No initialization required as we are using existing system log files."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -name \"*.log\" | xargs awk '/error/ {count++} END {print count}'"
        }
    },
    {
        "description": "Count the total number of text files (.txt) present in your home directory and all of its subdirectories, but only include those files that have been modified in the last 7 days.",
        "explanation": "To solve this problem, you need to use a combination of commands to find and filter files. You can use `find` command to search for text files and apply conditions like modification time. The `-type f` option can be used to specify regular files, `-name \"*.txt\"` to locate text files specifically, and `-mtime -7` to filter out those modified within the last 7 days. Finally, use `wc -l` or similar tools to count the results.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -name \"*.txt\" -mtime -7 | wc -l\n```",
        "create": {
            "init": "# Create sample directories and text files with various modification dates\nmkdir -p ~/test_dir/subdir1 ~/test_dir/subdir2\n\ntouch ~/test_dir/file1.txt\ntouch ~/test_dir/subdir1/file2.txt\ntouch ~/test_dir/subdir2/file3.txt\n\n# Modify file modification times for testing purposes\n# Files modified within the last 7 days\ntouch -m -d \"3 days ago\" ~/test_dir/file1.txt\ntouch -m -d \"5 days ago\" ~/test_dir/subdir1/file2.txt\n\n# File modified more than 7 days ago\ntouch -m -d \"10 days ago\" ~/test_dir/subdir2/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -name \"*.txt\" -mtime -7 | wc -l"
        }
    },
    {
        "description": "Find and count all the files in your home directory that were modified within the last 7 days and have a file size greater than 1MB.",
        "explanation": "To solve this problem, you need to use a combination of `find` command with appropriate options to filter files based on modification time and file size. The `-mtime` option can be used to specify files modified within the last 7 days, and `-size` option can help filter files larger than 1MB. You should also familiarize yourself with using logical operators like `-and` in find command for combining conditions.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization is required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "In your home directory, identify and count the number of files that have been modified in the last 7 days. Consider only regular files (not directories or symbolic links).",
        "explanation": "To solve this problem, you can use the `find` command to search for files in your home directory that have been modified within the last 7 days. The `-type f` option ensures you only count regular files. You can integrate the result with `wc -l` to count the number of matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total size of all text files in the `/home/student/documents` directory that contain the word \"Linux\" at least once. Count only files with a `.txt` extension and ignore case when searching for the word \"Linux\". Provide the total size of these files in human-readable format (e.g., KB, MB).",
        "explanation": "To solve this problem, you should first identify all `.txt` files in the given directory. Then, use a command to search each file for occurrences of the word \"Linux\", ignoring case sensitivity. If a file contains \"Linux\", include its size in your total calculation. Finally, output the total size in a human-readable format.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -name \"*.txt\" -exec grep -qi 'Linux' {} \\; -exec du -ch {} + | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho \"This is a Linux text file.\" > /home/student/documents/file1.txt\necho \"Another line with linux mentioned.\" > /home/student/documents/file2.txt\necho \"This file does not mention it.\" > /home/student/documents/file3.txt\necho \"Yet another Linux example.\" > /home/student/documents/file4.txt\ndd if=/dev/zero of=/home/student/documents/largefile.txt bs=1K count=1024  # 1MB dummy file without 'Linux'"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -name \"*.txt\" -exec grep -qi 'Linux' {} \\; -exec du -ch {} + | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "Find the total number of lines that contain the word \"Linux\" in all `.txt` files within your home directory and its subdirectories without using grep directly on the files.",
        "explanation": "You can solve this problem by using a combination of `find` to locate all `.txt` files and `xargs` to process each file. Use `xargs` to pass those files to a command that reads their content, such as `cat`, and then pipe the output to `grep` to filter lines containing \"Linux\". Finally, use `wc -l` to count these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use find and xargs with cat instead of grep directly on files.\nfind ~ -name \"*.txt\" | xargs cat | grep \"Linux\" | wc -l\n```",
        "create": {
            "init": "# Create some sample .txt files with varying content\nmkdir -p ~/test_directory/subdir1\nmkdir -p ~/test_directory/subdir2\n\necho -e \"This is a line about Linux.\\nAnother line.\" > ~/test_directory/file1.txt\necho -e \"Linux is great!\\nYet another line.\" > ~/test_directory/subdir1/file2.txt\necho -e \"No mention here.\\nStill no Linux.\" > ~/test_directory/subdir2/file3.txt\necho -e \"Here we go: Linux again.\\nAnd more Linux.\" > ~/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use find and xargs with cat instead of grep directly on files.\nfind ~ -name \"*.txt\" | xargs cat | grep \"Linux\" | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_dir\" that contains various types of files, including text files, binary files, and directories. Your task is to find the total number of lines across all text files (with extension .txt) in this directory and its subdirectories. Ignore binary files and directories.",
        "explanation": "To solve this problem, you can use the `find` command to search for all `.txt` files within \"project_dir\" and its subdirectories. Then, use `xargs` or a loop to pass these file paths to `wc -l`, which counts the number of lines in each file. Finally, sum up these counts to get the total number of lines across all text files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind project_dir -type f -name \"*.txt\" | xargs wc -l | awk 'END{print $1}'\n```",
        "create": {
            "init": "mkdir project_dir\necho -e \"Hello\\nWorld\" > project_dir/file1.txt\necho -e \"This is\\na test file.\" > project_dir/file2.txt\necho -e \"Another\\nExample\" > project_dir/subdir1/file3.txt\nmkdir project_dir/subdir1\ntouch project_dir/binaryfile.bin"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find project_dir -type f -name \"*.txt\" | xargs wc -l | awk 'END{print $1}'"
        }
    },
    {
        "description": "You have been given a log file named `system.log` located in the `/var/logs/` directory. This file contains entries of various system events. Your task is to count the number of unique IP addresses that appear in this log file. The IP addresses follow the standard IPv4 format (e.g., 192.168.1.1). You should directly interact with the shell to perform this task and submit your answer as an integer.",
        "explanation": "To solve this problem, you need to extract all IPv4 addresses from the `system.log` file, filter them to ensure uniqueness, and then count how many unique IP addresses are present. You can use tools like `grep`, `awk`, or `sed` to extract IP addresses, and `sort` with `uniq` to filter out duplicates before counting them using tools like `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '([0-9]{1,3}\\.){3}[0-9]{1,3}' /var/logs/system.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs\necho \"User logged in from 192.168.1.10\" > /var/logs/system.log\necho \"Error reported by 10.0.0.5\" >> /var/logs/system.log\necho \"Connection attempt from 172.16.0.3 failed\" >> /var/logs/system.log\necho \"Successful connection from 192.168.1.10\" >> /var/logs/system.log\necho \"System update completed by 10.0.0.5\" >> /var/logs/system.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '([0-9]{1,3}\\.){3}[0-9]{1,3}' /var/logs/system.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"files_directory\" containing multiple text files. Your task is to count how many unique words are present across all files in this directory. A word is defined as any sequence of characters separated by whitespace, and you should ignore case (i.e., treat \"Word\" and \"word\" as the same word).",
        "explanation": "To solve this problem, you need to read all the text files in the specified directory, extract words from each file while ignoring case sensitivity, and then determine the number of unique words across all files. You can use utilities like `cat`, `tr`, `sort`, `uniq`, and others to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat files_directory/*.txt | tr '[:upper:]' '[:lower:]' | tr -s '[:space:][:punct:]' '\\n' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir files_directory\necho -e \"Hello world\\nThis is a test.\" > files_directory/file1.txt\necho -e \"Another test\\nHELLO WORLD\" > files_directory/file2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat files_directory/*.txt | tr '[:upper:]' '[:lower:]' | tr -s '[:space:][:punct:]' '\\n' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of unique words in all text files (.txt) located in the \"documents\" directory, ignoring case sensitivity and excluding any words shorter than four letters.",
        "explanation": "To solve this problem, you need to read each text file in the \"documents\" directory, extract words from these files, convert them to lowercase to ensure case insensitivity, and filter out any words shorter than four letters. Finally, count the number of unique words that remain after applying these filters.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind documents -type f -name \"*.txt\" -exec cat {} + | \\\ntr '[:space:][:punct:]' '\\n' | \\\nawk 'length($0) >= 4 {print tolower($0)}' | \\\nsort | \\\nuniq | \\\nwc -l\n```",
        "create": {
            "init": "mkdir documents\necho -e \"Hello world!\\nThe quick brown fox jumps over the lazy dog.\" > documents/file1.txt\necho -e \"Hello again!\\nThis is a test document with several unique words.\" > documents/file2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find documents -type f -name \"*.txt\" -exec cat {} + | \\\ntr '[:space:][:punct:]' '\\n' | \\\nawk 'length($0) >= 4 {print tolower($0)}' | \\\nsort | \\\nuniq | \\\nwc -l"
        }
    },
    {
        "description": "Count the number of files and directories in your home directory that have been modified in the last 7 days. Only include regular files and directories (not symbolic links).",
        "explanation": "You can use the `find` command to search for files and directories based on their modification time. The `-type f` option will restrict the search to regular files, while `-type d` will target directories. You can combine these options with `-mtime -7` to find items modified in the last 7 days.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 | wc -l\nfind ~ -type d -mtime -7 | wc -l\n```",
        "create": {
            "init": "# This script is empty as no initialization is required."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 | wc -l\nfind ~ -type d -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all text files within your home directory that contain the word \"Linux\". Exclude hidden files and directories from your search.",
        "explanation": "To solve this problem, you need to use commands that can list files in a directory, filter out hidden files and directories, and search for a specific string within these files. You can use `find` to locate all non-hidden text files, `grep` to search for the word \"Linux\", and `wc` to count the lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all non-hidden text files and count lines containing 'Linux'\nfind ~ -maxdepth 1 -type f ! -name '.*' -exec grep -Hc 'Linux' {} \\; | awk '{sum += $NF} END {print sum}'\n```",
        "create": {
            "init": "# Create some sample text files in the home directory\necho -e \"This is a Linux tutorial.\\nLinux is an OS.\" > ~/file1.txt\necho -e \"Another line.\\nHello Linux world!\" > ~/file2.txt\necho -e \"Just some text.\\nNo match here.\" > ~/file3.txt\n\n# Create a hidden file which should be ignored\necho -e \"Hidden Linux content.\" > ~/.hidden_file.txt\n\n# Create a directory with another file inside which should also be ignored\nmkdir ~/ignore_dir\necho -e \"Linux test in dir.\" > ~/ignore_dir/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all non-hidden text files and count lines containing 'Linux'\nfind ~ -maxdepth 1 -type f ! -name '.*' -exec grep -Hc 'Linux' {} \\; | awk '{sum += $NF} END {print sum}'"
        }
    },
    {
        "description": "You need to find the total number of lines containing the word \"error\" in all `.log` files located in the `/var/logs` directory, and you must exclude any line that contains the word \"debug\".",
        "explanation": "To solve this problem, you should navigate to the `/var/logs` directory, use a combination of tools like `grep`, `find`, and `wc` to count lines that match specific criteria. You can start by finding all `.log` files, then using `grep` to filter lines containing \"error\" while excluding lines with \"debug\". Finally, count the resulting lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Find all .log files in /var/logs directory and count lines containing 'error' but not 'debug'\nfind /var/logs -type f -name \"*.log\" -exec grep -i 'error' {} \\; | grep -iv 'debug' | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create /var/logs directory if it doesn't exist\nmkdir -p /var/logs\n\n# Create sample log files\necho -e \"This is an error\\nThis is a debug message\\nAnother error occurred\" > /var/logs/system.log\necho -e \"Debugging information\\nError detected\\nNo errors here\" > /var/logs/application.log\necho -e \"Everything is fine\\nError found again\\ndebug mode active\" > /var/logs/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Find all .log files in /var/logs directory and count lines containing 'error' but not 'debug'\nfind /var/logs -type f -name \"*.log\" -exec grep -i 'error' {} \\; | grep -iv 'debug' | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all `.log` files within the `/var/logs` directory, excluding any that contain the word \"debug\".",
        "explanation": "To solve this problem, you need to use shell commands to search through all `.log` files in the specified directory. Use `grep` to find occurrences of \"error\" and exclude lines with \"debug\". You may need to use piping with `grep -v` for exclusion and `wc -l` for counting lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find and count lines containing 'error' but not 'debug'\ngrep 'error' /var/logs/*.log | grep -v 'debug' | wc -l\n```",
        "create": {
            "init": "# Create a sample /var/logs directory with some .log files\nmkdir -p /var/logs\n\n# Create some log files with mixed content\necho -e \"error: something went wrong\\ninfo: process started\\ndebug: variable x=5\\nerror: failed to load module\" > /var/logs/system.log\necho -e \"info: user logged in\\nwarning: disk space low\\ndebug: checking memory\\nerror: unable to access file\" > /var/logs/app.log\necho -e \"debug: initialization success\\ninfo: update complete\\nerror: network timeout\\ndebug: retrying connection\" > /var/logs/network.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find and count lines containing 'error' but not 'debug'\ngrep 'error' /var/logs/*.log | grep -v 'debug' | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all `.log` files located in your home directory and its subdirectories. Ensure that you search recursively and disregard case sensitivity.",
        "explanation": "To solve this problem, you need to use a combination of `find` to locate all `.log` files recursively within the home directory, and `grep` to count lines containing the word \"error\", with case insensitivity enabled. You can chain these commands using pipes to achieve the desired result.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files recursively from home directory and count lines containing 'error'\nfind ~/ -type f -name \"*.log\" | xargs grep -i 'error' | wc -l\n```",
        "create": {
            "init": "# Create sample log files with various content including the term 'error'\nmkdir -p ~/logs/subdir\necho -e \"This is a test line.\\nAnother line with error.\" > ~/logs/log1.log\necho -e \"An error occurred here.\\nNo issues here.\" > ~/logs/log2.log\necho -e \"ERROR found.\\nAll clear.\" > ~/logs/subdir/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files recursively from home directory and count lines containing 'error'\nfind ~/ -type f -name \"*.log\" | xargs grep -i 'error' | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all log files (files with \".log\" extension) within the \"/var/logs\" directory. You should only count lines where \"error\" is not part of another word (e.g., \"errors\" or \"erroneous\").",
        "explanation": "To solve this problem, you need to search for the exact substring \"error\" in each line of all \".log\" files within the \"/var/logs\" directory. Use tools like `grep` with appropriate options to match whole words and count occurrences across multiple files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -w 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "# Create a /var/logs directory and add some sample log files\nmkdir -p /var/logs\necho -e \"This is an error\\nThese are errors\\nAn erroneous situation\\nAnother error here\\nNo error found\" > /var/logs/system.log\necho -e \"All clear\\nSomething went wrong: error detected\\nNot an errors or erroneous case\\nJust an error\\nError again\" > /var/logs/application.log\necho -e \"Everything is fine\\nError spotted!\\nNo more errors here\\nFinal check without error.\" > /var/logs/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -w 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, you will find a folder named \"logs\" containing multiple .log files. Each file records system and application events with timestamps. Your task is to count the total number of \"ERROR\" occurrences across all these log files.",
        "explanation": "To solve this problem, you need to search through all .log files within the \"logs\" directory for lines containing the word \"ERROR\". You can use tools like `grep` to filter out occurrences and then count them using utilities like `wc`. Ensure that you handle potential large outputs efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h ERROR ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"[INFO] System started\\n[ERROR] Failed to load module\\n[INFO] Module loaded successfully\" > ~/logs/system.log\necho -e \"[ERROR] Connection lost\\n[INFO] Reconnected\\n[ERROR] Timeout occurred\" > ~/logs/network.log\necho -e \"[INFO] User login successful\\n[ERROR] User authentication failed\" > ~/logs/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h ERROR ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and whose names start with the letter 'a'.",
        "explanation": "To solve this problem, you should first navigate to your home directory. Then, you can use the `find` command to filter files based on their modification time and name pattern. Specifically, you'll want to use `-mtime` to find files modified within the last 7 days and `-name 'a*'` to filter for names starting with 'a'. Finally, count the results using a tool like `wc` or by redirecting the output into an array and checking its length.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~\nfind . -type f -mtime -7 -name 'a*' | wc -l\n```",
        "create": {
            "init": "# No initialization required."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~\nfind . -type f -mtime -7 -name 'a*' | wc -l"
        }
    },
    {
        "description": "You are required to count the total number of lines across all text files in your home directory, including those in subdirectories. Only consider files with the \".txt\" extension.",
        "explanation": "To solve this problem, you can use the `find` command to locate all \".txt\" files in the home directory and its subdirectories. Then you can use `xargs` to pass these files to `wc -l`, which will count the number of lines in each file. Summing up these counts will give you the total number of lines across all text files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Using find, xargs, and wc commands to count total lines.\nfind ~ -type f -name \"*.txt\" | xargs wc -l | tail -n 1 | awk '{print $1}'\n```",
        "create": {
            "init": "# Create sample text files with some content in the home directory and its subdirectories for testing.\nmkdir -p ~/test_dir/subdir1\nmkdir -p ~/test_dir/subdir2\n\necho \"Hello World\\nThis is a test file.\" > ~/test_dir/file1.txt\necho \"Another test file with\\nmultiple lines.\\nEnd line.\" > ~/test_dir/subdir1/file2.txt\necho \"Short file.\" > ~/test_dir/subdir2/file3.txt\necho \"Yet another test file.\\nWith more content\\nto check.\" > ~/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Using find, xargs, and wc commands to count total lines.\nfind ~ -type f -name \"*.txt\" | xargs wc -l | tail -n 1 | awk '{print $1}'"
        }
    },
    {
        "description": "Determine the total number of lines containing the word \"error\" in all `.log` files within a directory named \"logs\" located in your home directory. The count should exclude any lines that are commented out, which start with a `#`.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory inside your home directory. Use tools like `grep` to search for lines containing the word \"error\". Additionally, filter out any lines that begin with `#` using either `grep` with regular expressions or by combining multiple commands like `awk`, `sed`, or further `grep`. Sum up all occurrences from each file to get the total count.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Navigate to the logs directory and search for 'error' ignoring commented lines.\ncd ~/logs\n\ntotal_errors=$(grep -ih 'error' *.log | grep -v '^#' | wc -l)\necho $total_errors\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create a logs directory in the home directory\nmkdir -p ~/logs\n\n# Create sample log files\necho -e \"# This is a comment\\nError: failed to load module\\nInfo: system running smoothly\\nError: disk space low\" > ~/logs/app1.log\necho -e \"Warning: high memory usage\\nError: network connection lost\\n# Error: this line should be ignored\\nError: timeout occurred\" > ~/logs/app2.log\necho -e \"# Start of log\\nError: user authentication failed\\nInfo: user login successful\\n# Error: ignore this error message\" > ~/logs/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Navigate to the logs directory and search for 'error' ignoring commented lines.\ncd ~/logs\n\ntotal_errors=$(grep -ih 'error' *.log | grep -v '^#' | wc -l)\necho $total_errors"
        }
    },
    {
        "description": "You are given a directory `/var/logs` containing multiple `.log` files. Count how many times the word \"error\" appears across all log files in this directory, regardless of case.",
        "explanation": "To solve this problem, you need to search through each `.log` file in `/var/logs`, find occurrences of the word \"error\" (case-insensitive), and count the total number of occurrences across all files. You can use tools like `grep` with the `-i` flag to ignore case and `wc -l` to count lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use grep to find occurrences of 'error' (case-insensitive) and count them across all .log files.\ngrep -i 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "# Create /var/logs directory\nmkdir -p /var/logs\n\n# Create sample log files\necho -e \"Error: Something failed\\nThis is an error\\nERROR detected\" > /var/logs/app1.log\necho -e \"No issues found\\nAn error occurred here\\nWarning: potential error\" > /var/logs/app2.log\necho -e \"ERROR: Critical failure\\nAll systems go\\nerror handling routine executed\" > /var/logs/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use grep to find occurrences of 'error' (case-insensitive) and count them across all .log files.\ngrep -i 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory, which contains multiple compressed log files with the \".gz\" extension. Your task is to find out how many unique IP addresses accessed the server on the date \"2023-01-15\". Each log file contains lines formatted as \"[Date] [Time] [IP Address] [Request Details]\". Use bash commands to extract and count the number of unique IP addresses for that specific date.",
        "explanation": "To solve this problem, you need to decompress each \".gz\" log file, filter out the lines for the date \"2023-01-15\", extract the IP addresses from these lines, and then count the unique ones. You can use tools like `zgrep` to search within compressed files and `awk` or `cut` to extract specific fields from each line.\n\nYou can use this command pattern to perform the task:\n\n```bash\nzgrep \"2023-01-15\" ~/logs/*.gz | awk '{print $3}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL | gzip > ~/logs/logfile1.gz\n2023-01-15 08:00:00 192.168.1.1 GET /index.html\n2023-01-15 09:00:00 192.168.1.2 GET /about.html\n2023-01-14 08:30:00 192.168.1.1 GET /contact.html\nEOL\n\ncat <<EOL | gzip > ~/logs/logfile2.gz\n2023-01-15 10:00:00 192.168.1.3 POST /submit-form\n2023-01-15 11:30:00 192.168.1.4 GET /home.html\n2023-01-14 09:45:00 192.168.1.2 POST /login\nEOL\n\ncat <<EOL | gzip > ~/logs/logfile3.gz\n2023-01-15 12:45:00 192.168.1.5 GET /dashboard.html\n2023-01-13 07:50:00 192.168.1.6 GET /archive.zip\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "zgrep \"2023-01-15\" ~/logs/*.gz | awk '{print $3}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Locate all files in the `/var/log` directory that were modified in the last 7 days and have a size greater than 5MB, then count how many such files exist.",
        "explanation": "To solve this problem, you can use the `find` command to search for files based on modification time and size. You would need to specify the `-mtime` option to find files modified within the last 7 days and use `-size +5M` to filter out files larger than 5MB. After locating these files, you can pipe the output to `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -mtime -7 -size +5M | wc -l\n```",
        "create": {
            "init": "# No initialization required as it uses an existing system directory"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -mtime -7 -size +5M | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all `.txt` files located within the \"documents\" directory, but exclude any files that contain the word \"confidential\" in their content.",
        "explanation": "To solve this problem, you need to first search through all `.txt` files in the \"documents\" directory. Then filter out any files containing the word \"confidential\". Finally, count the number of lines in the remaining files and sum them up. You can use tools like `grep` to find files containing specific text and `wc -l` to count lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -L 'confidential' documents/*.txt | xargs wc -l | grep 'total' | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p documents\necho -e \"This is a sample file.\\nSecond line.\" > documents/file1.txt\necho -e \"This is another sample file.\\nConfidential information here.\" > documents/file2.txt\necho -e \"No confidential content here.\\nJust some text.\" > documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -L 'confidential' documents/*.txt | xargs wc -l | grep 'total' | awk '{print $1}'"
        }
    },
    {
        "description": "In your home directory, there are several log files named `log1.txt`, `log2.txt`, ..., `logN.txt` where N is a random number between 5 and 10. Each log file contains multiple lines, and each line records an event with a timestamp followed by a status code. Count the total number of unique status codes across all log files.",
        "explanation": "To solve this problem, you need to first list all the log files in your home directory. Then, you can use tools like `cat` or `awk` to extract all the status codes from these files. The status code is assumed to be the last space-separated value on each line. After extracting these codes, you can utilize commands such as `sort` and `uniq` to find out how many distinct status codes exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all unique status codes across all log files in home directory.\ncat ~/log*.txt | awk '{print $NF}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create random number of log files between 5 and 10\nnum_files=$((RANDOM % 6 + 5))\n\nfor i in $(seq 1 $num_files); do\n    # Create a new log file\n    touch \"$HOME/log$i.txt\"\n    \n    # Generate random content for each log file\n    num_lines=$((RANDOM % 10 + 5))\n    for j in $(seq 1 $num_lines); do\n        # Random timestamp format YYYY-MM-DD HH:MM:SS\n        timestamp=$(date -d \"$((RANDOM%30+1))-day ago\" '+%Y-%m-%d %H:%M:%S')\n        \n        # Random status code between 100 and 599\n        status_code=$((RANDOM % 500 + 100))\n        \n        echo \"$timestamp Event occurred with status $status_code\" >> \"$HOME/log$i.txt\"\n    done\ndone"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all unique status codes across all log files in home directory.\ncat ~/log*.txt | awk '{print $NF}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that are larger than 1MB but smaller than 10MB, and have been modified within the last 7 days.",
        "explanation": "To solve this problem, you need to list all files in your home directory and filter them based on their size and modification date. Use `find` command to search for files with specific size constraints (`-size`) and modification time (`-mtime`). You may need to use pipes or other utilities like `wc -l` to count the number of matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -size +1M -size -10M -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required as students will use their own home directories."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -size +1M -size -10M -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in your home directory that contain the word \"error\", ignoring case sensitivity.",
        "explanation": "To solve this problem, you need to use shell commands to search for the word \"error\" in each `.txt` file within your home directory. You can achieve this by using a combination of `grep`, `find`, and `wc` commands. Start by locating all `.txt` files using `find`, then use `grep -i` to filter lines containing \"error\" (case-insensitive), and finally count these lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example script to count lines with 'error' across all .txt files in the home directory\nfind ~ -name \"*.txt\" | xargs grep -i 'error' | wc -l\n```",
        "create": {
            "init": "# Create example .txt files in the home directory for testing\necho -e \"This is an error.\\nNo issues here.\" > ~/file1.txt\necho -e \"Another line with ERROR.\\nError again.\" > ~/file2.txt\necho -e \"Everything looks fine.\\nNothing wrong.\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example script to count lines with 'error' across all .txt files in the home directory\nfind ~ -name \"*.txt\" | xargs grep -i 'error' | wc -l"
        }
    },
    {
        "description": "In your home directory, there are multiple text files with various extensions. Your task is to count the total number of lines across all files with the \".txt\" extension that contain the string \"error\". Assume that the search criteria are case-sensitive and do not include subdirectories.",
        "explanation": "To solve this problem, you need to first find all files in your home directory with a \".txt\" extension. Then, you should read each file and count how many lines contain the exact string \"error\". Summing these counts will give you the final answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Example solution script\n\ntotal_lines_with_error=0\n\nfor file in ~/file*.txt; do\n    if [[ -f \"$file\" ]]; then  # Check if it's a regular file.\n        lines_with_error=$(grep -c '^.*error.*$' \"$file\")\n        total_lines_with_error=$((total_lines_with_error + lines_with_error))\n    fi\ndone\n\necho $total_lines_with_error  # Should output 2 for this example setup.\n```",
        "create": {
            "init": "#!/bin/bash\n# Creating sample .txt files in the home directory for testing\n\necho -e \"This is a test file.\\nNo error here.\" > ~/file1.txt\necho -e \"An error occurred.\\nAnother line.\" > ~/file2.txt\necho -e \"Error: something went wrong.\\nerror\\nJust another line.\" > ~/file3.txt\n\n# Also creating non-txt files and directories to ensure they are ignored.\necho -e \"This should not be counted.\" > ~/file4.log\nmkdir ~/test_directory\necho -e \"Error in directory.\" > ~/test_directory/file5.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Example solution script\n\ntotal_lines_with_error=0\n\nfor file in ~/file*.txt; do\n    if [[ -f \"$file\" ]]; then  # Check if it's a regular file.\n        lines_with_error=$(grep -c '^.*error.*$' \"$file\")\n        total_lines_with_error=$((total_lines_with_error + lines_with_error))\n    fi\ndone\n\necho $total_lines_with_error  # Should output 2 for this example setup."
        }
    },
    {
        "description": "Count the number of files in the directory `/var/log` that have been modified in the last 7 days. You should exclude directories and only consider regular files.",
        "explanation": "You can solve this problem by using the `find` command to search for files modified within a specific timeframe. The `-type f` option ensures that only regular files are considered. Use `wc -l` to count the number of results returned by `find`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required; assume the /var/log directory is populated with log files."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" across all text files in the directory \"/var/logs\". Assume the text files have a \".log\" extension.",
        "explanation": "To solve this problem, you can use the `grep` command to search for lines containing the word \"error\" within each \".log\" file in \"/var/logs\". Combine this with other commands such as `wc -l` to count the number of matching lines. Looping through or using a wildcard to access all files will be necessary.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Count lines containing 'error' across all .log files in /var/logs directory.\ngrep -i \"error\" /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Initialize /var/logs with sample log files\nmkdir -p /var/logs\necho -e \"error: something went wrong\\ninfo: operation successful\\nerror: failed to update\" > /var/logs/system.log\necho -e \"warning: low disk space\\nerror: unable to connect\\ndebug: connection retry\" > /var/logs/network.log\necho -e \"info: user login\\nerror: invalid credentials\\ninfo: user logout\" > /var/logs/auth.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Count lines containing 'error' across all .log files in /var/logs directory.\ngrep -i \"error\" /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "Count how many files in your home directory contain the word \"Linux\" in their content. You can disregard hidden files and directories.",
        "explanation": "To solve this problem, you need to search through all the non-hidden files in your home directory and check if they contain the word \"Linux\". You can use utilities like `grep` to search for the word within files and `find` to list all non-hidden files. Combining these commands will help you filter out the relevant files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\ngrep -l \"Linux\" $(find ~ -type f ! -name \".*\") | wc -l\n```",
        "create": {
            "init": "# No initialization needed as students will work within their own home directories"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\ngrep -l \"Linux\" $(find ~ -type f ! -name \".*\") | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all `.txt` files located in the `/home/student/text_files` directory, but only include lines that contain the word \"Linux\".",
        "explanation": "To solve this problem, you need to filter out lines that contain the word \"Linux\" from each `.txt` file in the specified directory and count them. You can use tools like `grep` to search for lines containing \"Linux\" and `wc -l` to count these lines. Make sure to handle multiple files at once.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'Linux' /home/student/text_files/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/text_files\necho -e \"This is a Linux operating system.\\nLearning Linux is fun.\" > /home/student/text_files/file1.txt\necho -e \"Linux kernel is powerful.\\nThis line does not mention Linux.\" > /home/student/text_files/file2.txt\necho -e \"I love using Linux.\\nLinux commands are useful.\" > /home/student/text_files/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'Linux' /home/student/text_files/*.txt | wc -l"
        }
    },
    {
        "description": "You need to find and count the number of unique IP addresses from a system log file named \"syslog.log\" located in your home directory, which contain the keyword \"ERROR\". The IP addresses are in the format xxx.xxx.xxx.xxx (IPv4).",
        "explanation": "To solve this problem, you can use a combination of grep to filter lines containing \"ERROR\", awk or sed to extract IP addresses, and sort with uniq to count unique occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script to find and count unique IPs related to errors\n\ngrep \"ERROR\" ~/syslog.log | awk '{print $NF}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a syslog.log file with sample data\ncat > ~/syslog.log << EOL\n2023-10-01 12:00:00 ERROR User failed login from 192.168.1.1\n2023-10-01 12:05:00 INFO Service started by admin from 192.168.1.2\n2023-10-01 12:10:00 ERROR Connection timeout from 192.168.1.3\n2023-10-01 12:15:00 ERROR Data retrieval failed from 192.168.1.1\n2023-10-01 12:20:00 WARNING High memory usage detected on server 192.168.1.4\n2023-10-01 12:25:00 ERROR Disk space low on device at IP address 192.168.1.5\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script to find and count unique IPs related to errors\n\ngrep \"ERROR\" ~/syslog.log | awk '{print $NF}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a file named \"server_logs.txt\" which contains logs of server requests. Each line in the file starts with a timestamp followed by the HTTP status code, and then the requested URL. Your task is to count how many requests resulted in a 404 error and occurred during peak hours (from 18:00 to 22:00) on any given day.",
        "explanation": "To solve this problem, you need to filter lines from \"server_logs.txt\" based on two criteria: the HTTP status code being 404 and the time being between 18:00 and 22:00. You can use tools like `grep` or `awk` to extract lines where both conditions are met, then count these lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script to count requests resulting in a 404 error during peak hours (18:00 - 22:00)\ngrep -E 'T(1[89]|2[0-1]):([0-5][0-9]):([0-5][0-9])\\s404' ~/server_logs.txt | wc -l\n```",
        "create": {
            "init": "# Create the server_logs.txt file in the user's home directory with sample data\ncat <<EOL > ~/server_logs.txt\n2023-10-01T17:45:23 200 /home\n2023-10-01T18:05:34 404 /missing-page\n2023-10-01T19:15:47 404 /another-missing-page\n2023-10-01T20:30:12 200 /home/about\n2023-10-01T21:55:59 404 /not-found\n2023-10-02T08:15:23 500 /error-page\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script to count requests resulting in a 404 error during peak hours (18:00 - 22:00)\ngrep -E 'T(1[89]|2[0-1]):([0-5][0-9]):([0-5][0-9])\\s404' ~/server_logs.txt | wc -l"
        }
    },
    {
        "description": "In your home directory, there are multiple text files with various extensions (.txt, .log, .md). Some of these files contain the keyword \"ERROR\". Your task is to count how many lines across all these files contain the keyword \"ERROR\" and return this count as an integer. Please ensure that you only consider files directly in your home directory and not in any subdirectories.",
        "explanation": "To solve this problem, you will need to use a combination of shell commands like `grep` to search for the keyword \"ERROR\" and `wc -l` to count the number of matching lines. You should iterate over all relevant files in your home directory using a shell loop or by combining commands efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all lines containing 'ERROR' in specified file types within the home directory and count them.\ngrep -r 'ERROR' --include=\\*.{txt,log,md} ~ | wc -l\n```",
        "create": {
            "init": "# Create sample text files in the home directory for testing\necho -e \"This is a test.\\nERROR: Something went wrong.\\nAnother line.\" > ~/file1.txt\necho -e \"No errors here.\\nStill no error.\" > ~/file2.log\necho -e \"ERROR: Critical failure.\\nERROR: Disk full.\" > ~/file3.md"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all lines containing 'ERROR' in specified file types within the home directory and count them.\ngrep -r 'ERROR' --include=\\*.{txt,log,md} ~ | wc -l"
        }
    },
    {
        "description": "Find the total number of lines across all `.txt` files in the `/home/student/documents` directory and its subdirectories, but exclude any lines that are empty or contain only whitespace.",
        "explanation": "To solve this problem, you should navigate to the `/home/student/documents` directory and use a combination of find, grep, and wc commands. The `find` command can be used to locate all `.txt` files in the specified directory and its subdirectories. Then, use `grep` with appropriate options to filter out only non-empty lines (lines containing characters other than whitespace) from these files. Finally, `wc -l` will count these filtered lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -name \"*.txt\" -exec grep -v '^[[:space:]]*$' {} + | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents/subdir1\nmkdir -p /home/student/documents/subdir2\n\necho \"This is a line.\" > /home/student/documents/file1.txt\necho \"\" >> /home/student/documents/file1.txt\necho \"   \" >> /home/student/documents/file1.txt\necho \"Another line here.\" >> /home/student/documents/file1.txt\n\necho \"Text in subdir1.\" > /home/student/documents/subdir1/file2.txt\necho \"\" >> /home/student/documents/subdir1/file2.txt\necho \"   More text.\" >> /home/student/documents/subdir1/file2.txt\n\necho \"Text in subdir2.\" > /home/student/documents/subdir2/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -name \"*.txt\" -exec grep -v '^[[:space:]]*$' {} + | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 24 hours.",
        "explanation": "To solve this problem, you can use the `find` command with appropriate flags to search for files in your home directory that have been modified within the last 24 hours. The command will return a list of files, and you can count them using tools like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\nfind ~/ -type f -mtime -1 | wc -l\n```",
        "create": {
            "init": "# No initialization needed for this task"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\nfind ~/ -type f -mtime -1 | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all `.txt` files located in your home directory and its subdirectories, excluding any files in directories named `backup`.",
        "explanation": "To solve this problem, you need to search for all `.txt` files within your home directory recursively while excluding any directories named `backup`. You can use the `find` command with appropriate options to achieve this. Once you have the list of relevant files, use `wc -l` to count the number of lines in each file and sum them up.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\nfind ~ -type f -name \"*.txt\" ! -path \"*/backup/*\" -exec cat {} + | wc -l\n```",
        "create": {
            "init": "# This script creates a sample directory structure with some .txt files\nmkdir -p ~/project/docs\nmkdir -p ~/project/backup\necho \"Line 1\" > ~/notes.txt\necho \"Line 1\\nLine 2\" > ~/project/docs/readme.txt\necho \"Backup line\" > ~/project/backup/info.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\nfind ~ -type f -name \"*.txt\" ! -path \"*/backup/*\" -exec cat {} + | wc -l"
        }
    },
    {
        "description": "You are given a directory named `logs` containing multiple `.log` files. Each file contains lines with timestamps and various log messages. Count how many times the word \"ERROR\" appears across all the log files in this directory.",
        "explanation": "To solve this problem, you need to iterate through each `.log` file in the `logs` directory and search for occurrences of the word \"ERROR\". You can use tools like `grep` to find and count these occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -o \"ERROR\" logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir logs\necho -e \"2023-10-01 12:00:00 INFO Starting process\\n2023-10-01 12:05:00 ERROR Failed to start component\\n2023-10-01 12:10:00 INFO Process running\" > logs/system1.log\necho -e \"2023-10-02 09:00:00 ERROR Component disconnected\\n2023-10-02 09:05:00 WARN High memory usage\\n2023-10-02 09:10:00 ERROR Unable to reconnect component\" > logs/system2.log\necho -e \"2023-10-03 18:30:00 INFO Shutdown initiated\\n2023-10-03 18:35:00 ERROR Shutdown failed due to open connections\" > logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -o \"ERROR\" logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all text files within your home directory that contain the word \"Linux\".",
        "explanation": "To solve this problem, you need to search through each text file in your home directory for occurrences of the word \"Linux\". You can use tools such as `grep` to search within files and `wc` to count lines. Make sure to handle cases where files might be empty or do not contain the keyword at all.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'Linux' ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Create example text files in the home directory with varying content\necho -e \"Linux is a great operating system.\\nI love using Linux.\" > ~/file1.txt\necho -e \"This is a test file.\\nNo relevant content here.\" > ~/file2.txt\necho -e \"Another mention of Linux here.\\nAnd another line mentioning Linux.\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'Linux' ~/file*.txt | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files located in the directory `/home/student/documents`, excluding any file that contains the word \"secret\" in its filename.",
        "explanation": "To solve this problem, you should first identify all `.txt` files in the specified directory. Then, filter out any files with \"secret\" in their filenames. Finally, count the total number of lines across the remaining files. You can use tools such as `find`, `grep`, and `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -name \"*.txt\" ! -name \"*secret*\" | xargs wc -l | awk 'END{print $1}'\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho -e \"This is a sample text file.\\nIt has multiple lines.\" > /home/student/documents/file1.txt\necho -e \"Another example.\\nWith more content.\" > /home/student/documents/file2.txt\necho -e \"Secret information.\\nNot to be counted.\" > /home/student/documents/secret_file.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -name \"*.txt\" ! -name \"*secret*\" | xargs wc -l | awk 'END{print $1}'"
        }
    },
    {
        "description": "In your home directory, there is a subdirectory named \"project_files\" containing various types of files. Your task is to find the total size of all text files (.txt) that contain the word \"Linux\" at least once. The size should be displayed in human-readable format.",
        "explanation": "To solve this problem, you need to navigate to the \"project_files\" directory and use a combination of commands to search for text files containing the word \"Linux\" and then calculate their total size in a human-readable format. You can use `grep` to search for the keyword within files and `find` to locate all `.txt` files. Finally, use `du` or similar utilities to sum up their sizes.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/project_files\ngrep -l 'Linux' *.txt | xargs du -ch | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p ~/project_files\necho \"This file mentions Linux.\" > ~/project_files/file1.txt\necho \"This is another text file with Linux inside.\" > ~/project_files/file2.txt\necho \"No relevant keyword here.\" > ~/project_files/file3.txt\necho \"Mentioning Linux again.\" > ~/project_files/file4.txt\necho \"This is not a text file but an image.\" > ~/project_files/image.jpg"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "cd ~/project_files\ngrep -l 'Linux' *.txt | xargs du -ch | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "Count the number of lines containing the word \"ERROR\" in all `.log` files located in your home directory and its subdirectories. Ensure that only files modified in the last 7 days are considered.",
        "explanation": "To solve this problem, you need to search through all `.log` files within your home directory and its subdirectories, filtering out those that have been modified within the last 7 days. You can use the `find` command to locate these files, combined with `grep` to count occurrences of \"ERROR\". Consider using `-mtime -7` with `find` to filter based on modification time.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files modified in the last 7 days and count lines containing 'ERROR'\nfind ~ -type f -name \"*.log\" -mtime -7 | xargs grep -c \"ERROR\"\n```",
        "create": {
            "init": "# Create sample log files for testing purposes\nmkdir -p ~/logs\necho -e \"INFO: All systems operational\\nERROR: Disk quota exceeded\\nINFO: User login successful\" > ~/logs/system.log\necho -e \"WARNING: High memory usage\\nERROR: Network timeout\\nINFO: Backup completed\" > ~/logs/network.log\n\n# Modify timestamps of some files to simulate recent modifications\ntouch -m -d \"2 days ago\" ~/logs/system.log\ntouch -m -d \"10 days ago\" ~/logs/network.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files modified in the last 7 days and count lines containing 'ERROR'\nfind ~ -type f -name \"*.log\" -mtime -7 | xargs grep -c \"ERROR\""
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and have a file size greater than 1MB.",
        "explanation": "To solve this problem, you can use a combination of `find` command with the `-mtime` option to filter files modified in the last 7 days, and `-size` option to find files larger than 1MB. You can then count the number of such files using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization needed as students will work within their home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all text files (with .txt extension) in your home directory and its subdirectories that contain the word \"Linux\" (case-insensitive).",
        "explanation": "To solve this problem, you need to search through your home directory and all its subdirectories for text files. You can use the `find` command to locate these files, and then use `grep` with a case-insensitive flag to count lines containing the word \"Linux\". The `wc -l` command can help count the number of matching lines. You may need to combine these commands using pipes.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -name \"*.txt\" -exec grep -i \"linux\" {} \\; | wc -l\n```",
        "create": {
            "init": "# No initialization is required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -name \"*.txt\" -exec grep -i \"linux\" {} \\; | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all `.log` files within the `/var/logs` directory, ensuring that you exclude lines that contain the word \"debug\".",
        "explanation": "To solve this problem, you need to use `grep` to search for lines containing the word \"error\" and exclude those containing \"debug\". You can use the `-v` option with `grep` to exclude matches. Use a combination of pipes or compound commands to filter appropriately within `.log` files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i error /var/logs/*.log | grep -vi debug | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs\necho -e \"This is an error message\\nThis is a debug message\\nAnother error here\" > /var/logs/system.log\necho -e \"Error occurred in module\\nDebugging completed\\nFinal error found\" > /var/logs/application.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i error /var/logs/*.log | grep -vi debug | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple log files with different extensions. Your task is to count the total number of lines across all files that have a \".log\" extension and contain the word \"ERROR\". Provide the final count.",
        "explanation": "To solve this problem, you need to navigate into the \"log_files\" directory and use tools like `grep` to filter lines containing \"ERROR\" in files with a \".log\" extension. The `wc -l` command can be used to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h 'ERROR' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nINFO: Backup completed\" > ~/log_files/system1.log\necho -e \"ERROR: Failed to connect\\nINFO: Connection established\\nERROR: Timeout occurred\" > ~/log_files/system2.log\necho -e \"NOTICE: New device connected\\nERROR: Device malfunctioned\" > ~/log_files/device.log\necho -e \"WARN: Low battery detected\\nNOTICE: Charging started\" > ~/log_files/alerts.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h 'ERROR' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing multiple log files with the \".log\" extension. Each log file contains lines of text, where each line starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique dates (in \"YYYY-MM-DD\" format) appear across all log files in this directory.",
        "explanation": "To solve this problem, you need to extract the date part from each line of every log file within the \"logs\" directory and then determine the number of unique dates. You can achieve this by using tools like `grep`, `awk`, `cut`, and `sort` in combination with other utilities like `uniq`. Start by listing all `.log` files, extract dates from each line, accumulate them into a single list, and finally count the unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind logs/ -type f -name \"*.log\" \\\n| xargs cat \\\n| awk '{print $1}' \\\n| sort \\\n| uniq \\\n| wc -l\n```",
        "create": {
            "init": "mkdir -p logs\necho -e \"2023-10-01 12:00:00 Event A\\n2023-10-01 13:45:00 Event B\\n2023-10-02 09:15:00 Event C\" > logs/file1.log\necho -e \"2023-10-02 14:30:00 Event D\\n2023-10-03 16:40:00 Event E\\n2023-10-03 18:05:00 Event F\" > logs/file2.log\necho -e \"2023-10-01 08:20:00 Event G\\n2023-10-04 11:25:00 Event H\\n2023-10-04 19:50:00 Event I\" > logs/file3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find logs/ -type f -name \"*.log\" \\\n| xargs cat \\\n| awk '{print $1}' \\\n| sort \\\n| uniq \\\n| wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of files, irrespective of their types, that have been modified in the last 7 days in your home directory and its subdirectories.",
        "explanation": "To solve this problem, you need to navigate through your home directory and all its subdirectories to find files that have been modified in the past week. You can use the `find` command with appropriate flags (`-mtime`) to filter these files based on their modification time. Once you have this list, count the total number of files found.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution to find all modified files within the last 7 days and count them.\nfind ~ -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# This initialization script creates sample directories and files for testing the problem.\nmkdir -p ~/experiment_dir/subdir1 ~/experiment_dir/subdir2\ntouch ~/experiment_dir/file1.txt ~/experiment_dir/file2.log\ntouch ~/experiment_dir/subdir1/file3.txt ~/experiment_dir/subdir1/file4.doc\ntouch ~/experiment_dir/subdir2/file5.pdf\n\n# Modify some files so they appear in search results for last 7 days.\necho \"Update\" >> ~/experiment_dir/file1.txt\necho \"Update\" >> ~/experiment_dir/subdir1/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution to find all modified files within the last 7 days and count them.\nfind ~ -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple \".log\" files. Each log file contains various system events logged with timestamps. Find the total number of error messages (lines containing the word \"ERROR\") across all log files and output that number.",
        "explanation": "To solve this problem, you need to search through each \".log\" file in the \"logs\" directory for lines containing the word \"ERROR\". You can use grep to filter these lines and wc to count them. Ensure that you only count occurrences of the word \"ERROR\" regardless of case sensitivity.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'ERROR' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: System started\\nERROR: Disk full\\nINFO: User login\\nERROR: Network timeout\" > ~/logs/system1.log\necho -e \"ERROR: Resource unavailable\\nINFO: Scheduled task completed\\nWARNING: Low memory\\nERROR: Permission denied\" > ~/logs/system2.log\necho -e \"INFO: Backup completed\\nWARNING: CPU temperature high\\nINFO: Shutdown initiated\\nERROR: Failed to connect to server\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'ERROR' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory containing multiple log files with the extension \".log\". Your task is to find out how many times the term \"ERROR\" appears across all these log files. You should consider case-sensitive matches only.",
        "explanation": "To solve this problem, you need to navigate through each log file in the \"log_files\" directory and count occurrences of the word \"ERROR\". You can use utilities like `grep` or `awk` to search for the term within each file, and then sum up the counts from all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -o 'ERROR' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"INFO: Start process\\nERROR: Failed to open file\\nWARNING: Disk space low\\nERROR: Network timeout\" > ~/log_files/log1.log\necho -e \"INFO: User login\\nERROR: Invalid password attempt\\nINFO: User logout\" > ~/log_files/log2.log\necho -e \"DEBUG: Connection established\\nERROR: Server not responding\\nINFO: Retry connection\" > ~/log_files/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -o 'ERROR' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.configfile` that contains various configuration settings in the format `KEY=VALUE`. You need to count how many unique keys exist in this file. Ensure to handle cases where some keys may appear multiple times with different values.",
        "explanation": "To solve the problem, you need to extract all the keys from the `.configfile`, remove any duplicates, and then count how many unique keys are present. A combination of `grep`, `cut`, `sort`, and `uniq` utilities will help achieve this. First, use `grep` or similar to filter out lines containing key-value pairs (ignoring comments or blank lines if present). Then, use `cut` to split each line by the equal sign (`=`) and focus on extracting the key part. With `sort` and `uniq`, you can eliminate duplicate keys and finally use a command like `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -v '^#' ~/.configfile | grep '=' | cut -d '=' -f 1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "cat > ~/.configfile <<EOL\n# Sample configuration settings\nSETTING1=value1\nSETTING2=value2\nSETTING3=value3\nSETTING1=different_value1\nSETTING4=value4\n\n# Another comment line\nSETTING5=value5\nSETTING2=another_value2\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -v '^#' ~/.configfile | grep '=' | cut -d '=' -f 1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that were accessed within the last 7 days and have a file size greater than 100KB.",
        "explanation": "To solve this problem, you can use the `find` command with appropriate options to filter files based on access time and size. The `-atime` option helps you find files accessed within a certain number of days, and the `-size` option allows filtering by file size. Use these options to list files that meet both criteria, then count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -atime -7 -size +100k | wc -l\n```",
        "create": {
            "init": "# No initialization required as students will work with their existing home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -atime -7 -size +100k | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all `.log` files within the `/var/logs` directory, and then sum up the total number of occurrences.",
        "explanation": "To solve this problem, you need to search through all `.log` files in the `/var/logs` directory for lines that contain the word \"error\". You can use tools like `grep` to search and count occurrences, then sum up these counts. Be sure to handle multiple files and aggregate results correctly.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count occurrences of 'error' in each .log file and sum them up\ngrep -i 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "# Create /var/logs directory and some log files for testing\nmkdir -p /var/logs\necho -e \"This is an error\\nThis is a test\\nError occurred again\" > /var/logs/file1.log\necho -e \"No issues here\\nJust another error\\nAll good\" > /var/logs/file2.log\necho -e \"Error found\\nAnother line without error\" > /var/logs/file3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count occurrences of 'error' in each .log file and sum them up\ngrep -i 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and have a size greater than 500KB.",
        "explanation": "To solve this problem, you need to use the `find` command to locate files within your home directory that meet both conditions: modified within the last 7 days and larger than 500KB. The `-mtime` option can be used to find files modified within a certain time frame, and the `-size` option helps filter based on file size. Once you've filtered these files, you can count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +500k | wc -l\n```",
        "create": {
            "init": "# No initialization required."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +500k | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with \".log\" extension. Each log file contains various entries, some of which include IP addresses. Your task is to count how many unique IP addresses appear across all the log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to extract all IP addresses from each log file in the \"logs\" directory, combine them into a single list, and then identify and count only the unique IP addresses. You can use tools like `grep`, `awk`, `sort`, and `uniq` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\nmkdir -p ~/logs\necho -e \"User login from 192.168.1.1\\nFailed attempt from 10.0.0.5\\nAccess granted to 172.16.0.2\" > ~/logs/log1.log\necho -e \"192.168.1.1 accessed the system\\nAttempt from 10.0.0.5\\n172.16.0.3 granted access\" > ~/logs/log2.log\necho -e \"New connection from 172.16.0.2\\n192.168.1.1 login successful\\nError at 10.0.0.x\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to find the total number of lines containing the word \"error\" in all `.log` files located in the `/var/logs` directory, which have been modified within the last 7 days.",
        "explanation": "To solve this problem, first navigate to the `/var/logs` directory. Use `find` command with appropriate arguments to filter out files that have been modified in the last 7 days. Then use `grep` to search for occurrences of the word \"error\" within those files and count the total number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Find .log files modified in the last 7 days and count lines containing 'error'\nfind /var/logs/ -name \"*.log\" -mtime -7 -exec grep -c \"error\" {} + | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "#!/bin/bash\n# Create /var/logs directory if it doesn't exist\nmkdir -p /var/logs\n\n# Create some log files with different modification times and content\necho \"This is an error line\" > /var/logs/file1.log\necho \"This is a warning line\" > /var/logs/file2.log\necho \"Another error occurred here\" > /var/logs/file3.log\n\n# Modify timestamps: file1.log is recent, others are older than 7 days\ntouch -m -d \"-3 days\" /var/logs/file1.log\ntouch -m -d \"-10 days\" /var/logs/file2.log\ntouch -m -d \"-8 days\" /var/logs/file3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Find .log files modified in the last 7 days and count lines containing 'error'\nfind /var/logs/ -name \"*.log\" -mtime -7 -exec grep -c \"error\" {} + | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with various extensions (e.g., .log, .txt). Each file contains lines of text. Count the total number of lines across all the log files in the \"logs\" directory, ignoring any files that do not have a \".log\" extension.",
        "explanation": "To solve this problem, you should navigate to the \"logs\" directory and use commands to filter out non-log files. Then, count the lines in all remaining \".log\" files using utilities such as `find`, `grep`, or `wc`. The total number of lines across these filtered files is required.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\nfind . -type f -name \"*.log\" | xargs wc -l | grep total | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"Error: Disk full\\nWarning: High CPU usage\\nInfo: Update available\" > ~/logs/system.log\necho -e \"User logged in\\nUser logged out\\nError: Invalid password\" > ~/logs/auth.log\necho -e \"Backup started\\nBackup completed\\nWarning: Low disk space\" > ~/logs/backup.txt\necho -e \"Error: Network disconnected\\nInfo: Reconnected to network\\nWarning: Slow response time\" > ~/logs/network.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\nfind . -type f -name \"*.log\" | xargs wc -l | grep total | awk '{print $1}'"
        }
    },
    {
        "description": "Count the total number of lines in all text files located within the `/home/student/documents` directory, ignoring any empty lines.",
        "explanation": "To solve this problem, you should navigate to the `/home/student/documents` directory and list all text files. Use utilities like `find`, `wc`, and `grep` to count the non-empty lines in each file and sum them up. Remember that empty lines can be filtered out using `grep` with an appropriate pattern.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -name \"*.txt\" | xargs grep -v '^$' | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho -e \"This is a line.\\n\\nAnother line.\" > /home/student/documents/file1.txt\necho -e \"\\n\\nLine3.\\nLine4.\\n\" > /home/student/documents/file2.txt\necho -e \"Line5.\\n\" > /home/student/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -name \"*.txt\" | xargs grep -v '^$' | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all \".log\" files located in the \"/var/logs\" directory, and provide the sum as your answer.",
        "explanation": "To solve this problem, you need to search through each \".log\" file within the \"/var/logs\" directory for lines that contain the word \"error\". You can use tools like `grep` to filter these lines and `wc -l` to count them. Summing up these counts from each file will give you the total number of occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Count lines containing 'error' in all .log files in /var/logs\n\n# Initialize error count variable\ntotal_error_count=0\n\n# Iterate over each .log file in /var/logs\nfor log_file in /var/logs/*.log; do\n  # Count errors using grep and wc, then add to total_error_count\n  error_count=$(grep -i \"error\" \"$log_file\" | wc -l)\n  total_error_count=$((total_error_count + error_count))\ndone\n\n# Output the total error count without any extra message for integer-match evaluation.\necho $total_error_count\n```",
        "create": {
            "init": "#!/bin/bash\n# Create /var/logs directory if it doesn't exist\nmkdir -p /var/logs\n\n# Create some sample log files with varying content\necho -e \"Info: Everything is running smoothly\\nError: Something went wrong\\nWarning: Check your configurations\\nError: Another issue detected\" > /var/logs/system.log\n\necho -e \"Debug: Starting process\\nError: Failed to start process\\nInfo: Process started successfully\" > /var/logs/process.log\n\necho -e \"Notice: User login successful\\nError: Unauthorized access attempt detected\\nError: Password incorrect\" > /var/logs/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Count lines containing 'error' in all .log files in /var/logs\n\n# Initialize error count variable\ntotal_error_count=0\n\n# Iterate over each .log file in /var/logs\nfor log_file in /var/logs/*.log; do\n  # Count errors using grep and wc, then add to total_error_count\n  error_count=$(grep -i \"error\" \"$log_file\" | wc -l)\n  total_error_count=$((total_error_count + error_count))\ndone\n\n# Output the total error count without any extra message for integer-match evaluation.\necho $total_error_count"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Each log file follows the naming pattern \"serverYYYYMMDD.log\", where YYYYMMDD represents the date. Your task is to identify and count how many unique IP addresses have accessed the server on the most recent date present in these logs.",
        "explanation": "To solve this problem, you need to first identify which log file corresponds to the most recent date. Then, extract all IP addresses from that log file and determine how many of them are unique. You can use tools like `ls`, `grep`, `awk`, or `sort` along with pipelines to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find the most recent log file by listing files and sorting them by filename (date)\nlatest_log=$(ls ~/logs | sort | tail -n 1)\n\n# Extract IP addresses, sort them uniquely, and count them\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/logs/\"$latest_log\" | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\n\n# Create sample log files for different dates with random IP addresses\necho -e \"192.168.0.1\\n192.168.0.2\\n192.168.0.1\" > ~/logs/server20230101.log\necho -e \"10.0.0.5\\n10.0.0.8\\n10.0.0.5\" > ~/logs/server20230102.log\necho -e \"172.16.1.3\\n172.16.1.4\\n172 .16 .1 .3\" > ~/logs/server20230103.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find the most recent log file by listing files and sorting them by filename (date)\nlatest_log=$(ls ~/logs | sort | tail -n 1)\n\n# Extract IP addresses, sort them uniquely, and count them\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/logs/\"$latest_log\" | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory called \"logs\" containing multiple log files with the \".log\" extension. Each file may contain multiple lines of text in the format \"TIMESTAMP - LEVEL - MESSAGE\". Your task is to count how many error messages, i.e., lines where LEVEL is \"ERROR\", exist across all the log files in this directory.",
        "explanation": "To solve this problem, you need to iterate over each .log file in the \"logs\" directory, read through each line of these files, and identify lines where the LEVEL section is \"ERROR\". You can use tools like `grep` or `awk` to filter and count these lines efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Count all instances of \"ERROR\" across all .log files in the 'logs' directory.\ngrep \"ERROR\" logs/*.log | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create a 'logs' directory\nmkdir -p logs\n\n# Create sample log files with various log entries\ncat <<EOL > logs/server1.log\n2023-10-01 12:00:00 - INFO - Server started\n2023-10-01 12:15:10 - ERROR - Connection failed\n2023-10-01 12:20:30 - INFO - User login successful\nEOL\n\ncat <<EOL > logs/server2.log\n2023-10-02 09:05:45 - WARNING - Disk space low\n2023-10-02 09:07:55 - ERROR - Disk write error\n2023-10-02 09:08:00 - ERROR - Unable to save file\nEOL\n\ncat <<EOL > logs/server3.log\n2023-10-03 18:22:11 - INFO - Backup completed successfully\nEOL\n\n# Make sure permissions are set correctly so students can read the files.\nchmod u+r logs/*.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Count all instances of \"ERROR\" across all .log files in the 'logs' directory.\ngrep \"ERROR\" logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" across all text files (.txt) in your home directory, ignoring case sensitivity.",
        "explanation": "To solve this problem, you can use the `grep` command with the `-i` flag to ignore case sensitivity and the `-c` flag to count occurrences. You will need to iterate over all `.txt` files in your home directory and sum up the counts.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Using grep to count lines containing 'error' in each file and summing them up.\ngrep -i \"error\" ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample text files with varying content in the home directory for testing purposes.\necho -e \"This is a test file.\\nError occurred here.\" > ~/file1.txt\necho -e \"No issues found.\\nERROR: Something went wrong.\" > ~/file2.txt\necho -e \"All systems go.\\nAn error slipped through.\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Using grep to count lines containing 'error' in each file and summing them up.\ngrep -i \"error\" ~/file*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and contain the word \"backup\" in their name.",
        "explanation": "To solve this problem, you need to use the `find` command to search for files within your home directory. You'll need to utilize options to filter files based on modification time (`-mtime`) and name pattern (`-name`). The challenge involves correctly setting up these parameters to get the desired result.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -maxdepth 1 -type f -name \"*backup*\" -mtime -7 | wc -l\n```",
        "create": {
            "init": "# Create sample files in the home directory\nmkdir -p ~/test_environment\ntouch ~/test_environment/backup1.txt\ntouch ~/test_environment/backup2.log\ntouch ~/test_environment/not_backup.txt\n\n# Modify timestamps for demonstration purposes\n# Recent file modifications (within 7 days)\ntouch -m -d \"2 days ago\" ~/test_environment/backup1.txt\n\n# Old file modifications (over 7 days)\ntouch -m -d \"10 days ago\" ~/test_environment/backup2.log\ntouch -m -d \"15 days ago\" ~/test_environment/not_backup.txt\n\n# Move all test files into home directory for easier access\nmv ~/test_environment/* ~/\nrmdir ~/test_environment"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -maxdepth 1 -type f -name \"*backup*\" -mtime -7 | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with various extensions. Count the total number of lines that contain the word \"ERROR\" across all \".log\" files within this directory.",
        "explanation": "To solve the problem, you need to iterate over all \".log\" files in the \"logs\" directory and search for lines containing the word \"ERROR\". You can use tools like `grep` to filter out these lines and then `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h \"ERROR\" ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO\\nERROR\\nDEBUG\\nERROR\" > ~/logs/app1.log\necho -e \"ERROR\\nDEBUG\\nINFO\\nINFO\" > ~/logs/app2.log\necho -e \"DEBUG\\nINFO\\nERROR\\nDEBUG\" > ~/logs/app3.log\ntouch ~/logs/readme.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h \"ERROR\" ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all '.txt' files in your home directory that contain the word \"Linux\", and ensure that each file is processed only once.",
        "explanation": "You can solve this problem by using a combination of `grep` and `wc` commands. First, use `grep` to search for the word \"Linux\" within all '.txt' files located in your home directory, then pipe the results to `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count lines containing 'Linux' in all .txt files in home directory\ngrep -h \"Linux\" ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample .txt files with content for testing\necho -e \"Linux is great.\\nI love using Linux.\" > ~/file1.txt\necho -e \"Linux is versatile.\\nOpen-source community.\" > ~/file2.txt\necho -e \"The Linux kernel is powerful.\" > ~/file3.txt\necho -e \"This line doesn't mention it.\" > ~/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count lines containing 'Linux' in all .txt files in home directory\ngrep -h \"Linux\" ~/file*.txt | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all `.log` files located in the `/var/logs` directory on your Linux system. You need to ensure that you only count lines that are case-insensitive matches for \"error\".",
        "explanation": "To solve this problem, you need to search through all `.log` files in the `/var/logs` directory, utilizing tools like `grep`. The task requires you to perform a case-insensitive search for the word \"error\" and count the occurrences across all files. Using `grep -i` will help perform a case-insensitive match, while `wc -l` can be used to count lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i error /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs\necho -e \"Error: Something went wrong\\nWarning: Check configuration\\nerror: Critical error detected\\ninfo: All systems go\" > /var/logs/system.log\necho -e \"ERROR occurred during processing\\nInfo: Process completed successfully\\nwarning: Low memory usage\\ndebugging info\" > /var/logs/application.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i error /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"log_files\" containing multiple log files with \".log\" extension. Each log file contains multiple lines, and each line records an event timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to count how many events occurred on the 15th of any month across all these log files and report the total count.",
        "explanation": "To solve this problem, you need to iterate through each \".log\" file in the \"log_files\" directory within your home directory, extract lines that match the date pattern for the 15th day of any month (e.g., \"2023-03-15\"), and count these lines. You can use tools like `grep` to filter relevant lines and `wc -l` to count them. Combining these utilities will help you achieve the desired result.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^[0-9]\\{4\\}-[0-9]\\{2\\}-15' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-03-14 12:00:01\\n2023-03-15 13:20:30\\n2023-04-15 09:10:11\\n2023-05-16 08:45:55\" > ~/log_files/log1.log\necho -e \"2022-11-15 10:00:00\\n2022-12-12 11:11:11\\n2023-01-15 14:22:22\" > ~/log_files/log2.log\necho -e \"2023-05-10 16:30:30\\n2023-06-15 17:40:40\\n2023-07-15 18:50:50\" > ~/log_files/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^[0-9]\\{4\\}-[0-9]\\{2\\}-15' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "You need to find the total number of lines across all `.txt` files in the `/home/student/documents` directory that contain the word \"Linux\". Ignore case sensitivity while searching for the word.",
        "explanation": "To solve this problem, you should first locate all `.txt` files within the specified directory. Then, for each file, search for lines containing the word \"Linux\" without regard to case. Finally, count and sum up these lines across all files. You can use utilities like `find`, `grep`, and `wc` to achieve this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -name \"*.txt\" | xargs grep -i 'Linux' | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho -e \"Linux is great.\\nI love Linux.\" > /home/student/documents/file1.txt\necho -e \"This line does not mention it.\\nAnother one with Linux.\" > /home/student/documents/file2.txt\necho -e \"Completely irrelevant content here.\" > /home/student/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -name \"*.txt\" | xargs grep -i 'Linux' | wc -l"
        }
    },
    {
        "description": "Find and count the number of Python files (.py) in your home directory that contain the word \"import\" within them. You must filter out any file paths that are symbolic links.",
        "explanation": "To solve this problem, you need to navigate through your home directory and identify all Python files. Use tools such as `find` to locate `.py` files, `grep` to search for the word \"import\" within these files, and consider using `readlink` or similar commands to exclude symbolic links from your results.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find .py files containing \"import\" excluding symbolic links, then count them.\nfind ~ -type f -name \"*.py\" ! -type l | xargs grep -l \"import\" | wc -l\n```",
        "create": {
            "init": "# Create a sample environment with Python files\nmkdir -p ~/python_test\necho 'import os' > ~/python_test/test1.py\necho 'print(\"Hello World\")' > ~/python_test/test2.py\necho 'import sys' > ~/python_test/test3.py\nln -s ~/python_test/test1.py ~/python_test/symlink_test1.py"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find .py files containing \"import\" excluding symbolic links, then count them.\nfind ~ -type f -name \"*.py\" ! -type l | xargs grep -l \"import\" | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in the `/home/student/documents` directory that contain the word \"Linux\". You should only consider lines where \"Linux\" is a standalone word (not part of another word).",
        "explanation": "To solve this problem, you can use the `grep` command to search for lines containing the word \"Linux\". Use the `-w` option with `grep` to ensure you only match \"Linux\" as a standalone word. You may need to use `cat` or similar commands to combine results from multiple files, and finally use `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r -w 'Linux' /home/student/documents/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho -e \"I love Linux\\nLinux is great\\nUnix is not Linux\" > /home/student/documents/file1.txt\necho -e \"Linux kernel\\nThe Linux Foundation\\nLearn about Linux\" > /home/student/documents/file2.txt\necho -e \"This is not about Linus\\nAnother mention of Linux here\" > /home/student/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r -w 'Linux' /home/student/documents/*.txt | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains timestamps followed by error messages. Your task is to count how many unique error messages occurred across all log files.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"logs\" directory.\n2. Use a combination of tools like `cat`, `grep`, `awk`, and `sort` to extract error messages from all `.log` files.\n3. Identify and count unique error messages using `uniq`.\nHint: Error messages are assumed to start immediately after timestamps, which can be filtered out using regular expressions.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep 'ERROR' *.log | awk -F 'ERROR ' '{print $2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 12:00:01 ERROR Connection lost\\n2023-01-01 12:05:22 ERROR Timeout occurred\\n2023-01-01 12:10:33 ERROR Connection lost\" > ~/logs/system1.log\necho -e \"2023-02-15 08:45:16 ERROR Disk full\\n2023-02-15 09:00:20 ERROR Timeout occurred\\n2023-02-15 09:30:11 ERROR Connection lost\" > ~/logs/system2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep 'ERROR' *.log | awk -F 'ERROR ' '{print $2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing multiple log files with the extension \".log\". Each log file contains lines in the format \"[DATE] [TIME] - [LEVEL] - [MESSAGE]\". Your task is to count how many times the log level \"ERROR\" appears across all these files. Only consider files directly in the \"logs\" directory, not in any subdirectories.",
        "explanation": "To solve this problem, you need to iterate over all files in the \"logs\" directory, read each file and count occurrences of lines that contain \"ERROR\" as their log level. Use tools like `grep` to filter these lines and `wc` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"ERROR\" logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir logs\necho \"[2023-10-01] [12:00:00] - INFO - All systems operational\" > logs/system1.log\necho \"[2023-10-01] [12:01:00] - ERROR - Failed to connect to database\" >> logs/system1.log\necho \"[2023-10-01] [12:02:00] - WARNING - High memory usage detected\" >> logs/system1.log\necho \"[2023-10-01] [12:03:00] - ERROR - Disk space running low\" >> logs/system1.log\n\necho \"[2023-10-02] [13:00:00] - INFO - Scheduled maintenance started\" > logs/system2.log\necho \"[2023-10-02] [13:05:00] - ERROR - Unexpected shutdown occurred\" >> logs/system2.log\necho \"[2023-10-02] [13:06:00] - INFO - Maintenance completed successfully\" >> logs/system2.log\n\n# Add more log files as needed for complexity."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"ERROR\" logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all `.txt` files within the `/var/logs` directory that contain the word \"error\", and then sum these counts to get a total number. Assume case-insensitivity for the word \"error\".",
        "explanation": "To solve this problem, you need to search through each `.txt` file in the `/var/logs` directory for lines containing the word \"error\". You can use tools like `grep` with the `-i` option to ensure case-insensitivity. Then, count these lines using `wc -l`, and finally sum up all counts from each file to obtain a total.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' /var/logs/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs\necho -e \"This is an error.\\nNo issues found.\\nERROR detected.\" > /var/logs/file1.txt\necho -e \"All systems go.\\nError occurred here.\\nNothing wrong.\" > /var/logs/file2.txt\necho -e \"Everything is fine.\\nERROR: Something happened.\" > /var/logs/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' /var/logs/*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all `.log` files within the `/var/logs` directory, excluding any log files modified more than 7 days ago.",
        "explanation": "To solve this problem, you will need to use a combination of `find`, `grep`, and `wc` commands. First, use `find` to locate all `.log` files in the `/var/logs` directory that have been modified within the last 7 days. Then, use `grep` to search for lines containing the word \"error\" in these files. Finally, count the number of matching lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find .log files modified within the last 7 days and count lines with \"error\"\nfind /var/logs -name \"*.log\" -mtime -7 -exec grep -i 'error' {} \\; | wc -l\n```",
        "create": {
            "init": "# Create /var/logs directory and sample .log files for testing\nmkdir -p /var/logs\n\n# Create test log files\necho -e \"This is a test log.\\nNo errors here.\" > /var/logs/test1.log\necho -e \"Error: Something went wrong.\\nAnother error.\" > /var/logs/test2.log\necho -e \"All systems operational.\\nNo errors reported.\" > /var/logs/test3.log\n\n# Update modification times for testing purposes (test2.log is older than 7 days)\ntouch -d '8 days ago' /var/logs/test2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find .log files modified within the last 7 days and count lines with \"error\"\nfind /var/logs -name \"*.log\" -mtime -7 -exec grep -i 'error' {} \\; | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in the `/var/logs` directory that contain the word \"ERROR\", and output the total count.",
        "explanation": "To solve this problem, you need to search for occurrences of the word \"ERROR\" within each `.txt` file located in the `/var/logs` directory. You can use tools like `grep` to filter lines containing \"ERROR\", then use `wc -l` to count these lines and add them together for all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h ERROR /var/logs/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs\necho -e \"INFO: All systems operational\\nERROR: Failed to connect\\nWARNING: Low disk space\" > /var/logs/system.txt\necho -e \"DEBUG: Starting process\\nERROR: Timeout occurred\\nINFO: Process completed\" > /var/logs/network.txt\necho -e \"INFO: User login successful\\nDEBUG: Database query executed\\nERROR: Unauthorized access attempt\" > /var/logs/security.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h ERROR /var/logs/*.txt | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named `log_files` which contains multiple `.log` files. Each file logs various system events with timestamps in the format `[YYYY-MM-DD HH:MM:SS] Event message`. Your task is to identify all unique event messages that occurred on the most recent date present across all files, and output these messages sorted alphabetically. Assume that all timestamps are in UTC.",
        "explanation": "To solve this problem, you need to go through each `.log` file in the `log_files` directory and extract the dates from each event's timestamp. Determine the most recent date among all events across all files. Filter out only those events that occurred on this date, collect their unique messages, and finally sort them alphabetically for output.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all unique event messages from the most recent date.\nmost_recent_date=$(grep -hoP '\\[\\K\\d{4}-\\d{2}-\\d{2}' log_files/*.log | sort | uniq | tail -n1)\ngrep -h \"\\[$most_recent_date\" log_files/*.log | sed 's/.*\\] //' | sort | uniq\n```",
        "create": {
            "init": "mkdir -p log_files\ncat > log_files/system1.log <<EOL\n[2023-10-01 12:00:00] System startup\n[2023-10-02 09:15:23] User login\n[2023-10-03 14:45:30] Backup completed\nEOL\n\ncat > log_files/system2.log <<EOL\n[2023-10-02 08:00:00] Network connected\n[2023-10-03 11:22:33] Disk space low\n[2023-10-03 16:30:45] Error detected\nEOL\n\ncat > log_files/system3.log <<EOL\n[2023-09-30 06:20:40] System update available\n[2023-10-01 14:35:50] User logout\n[2023-10-03 18:45:59] Maintenance scheduled\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "# Find all unique event messages from the most recent date.\nmost_recent_date=$(grep -hoP '\\[\\K\\d{4}-\\d{2}-\\d{2}' log_files/*.log | sort | uniq | tail -n1)\ngrep -h \"\\[$most_recent_date\" log_files/*.log | sed 's/.*\\] //' | sort | uniq"
        }
    },
    {
        "description": "In your home directory, you will find a folder named `log_files` containing multiple `.log` files. Each log file contains entries of user activity logs with timestamps. Your task is to determine the total number of unique users who logged in on a specific day. The date should be provided as an input in the format `YYYY-MM-DD`. Ensure that you only count unique user IDs from all log files combined.",
        "explanation": "To solve this problem, you need to:\n1. Use the `grep` command to filter out lines corresponding to the specified date.\n2. Extract user IDs from these filtered lines (assuming each log entry has a structure like \"timestamp - userID - action\").\n3. Use `sort` and `uniq` commands to count distinct user IDs across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Input date for which we are counting unique users.\ntarget_date=\"2023-10-15\"\n\n# Find, extract, and count unique users for the given date.\nunique_users=$(grep \"$target_date\" ~/log_files/*.log | awk '{print $4}' | sort | uniq | wc -l)\n\necho $unique_users\n```",
        "create": {
            "init": "mkdir -p ~/log_files\ncat <<EOL > ~/log_files/activity_1.log\n2023-10-15 08:45:00 - userA - login\n2023-10-15 09:00:00 - userB - login\n2023-10-15 09:30:00 - userC - logout\n2023-10-16 08:45:00 - userA - login\nEOL\n\ncat <<EOL > ~/log_files/activity_2.log\n2023-10-15 10:00:00 - userD - login\n2023-10-15 11:30:00 - userB - logout\n2023-10-16 12:45:00 - userD - login\nEOL\n\ncat <<EOL > ~/log_files/activity_3.log\n2023-10-15 12:45:00 - userA - logout\n2023-10-15 13:50:00 - userC - login\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Input date for which we are counting unique users.\ntarget_date=\"2023-10-15\"\n\n# Find, extract, and count unique users for the given date.\nunique_users=$(grep \"$target_date\" ~/log_files/*.log | awk '{print $4}' | sort | uniq | wc -l)\n\necho $unique_users"
        }
    },
    {
        "description": "Count the number of files in the /var/log directory that have been modified in the last 24 hours and are larger than 5MB.",
        "explanation": "To solve this problem, you can use the `find` command with appropriate options to filter files based on modification time and size. You will need to calculate the number of files that meet these criteria.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -mtime -1 -size +5M | wc -l\n```",
        "create": {
            "init": "# No special initialization is required."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -mtime -1 -size +5M | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains lines formatted as \"YYYY-MM-DD INFO|ERROR|DEBUG: Message\". Your task is to count how many times the word \"ERROR\" appears across all log files in this directory.",
        "explanation": "To solve this problem, you need to iterate over each \".log\" file in the \"project_logs\" directory and search for lines containing the word \"ERROR\". You can use tools like `grep` to filter these lines and then count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/project_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"2023-10-01 INFO: Starting process\\n2023-10-01 ERROR: Failed to start\\n2023-10-01 DEBUG: Debugging info\" > ~/project_logs/log1.log\necho -e \"2023-10-02 ERROR: Connection lost\\n2023-10-02 INFO: Retrying connection\\n2023-10-02 ERROR: Connection failed again\" > ~/project_logs/log2.log\necho -e \"2023-10-03 INFO: Process completed successfully\\n2023-10-03 DEBUG: No errors found\" > ~/project_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/project_logs/*.log | wc -l"
        }
    },
    {
        "description": "Find out how many files in your home directory have a size greater than 1MB, and contain the word \"Linux\" in their contents. You need to count only text files with extensions '.txt', '.md', or '.log'.",
        "explanation": "To solve this problem, you should first list all files with the specified extensions in your home directory that are larger than 1MB. Then, use a tool like `grep` to search within those files for the word \"Linux\". Finally, count the number of files that match both criteria.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -maxdepth 1 \\( -name \"*.txt\" -o -name \"*.md\" -o -name \"*.log\" \\) -size +1M | xargs grep -l 'Linux' | wc -l\n```",
        "create": {
            "init": "# Create sample files in the student's home directory for testing\nmkdir -p ~/test_files\n\necho \"This file contains Linux.\" > ~/test_files/file1.txt\necho \"Another file containing Linux.\" > ~/test_files/file2.md\necho \"Linux is not here.\" > ~/test_files/file3.log\necho \"No mention of Linux here.\" > ~/test_files/file4.txt\n\n# Add more content to some files to exceed 1MB size\nfor i in {1..2000}; do echo \"This line makes the file bigger.\" >> ~/test_files/file1.txt; done\nfor i in {1..2000}; do echo \"This line makes the file bigger.\" >> ~/test_files/file2.md; done\n\n# Move these test files into the home directory for easy access.\nmv ~/test_files/* ~/"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -maxdepth 1 \\( -name \"*.txt\" -o -name \"*.md\" -o -name \"*.log\" \\) -size +1M | xargs grep -l 'Linux' | wc -l"
        }
    },
    {
        "description": "You need to count the number of lines in all text files within your home directory that contain the word \"Linux\", and then find the sum of these line counts.",
        "explanation": "To solve this problem, you need to use a combination of `grep` to search for the word \"Linux\" in each text file, `wc -l` to count the lines containing the word, and `find` to locate all text files within your home directory. You can use a loop or command substitution to iterate over each file and accumulate the total line count.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all text files in home directory and count lines containing 'Linux'\ntotal_lines=0\n\nfor file in $(find ~ -type f -name \"*.txt\"); do\n  line_count=$(grep -c 'Linux' \"$file\")\n  total_lines=$((total_lines + line_count))\ndone\n\necho $total_lines\n```",
        "create": {
            "init": "# This script creates some sample text files in the student's home directory.\nmkdir -p ~/test_files\necho -e \"This is a Linux tutorial.\\nLinux is powerful.\" > ~/test_files/file1.txt\necho -e \"Operating systems include Linux.\\nLinux kernel is monolithic.\" > ~/test_files/file2.txt\necho -e \"No mention here.\" > ~/test_files/file3.txt\necho -e \"The Linux community contributes widely.\" > ~/test_files/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all text files in home directory and count lines containing 'Linux'\ntotal_lines=0\n\nfor file in $(find ~ -type f -name \"*.txt\"); do\n  line_count=$(grep -c 'Linux' \"$file\")\n  total_lines=$((total_lines + line_count))\ndone\n\necho $total_lines"
        }
    },
    {
        "description": "Count the number of lines in all text files (*.txt) located in the \"documents\" directory under your home directory, excluding any lines that contain only whitespace or are empty.",
        "explanation": "To solve this problem, you need to navigate to the \"documents\" directory within your home directory. Then, you can use a combination of shell commands to iterate over each text file and count non-empty lines that do not consist solely of whitespace. Useful commands for solving this task include `find` to locate files, `grep` with appropriate flags to filter lines, and `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/documents -type f -name \"*.txt\" | xargs grep -v '^[[:space:]]*$' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/documents\necho -e \"Hello World\\n\\nThis is a test.\\n   \\nAnother line.\" > ~/documents/file1.txt\necho -e \"\\n\\nWhitespace only line.\\nContent line.\" > ~/documents/file2.txt\necho -e \"Last file.\\n \\nEnd.\" > ~/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/documents -type f -name \"*.txt\" | xargs grep -v '^[[:space:]]*$' | wc -l"
        }
    },
    {
        "description": "In your home directory, there exists a folder named `log_analysis` containing multiple `.log` files. Each log file records various system events in the format: `YYYY-MM-DD HH:MM:SS [EVENT_TYPE] Message`. Your task is to determine how many times the event type `[ERROR]` occurs across all log files within the `log_analysis` directory. Assume that no other directories or files are present in your home directory.",
        "explanation": "To solve this problem, you need to use command-line utilities to navigate through the `log_analysis` directory, read the contents of each `.log` file, search for lines containing `[ERROR]`, and count these occurrences. Useful commands include `grep` for searching text patterns and `wc -l` for counting lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"\\[ERROR\\]\" ~/log_analysis/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_analysis\ncat <<EOL > ~/log_analysis/system1.log\n2023-10-01 10:00:00 [INFO] System started\n2023-10-01 11:00:00 [ERROR] Failed to load module\n2023-10-01 12:00:00 [WARN] Low memory\nEOL\n\ncat <<EOL > ~/log_analysis/system2.log\n2023-10-02 09:30:00 [ERROR] Disk not found\n2023-10-02 09:45:00 [INFO] Reconnected disk\n2023-10-02 10:15:00 [ERROR] Timeout on request\nEOL\n\ncat <<EOL > ~/log_analysis/system3.log\n2023-10-03 14:55:00 [INFO] Backup completed successfully\n2023-10-03 15:05:00 [ERROR] Network unreachable\n2023-10-03 16:20:00 [DEBUG] Verbose logging enabled\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"\\[ERROR\\]\" ~/log_analysis/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, you will find a text file named \"system_logs.txt\". Count the number of unique IP addresses that have accessed the system based on this log file. Ignore any lines that do not contain an IP address.",
        "explanation": "To solve the problem, you need to extract all IP addresses from the \"system_logs.txt\" file and count only the unique ones. Use tools like grep to filter lines containing IP addresses and awk or sed to extract them. Then, utilize sort and uniq to determine the unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/system_logs.txt | sort | uniq | wc -l\n```",
        "create": {
            "init": "cat << EOF > ~/system_logs.txt\n192.168.1.1 - - [12/Oct/2023:14:23:54 +0000] \"GET /index.html HTTP/1.1\" 200 1043\n192.168.1.2 - - [12/Oct/2023:14:24:34 +0000] \"POST /form HTTP/1.1\" 302 512\nInvalid log entry without IP address\n192.168.1.3 - - [12/Oct/2023:14:25:01 +0000] \"GET /image.png HTTP/1.1\" 200 2048\n192.168.1.2 - - [12/Oct/2023:14:26:22 +0000] \"GET /style.css HTTP/1.1\" 304 1234\nEOF"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/system_logs.txt | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that were modified in the last 7 days and have a size larger than 1MB.",
        "explanation": "To solve this problem, you need to interact with the shell to find files in your home directory. You can use the `find` command with options to filter files based on modification time and size. Specifically, use `-mtime` to specify a time range and `-size` for file size filtering. Combine these criteria to locate the relevant files and then count them using tools like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "You need to find all files in your home directory that have been modified in the last 7 days and contain the word \"error\" in their content. Count how many of these files exist.",
        "explanation": "To solve this problem, you can use the `find` command combined with `grep`. First, use `find` to locate files modified within the last 7 days. Then, apply `grep` to search for the word \"error\" in those files. Finally, count how many files meet these criteria using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find and count all files modified within the last 7 days containing \"error\"\nfind ~ -type f -mtime -7 | xargs grep -l \"error\" | wc -l\n```",
        "create": {
            "init": "# Create test files for demonstration\nmkdir -p ~/test_files\necho \"This is a test file containing error.\" > ~/test_files/file1.txt\necho \"This file does not contain the keyword.\" > ~/test_files/file2.txt\necho \"Error found here as well.\" > ~/test_files/file3.log\n\n# Modify timestamp of some files for testing purposes\ntouch -m -d '5 days ago' ~/test_files/file1.txt\ntouch -m -d '10 days ago' ~/test_files/file2.txt\ntouch -m -d '3 days ago' ~/test_files/file3.log\n\n# Ensure these test files are present in the home directory for student interaction."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find and count all files modified within the last 7 days containing \"error\"\nfind ~ -type f -mtime -7 | xargs grep -l \"error\" | wc -l"
        }
    },
    {
        "description": "Determine the total number of lines containing the word \"error\" in all `.log` files within the `/var/logs` directory, ignoring case sensitivity.",
        "explanation": "To solve this problem, you need to search for the word \"error\" in all `.log` files located in the `/var/logs` directory. You can use `grep` with the `-i` option to ignore case sensitivity and count the occurrences using `wc -l`. Utilize a loop or find command to iterate through each file if necessary.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script to count occurrences of 'error' in all .log files ignoring case.\ngrep -i 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "# Create /var/logs directory and some sample .log files for testing\nmkdir -p /var/logs\necho \"This is an ERROR line.\" > /var/logs/system.log\necho \"Another error detected.\" > /var/logs/application.log\necho \"No errors here.\" > /var/logs/network.log\necho \"ERROR: Something went wrong.\" > /var/logs/auth.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script to count occurrences of 'error' in all .log files ignoring case.\ngrep -i 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, containing multiple text files with server logs. Each log entry is on a new line and follows the format: \"YYYY-MM-DD HH:MM:SS - LEVEL - Message\". Your task is to count how many ERROR level entries are there across all files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to iterate over each file in the \"logs\" directory. For each file, use tools like `grep` to filter lines that contain the string \"ERROR\". Count these lines using `wc -l` and accumulate the counts from all files to get the total number of ERROR entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep 'ERROR' *.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:01 - INFO - Server started\\n2023-10-01 12:05:23 - ERROR - Failed to connect to database\\n2023-10-01 12:07:45 - WARNING - Low disk space\\n2023-10-01 12:11:30 - ERROR - User authentication failed\" > ~/logs/server1.log\necho -e \"2023-10-02 09:15:00 - INFO - Backup completed\\n2023-10-02 09:20:30 - ERROR - Disk write error\\n2023-10-02 09:25:45 - INFO - File uploaded successfully\\n2023-10-02 09:37:50 - ERROR - Timeout while accessing external API\" > ~/logs/server2.log\necho > ~/logs/server3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep 'ERROR' *.log | wc -l"
        }
    },
    {
        "description": "Count the number of unique file extensions present in the `/var/log` directory, excluding directories and files with no extensions.",
        "explanation": "To solve this problem, you need to list all files in the `/var/log` directory, filter out directories, and exclude files without extensions. Afterwards, extract the extensions from the remaining files and count how many unique ones there are.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all files in /var/log excluding directories\nfiles=$(find /var/log -type f)\n\n# Extract file extensions and filter out files without extension\nextensions=$(echo \"$files\" | awk -F. 'NF>1 {print $NF}' | sort | uniq)\n\n# Count unique extensions\necho \"$extensions\" | wc -l\n```",
        "create": {
            "init": "# No initialization required for this task as we are using existing system logs."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# List all files in /var/log excluding directories\nfiles=$(find /var/log -type f)\n\n# Extract file extensions and filter out files without extension\nextensions=$(echo \"$files\" | awk -F. 'NF>1 {print $NF}' | sort | uniq)\n\n# Count unique extensions\necho \"$extensions\" | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all .log files within the /var/log directory and its subdirectories, and report the total count.",
        "explanation": "To solve this problem, you will need to search through all .log files in the /var/log directory and its subdirectories for lines containing the word \"error\". You can use a combination of `find`, `grep`, and `wc` commands. First, use `find` to locate all .log files, then use `grep` to filter lines containing \"error\", and finally, use `wc -l` to count those lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files in /var/log directory and its subdirectories\nfind /var/log -type f -name \"*.log\" | xargs grep -i \"error\" | wc -l\n```",
        "create": {
            "init": "# No initialization needed; this script is intentionally left blank."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files in /var/log directory and its subdirectories\nfind /var/log -type f -name \"*.log\" | xargs grep -i \"error\" | wc -l"
        }
    },
    {
        "description": "You need to find and count the total number of lines containing the word \"error\" (case-insensitive) in all `.log` files located within the `/var/logs/` directory and its subdirectories on your Ubuntu system. Ensure each file is opened only once during this process.",
        "explanation": "To solve this problem, you can use the `find` command to locate all `.log` files within the specified directory and its subdirectories. Then, you can use `xargs` along with `grep -i` to search for occurrences of \"error\" in a case-insensitive manner across these files. Finally, aggregate the results using `wc -l` to count the matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/logs/ -type f -name \"*.log\" | xargs grep -i \"error\" | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs/test\necho \"Error: Something went wrong\" > /var/logs/test/app.log\necho \"All systems operational\" > /var/logs/test/system.log\necho \"ERROR: Disk space low\" > /var/logs/test/disk.log\necho \"No issues detected\" > /var/logs/no_issues.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/logs/ -type f -name \"*.log\" | xargs grep -i \"error\" | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified within the last 7 days and are larger than 500KB.",
        "explanation": "To solve this problem, you can use a combination of `find` command options to filter files based on their modification time and size. Specifically, you'll want to use `-type f` to target files (not directories), `-mtime -7` to find files modified in the last 7 days, and `-size +500k` to select files larger than 500KB. You can then count these files using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind \"$HOME\" -type f -mtime -7 -size +500k | wc -l\n```",
        "create": {
            "init": "# Initialization script is empty because no specific setup is required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find \"$HOME\" -type f -mtime -7 -size +500k | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple .log files. Each log file has entries with timestamps in the format \"YYYY-MM-DD HH:MM:SS\" followed by a message. Your task is to find out how many unique days are represented across all log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to extract the date part from each timestamp in every log file within the \"logs\" directory, then determine the number of unique dates. This can be achieved by using tools like `grep` or `awk` to extract dates, and then using `sort` and `uniq` utilities to find distinct dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract all dates from logs\ngrep -hEo '^[0-9]{4}-[0-9]{2}-[0-9]{2}' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 Entry one\\n2023-10-02 13:00:00 Entry two\\n2023-10-01 14:00:00 Entry three\" > ~/logs/log1.log\necho -e \"2023-10-03 15:30:00 Entry four\\n2023-10-01 16:45:00 Entry five\" > ~/logs/log2.log\necho -e \"2023-10-04 09:15:00 Entry six\\n2023-10-03 11:20:00 Entry seven\\n2023-10-02 17:55:00 Entry eight\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract all dates from logs\ngrep -hEo '^[0-9]{4}-[0-9]{2}-[0-9]{2}' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Find and count the number of files in your home directory and its subdirectories that have been modified within the last 7 days. Do not include directories themselves in the count.",
        "explanation": "To solve this problem, you can use the `find` command with the `-type f` option to ensure only files are counted, and the `-mtime` option to filter files modified in the last 7 days. The output should be just a single integer representing the count of these files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script to count files modified in the last 7 days.\nfind ~ -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# This script prepares some example files in the user's home directory for testing purposes.\nmkdir -p ~/test_dir\ntouch ~/test_file.txt\ntouch ~/test_dir/old_file.txt\ntouch -d '10 days ago' ~/test_dir/old_file.txt\ntouch -d '3 days ago' ~/recent_file_1.txt\ntouch -d '5 days ago' ~/recent_file_2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script to count files modified in the last 7 days.\nfind ~ -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the largest file in terms of size within your home directory and all its subdirectories, but only considering files that have been modified in the last 7 days. Your answer should be the absolute path of this file.",
        "explanation": "To solve this problem, you need to:\n1. Use the `find` command to locate files within your home directory that have been modified in the last 7 days.\n2. Use `xargs` or a loop to process these files and determine their sizes.\n3. Utilize the `sort` command to sort these files by size.\n4. Extract the absolute path of the largest file.\n\nHints:\n- The `find` command can filter files based on modification time using `-mtime`.\n- The `stat` command can be used to get file sizes.\n- Pay attention to symbolic links and avoid including them unless they point directly to regular files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all regular files modified in the last 7 days within the home directory\nlargest_file=$(find ~ -type f -mtime -7 -exec stat --format=\"%s %n\" {} + | sort -nr | head -n 1 | cut -d' ' -f2)\n\n# Output only the absolute path of the largest file\necho $largest_file\n```",
        "create": {
            "init": "# Assuming no specific initialization is required as students will use their own home directories."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "# Find all regular files modified in the last 7 days within the home directory\nlargest_file=$(find ~ -type f -mtime -7 -exec stat --format=\"%s %n\" {} + | sort -nr | head -n 1 | cut -d' ' -f2)\n\n# Output only the absolute path of the largest file\necho $largest_file"
        }
    },
    {
        "description": "Determine the number of lines in all text files within your home directory that contain the word \"Linux\". You should consider only files with a \".txt\" extension.",
        "explanation": "To solve the problem, you need to locate all '.txt' files in your home directory, then examine each file for occurrences of the word \"Linux\". Count the number of lines containing this word across all files. Useful commands include `find`, `grep`, and `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Locate .txt files and count lines containing 'Linux'\nfind ~ -name \"*.txt\" -exec grep -i 'Linux' {} \\; | wc -l\n```",
        "create": {
            "init": "# Create sample text files in the home directory for testing\necho -e \"Linux is great.\\nI love Linux.\\nOperating systems are cool.\" > ~/file1.txt\necho -e \"Some other content.\\nNo mention here.\" > ~/file2.txt\necho -e \"Another Linux line here.\\nLinux again!\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Locate .txt files and count lines containing 'Linux'\nfind ~ -name \"*.txt\" -exec grep -i 'Linux' {} \\; | wc -l"
        }
    },
    {
        "description": "You have several text files in your home directory, each containing lines of text with different lengths. Your task is to find the longest line across all files and report its length in characters.",
        "explanation": "To solve this problem, you need to iterate through each file in the home directory and read their contents. For each line in the files, you should calculate its length using a command such as `wc -L` to find the maximum length of any line. This involves using utilities like `find`, `xargs`, and `wc` to efficiently handle multiple files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all text files in the home directory, calculate the longest line length for each file, then find the maximum length overall.\nfind ~ -maxdepth 1 -type f -name \"*.txt\" | xargs wc -L | awk 'BEGIN {max = 0} {if ($1+0 > max) max=$1} END {print max}'\n```",
        "create": {
            "init": "# Create some sample text files with varying line lengths\necho -e \"This is a short line.\\nAnother short one.\" > ~/file1.txt\necho -e \"A much longer line than before.\\nShort again.\" > ~/file2.txt\necho -e \"The longest line we have seen so far in these examples.\\nTiny.\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all text files in the home directory, calculate the longest line length for each file, then find the maximum length overall.\nfind ~ -maxdepth 1 -type f -name \"*.txt\" | xargs wc -L | awk 'BEGIN {max = 0} {if ($1+0 > max) max=$1} END {print max}'"
        }
    },
    {
        "description": "Count the total number of lines of code in all Python files located within the directory `/home/student/projects`, including subdirectories, and ignore any lines that are either empty or contain only whitespace.",
        "explanation": "To solve this problem, you need to find all Python files under the specified directory recursively. You can use `find` command to locate `.py` files. Then, use `grep` with appropriate options to count non-empty lines. Finally, sum the counts from all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/projects -type f -name \"*.py\" | xargs grep -hv '^[[:space:]]*$' | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/projects\necho -e \"print('Hello World')\\n\\n\" > /home/student/projects/file1.py\necho -e \"# This is a comment\\nimport os\\n\" > /home/student/projects/subdir/file2.py\nmkdir -p /home/student/projects/subdir\necho -e \"\\n\\ndef foo():\\n    pass\\n\" > /home/student/projects/subdir/file3.py"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/projects -type f -name \"*.py\" | xargs grep -hv '^[[:space:]]*$' | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"log_files\" containing multiple log files with the extension \".log\". Your task is to count the total number of unique IP addresses across all these log files. Each log entry begins with an IP address, followed by a space and additional text. You should ignore any malformed lines that do not start with an IP address.",
        "explanation": "To solve this problem, you need to iterate through each \".log\" file in the \"log_files\" directory. For each file, extract the lines that start with a valid IP address pattern. You can use tools like `grep` to filter out valid IP addresses and then use `sort` and `uniq` to count unique addresses. Consider using regular expressions to match valid IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the log_files directory\ncd ~/log_files\n\n# Use grep to extract valid IPs from all .log files, sort them, and count unique ones.\ngrep -hoE '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' *.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"192.168.1.1 User login\\nMalformed entry\\n10.0.0.2 System update\\n192.168.1.1 User logout\" > ~/log_files/log1.log\necho -e \"172.16.0.3 Error detected\\n10.0.0.x Invalid entry\\n192.168.l.l Typo error\\n172.16.0.3 Recovery action\" > ~/log_files/log2.log\necho -e \"192.168.l.l Another typo\\n256.x.y.z Invalid ip\\n172.invalid.ip Entry\\n172.invalid.entry Entry again\" > ~/log_files/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to the log_files directory\ncd ~/log_files\n\n# Use grep to extract valid IPs from all .log files, sort them, and count unique ones.\ngrep -hoE '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' *.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count how many files in the `/var/log` directory have been modified within the last 7 days.",
        "explanation": "To solve this problem, you can use the `find` command to search for files in the `/var/log` directory that have been modified within the last 7 days. The `-mtime` option with a negative value will help you filter these files. Finally, use `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You need to find the total number of lines containing the word \"ERROR\" in all text files located within a directory named \"logs\" in your home directory, and then calculate the sum of these line counts.",
        "explanation": "To solve this problem, you should navigate to the \"logs\" directory within your home directory, and use a combination of command-line utilities like `grep` to search for occurrences of \"ERROR\" in each file. You can use `wc -l` to count the lines that match, and finally sum these counts across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/logs/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: All systems operational\\nERROR: Failed to connect\\nINFO: Retrying connection\\nERROR: Connection timeout\" > ~/logs/log1.txt\necho -e \"INFO: Transaction started\\nERROR: Insufficient funds\\nINFO: Transaction completed successfully\" > ~/logs/log2.txt\necho -e \"DEBUG: Starting diagnostic\\nERROR: Diagnostic failed at step 3\\nDEBUG: Attempting recovery\\nERROR: Recovery unsuccessful\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/logs/*.txt | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all `.log` files within the `/var/logs` directory and its subdirectories, considering case-insensitivity.",
        "explanation": "To solve this problem, you need to search through all `.log` files in `/var/logs` and its subdirectories. You can use `grep` with the `-i` option to perform a case-insensitive search for the word \"error\". Use `find` to locate all `.log` files and then pipe them to `xargs` or directly use `grep`. Sum up the line counts from each file to get the total number of lines containing \"error\".\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/logs -type f -name \"*.log\" | xargs grep -i \"error\" | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs/app1 /var/logs/app2\necho -e \"Error: Unable to fetch data\\nInfo: Fetching complete\\nERROR: Disk full\" > /var/logs/app1/application.log\necho -e \"Warning: High memory usage\\nerror: Network down\\nINFO: Connection established\" > /var/logs/app2/server.log\necho -e \"Error occurred during process\\nDEBUG: Process started\\nerror: Timeout reached\" > /var/logs/system.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/logs -type f -name \"*.log\" | xargs grep -i \"error\" | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory, which contains multiple text files with server log entries. Each log entry is on a new line and contains a timestamp followed by a message type (INFO, WARNING, ERROR) and then the actual message. Your task is to count how many ERROR messages occurred on the most recent date present in these log files.",
        "explanation": "First, you need to identify the most recent date from all the log entries across all files in the \"logfiles\" directory. Then, filter out only those entries that match this date and have an \"ERROR\" message type. Finally, count these ERROR messages to get your answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find the most recent date from all logs.\nmost_recent_date=$(grep -h '^[0-9]' ~/logfiles/*.txt | cut -d' ' -f1 | sort | tail -n1)\n\n# Count how many ERROR messages are present for that date.\nerror_count=$(grep \"$most_recent_date\" ~/logfiles/*.txt | grep 'ERROR' | wc -l)\n\n# Output the result.\necho $error_count\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\ncat <<EOL > ~/logfiles/log1.txt\n2023-10-01 10:00:00 INFO Starting process\n2023-10-01 10:05:00 ERROR Failed to start service\n2023-10-02 12:30:00 WARNING Low memory\n2023-10-03 14:45:00 ERROR Connection lost\nEOL\n\ncat <<EOL > ~/logfiles/log2.txt\n2023-10-03 09:15:00 INFO User login successful\n2023-10-03 18:25:00 ERROR Disk full\n2023-10-04 07:50:00 INFO Scheduled job started\n2023-10-04 11:20:00 ERROR Unable to connect to database\nEOL\n\ncat <<EOL > ~/logfiles/log3.txt\n2023-10-02 08:30:00 INFO Backup completed successfully\n2023-10-04 06:15:00 WARNING High CPU usage detected\n2023-10-04 09:45:00 ERROR Network timeout occurred \nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find the most recent date from all logs.\nmost_recent_date=$(grep -h '^[0-9]' ~/logfiles/*.txt | cut -d' ' -f1 | sort | tail -n1)\n\n# Count how many ERROR messages are present for that date.\nerror_count=$(grep \"$most_recent_date\" ~/logfiles/*.txt | grep 'ERROR' | wc -l)\n\n# Output the result.\necho $error_count"
        }
    },
    {
        "description": "Count the number of lines in all text files located within the \"documents\" directory in your home directory that contain the word \"Linux\".",
        "explanation": "To solve this problem, you need to search through each text file in the \"documents\" directory for occurrences of the word \"Linux\" and count how many lines contain it. You can use utilities like `grep` to filter lines containing specific words and `wc` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'Linux' ~/documents/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/documents\necho -e \"This is a Linux tutorial.\\nWelcome to Linux.\" > ~/documents/file1.txt\necho -e \"Learning about operating systems.\\nLinux kernel is powerful.\" > ~/documents/file2.txt\necho -e \"Exploring file systems.\\nNo mention here.\" > ~/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'Linux' ~/documents/*.txt | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Each log file contains timestamps and event messages. Your task is to find out how many unique dates (in YYYY-MM-DD format) are present across all the log files. You must count only the dates at the beginning of each line in the log files.",
        "explanation": "To solve this problem, you need to iterate over each \".log\" file within the \"logs\" directory, extract the date from each line (assuming it's at the start of every line), and collect these dates into a set to ensure uniqueness. Finally, count the number of unique dates in that set.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 Event A\\n2023-01-02 Event B\\n2023-01-01 Event C\" > ~/logs/log1.log\necho -e \"2023-01-03 Event D\\n2023-01-02 Event E\\n2023-01-04 Event F\" > ~/logs/log2.log\necho -e \"2023-01-04 Event G\\n2023-01-05 Event H\\n2023-01-03 Event I\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"project_logs\" containing multiple log files with the \".log\" extension. Each log file records events with timestamps, and some lines contain the keyword \"ERROR\". Your task is to count the total number of \"ERROR\" occurrences across all log files in the \"project_logs\" directory. Assume each log file is well-formed with consistent structure.",
        "explanation": "To solve this problem, you need to iterate over all the \".log\" files in the \"project_logs\" directory and search for lines containing the keyword \"ERROR\". You can use utilities like `grep` to filter these lines and `wc` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' project_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p project_logs\necho -e \"[2023-10-01 10:00:00] INFO Starting process\\n[2023-10-01 10:05:00] ERROR Process failed\\n[2023-10-01 10:10:00] INFO Process restarted\\n[2023-10-01 11:00:00] ERROR Another failure detected\" > project_logs/log1.log\necho -e \"[2023-10-02 09:30:00] INFO Initialization complete\\n[2023-10-02 09:35:00] ERROR Failed to initialize component\\n[2023-10-02 09:40:00] WARN Component slow response\\n[2023-10-02 09:45:00] ERROR Critical error encountered\" > project_logs/log2.log\necho -e \"[2023-10-03 08:15:00] DEBUG Diagnostic message\\n[2023-10-03 08:20:00] INFO System operational\\n[2023-10-03 08:25:00] ERROR Minor issue occurred\" > project_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' project_logs/*.log | wc -l"
        }
    },
    {
        "description": "Count how many files in your home directory and its subdirectories have been modified within the last 7 days. You are required to exclude hidden files (files that start with a dot).",
        "explanation": "You can use the `find` command to search for files modified within the last 7 days. Utilize the `-type f` option to specifically target files, and `-mtime -7` to filter based on modification time. To exclude hidden files, you can use the `! -name '.*'` option or adjust your search pattern accordingly.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f ! -name '.*' -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f ! -name '.*' -mtime -7 | wc -l"
        }
    },
    {
        "description": "In your home directory, there's a folder named \"project_logs\" containing multiple log files. Each log file records various events with timestamps. Your task is to find out which day (in the format YYYY-MM-DD) has the highest number of logged events across all files in this directory. You need to count the event occurrences based on the dates extracted from each line of every log file.",
        "explanation": "To solve this problem, you need to iterate over all the log files in the \"project_logs\" directory and extract dates from each line. Use tools like `grep`, `awk`, or `sed` to parse and count these dates. Once you have collected counts for each date, determine which date has the maximum number of events.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to project_logs directory and list all files.\ncd ~/project_logs\n\n# Extract all dates from each file, sort them, and count occurrences.\ncat *.txt | awk '{print $1}' | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\ncat <<EOL > ~/project_logs/log1.txt\n2023-10-01 12:34:56 Event A\n2023-10-01 13:45:00 Event B\n2023-10-02 09:00:00 Event C\nEOL\n\ncat <<EOL > ~/project_logs/log2.txt\n2023-10-01 14:20:30 Event D\n2023-10-03 08:30:00 Event E\n2023-10-03 09:15:15 Event F\nEOL\n\ncat <<EOL > ~/project_logs/log3.txt\n2023-10-02 11:11:11 Event G\n2023-10-02 12:12:12 Event H\n2023-10-04 14:14:14 Event I\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "# Navigate to project_logs directory and list all files.\ncd ~/project_logs\n\n# Extract all dates from each file, sort them, and count occurrences.\ncat *.txt | awk '{print $1}' | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" within all `.log` files in the current directory and its subdirectories.",
        "explanation": "To solve this problem, you need to use tools like `find` to locate all `.log` files within the current directory and its subdirectories. Then, you can use `grep` to search for occurrences of the word \"error\" in each file, and finally count the number of matching lines across all files using tools like `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files and search for 'error', then count matching lines\nfind . -name \"*.log\" -type f -exec grep -i \"error\" {} \\; | wc -l\n```",
        "create": {
            "init": "# Create a few log files with some sample content\nmkdir -p logs/subdir\necho -e \"This is an error\\nAnother line\" > logs/error1.log\necho -e \"No errors here\\nYet another error\" > logs/subdir/error2.log\necho -e \"Random text\\nError occurred again\" > logs/error3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files and search for 'error', then count matching lines\nfind . -name \"*.log\" -type f -exec grep -i \"error\" {} \\; | wc -l"
        }
    },
    {
        "description": "Find and count the number of regular files in your home directory that were modified in the last 7 days and have a size greater than 1MB.",
        "explanation": "To solve this problem, you need to use the `find` command with appropriate options to filter files based on their modification time and size. The `-mtime` option can be used to find files modified within the last 7 days, and the `-size` option can be used to filter files larger than 1MB. You should also use the `wc -l` command to count the number of files found.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# This script is intentionally left empty as no initialization is needed."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "You have a directory named \"system_logs\" in your home directory containing multiple log files with the extension \".log\". Each log file records entries with timestamps of events in the format \"YYYY-MM-DD HH:MM:SS\". Count how many unique days (YYYY-MM-DD) appear across all the log files in this directory.",
        "explanation": "To solve this problem, you need to iterate through each log file within the \"system_logs\" directory, extract the date part of each timestamp (the first 10 characters), and determine the count of unique dates. You can achieve this by using text processing utilities like `cut`, `awk`, or `sed` to extract dates, followed by using `sort` and `uniq` to find unique entries. Finally, count these unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/system_logs -type f -name \"*.log\" | xargs cat | cut -d' ' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/system_logs\necho -e \"2023-01-01 12:00:00 Event A\\n2023-01-02 13:15:30 Event B\\n2023-01-03 14:45:00 Event C\" > ~/system_logs/log1.log\necho -e \"2023-01-02 09:00:00 Event D\\n2023-01-04 16:30:45 Event E\\n2023-01-05 17:00:20 Event F\" > ~/system_logs/log2.log\necho -e \"2023-01-03 08:55:10 Event G\\n2023-01-06 11:22:33 Event H\" > ~/system_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/system_logs -type f -name \"*.log\" | xargs cat | cut -d' ' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to find all files within the `/var/log` directory that contain the word \"error\" and count how many unique IP addresses are associated with these errors. Assume each line in the log files that contain an error message also includes an IP address in the format `xxx.xxx.xxx.xxx`.",
        "explanation": "To solve this problem, you can use a combination of `grep`, `awk`, and `sort` utilities. First, use `grep` to filter out lines containing the word \"error\". Then, use `awk` or a similar tool to extract IP addresses from those lines. Finally, sort these addresses and count unique occurrences using `uniq`. Ensure that your command accounts for potential variations in log file formats.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find lines containing \"error\", extract IP addresses, sort them, and count unique ones.\ngrep 'error' /var/log/*.log | awk '{for(i=1;i<=NF;i++)if($i ~ /^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+$/)print $i}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create dummy log files with error messages and random IP addresses\necho -e \"2023-10-01 12:00:01 error Connection failed from 192.168.1.1\\n2023-10-01 12:05:01 error Timeout occurred at 192.168.1.2\\n2023-10-01 12:10:01 info Connection established from 192.168.1.1\\n2023-10-01 12:15:01 error Connection reset by peer at 192.168.1.3\\n2023-10-01 12:20:01 error Failed login attempt from 192.168.1.2\" > /var/log/dummy_log_1.log\n\necho -e \"2023-10-02 13:00:03 error Disk full on server with IP 192.168.2.4\\n2023-10-02 13:05:03 warning High memory usage on server with IP 192.168.2.5\\n2023-10-02 13:10:03 error Network unreachable for host at IP address 192.168.2.6\" > /var/log/dummy_log_2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find lines containing \"error\", extract IP addresses, sort them, and count unique ones.\ngrep 'error' /var/log/*.log | awk '{for(i=1;i<=NF;i++)if($i ~ /^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+$/)print $i}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in the `/home/student/documents` directory that contain the word \"Linux\". You must ignore case when searching for the word.",
        "explanation": "To solve this problem, you can use tools like `grep` with its `-i` option to perform a case-insensitive search. By using `grep -i 'Linux' /home/student/documents/*.txt`, you can filter lines containing \"Linux\" from all `.txt` files in the specified directory. Then, use `wc -l` to count these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'Linux' /home/student/documents/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho -e \"This is a Linux tutorial.\\nWelcome to Linux world.\" > /home/student/documents/file1.txt\necho -e \"linux kernel basics.\\nUnderstanding Linux.\" > /home/student/documents/file2.txt\necho -e \"Operating systems overview.\" > /home/student/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'Linux' /home/student/documents/*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and whose names end with '.log'.",
        "explanation": "To solve this problem, you need to list all files in your home directory, filter those ending with '.log', and check their modification dates. Use `find` to filter files by modification date and name pattern.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count the number of log files modified in the last 7 days within home directory.\nfind ~ -type f -name \"*.log\" -mtime -7 | wc -l\n```",
        "create": {
            "init": "# Create some sample log files with different modification dates for testing\nmkdir -p ~/test_logs\ntouch ~/test_logs/test1.log\ntouch ~/test_logs/test2.log\nsleep 60 # Ensure there's a time difference between file modifications\ntouch -d '8 days ago' ~/test_logs/old1.log\ntouch -d '5 days ago' ~/test_logs/recent1.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count the number of log files modified in the last 7 days within home directory.\nfind ~ -type f -name \"*.log\" -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all `.log` files within the `/var/logs` directory, and provide the count as an integer.",
        "explanation": "To solve this problem, you need to search through every `.log` file in the `/var/logs` directory. You can use a combination of `grep`, `find`, and `wc` commands. First, find all files ending with `.log`, then use `grep` to filter lines containing \"error\", and finally count these lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files in /var/logs, search for 'error', count the lines, and output only the integer result.\nfind /var/logs -name \"*.log\" -exec grep -i 'error' {} \\; | wc -l\n```",
        "create": {
            "init": "# Create the /var/logs directory if it doesn't exist\nmkdir -p /var/logs\n\n# Create sample log files with varied content\necho -e \"Info: System started\\nWarning: Low disk space\\nError: Disk full\" > /var/logs/system.log\necho -e \"Error: Network unreachable\\nInfo: Connected to server\" > /var/logs/network.log\necho -e \"Error: Failed login attempt\\nWarning: High CPU usage\" > /var/logs/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files in /var/logs, search for 'error', count the lines, and output only the integer result.\nfind /var/logs -name \"*.log\" -exec grep -i 'error' {} \\; | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" that contains multiple log files with the \".log\" extension. Each log file contains timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to count how many unique dates (in \"YYYY-MM-DD\" format) appear across all log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to iterate through all files with a \".log\" extension within the \"logs\" directory. For each file, extract lines containing timestamps and isolate the date part (\"YYYY-MM-DD\"). Collect all unique dates and count them. You can use tools such as `grep`, `cut`, `sort`, and `uniq` to manipulate and process the data efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat logs/*.log | grep -oP '^\\d{4}-\\d{2}-\\d{2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p logs\necho -e \"2023-01-01 12:00:00\\n2023-01-02 13:00:00\\n2023-01-01 14:00:00\" > logs/log1.log\necho -e \"2023-01-03 15:30:00\\n2023-01-02 09:45:00\\n2023-01-04 08:20:00\" > logs/log2.log\necho -e \"2023-01-04 20:35:00\\n2023-01-05 21:45:00\\n2023-01-03 11:10:00\" > logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat logs/*.log | grep -oP '^\\d{4}-\\d{2}-\\d{2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified within the last 7 days.",
        "explanation": "To solve this problem, you can use the `find` command which is useful for searching files in a directory based on different criteria. You will need to specify your home directory as the starting point, and use the `-mtime` option with an appropriate argument to filter files modified within the last 7 days. The `wc -l` command can then be used to count the number of lines returned, which corresponds to the number of files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization is required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "Determine the total number of files (not directories) present in a directory named \"data_files\" and its subdirectories, which have a \".txt\" extension and were modified in the last 7 days.",
        "explanation": "To solve this problem, you should use the `find` command to search for files with the \".txt\" extension within the \"data_files\" directory and its subdirectories. The `-type f` option will ensure that only files are considered (ignoring directories), and `-mtime -7` will filter those modified within the last 7 days. Finally, count the number of resulting files using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind data_files -type f -name '*.txt' -mtime -7 | wc -l\n```",
        "create": {
            "init": "mkdir -p data_files/subdir1\nmkdir -p data_files/subdir2\n\n# Create some sample .txt files with modification dates\ntouch data_files/file1.txt\ntouch data_files/file2.txt\ntouch data_files/subdir1/file3.txt\ntouch data_files/subdir2/file4.txt\n\n# Modify dates so that some are within 7 days, others are not.\n# Assume today is day 10; file1 is on day 4, other files on day 8.\ntouch -d '4 days ago' data_files/file1.txt\ntouch -d '8 days ago' data_files/file2.txt\ntouch -d '8 days ago' data_files/subdir1/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find data_files -type f -name '*.txt' -mtime -7 | wc -l"
        }
    },
    {
        "description": "Count the total number of files that contain the word \"error\" within their content in your home directory, but exclude any hidden files (those beginning with a dot).",
        "explanation": "To solve this problem, you can use the `grep` command to search for the word \"error\" within files. Since hidden files should be excluded, you'll need to filter them out using appropriate options or by piping commands. The task involves navigating through your home directory and considering all non-hidden files recursively.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~\nfind . -type f ! -name \".*\" | xargs grep -l \"error\" | wc -l\n```",
        "create": {
            "init": "# Initialization script to create sample files in the student's home directory\nmkdir -p ~/test_environment\necho \"This is an error log file.\" > ~/test_environment/file1.txt\necho \"No issues found here.\" > ~/test_environment/file2.txt\necho \"Error occurred on line 10.\" > ~/test_environment/file3.txt\necho \"All good!\" > ~/test_environment/.hidden_file.txt  # Hidden file"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~\nfind . -type f ! -name \".*\" | xargs grep -l \"error\" | wc -l"
        }
    },
    {
        "description": "Count the number of unique IP addresses that have accessed the server, using log files located in the `/var/log/apache2/` directory. Assume the log files are named `access.log` and may have multiple entries for each IP.",
        "explanation": "To solve this problem, you need to extract IP addresses from the Apache access logs and count how many unique ones there are. You can use tools such as `grep`, `awk`, or `sed` to filter and extract IP addresses, followed by `sort` and `uniq` to determine uniqueness.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract, sort, and count unique IPs from access.log\ngrep '^[0-9]' /var/log/apache2/access.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample access.log file with some repeated IPs for demonstration.\nmkdir -p /var/log/apache2/\ncat <<EOL > /var/log/apache2/access.log\n192.168.1.1 - - [12/Oct/2023:06:25:24 +0000] \"GET /index.html HTTP/1.1\" 200 2326\n192.168.1.2 - - [12/Oct/2023:06:25:30 +0000] \"POST /form HTTP/1.1\" 404 528\n192.168.1.3 - - [12/Oct/2023:06:25:35 +0000] \"GET /about.html HTTP/1.0\" 302 -\n192.168.1.1 - - [12/Oct/2023:06:26:24 +0000] \"GET /contact.html HTTP/1.1\" 200 1234\n192.168.1.4 - - [12/Oct/2023:06:27:24 +0000] \"GET /services.html HTTP/2\" 200 2048\n192.168.1.2 - - [12/Oct/2023:06:28:24 +0000] \"GET /home.html HTTP/2\" 500 -\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract, sort, and count unique IPs from access.log\ngrep '^[0-9]' /var/log/apache2/access.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"Linux\" in all `.txt` files located in the `/home/student/documents` directory and its subdirectories, ignoring case sensitivity.",
        "explanation": "To solve this problem, you need to use a combination of `find`, `grep`, and `wc` commands. First, use `find` to locate all `.txt` files in the specified directory and its subdirectories. Then, use `grep` with the `-i` option to search for lines containing \"Linux\" in each file, ignoring case sensitivity. Finally, pipe the output to `wc -l` to count the total number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -name \"*.txt\" | xargs grep -i 'Linux' | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents/subdir1\nmkdir -p /home/student/documents/subdir2\n\necho \"This is a Linux tutorial.\" > /home/student/documents/file1.txt\necho \"LINUX is an operating system.\" > /home/student/documents/file2.txt\necho \"Welcome to the world of Linux.\" > /home/student/documents/subdir1/file3.txt\necho \"Another line without keyword.\" > /home/student/documents/subdir2/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -name \"*.txt\" | xargs grep -i 'Linux' | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files within the `/home/student/data` directory, excluding any lines that contain the word \"error\".",
        "explanation": "To solve this problem, you should first navigate to the `/home/student/data` directory. Use a combination of `find`, `grep`, and `wc` commands. Start by using `find` to locate all `.txt` files. Then use `grep -v` to exclude lines containing \"error\" before counting lines with `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd /home/student/data\nfind . -name '*.txt' | xargs grep -v 'error' | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/data\necho -e \"This is a test.\\nAnother line.\\nError occurred.\" > /home/student/data/file1.txt\necho -e \"Sample line.\\nError in processing.\\nFinal line.\" > /home/student/data/file2.txt\necho -e \"Line one.\\nLine two.\\nNo errors here.\" > /home/student/data/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd /home/student/data\nfind . -name '*.txt' | xargs grep -v 'error' | wc -l"
        }
    },
    {
        "description": "You have been provided with a directory named \"server_logs\" in your home directory. This directory contains multiple log files with the \".log\" extension. Your task is to find out how many unique IP addresses made requests to the server on a specific date, which is mentioned in each log file in the format \"YYYY-MM-DD\". You need to count the number of unique IP addresses for the date \"2023-10-01\".",
        "explanation": "To solve this problem, you will need to perform several steps:\n1. Navigate to the \"server_logs\" directory.\n2. Use a tool like `grep` or `awk` to filter lines containing the date \"2023-10-01\".\n3. Extract IP addresses from these lines using a pattern matching tool like `awk` or regular expressions.\n4. Use a command like `sort` and `uniq` to count the number of unique IPs.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/server_logs\ngrep '2023-10-01' *.log | awk '{print $2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/server_logs\necho -e \"2023-10-01 192.168.1.1 accessed\\n2023-10-02 192.168.1.2 accessed\\n2023-10-01 192.168.1.3 accessed\\n2023-10-01 192.168.1.1 accessed\" > ~/server_logs/log1.log\necho -e \"2023-10-01 192.168.1.4 accessed\\n2023-10-03 192.168.1.5 accessed\\n2023-10-01 192.168.1.2 accessed\" > ~/server_logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/server_logs\ngrep '2023-10-01' *.log | awk '{print $2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, you will find a file named `access.log` containing server access logs. Your task is to count how many unique IP addresses have accessed the server.",
        "explanation": "To solve this problem, you can use the `awk` command to extract the IP address from each line of the log file. Then, use `sort` and `uniq` commands to find and count unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract IP addresses, sort them, filter unique ones and count them.\nawk '{print $1}' ~/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample access.log with random IP addresses\ncat > ~/access.log << EOL\n192.168.1.1 - - [01/Oct/2023:12:34:56 +0000] \"GET /index.html HTTP/1.1\" 200 1024\n192.168.1.2 - - [01/Oct/2023:12:35:00 +0000] \"POST /form HTTP/1.1\" 200 512\n192.168.1.3 - - [01/Oct/2023:12:35:30 +0000] \"GET /home.html HTTP/1.1\" 404 2048\n192.168.1.2 - - [01/Oct/2023:12:36:00 +0000] \"GET /about.html HTTP/1.1\" 200 256\n192.168.1.4 - - [01/Oct/2023:12:37:45 +0000] \"GET /contact.html HTTP/1.0\" 403 128\n192.168.1.5 - - [01/Oct/2023:12:38:00 +0000] \"GET /index.html HTTP/2\" 200 1024\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract IP addresses, sort them, filter unique ones and count them.\nawk '{print $1}' ~/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there are multiple text files with various extensions. Find the total number of lines across all files that have the \".txt\" extension and contain the word \"Linux\" (case-insensitive). Ignore any symbolic links to files.",
        "explanation": "To solve this problem, you need to list all files in your home directory with a \".txt\" extension. Then, for each file, check if it contains the word \"Linux\" in any case. You can use utilities like `find` to locate the files, `grep` to search for the keyword within them, and `wc -l` to count lines. Make sure to exclude symbolic links using appropriate options in `find`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files that are not symbolic links and contain 'Linux'\ntotal_lines=$(find ~ -type f -name \"*.txt\" ! -type l -exec grep -i 'Linux' {} + | wc -l)\necho $total_lines\n```",
        "create": {
            "init": "# Create sample text files in the student's home directory.\necho \"Welcome to Linux OS tutorial.\" > ~/file1.txt\necho \"This is a test file for Linux operations.\" > ~/file2.txt\necho \"Another line with linux mentioned.\" > ~/file3.txt\necho \"No mention of keyword here.\" > ~/file4.txt\n\n# Create non-txt file\necho \"This is not a txt file but has Linux keyword.\" > ~/file5.log\n\n# Create a symbolic link to one of the txt files\nln -s ~/file2.txt ~/linked_file.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files that are not symbolic links and contain 'Linux'\ntotal_lines=$(find ~ -type f -name \"*.txt\" ! -type l -exec grep -i 'Linux' {} + | wc -l)\necho $total_lines"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory. This directory contains multiple log files with a \".log\" extension. Each log file contains lines of text, and each line includes a timestamp followed by a message. Your task is to calculate the total number of unique error messages (lines containing the word \"ERROR\") across all the log files in the \"logs\" directory. Consider only lines that are distinct in content when counting unique errors.",
        "explanation": "To solve this problem, you need to perform several tasks:\n1. Navigate to the \"logs\" directory.\n2. Use `grep` to filter out lines containing the word \"ERROR\" from all \".log\" files.\n3. Use `sort` and `uniq` commands to find and count unique error messages.\n4. Print the total number of unique error messages.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep 'ERROR' *.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 10:00:00 ERROR User not found\\n2023-10-01 10:05:00 INFO User logged in\\n2023-10-01 10:10:00 ERROR User not found\" > ~/logs/file1.log\necho -e \"2023-10-02 09:00:00 ERROR Disk full\\n2023-10-02 09:05:00 WARN Low memory\\n2023-10-02 09:15:00 ERROR Disk full\" > ~/logs/file2.log\necho -e \"2023-10-03 08:30:00 ERROR Network timeout\\n2023-10-03 08:45:00 INFO Connection established\\n2023-10-03 09:00:00 ERROR Network timeout\" > ~/logs/file3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep 'ERROR' *.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named `logs` containing multiple `.log` files. Each file represents server logs for a specific day, and the entries in each file are structured with timestamps followed by error messages. Your task is to find out how many unique error messages were logged across all files in the `logs` directory during the time frame between 02:00 and 04:00 (inclusive). You should consider only the error message text for uniqueness, ignoring timestamps.",
        "explanation": "To solve this problem, you need to perform several steps:\n1. Navigate to the `logs` directory.\n2. Use a command to iterate through each `.log` file in the directory.\n3. Extract log entries that have timestamps between 02:00 and 04:00.\n4. From these entries, extract only the error message text (assuming it starts right after the timestamp).\n5. Collect all unique error messages across all files.\n6. Count how many unique error messages are present.\n\nHints:\n- You can use tools like `awk`, `grep`, or `sed` to filter lines based on timestamp and extract necessary parts of each line.\n- Use utilities like `sort` and `uniq` to handle uniqueness.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd logs\ngrep -hE '^(02|03):' *.log | awk '{sub(/^[0-9]{2}:[0-9]{2} /,\"\"); print}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p logs\necho -e \"01:30 Server started\\n02:15 Error: Disk full\\n03:00 Error: Network down\\n03:45 Error: Disk full\\n04:05 Server shutdown\" > logs/day1.log\necho -e \"02:10 Error: CPU overload\\n02:50 Error: Memory leak\\n03:30 Error: Network down\\n05:00 Maintenance completed\" > logs/day2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd logs\ngrep -hE '^(02|03):' *.log | awk '{sub(/^[0-9]{2}:[0-9]{2} /,\"\"); print}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a large log file named \"server.log\" in your home directory, which contains information about server access requests. Each line in the file follows the format: \"IP_ADDRESS - - [DATE] 'REQUEST' STATUS SIZE\". Your task is to determine how many unique IP addresses made requests to the server on the date \"15/Oct/2023\".",
        "explanation": "To solve this problem, you need to extract all lines from the log file where the date is \"15/Oct/2023\", then parse these lines to retrieve IP addresses. Finally, count the number of unique IP addresses. This can be accomplished using tools like `grep` for filtering and `awk` or `cut` for parsing, followed by `sort` and `uniq` to find unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract lines with date \"15/Oct/2023\"\ngrep '\\[15\\/Oct\\/2023\\]' ~/server.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample server.log file in the student's home directory with dummy data.\ncat <<EOL > ~/server.log\n192.168.1.1 - - [12/Oct/2023] 'GET /index.html HTTP/1.1' 200 1024\n192.168.1.2 - - [15/Oct/2023] 'GET /home HTTP/1.1' 404 512\n192.168.1.3 - - [15/Oct/2023] 'POST /api/data HTTP/1.0' 200 2048\n192.168.1.2 - - [15/Oct/2023] 'GET /about HTTP/1.0' 200 1024\n10.0.0.5 - - [13/Oct/2023] 'GET /contact HTTP/2' 200 256\n192.168.1.4 - - [15/Oct/2023] 'DELETE /old_data HTTP/1.0' 410 128\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract lines with date \"15/Oct/2023\"\ngrep '\\[15\\/Oct\\/2023\\]' ~/server.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all `.txt` files within a directory named `data`, and ensure that only non-empty lines are counted.",
        "explanation": "To solve this problem, you need to use `find` to locate all `.txt` files in the `data` directory. Then, utilize tools like `grep` or `awk` to filter out non-empty lines and count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind data -name \"*.txt\" | xargs grep -v '^$' | wc -l\n```",
        "create": {
            "init": "mkdir -p data\necho -e \"Hello\\nWorld\\n\" > data/file1.txt\necho -e \"\\nLine1\\nLine2\\n\" > data/file2.txt\necho -e \"\\n\\nLast Line\" > data/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find data -name \"*.txt\" | xargs grep -v '^$' | wc -l"
        }
    },
    {
        "description": "You are tasked with finding out how many files in your home directory are larger than 1MB. You should count the files that meet this criterion and provide the total number.",
        "explanation": "To solve this problem, you need to navigate through your home directory, examining each file's size. The command `find` can be used to filter files based on their size in bytes (1MB equals 1048576 bytes). Use `wc -l` to count the number of lines outputted by `find`, which corresponds to the number of files meeting the size requirement.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -size +1048576c | wc -l\n```",
        "create": {
            "init": "# No initialization required for this task"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -size +1048576c | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all `.log` files located in the `/var/logs` directory. You should only consider files that have been modified in the last 7 days.",
        "explanation": "To solve this problem, you need to navigate to the `/var/logs` directory and list all `.log` files that have been modified in the last 7 days. You can use `find` command with `-mtime` option to filter these files. Then, use `grep` command to search for occurrences of the word \"error\" within these files and count how many lines contain this word.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find .log files modified in the last 7 days and count lines containing 'error'\nfind /var/logs -name \"*.log\" -mtime -7 -exec grep -i 'error' {} \\; | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create /var/logs directory if it doesn't exist\nmkdir -p /var/logs\n\n# Create sample .log files with various modification dates\ntouch /var/logs/system.log\ntouch /var/logs/application.log\ntouch /var/logs/network.log\n\n# Modify some files to simulate recent changes\necho \"This is a test error line.\" >> /var/logs/system.log\necho \"Another error occurred here.\" >> /var/logs/application.log\n\n# Set modification time for testing purposes\ntouch -d \"$(date -d '3 days ago')\" /var/logs/system.log\ntouch -d \"$(date -d '10 days ago')\" /var/logs/network.log\n\n# Add more content to logs for complexity\necho \"No errors here.\" >> /var/logs/system.log\necho \"Yet another error line.\" >> /var/logs/application.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find .log files modified in the last 7 days and count lines containing 'error'\nfind /var/logs -name \"*.log\" -mtime -7 -exec grep -i 'error' {} \\; | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Your task is to count how many times the word \"ERROR\" appears across all these log files, regardless of case sensitivity.",
        "explanation": "To solve this problem, you can use the `grep` command with the `-i` option for case-insensitive search combined with `wc -l` to count occurrences. The command should be executed on each file within the \"logs\" directory and then summed up to get the total count.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'ERROR' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: All systems operational\\nERROR: Disk failure detected\\nWarning: High memory usage\\nerror: Network timeout\\nERROR: Unable to connect to database\" > ~/logs/system1.log\necho -e \"ERROR: User authentication failed\\ninfo: Scheduled maintenance\\nError: Data inconsistency found\\nerror: Configuration mismatch\" > ~/logs/system2.log\necho -e \"Notice: New software update available\\nerror: Unable to reach server\\nINFO: Backup completed successfully\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'ERROR' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple `.log` files. Each file consists of lines with timestamps and log messages. Identify the log message that appears most frequently across all files. If there's a tie, return the lexicographically smallest message. You should ignore case when counting frequency.",
        "explanation": "To solve this problem, you need to perform several tasks:\n1. Traverse the \"log_files\" directory and read each `.log` file.\n2. Extract the log messages from each line, ignoring the timestamp.\n3. Normalize the log messages by converting them to lowercase for consistent counting.\n4. Count the frequency of each normalized log message across all files.\n5. Identify the most frequently occurring log message and handle ties by selecting the lexicographically smallest message.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -hoP '(?<=\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} ).*' ~/log_files/*.log | awk '{print tolower($0)}' | sort | uniq -c | sort -k1,1nr -k2,2 | head -n1 | awk '{$1=\"\"; print substr($0,2)}'\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-10-01 10:00:00 Error loading module\\n2023-10-01 11:00:00 Connection timed out\\n2023-10-01 12:00:00 Error loading module\" > ~/log_files/system1.log\necho -e \"2023-10-02 09:30:00 User logged in\\n2023-10-02 09:45:00 Connection timed out\\n2023-10-02 10:15:00 error loading module\" > ~/log_files/system2.log\necho -e \"2023-10-03 08:20:00 Connection timed out\\n2023-10-03 08:25:00 User logged in\\n2023-10-03 08:30:00 user logged in\" > ~/log_files/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "grep -hoP '(?<=\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} ).*' ~/log_files/*.log | awk '{print tolower($0)}' | sort | uniq -c | sort -k1,1nr -k2,2 | head -n1 | awk '{$1=\"\"; print substr($0,2)}'"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with \".log\" extension. Count the total number of unique IP addresses found across all these log files.",
        "explanation": "To solve this problem, you should iterate through each log file in the \"logs\" directory, extract IP addresses using regular expressions, and then count the unique ones. You can use tools like `grep` or `awk` to find IPs, and `sort` followed by `uniq` to identify the unique ones.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/access1.log\n192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \"GET /index.html HTTP/1.0\"\n192.168.1.2 - - [10/Oct/2023:13:56:01 +0000] \"POST /form HTTP/1.0\"\n192.168.1.3 - - [10/Oct/2023:13:57:15 +0000] \"GET /images/logo.png HTTP/1.0\"\n192.168.1.2 - - [10/Oct/2023:13:58:27 +0000] \"GET /contact.html HTTP/1.0\"\nEOL\n\ncat <<EOL > ~/logs/access2.log\n192.168.1.4 - - [11/Oct/2023:14:05:21 +0000] \"GET /about.html HTTP/1.0\"\n192.168.1.5 - - [11/Oct/2023:14:06:42 +0000] \"POST /login HTTP/1.0\"\n192-168-1-6.example.com 192-168-1-7.example.com\nEOL\n\necho '192-168-2.log' > ~/logs/access3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logfiles\" in your home directory containing multiple .log files. Each .log file contains lines with timestamps and error messages. Your task is to count the total number of unique error messages that appear across all the log files. Note that an error message is considered unique if it has a different text, regardless of timestamps.",
        "explanation": "To solve this problem, you need to extract all error messages from the .log files within the \"logfiles\" directory. You can use tools like `grep` or `awk` to filter out lines that contain error messages, then process these lines to remove any timestamp information, leaving only the message text. Use commands like `sort` and `uniq` to identify and count unique messages across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'Error:' ~/logfiles/*.log | sed 's/^[^ ]* [^ ]* //' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-10-01 10:00:00 Error: File not found\\n2023-10-01 10:05:00 Error: Disk full\" > ~/logfiles/system1.log\necho -e \"2023-10-02 11:00:00 Error: Network timeout\\n2023-10-02 11:05:00 Error: File not found\" > ~/logfiles/system2.log\necho -e \"2023-10-03 09:00:00 Error: Memory leak\\n2023-10-03 09:05:00 Error: Disk full\" > ~/logfiles/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'Error:' ~/logfiles/*.log | sed 's/^[^ ]* [^ ]* //' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to find and count the number of files in your home directory that are larger than 1MB and have been modified within the last 7 days.",
        "explanation": "To solve this problem, you can use the `find` command with appropriate options to search for files in your home directory. Use `-size +1M` to filter files larger than 1MB and `-mtime -7` to filter files modified in the last 7 days. Finally, use `wc -l` to count the number of such files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -size +1M -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required as students will work directly with their home directories."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -size +1M -mtime -7 | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory that contains multiple log files with names formatted as \"log-YYYY-MM-DD.txt\". Count how many lines contain the error message \"ERROR 404\" across all these log files, and ensure the count is output as an integer.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and search through all the log files with names matching the specified pattern. Use tools like `grep` or `awk` to filter lines containing the specified error message and then count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"ERROR 404\" ~/logs/ | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"INFO: User logged in\\nERROR 404: Page not found\\nINFO: User logged out\" > ~/logs/log-2023-01-01.txt\necho \"ERROR 503: Service unavailable\\nERROR 404: Page not found\\nERROR 404: Page not found\" > ~/logs/log-2023-01-02.txt\necho \"INFO: System update\\nWARNING: Disk space low\" > ~/logs/log-2023-01-03.txt\necho \"ERROR 404: Page not found\\nERROR 500: Internal server error\\nINFO: Backup completed\" > ~/logs/log-2023-01-04.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"ERROR 404\" ~/logs/ | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logfiles\" in your home directory that contains multiple log files with the \".log\" extension. Each log file consists of lines formatted as \"[timestamp] ERROR: message\". Your task is to count the total number of \"ERROR\" messages across all log files in this directory and determine which specific hour (in 24-hour format) had the highest number of errors. Note that timestamps are formatted as \"YYYY-MM-DD HH:MM:SS\". Output the hour with the highest error count.",
        "explanation": "To solve this problem, you need to first navigate to the \"logfiles\" directory and then aggregate all lines containing \"ERROR\" messages from each \".log\" file. Extract the hour from each timestamp, accumulate the counts for each hour, and identify which hour has the highest count of errors. You can use tools like `grep`, `awk`, and `sort` along with basic shell scripting techniques to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Navigate to logfiles directory \ncd ~/logfiles || exit\n\n# Count errors per hour \ngrep 'ERROR' *.log | awk '{split($2,a,\":\"); print a[1]}' | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\ncat <<EOL > ~/logfiles/log1.log\n2023-10-01 14:23:45 ERROR: Disk space low\n2023-10-01 14:25:30 ERROR: Unable to connect to server\n2023-10-01 15:02:15 ERROR: Timeout occurred\nEOL\n\ncat <<EOL > ~/logfiles/log2.log\n2023-10-01 14:29:50 ERROR: Failed login attempt\n2023-10-01 16:12:04 ERROR: Database connection lost\n2023-10-01 16:59:59 ERROR: Error reading file\nEOL\n\ncat <<EOL > ~/logfiles/log3.log\n2023-10-01 14:32:00 ERROR: Service unavailable\n2023-10-01 17:08:22 ERROR:\n2023-10-01 17:42:19 ERROR:\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Navigate to logfiles directory \ncd ~/logfiles || exit\n\n# Count errors per hour \ngrep 'ERROR' *.log | awk '{split($2,a,\":\"); print a[1]}' | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'"
        }
    },
    {
        "description": "Find the total number of lines in all `.txt` files within your home directory that contain the word \"Linux\". Assume the search is case-sensitive.",
        "explanation": "To solve this problem, you need to use a combination of Linux utilities like `grep`, `find`, and `wc`. First, locate all `.txt` files in your home directory using `find`. Then, use `grep` to filter lines containing the word \"Linux\" from these files. Finally, count the total number of lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files and count lines containing 'Linux'\nfind ~/experiment -type f -name \"*.txt\" | xargs grep 'Linux' | wc -l\n```",
        "create": {
            "init": "# Create sample .txt files with varying content\nmkdir -p ~/experiment\necho -e \"This is a test file.\\nLinux is an operating system.\\nAnother line.\" > ~/experiment/file1.txt\necho -e \"Some random text.\\nLinux kernel is powerful.\\nText without keyword.\" > ~/experiment/file2.txt\necho -e \"Linux\\nis\\nversatile.\" > ~/experiment/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files and count lines containing 'Linux'\nfind ~/experiment -type f -name \"*.txt\" | xargs grep 'Linux' | wc -l"
        }
    },
    {
        "description": "Find and count the number of lines containing the word \"error\" across all log files in the \"/var/logs/\" directory that have been modified within the last 7 days.",
        "explanation": "To solve this problem, you need to use a combination of find, grep, and wc commands. First, utilize the find command to locate files in the \"/var/logs/\" directory that have been modified within the last 7 days. Then, employ grep to search for lines containing the word \"error\" within those files. Finally, use wc -l to count these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/logs/ -type f -mtime -7 | xargs grep -c \"error\" | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "# Create a mock /var/logs/ directory with sample log files\nmkdir -p /var/logs/\ntouch /var/logs/app.log\ntouch /var/logs/system.log\n\n# Add content to app.log\necho -e \"2023-10-01 12:00:00 error Something went wrong\\n2023-10-02 14:00:00 info All systems operational\" >> /var/logs/app.log\n\n# Add content to system.log\necho -e \"2023-10-03 09:30:00 error Disk space low\\n2023-10-04 11:45:00 warning High memory usage\" >> /var/logs/system.log\n\n# Update modification time of logs to be within last 7 days\ntouch -d \"$(date -d '7 days ago')\" /var/logs/app.log\ntouch -d \"$(date)\" /var/logs/system.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/logs/ -type f -mtime -7 | xargs grep -c \"error\" | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "Find the total number of lines that contain the word \"error\" in all \".log\" files within the \"/var/logs\" directory, and then filter out lines containing \"debug\" from those results. You should output only the total count of filtered lines.",
        "explanation": "To solve this problem, first search for lines containing the word \"error\" across all \".log\" files in the specified directory using `grep`. Then pipe these results to another `grep` command to exclude lines containing \"debug\". Finally, count and output the number of remaining lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"error\" /var/logs/*.log | grep -v \"debug\" | wc -l\n```",
        "create": {
            "init": "# Create a sample environment with .log files containing various entries\nmkdir -p /var/logs\necho -e \"error: failed to load\\ninfo: system reboot\\nerror: missing file\\ndebug: initializing service\\nerror: disk full\" > /var/logs/system.log\necho -e \"info: user login\\nerror: network unreachable\\ndebug: connection attempt\\nerror: access denied\" > /var/logs/access.log\necho -e \"warning: low memory\\ndebug: cache cleared\\ninfo: update complete\\nerror: timeout occurred\" > /var/logs/update.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"error\" /var/logs/*.log | grep -v \"debug\" | wc -l"
        }
    },
    {
        "description": "Find the total number of lines containing the word \"ERROR\" in all `.log` files within the `/var/logs` directory, and count only unique occurrences of each line across all files.",
        "explanation": "To solve this problem, you need to search for the word \"ERROR\" in each `.log` file located in the `/var/logs` directory. You can use `grep` to filter the lines containing \"ERROR\", followed by `sort` and `uniq` to ensure that each unique line is counted only once. Finally, use `wc -l` to count these unique lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"ERROR\" /var/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs\necho -e \"INFO: System started\\nERROR: Disk not found\\nERROR: Disk not found\" > /var/logs/system1.log\necho -e \"WARNING: High memory usage\\nERROR: Disk not found\\nERROR: Network failure\" > /var/logs/system2.log\necho -e \"ERROR: Network failure\\nINFO: Update complete\\nERROR: Disk not found\" > /var/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"ERROR\" /var/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines containing the word \"error\" across all log files in your home directory. Log files have the extension \".log\".",
        "explanation": "To solve this problem, you need to search through each file in your home directory that has a \".log\" extension and count the occurrences of the word \"error\". You can use tools like `grep` to find lines containing specific text and `wc` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count lines containing 'error' in all .log files within the home directory\ngrep -i error ~/test*.log | wc -l\n```",
        "create": {
            "init": "# Create sample log files in the home directory with different contents\necho -e \"This is a test log file.\\nError occurred at line 2.\\nAll systems operational.\" > ~/test1.log\necho -e \"Warning: High memory usage.\\nError: Disk space low.\\nError: Network timeout.\" > ~/test2.log\necho -e \"No issues detected.\\nBackup completed successfully.\" > ~/test3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count lines containing 'error' in all .log files within the home directory\ngrep -i error ~/test*.log | wc -l"
        }
    },
    {
        "description": "You need to find out how many files in your home directory contain the word \"Linux\" at least once, ignoring case sensitivity.",
        "explanation": "To solve this problem, you can use the `grep` command with the `-i` flag to ignore case sensitivity and recursively search through all files in your home directory. You'll also need to count the number of matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -ril \"Linux\" ~ | wc -l\n```",
        "create": {
            "init": "# No initialization required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -ril \"Linux\" ~ | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all \".log\" files located within the \"/var/logs\" directory and its subdirectories. Ensure you ignore case sensitivity when matching \"error\".",
        "explanation": "To solve this problem, you should use a combination of `find` to locate all \".log\" files within \"/var/logs\" and its subdirectories and then use `grep` with the `-i` option to perform a case-insensitive search for the word \"error\". The output from `grep` can be piped to `wc -l` to count the total number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files and count the lines containing 'error' (case-insensitive)\nfind /var/logs -type f -name \"*.log\" | xargs grep -i 'error' | wc -l\n```",
        "create": {
            "init": "# Create a sample /var/logs directory structure with some .log files for testing\nmkdir -p /var/logs/subdir1 /var/logs/subdir2\n\necho -e \"This is a test log.\\nNo errors here.\" > /var/logs/test1.log\necho -e \"Another error found.\\nYet another Error.\" > /var/logs/test2.log\necho -e \"Error occurred.\\nSome random text.\" > /var/logs/subdir1/test3.log\necho -e \"Normal operation.\\nAn ERROR appeared!\" > /var/logs/subdir2/test4.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files and count the lines containing 'error' (case-insensitive)\nfind /var/logs -type f -name \"*.log\" | xargs grep -i 'error' | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"log_files\" in your home directory, which contains multiple log files with the \".log\" extension. Each log file contains entries of various system events. Your task is to determine how many unique IP addresses are present across all the log files. Assume each log entry starts with an IP address followed by a space.",
        "explanation": "To solve this problem, you need to iterate over each \".log\" file in the \"log_files\" directory and extract the IP addresses from each line. You can use tools like `grep`, `awk`, or `sed` to process each line and extract IP addresses. After extracting these addresses, store them in a way that ensures uniqueness, such as using the `sort` and `uniq` commands, or storing them in an associative array if using a shell script.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/log_files/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"192.168.0.1 Event A\\n10.0.0.2 Event B\\n192.168.0.3 Event C\" > ~/log_files/log1.log\necho -e \"192.168.0.1 Event D\\n172.16.0.1 Event E\\n10.0.0.2 Event F\" > ~/log_files/log2.log\necho -e \"10.0.0.3 Event G\\n172.16.0.1 Event H\\n192.168.0.4 Event I\" > ~/log_files/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/log_files/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of unique words across all text files within the \"/home/student/documents\" directory and its subdirectories, ignoring case sensitivity.",
        "explanation": "To solve this problem, you need to recursively find all text files in the specified directory and read their contents. Use a combination of `find` to locate the files, `tr` to standardize case sensitivity, and `sort` with `uniq` to count unique words.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all .txt files and process them to count unique words (case insensitive)\nfind /home/student/documents -type f -name \"*.txt\" | xargs cat | tr '[:upper:]' '[:lower:]' | tr -c '[:alnum:]' '[\\n*]' | sort | uniq -c | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create directories and sample text files for testing\nmkdir -p /home/student/documents/subdir1 /home/student/documents/subdir2\n\necho \"Hello world\" > /home/student/documents/file1.txt\necho \"hello Universe\" > /home/student/documents/subdir1/file2.txt\necho \"Greetings Earth\" > /home/student/documents/subdir2/file3.txt\necho \"HELLO Mars\" > /home/student/documents/subdir1/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all .txt files and process them to count unique words (case insensitive)\nfind /home/student/documents -type f -name \"*.txt\" | xargs cat | tr '[:upper:]' '[:lower:]' | tr -c '[:alnum:]' '[\\n*]' | sort | uniq -c | wc -l"
        }
    },
    {
        "description": "You need to determine the total size of all files in your home directory that have been modified in the last 7 days. The size should be reported in human-readable format.",
        "explanation": "To solve this problem, you can use the `find` command to filter out files based on their modification time, and then pipe the output to `du` with appropriate options to calculate and display the total size. You may also use `date` command to get the current date and compute past dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -print0 | du --files0-from=- -ch | tail -n 1 | awk '{print $1}'\n```",
        "create": {
            "init": "# No initialization needed for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -print0 | du --files0-from=- -ch | tail -n 1 | awk '{print $1}'"
        }
    },
    {
        "description": "You are given a directory named \"data_logs\" in your home directory, which contains multiple log files with the extension \".log\". Your task is to count how many unique IP addresses appear across all these log files. Assume each line of a log file starts with an IP address. Provide the total count of unique IP addresses.",
        "explanation": "To solve this problem, you need to iterate over all the \".log\" files in the \"data_logs\" directory and extract the IP addresses from each line of these files. You can use tools like `awk` or `cut` to isolate the IP addresses. Once extracted, `sort` and `uniq` will be useful to identify unique IP addresses, and finally, you can use `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/data_logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/data_logs\necho -e \"192.168.1.1 - access granted\\n192.168.1.2 - access denied\\n10.0.0.1 - access granted\" > ~/data_logs/log1.log\necho -e \"192.168.1.3 - access granted\\n192.168.1.2 - access denied\\n10.0.0.2 - access granted\" > ~/data_logs/log2.log\necho -e \"172.16.0.1 - access granted\\n172.16.0.2 - access denied\\n192.168.1.3 - access granted\" > ~/data_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/data_logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"test_dir\" in your home directory containing various files and subdirectories. Your task is to count the total number of regular files (excluding directories) that end with the \".txt\" extension within \"test_dir\" and all of its subdirectories.",
        "explanation": "To solve this problem, you can use the `find` command to recursively search through \"test_dir\" for files ending with \".txt\". The `find` command can filter out directories and provide a list of matching regular files. You then need to count these files using commands like `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use find command to locate all .txt files and count them.\nfind ~/test_dir -type f -name \"*.txt\" | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/test_dir/subdir1\nmkdir -p ~/test_dir/subdir2\n\n# Create some .txt and non-.txt files\ntouch ~/test_dir/file1.txt\ntouch ~/test_dir/file2.txt\ntouch ~/test_dir/file3.doc\ntouch ~/test_dir/subdir1/file4.txt\ntouch ~/test_dir/subdir1/file5.md\ntouch ~/test_dir/subdir2/file6.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use find command to locate all .txt files and count them.\nfind ~/test_dir -type f -name \"*.txt\" | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word 'error' in all '.log' files located in the '/var/logs/' directory on your Linux system. You should only consider lines where 'error' is a standalone word, not part of another word (e.g., 'errors').",
        "explanation": "To solve this problem, you need to use tools like `grep` with appropriate options to search for standalone occurrences of the word 'error'. Using `grep -w` will help you find whole words only. You will also need to iterate over multiple files in a directory and count matching lines using tools like `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use grep with -w option to find whole words 'error'\ngrep -w 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "# Create /var/logs directory if it doesn't exist\nmkdir -p /var/logs/\n\n# Create some sample log files with varying content\necho \"This is an error message.\" > /var/logs/system.log\necho \"Something went wrong: error occured.\" >> /var/logs/system.log\necho \"All operations completed successfully.\" >> /var/logs/system.log\n\necho \"User login successful.\" > /var/logs/auth.log\necho \"Failed login attempt due to error.\" >> /var/logs/auth.log\n\necho \"error detected in process 1234\" > /var/logs/debug.log\necho \"debugging started...\" >> /var/logs/debug.log\n\n# More complex examples can be added as needed."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use grep with -w option to find whole words 'error'\ngrep -w 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.myconfig` that contains multiple lines where each line represents a key-value pair separated by an equal sign (`=`). Your task is to count the number of unique keys present in this file, ignoring any duplicate keys.",
        "explanation": "To solve the problem, you need to read the contents of the hidden `.myconfig` file, extract the keys from each line, and determine how many unique keys are present. You can achieve this by using tools like `awk` or `cut` for extracting keys and `sort` with `uniq` for finding unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract keys and count unique ones\nawk -F '=' '{print $1}' ~/.myconfig | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a .myconfig file with some key-value pairs\necho -e \"username=admin\\npassword=1234\\nemail=admin@example.com\\nusername=guest\\ntheme=dark\" > ~/.myconfig"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract keys and count unique ones\nawk -F '=' '{print $1}' ~/.myconfig | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to count the number of files in your home directory and all its subdirectories that were modified in the last 7 days. Use the `find` command to accomplish this task.",
        "explanation": "To solve this problem, you can use the `find` command to search for files based on their modification time. The `-mtime` option allows you to filter files modified within a certain number of days. For instance, `-mtime -7` will find files modified within the last 7 days. You can combine this with the `wc -l` command to count the number of lines, which corresponds to the number of files found.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization is required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple \".log\" files. Some of these files are older than 7 days, and some contain the word \"ERROR\". Count how many lines in total contain the word \"ERROR\" from files that are older than 7 days.",
        "explanation": "To solve this problem, you can use the `find` command to list files older than 7 days in the \"logs\" directory. Then, use `grep` to search for lines containing the word \"ERROR\". Finally, count these lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -mtime +7 | xargs grep -c 'ERROR' | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "mkdir -p ~/logs\ntouch ~/logs/file1.log\necho -e \"INFO: All systems go\\nERROR: Failed to load resource\\nINFO: Resource loaded successfully\" > ~/logs/file1.log\ntouch ~/logs/file2.log\necho -e \"WARNING: Low disk space\\nERROR: Unable to connect to server\\nINFO: Connection established successfully\" > ~/logs/file2.log\n# Change modification time of file1.log to be older than 7 days\ntouch -d '10 days ago' ~/logs/file1.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -mtime +7 | xargs grep -c 'ERROR' | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified within the last 7 days and are larger than 1MB.",
        "explanation": "To solve this problem, you can use the `find` command to search for files based on their modification time and size. The `-mtime` option allows you to filter files that were modified within a certain number of days, while `-size` lets you specify the minimum file size. Combine these options with logical operators to find files that meet both conditions. Finally, you can use `wc -l` to count the number of matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and have a file size larger than 100KB.",
        "explanation": "You should use `find` command to search for files in your home directory. Utilize the `-mtime` option to filter files modified within the last 7 days, and `-size` option to find files larger than 100KB. You can use the `wc -l` command to count the number of matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +100k | wc -l\n```",
        "create": {
            "init": "# No initialization is required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +100k | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all \".log\" files located within the \"/var/log\" directory and its subdirectories that contain the word \"error\", but ignore case sensitivity.",
        "explanation": "To solve this problem, you need to search through all \".log\" files in the \"/var/log\" directory and its subdirectories for lines containing the word \"error\" regardless of case. You can use tools like `grep` with appropriate options to achieve this. Make sure to count only those lines containing \"error\".\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all \".log\" files within /var/log and its subdirectories\n# Use grep to search for 'error' (case-insensitive) and count lines containing it\nfind /var/log -type f -name \"*.log\" -exec grep -i \"error\" {} + | wc -l\n```",
        "create": {
            "init": "# No specific initialization required as students will be using their own Linux system's /var/log directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all \".log\" files within /var/log and its subdirectories\n# Use grep to search for 'error' (case-insensitive) and count lines containing it\nfind /var/log -type f -name \"*.log\" -exec grep -i \"error\" {} + | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing multiple log files in the format \"logYYYYMMDD.txt\" (e.g., log20231001.txt). Your task is to count how many lines contain the word \"ERROR\" across all files in this directory. Assume you have read permission for all files.",
        "explanation": "To solve this problem, you can use the `grep` command with the `-r` option to recursively search through all files in the \"logs\" directory for lines containing the word \"ERROR\". The `wc -l` command can then be used to count these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' logs | wc -l\n```",
        "create": {
            "init": "mkdir logs\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nINFO: Scheduled maintenance\\nERROR: Network timeout\" > logs/log20231001.txt\necho -e \"INFO: Backup completed\\nERROR: Unauthorized access\\nERROR: Failed login attempt\\nINFO: Running diagnostics\" > logs/log20231002.txt\necho -e \"WARNING: High memory usage\\nINFO: Update available\\nERROR: Application crash\\nINFO: System rebooted\" > logs/log20231003.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' logs | wc -l"
        }
    },
    {
        "description": "You have a directory called \"project_files\" in your home directory, which contains various types of files (e.g., .txt, .log, .csv). Your task is to determine the total number of lines across all .txt files in this directory. However, you should exclude any lines that are blank or contain only whitespace.",
        "explanation": "To solve this problem, you need to navigate to the \"project_files\" directory and list all the .txt files. Then, for each file, you will count the lines after stripping out blank or whitespace-only lines. You can use a combination of `find`, `grep`, and `wc` commands to achieve this. The key steps include finding all the .txt files using `find`, filtering out non-blank lines using `grep -v`, and counting them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the project_files directory and count non-blank lines in all .txt files\nfind ~/project_files -name \"*.txt\" | xargs grep -v '^\\s*$' | wc -l\n```",
        "create": {
            "init": "# Create the project_files directory if it doesn't exist\nmkdir -p ~/project_files\n\n# Add example .txt files with varying content\necho -e \"Hello World\\n\\nThis is a test file.\\n\\n\" > ~/project_files/file1.txt\necho -e \"\\nAnother test file.\\nWith some content.\\n\\nAnd some more text.\" > ~/project_files/file2.txt\necho -e \"\\n\\nJust another file.\\nWith just one line here.\" > ~/project_files/file3.txt\n\n# Add other types of files which should be ignored\necho \"This is a log file.\" > ~/project_files/logfile.log\necho \"Name, Age\\nJohn Doe, 30\" > ~/project_files/data.csv"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to the project_files directory and count non-blank lines in all .txt files\nfind ~/project_files -name \"*.txt\" | xargs grep -v '^\\s*$' | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all \".log\" files located in a directory named \"logs\" within your home directory. You must ensure that subdirectories within \"logs\" are also included in your search.",
        "explanation": "To solve this problem, you should use the `grep` command to search for occurrences of the word \"error\" in all \".log\" files. The `grep` command can be combined with other utilities such as `find` to recursively search through subdirectories. The final count of lines can be obtained using the `wc -l` command, which counts the number of lines outputted by `grep`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -name \"*.log\" -exec grep -i \"error\" {} \\; | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs/subdir1\nmkdir -p ~/logs/subdir2\necho \"This is an error log.\" > ~/logs/error.log\necho \"No issues here.\" > ~/logs/normal.log\necho \"An error has occurred.\" > ~/logs/subdir1/error_sub.log\necho \"Everything is fine.\" > ~/logs/subdir2/normal_sub.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -name \"*.log\" -exec grep -i \"error\" {} \\; | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all text files located in your home directory and its subdirectories, but exclude any lines that contain the word \"error\".",
        "explanation": "To solve this problem, you need to navigate through your home directory and all its subdirectories to find and process text files. You can use tools like `find` to locate these files, and then use `grep` or `awk` to filter out lines containing the word \"error\". Finally, sum up the remaining lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example script that counts lines excluding those with 'error'\nfind ~ -type f -name \"*.txt\" | xargs grep -v 'error' | wc -l\n```",
        "create": {
            "init": "# This script creates some sample text files in the user's home directory for testing.\nmkdir -p ~/testdir/subdir\necho -e \"This is a test.\\nThis line contains error.\\nAnother line.\" > ~/testdir/file1.txt\necho -e \"Error here.\\nAll good here.\\nAnd another good line.\" > ~/testdir/file2.txt\necho -e \"Nothing wrong.\\nOops an error.\\nClear skies.\" > ~/testdir/subdir/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example script that counts lines excluding those with 'error'\nfind ~ -type f -name \"*.txt\" | xargs grep -v 'error' | wc -l"
        }
    },
    {
        "description": "Find the total number of lines across all `.txt` files in your home directory, but exclude lines that contain the word \"ERROR\". You should report just the integer count of these lines.",
        "explanation": "To solve this problem, you can use a combination of commands to search for `.txt` files and filter out lines containing \"ERROR\". First, use `find` to locate all `.txt` files in your home directory. Then, use `grep -v ERROR` to exclude those lines and `wc -l` to count the remaining lines. This requires interacting with multiple utilities and understanding how they work together.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -name \"*.txt\" | xargs grep -v 'ERROR' | wc -l\n```",
        "create": {
            "init": "# Create sample .txt files in the user's home directory for testing.\necho -e \"This is a test.\\nERROR: Something went wrong.\" > ~/file1.txt\necho -e \"All systems operational.\\nNo issues found.\" > ~/file2.txt\necho -e \"ERROR: Failed to load module.\\nProceed with caution.\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -name \"*.txt\" | xargs grep -v 'ERROR' | wc -l"
        }
    },
    {
        "description": "You have a file named \"access.log\" in your home directory, which contains Apache web server access logs. Count the number of unique IP addresses that made requests in the last 24 hours.",
        "explanation": "To solve this problem, you need to filter out logs from the last 24 hours and then extract the IP addresses from these entries. Use `grep` or `awk` to filter lines based on timestamps, and then use `cut`, `awk`, or `sed` to extract IP addresses. Finally, use `sort` and `uniq` to count unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example script to count unique IPs from the last day (assuming current date is October 11, 2023)\ngrep '11\\/Oct\\/2023' ~/access.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample access.log file with some entries\ncat > ~/access.log << EOL\n127.0.0.1 - - [10/Oct/2023:13:55:36 +0000] \"GET /index.html HTTP/1.1\" 200 2326\n192.168.1.5 - - [11/Oct/2023:08:30:22 +0000] \"POST /form HTTP/1.1\" 404 1234\n203.0.113.15 - - [11/Oct/2023:09:45:15 +0000] \"GET /about.html HTTP/1.1\" 200 1024\n198.51.100.21 - - [11/Oct/2023:10:15:00 +0000] \"PUT /update HTTP/1.1\" 500 5678\n192.168.1.5 - - [11/Oct/2023:14:02:01 +0000] \"GET /home HTTP/1.1\" 200 3456\n203.0.113.15 - - [11/Oct/2023:16:22:45 +0000] \"DELETE /remove HTTP/1.1\" 204 -\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example script to count unique IPs from the last day (assuming current date is October 11, 2023)\ngrep '11\\/Oct\\/2023' ~/access.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with \".log\" extension. Count the number of lines across all \".log\" files that contain the word \"ERROR\".",
        "explanation": "To solve this problem, you need to use command-line utilities to search for lines containing the word \"ERROR\" in all \".log\" files within the \"logs\" directory and then count them. You can use utilities like `grep` to filter out these lines and `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep ERROR ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: Starting process\\nERROR: Failed to start\\nINFO: Process completed successfully\\nERROR: Memory leak detected\" > ~/logs/system.log\necho -e \"INFO: User login\\nERROR: Password incorrect\\nINFO: User logout\\nERROR: Timeout occurred\" > ~/logs/auth.log\necho -e \"DEBUG: Initializing components\\nINFO: Components initialized successfully\\nERROR: Disk full error encountered\\nERROR: Network failure detected\" > ~/logs/application.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep ERROR ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in the `/var/log` directory that contain the word \"error\", ignoring case sensitivity.",
        "explanation": "To solve this problem, you need to search through all `.txt` files in the `/var/log` directory for lines containing the word \"error\". You can use tools such as `grep` with options to ignore case sensitivity and count matching lines, and then sum these counts across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example script to count lines containing \"error\" (case insensitive)\ngrep -i 'error' /var/log/*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample .txt log files with varying content\ntouch /var/log/sample1.txt /var/log/sample2.txt /var/log/sample3.txt\necho -e \"Error occurred\\nAll good\\nCritical error\\nWarning\" > /var/log/sample1.txt\necho -e \"No issues detected\\nERROR found\\nAnother line\" > /var/log/sample2.txt\necho -e \"Everything is fine\\nerror reported here\" > /var/log/sample3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example script to count lines containing \"error\" (case insensitive)\ngrep -i 'error' /var/log/*.txt | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple \".log\" files. Count the total number of unique IP addresses found across all these log files.",
        "explanation": "To solve this problem, you need to iterate through each \".log\" file in the \"logs\" directory and extract IP addresses using regular expressions. You can use tools like `grep`, `awk`, or `sed` to filter out IP addresses and then utilize `sort` and `uniq` to count distinct IPs.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/access1.log\n192.168.1.1 - - [10/Oct/2023:13:55:36] \"GET /index.html HTTP/1.0\" 200 2326\n192.168.1.2 - - [10/Oct/2023:13:56:36] \"POST /form HTTP/1.0\" 200 1234\n192.168.1.3 - - [10/Oct/2023:13:57:36] \"GET /about HTTP/1.0\" 404 789\nEOL\n\ncat <<EOL > ~/logs/access2.log\n192.168.1.2 - - [11/Oct/2023:14:01:36] \"GET /home HTTP/1.0\" 200 2326\n192.168.1.4 - - [11/Oct/2023:14:02:36] \"POST /login HTTP/1.0\" 401 5678\nEOL\n\ncat <<EOL > ~/logs/access3.log\n192.168.1.5 - - [12/Oct/2023:15:03:36] \"GET /contact HTTP/2.0\" 200 3456\n192.168.1.4 - - [12/Oct/2023:15:04:36] \"GET /services HTTP/2.\" 404 2345\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all `.log` files located in your home directory and its subdirectories.",
        "explanation": "To solve this problem, you need to search for the word \"error\" within all `.log` files in your home directory and its subdirectories. You can use `find` to locate these files and `grep` to search for occurrences of the word. Then, `wc -l` can be used to count the total lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files, search for 'error', and count lines containing it.\nfind ~/ -type f -name \"*.log\" -exec grep -i 'error' {} \\; | wc -l\n```",
        "create": {
            "init": "# Create some sample log files with various content in the home directory and subdirectories\nmkdir -p ~/logs/subdir1 ~/logs/subdir2\n\necho -e \"This is a test log.\\nAn error occurred here.\\nAnother line.\" > ~/logs/log1.log\necho -e \"Everything is fine.\\nNo errors.\" > ~/logs/subdir1/log2.log\necho -e \"Error found again.\\nJust another line.\" > ~/logs/subdir2/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files, search for 'error', and count lines containing it.\nfind ~/ -type f -name \"*.log\" -exec grep -i 'error' {} \\; | wc -l"
        }
    },
    {
        "description": "You need to count the total number of lines in all `.txt` files located within the `/home/student/documents` directory and its subdirectories, but only for those files that have been modified in the last 7 days.",
        "explanation": "To solve this problem, you can use the `find` command to locate `.txt` files modified within the last 7 days in the specified directory and its subdirectories. Then, use `xargs` along with `wc -l` to count the lines in these files. The key is combining these utilities to filter and process multiple files efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -name \"*.txt\" -mtime -7 | xargs wc -l | tail -n 1 | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p /home/student/documents/subdir1\nmkdir -p /home/student/documents/subdir2\necho \"This is a test file.\" > /home/student/documents/file1.txt\necho \"Another test file.\" > /home/student/documents/subdir1/file2.txt\necho \"Yet another test file.\" > /home/student/documents/subdir2/file3.txt\n\n# Set modification time of some files to within last 7 days\ntouch -mt $(date -d '6 days ago' +'%Y%m%d%H%M') /home/student/documents/file1.txt\ntouch -mt $(date -d '8 days ago' +'%Y%m%d%H%M') /home/student/documents/subdir1/file2.txt\ntouch -mt $(date +'%Y%m%d%H%M') /home/student/documents/subdir2/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -name \"*.txt\" -mtime -7 | xargs wc -l | tail -n 1 | awk '{print $1}'"
        }
    },
    {
        "description": "In your home directory, count the total number of lines that contain the word \"Linux\" across all text files (.txt) and subdirectories recursively.",
        "explanation": "You can use `grep` with recursive search enabled to find occurrences of \"Linux\" in all text files. Combine this with `wc -l` to count the lines. Consider using pipes to pass output from one command to another.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -roh 'Linux' ~/ | wc -l\n```",
        "create": {
            "init": "# Create sample text files with various content\nmkdir -p ~/testdir/subdir1 ~/testdir/subdir2\necho -e \"Linux is a kernel.\\nThere are many Linux distributions.\" > ~/testdir/file1.txt\necho -e \"The Linux operating system is popular.\\nLinux powers many servers.\" > ~/testdir/subdir1/file2.txt\necho -e \"Not every OS is Linux.\\nSome prefer Windows or macOS.\" > ~/testdir/subdir1/file3.txt\necho -e \"Why choose Linux?\\nMany reasons include its open-source nature.\" > ~/testdir/subdir2/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -roh 'Linux' ~/ | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files. Your task is to count the number of unique IP addresses present across all these log files. Each log file contains lines with an IP address at the beginning, followed by a space and some other information. Assume all IP addresses are valid IPv4 addresses.",
        "explanation": "To solve this problem, you need to read through each log file in the \"logs\" directory, extract the IP addresses from each line, and then count how many distinct IP addresses there are across all files. You can use tools like `grep` to find patterns and `awk` or `cut` to extract specific fields from text. To ensure uniqueness, you can leverage utilities such as `sort` and `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/* | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 User logged in\\n192.168.1.2 User logged out\\n192.168.1.3 Error occurred\" > ~/logs/log1.txt\necho -e \"192.168.1.2 User logged in\\n192.168.1.4 User logged out\\n192.168.1.5 Error occurred\" > ~/logs/log2.txt\necho -e \"192.168.1.3 User logged in\\n192.168.1.6 User logged out\\n192.168  user error\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/* | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named `logs` in your home directory containing multiple log files with the `.log` extension. Each log file contains lines of text, where each line represents a log entry with a timestamp in the format `YYYY-MM-DD HH:MM:SS`. Your task is to find and count all the unique dates across all log files and return the total number of unique dates.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the `logs` directory.\n2. Read each `.log` file and extract the date part (YYYY-MM-DD) from each line.\n3. Collect these dates in a set or use a command that filters out duplicates.\n4. Count the number of unique dates.\n\nHints:\n- Use tools like `awk`, `sort`, and `uniq` to process and filter data.\n- Consider redirecting outputs through pipes for efficient processing.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\ncd ~/logs\ncat *.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\nmkdir -p ~/logs\necho -e \"2023-01-01 12:00:00 Some log message\\n2023-01-02 13:00:00 Another message\" > ~/logs/log1.log\necho -e \"2023-01-02 14:00:00 More messages\\n2023-01-03 15:00:00 Different message\" > ~/logs/log2.log\necho -e \"2023-01-03 16:00:00 New day\\n2023-01-04 17:00:00 Yet another message\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\ncd ~/logs\ncat *.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing a log file named \"system.log\" located in the \"/var/logs\" directory of your Linux system. Your goal is to find out how many unique IP addresses have accessed the server. You can assume that each line in the log file contains an IP address. Count and return the number of unique IP addresses.",
        "explanation": "To solve this problem, you need to read through the \"system.log\" file, extract all the IP addresses, and then identify and count only the unique ones. You can utilize tools like `awk`, `sort`, and `uniq` to achieve this. Here’s a hint: Use `awk` to extract the IP addresses, then pipe them through `sort` and `uniq` to filter out duplicates.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract all unique IP addresses from system.log and count them.\nawk '{print $1}' /var/logs/system.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create a sample system.log file with multiple repeated IPs for testing.\nmkdir -p /var/logs\ncat <<EOL > /var/logs/system.log\n192.168.1.10 accessed at 10:00 AM\n192.168.1.11 accessed at 10:01 AM\n192.168.1.12 accessed at 10:02 AM\n192.168.1.10 accessed at 10:03 AM\n192.168.1.13 accessed at 10:04 AM\n192.168.1.11 accessed at 10:05 AM\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract all unique IP addresses from system.log and count them.\nawk '{print $1}' /var/logs/system.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Each log file contains various entries, and each entry starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to count how many entries occurred on August 15, 2023, across all these log files.",
        "explanation": "To solve this problem, you need to iterate through all the log files in the \"logs\" directory and filter out entries that match the specific date \"2023-08-15\". Use tools like `grep` to search for lines starting with this date. Finally, count these filtered lines using `wc -l` or similar utilities.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^2023\\-08\\-15' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-08-15 12:30:45 Entry1\\n2023-08-14 09:20:00 Entry2\\n2023-08-15 13:45:50 Entry3\" > ~/logs/log1.log\necho -e \"2023-08-16 10:00:00 Entry4\\n2023-08-15 11:15:30 Entry5\\n2023-08-17 17:25:10 Entry6\" > ~/logs/log2.log\necho -e \"2023-08-13 07:05:25 Entry7\\n2023-08-15 14:10:15 Entry8\\n2023-08-18 19:55:40 Entry9\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^2023\\-08\\-15' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "Count how many executable files are in the `/usr/bin` directory that contain the word \"test\" in their names.",
        "explanation": "To solve this problem, you need to list all files in the `/usr/bin` directory, filter out those that contain \"test\" in their names, and check which of them are executable. You can use utilities like `ls`, `grep`, and `find` combined with various options to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all files in /usr/bin, filter by name containing 'test', and check if they are executable\nfind /usr/bin -type f -executable -name '*test*' | wc -l\n```",
        "create": {
            "init": "# No initialization is required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# List all files in /usr/bin, filter by name containing 'test', and check if they are executable\nfind /usr/bin -type f -executable -name '*test*' | wc -l"
        }
    },
    {
        "description": "In the current directory, you will find several text files named `data1.txt`, `data2.txt`, ..., up to `data5.txt`. Each file contains a list of integers, one per line. Your task is to determine the sum of the highest integer from each file and then compare this total sum against a threshold value of 500. If the sum is greater than 500, output \"Above Threshold\", otherwise output \"Below Threshold\".",
        "explanation": "To solve this problem, you need to read each file and extract the integers. From each file, identify the maximum integer and keep a running total of these maximum values. Finally, compare the total with 500 and print \"Above Threshold\" if it's greater or \"Below Threshold\" otherwise.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract maximum from each file and sum them up:\nmax1=$(sort -nr data1.txt | head -n 1)\nmax2=$(sort -nr data2.txt | head -n 1)\nmax3=$(sort -nr data3.txt | head -n 1)\nmax4=$(sort -nr data4.txt | head -n 1)\nmax5=$(sort -nr data5.txt | head -n 1)\n\n# Calculate total sum:\ntotal_sum=$((max1 + max2 + max3 + max4 + max5))\n\n# Compare against threshold:\nif [ $total_sum -gt 500 ]; then\n    echo \"Above Threshold\"\nelse\n    echo \"Below Threshold\"\nfi\n```",
        "create": {
            "init": "echo -e \"23\\n45\\n67\\n89\\n12\" > data1.txt\necho -e \"34\\n56\\n78\\n90\\n33\" > data2.txt\necho -e \"11\\n22\\n33\\n44\\n55\" > data3.txt\necho -e \"99\\n88\\n77\\n66\\n55\" > data4.txt\necho -e \"10\\n20\\n30\\n40\\n50\" > data5.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "# Extract maximum from each file and sum them up:\nmax1=$(sort -nr data1.txt | head -n 1)\nmax2=$(sort -nr data2.txt | head -n 1)\nmax3=$(sort -nr data3.txt | head -n 1)\nmax4=$(sort -nr data4.txt | head -n 1)\nmax5=$(sort -nr data5.txt | head -n 1)\n\n# Calculate total sum:\ntotal_sum=$((max1 + max2 + max3 + max4 + max5))\n\n# Compare against threshold:\nif [ $total_sum -gt 500 ]; then\n    echo \"Above Threshold\"\nelse\n    echo \"Below Threshold\"\nfi"
        }
    },
    {
        "description": "Count the total number of lines across all text files in the directory `/home/student/data`, excluding lines that contain only whitespace.",
        "explanation": "To solve this problem, you should use a combination of commands such as `find` to locate all `.txt` files in the specified directory, and then use `grep` to filter out lines containing only whitespace. You can then use `wc -l` to count the number of lines. An example pipeline could involve these commands together with other utilities like `xargs`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Find all .txt files and count non-whitespace-only lines.\nfind /home/student/data -type f -name \"*.txt\" \\\n    | xargs grep -v '^[[:space:]]*$' \\\n    | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create the data directory and some sample text files for the students to work with.\nmkdir -p /home/student/data\necho -e \"Hello\\nworld\\n  \\nLinux\\nOperating Systems\" > /home/student/data/file1.txt\necho -e \"\\nUbuntu\\nis\\ngreat!\\n  \\n\" > /home/student/data/file2.txt\necho -e \"Shell scripting\\nis powerful.\\n  \\nLearn it!\" > /home/student/data/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Find all .txt files and count non-whitespace-only lines.\nfind /home/student/data -type f -name \"*.txt\" \\\n    | xargs grep -v '^[[:space:]]*$' \\\n    | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all `.log` files located in `/var/logs`. You must exclude any files modified within the last 24 hours.",
        "explanation": "To solve this problem, you need to filter out `.log` files that have been modified within the last 24 hours and then search for lines containing the word \"error\" in the remaining files. You can use `find` to list files based on modification time, `grep` to search for matching lines, and `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files excluding those modified in the last 24 hours, then count lines with 'error'\nfind /var/logs -name \"*.log\" ! -mtime -1 | xargs grep -i \"error\" | wc -l\n```",
        "create": {
            "init": "# Create a directory and sample log files for testing\nmkdir -p /var/logs\necho -e \"Info: System running\\nError: Disk full\\nWarning: Low memory\" > /var/logs/system.log\necho -e \"Error: Network unreachable\\nInfo: Connection established\" > /var/logs/network.log\necho -e \"Debugging error\\nError: Failed to load module\" > /var/logs/kernel.log\n\n# Set modification time for one of the logs to be within 24 hours ago\ntouch -m --date=\"1 hour ago\" /var/logs/kernel.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files excluding those modified in the last 24 hours, then count lines with 'error'\nfind /var/logs -name \"*.log\" ! -mtime -1 | xargs grep -i \"error\" | wc -l"
        }
    },
    {
        "description": "Find and count the number of unique IP addresses that have accessed the web server. The log file named \"access.log\" is located in the \"/var/logs\" directory. Assume each line in the log file starts with an IP address.",
        "explanation": "To solve this problem, you need to read the \"access.log\" file, extract the IP addresses from each line, and then find and count the number of unique IP addresses. You can use tools like `awk` or `cut` to extract IP addresses, `sort` to arrange them, and `uniq` with `wc -l` to count unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{print $1}' /var/logs/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\nmkdir -p /var/logs\ncat <<EOL > /var/logs/access.log\n192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \"GET /index.html HTTP/1.1\" 200 2326\n192.168.1.2 - - [10/Oct/2023:13:57:01 +0000] \"POST /form HTTP/1.1\" 200 1234\n192.168.1.3 - - [10/Oct/2023:14:03:15 +0000] \"GET /about.html HTTP/1.1\" 404 512\n192.168.1.2 - - [10/Oct/2023:14:07:53 +0000] \"GET /contact.html HTTP/1.1\" 200 1024\n192.168.1.4 - - [10/Oct/2023:14:09:22 +0000] \"GET /home.html HTTP/2\" 302 -\n192.168.1.5 - - [10/Oct/2023:14:11:47 +0000] \"PUT /api/data HTTP/2\" 201 -\n192.168.1.4 - - [10/Oct/2023:14:15:05 +0000] \"DELETE /api/data HTTP/2\" 200 -\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{print $1}' /var/logs/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named 'logs' containing multiple .log files. Each log file contains various system messages logged over time. Your task is to find out how many unique IP addresses have accessed the system across all these log files. You are not allowed to use any graphical tools or text editors; only command-line utilities.",
        "explanation": "To solve this problem, you can use command-line tools like `grep` to extract lines containing IP addresses from the log files, `awk` or `sed` to isolate the IP address part, and `sort` along with `uniq` to count unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"User login from 192.168.1.1\" > ~/logs/access1.log\necho \"Connection established with 10.0.0.5\" >> ~/logs/access1.log\necho \"Attempt from 172.16.0.2 failed\" > ~/logs/access2.log\necho \"User login from 192.168.1.1\" >> ~/logs/access2.log\necho \"Connection established with 10.0.0.6\" >> ~/logs/access3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in the `/etc` directory that have a `.conf` extension and were last modified more than 30 days ago.",
        "explanation": "To solve this problem, you need to list all files in the `/etc` directory, filter those with a `.conf` extension, and further filter them based on their modification time. You can use `find` command with appropriate flags to achieve this: `-name` to match file extension and `-mtime` to check modification time.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /etc -type f -name \"*.conf\" -mtime +30 | wc -l\n```",
        "create": {
            "init": "# No initialization required as we are using an existing system directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /etc -type f -name \"*.conf\" -mtime +30 | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains timestamps and error messages. Your task is to find out how many unique error messages are present across all the log files combined. Consider an error message unique if its content (excluding the timestamp) is different from others.",
        "explanation": "To solve this problem, you need to iterate over each \".log\" file in the \"log_files\" directory, extract the error messages while ignoring their timestamps, and then determine how many of these messages are unique across all files. You can use tools like `grep` or `awk` to filter out timestamps, and `sort` and `uniq` to identify unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR' ~/log_files/*.log | sed 's/^[^E]*ERROR/ERROR/' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-10-01 10:00:01 ERROR Failed to connect to server\\n2023-10-01 10:05:22 ERROR User not found\\n2023-10-01 11:00:00 ERROR Failed to connect to server\" > ~/log_files/server1.log\necho -e \"2023-10-02 12:30:15 ERROR Disk space low\\n2023-10-02 13:15:45 ERROR Failed to connect to server\\n2023-10-02 14:30:55 ERROR Network timeout\" > ~/log_files/server2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR' ~/log_files/*.log | sed 's/^[^E]*ERROR/ERROR/' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of unique words in the file named \"document.txt\" located in your home directory, ignoring case sensitivity and punctuation.",
        "explanation": "To solve this problem, you need to preprocess the text by converting all characters to lowercase and removing punctuation. Then, you can split the text into words and use a command or tool to count the unique words.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example script to count unique words\n\n# Preprocess the text: convert to lowercase and remove punctuation\ntr '[:upper:]' '[:lower:]' < ~/document.txt | tr -d '[:punct:]' | tr ' ' '\\n' | sort -u | wc -l\n```",
        "create": {
            "init": "# Create a file called \"document.txt\" in the user's home directory with sample content.\necho \"Hello, World! This is a test document. Hello again; testing, Testing: one, two, three.\" > ~/document.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example script to count unique words\n\n# Preprocess the text: convert to lowercase and remove punctuation\ntr '[:upper:]' '[:lower:]' < ~/document.txt | tr -d '[:punct:]' | tr ' ' '\\n' | sort -u | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a file named \"server_logs.txt\". The file contains multiple lines where each line represents a log entry with a timestamp followed by an error code. Count how many entries have the error code \"404\" and occurred in the month of September 2023.",
        "explanation": "To solve this problem, you need to filter out lines from the \"server_logs.txt\" file that contain both the error code \"404\" and a timestamp within September 2023. You can use tools like `grep` to search for specific patterns in the file and then count the number of matching lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '404' ~/server_logs.txt | grep '^2023-09' | wc -l\n```",
        "create": {
            "init": "echo -e \"2023-09-01T12:00:00 200\\n2023-09-05T15:30:45 404\\n2023-10-01T08:45:23 500\\n2023-09-20T21:15:10 404\\n2023-09-25T13:05:32 404\\n2023-08-30T07:15:00 404\" > ~/server_logs.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '404' ~/server_logs.txt | grep '^2023-09' | wc -l"
        }
    },
    {
        "description": "Find the total size in bytes of all text files in your home directory that have been modified within the last 7 days.",
        "explanation": "To solve this problem, you need to identify text files by their MIME type or extension, filter them based on their modification time using the `find` command, and sum up their sizes using `du` or `stat`. You can use the `date` command to get the current date and time for comparison.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find text files modified within the last 7 days and calculate their total size.\nfind ~/experiment -name \"*.txt\" -type f -mtime -7 -exec stat --format=\"%s\" {} \\; | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "# Create some sample text files with different modification times.\nmkdir -p ~/experiment\necho \"Sample content\" > ~/experiment/file1.txt\necho \"Another sample content\" > ~/experiment/file2.txt\n\n# Set random modification times for testing purposes.\ntouch -t \"$(date -d '8 days ago' +'%Y%m%d%H%M')\" ~/experiment/file1.txt\ntouch -t \"$(date -d '3 days ago' +'%Y%m%d%H%M')\" ~/experiment/file2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find text files modified within the last 7 days and calculate their total size.\nfind ~/experiment -name \"*.txt\" -type f -mtime -7 -exec stat --format=\"%s\" {} \\; | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "Count the number of lines in all `.log` files located in the `/var/logs` directory that contain the word \"ERROR\" and were modified in the last 7 days.",
        "explanation": "To solve this problem, you can use a combination of `find`, `grep`, and `wc` commands. First, use `find` to locate `.log` files modified within the last 7 days. Then, pipe these results to `grep` to filter lines containing \"ERROR\". Finally, count these lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find .log files modified within the last 7 days and count lines containing 'ERROR'\nfind /var/logs -name \"*.log\" -mtime -7 | xargs grep 'ERROR' | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create /var/logs directory if it doesn't exist\nmkdir -p /var/logs\n\n# Create sample .log files with some content\necho -e \"INFO: System started\\nERROR: Disk space low\\nINFO: Task completed\" > /var/logs/system.log\necho -e \"ERROR: Unable to connect\\nINFO: Connection established\" > /var/logs/network.log\n\n# Update modification time of files to ensure they were modified within the last 7 days\ntouch -a -m -d \"3 days ago\" /var/logs/system.log\ntouch -a -m -d \"5 days ago\" /var/logs/network.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find .log files modified within the last 7 days and count lines containing 'ERROR'\nfind /var/logs -name \"*.log\" -mtime -7 | xargs grep 'ERROR' | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing several log files with different extensions (.txt, .log, .bak). Your task is to count the number of lines that contain the word \"ERROR\" in all files with a \".log\" extension within this directory. You should then multiply this count by 2 and provide the result.",
        "explanation": "To solve this problem, first navigate to the \"logs\" directory. Use a combination of `grep` to search for lines containing the word \"ERROR\" and `wc -l` to count these lines specifically in files with a \".log\" extension. Multiply the resulting count by 2 before submitting your answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h ERROR logs/*.log | wc -l | awk '{print $1 * 2}'\n```",
        "create": {
            "init": "mkdir logs\necho -e \"INFO: System running\\nERROR: Disk full\\nINFO: User login\\nERROR: Network down\" > logs/system.log\necho -e \"INFO: Application started\\nWARNING: High memory usage\\nERROR: Failed to load module\\nINFO: Shutdown complete\" > logs/application.log\necho -e \"DEBUG: Debugging mode enabled\\nERROR: Invalid configuration\\nINFO: Configuration loaded successfully\" > logs/config.bak\necho -e \"ERROR: Unable to connect\\nINFO: Reconnect successful\\nWARNING: Low battery level\" > logs/connect.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h ERROR logs/*.log | wc -l | awk '{print $1 * 2}'"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines across all `.txt` files in your current directory and its subdirectories. Ignore any files that contain the word \"skip\" in their filenames.",
        "explanation": "To solve this problem, you need to recursively search through the current directory and all subdirectories for files with a `.txt` extension. You should then count the number of lines in these files, excluding any that have \"skip\" in their filename. Utilities like `find`, `grep`, and `wc` will be helpful for this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind . -type f -name \"*.txt\" ! -name \"*skip*\" | xargs cat | wc -l\n```",
        "create": {
            "init": "mkdir -p test_dir/subdir1\nmkdir -p test_dir/subdir2\necho -e \"Line 1\\nLine 2\\nLine 3\" > test_dir/file1.txt\necho -e \"Skip this line\\nAnother line\" > test_dir/file_skip.txt\necho -e \"Just one line\" > test_dir/subdir1/file2.txt\necho -e \"Another file's\\nFirst line\\nSecond line\" > test_dir/subdir2/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find . -type f -name \"*.txt\" ! -name \"*skip*\" | xargs cat | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"logs\" in your home directory, which contains multiple log files with extensions \".log\". Each log file records various events with timestamps. Your task is to determine how many unique IP addresses have accessed the system today by analyzing all the log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to:\n1. List all the \".log\" files in the \"logs\" directory.\n2. Extract lines from today's date from each log file.\n3. Extract IP addresses from these lines using a regular expression that matches typical IP address formats.\n4. Count and report the number of unique IP addresses.\n\nHint: You can use utilities like `grep` to filter today's logs, `awk` or `sed` to extract IPs, and `sort` and `uniq` to find unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\ntoday=$(date +\"%Y-%m-%d\")\n\n# Combine all logs for today's date into a single list of IPs\ngrep \"$today\" ~/logs/*.log | sed -E 's/.*Access from ([0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+).*/\\1/' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\nmkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 Access from 192.168.0.1\\n2023-10-01 13:00:00 Access from 192.168.0.2\\n2023-10-02 14:00:00 Access from 192.168.0.1\\n2023-10-02 15:30:00 Access from 192.168.0.3\" > ~/logs/log1.log\necho -e \"2023-10-02 16:45:00 Access from 192.168.0.4\\n2023-10-01 17:50:00 Access from 192.168.0.2\\n2023-10-02 18:20:00 Access from 192.168.0.5\" > ~/logs/log2.log\n# Adjust dates if necessary based on current date while testing."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\ntoday=$(date +\"%Y-%m-%d\")\n\n# Combine all logs for today's date into a single list of IPs\ngrep \"$today\" ~/logs/*.log | sed -E 's/.*Access from ([0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+).*/\\1/' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to find and count the number of files that have been modified in the last 7 days within the `/var/log` directory. Ensure that you only consider files and not directories, and filter out any hidden files.",
        "explanation": "To solve this problem, you can use the `find` command with appropriate options to search for files modified in the last 7 days. The `-type f` option ensures only files are considered, while `-mtime -7` specifies those modified in the last 7 days. Hidden files can be filtered using `! -name '.*'`. The final count can be obtained using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -mtime -7 ! -name '.*' | wc -l\n```",
        "create": {
            "init": "# No initialization required"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -mtime -7 ! -name '.*' | wc -l"
        }
    },
    {
        "description": "You are given a directory named `logs` containing multiple `.log` files. Each file contains various log entries, some of which include error messages labeled with the prefix \"ERROR:\". Your task is to interact with the shell to count the total number of unique error messages across all log files in the `logs` directory and submit this count.",
        "explanation": "To solve this problem, you will need to perform the following steps:\n1. Use a command to list all `.log` files in the `logs` directory.\n2. Extract lines containing \"ERROR:\" from each file.\n3. Normalize these lines (e.g., removing leading/trailing spaces, making them lowercase) to ensure uniqueness.\n4. Use a command to filter out unique error messages.\n5. Count and output the number of these unique error messages.\n\nHints:\n- You may use commands such as `grep`, `sed`, or `awk` for pattern matching and extraction.\n- Consider using pipes (`|`) and redirection (`>`, `<`) for chaining commands together.\n- Use `sort` and `uniq` commands for finding unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all .log files in the logs directory\nfind logs -type f -name \"*.log\" | while read file; do\n  # Extract lines with \"ERROR:\" and normalize them (trim spaces, lower case)\n  grep \"ERROR:\" \"$file\" | sed 's/^[ \\t]*//;s/[ \\t]*$//' | tr '[:upper:]' '[:lower:]'\ndone | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p logs\necho -e \"INFO: Starting process\\nERROR: Failed to start service\\nINFO: Process running\" > logs/log1.log\necho -e \"ERROR: Network timeout\\nINFO: Retrying connection\\nERROR: Failed to start service\" > logs/log2.log\necho -e \"WARNING: Disk space low\\nERROR: Memory leak detected\\nERROR: Failed database connection\" > logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# List all .log files in the logs directory\nfind logs -type f -name \"*.log\" | while read file; do\n  # Extract lines with \"ERROR:\" and normalize them (trim spaces, lower case)\n  grep \"ERROR:\" \"$file\" | sed 's/^[ \\t]*//;s/[ \\t]*$//' | tr '[:upper:]' '[:lower:]'\ndone | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all text files (.txt) in your home directory and its subdirectories, excluding files that are empty.",
        "explanation": "You need to find all .txt files in your home directory and its subdirectories. Then, you should count the total number of lines in these files, but exclude any file that does not contain any lines (i.e., empty files). You can use tools like `find`, `grep`, `wc`, and `xargs` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all non-empty .txt files and count their lines.\nfind ~ -type f -name \"*.txt\" ! -size 0 | xargs wc -l | grep -v total | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "# Create some example text files with varying numbers of lines in the home directory and subdirectories.\nmkdir -p ~/example_dir/subdir\necho -e \"Line 1\\nLine 2\" > ~/example_dir/file1.txt\necho \"Single line\" > ~/example_dir/file2.txt\ntouch ~/example_dir/empty_file.txt\necho -e \"Another file\\nWith multiple\\nLines\" > ~/example_dir/subdir/file3.txt\ntouch ~/example_dir/subdir/empty_file2.txt\necho \"Just one more line\" > ~/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all non-empty .txt files and count their lines.\nfind ~ -type f -name \"*.txt\" ! -size 0 | xargs wc -l | grep -v total | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple text files. Each file represents logs from different days and contains various entries, including timestamps. Your task is to count how many distinct log entries mention the word \"error\" within the last 7 days.",
        "explanation": "To solve this problem, you need to filter entries that contain the word \"error\" and were logged within the last 7 days. You can use tools like `grep` to search for entries containing \"error\" and `date` to calculate dates from the last 7 days. Combining these tools with `find`, `awk`, or `sed` will help extract and count distinct entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all unique 'error' entries in the past 7 days from all logs in the 'logs' directory.\nfind ~/logs -type f -exec grep \"error\" {} \\; | grep -E \"$(date --date='7 days ago' +'%Y-%m-%d')|$(date +'%Y-%m-%d')\" | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create logs directory in home\nmkdir -p ~/logs\n\n# Generate sample log files with varying content\ncat <<EOF > ~/logs/log1.txt\n2023-10-01 12:00:00 error Connection lost\n2023-10-02 15:45:23 info User login successful\n2023-10-03 09:30:45 error Disk space low\n2023-10-04 17:22:11 warning High CPU usage detected\nEOF\n\ncat <<EOF > ~/logs/log2.txt\n2023-10-05 13:20:30 error Unable to fetch data\n2023-10-06 08:15:50 info Backup completed successfully\n2023-10-07 14:55:33 error Timeout occurred during operation\nEOF\n\ncat <<EOF > ~/logs/log3.txt\n2023-10-05 11:42:00 error Connection lost (repeated)\n2023-10-08 16:30:45 info Scheduled maintenance started\nEOF\n\n# Note that some errors may be repeated across files or within a file."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all unique 'error' entries in the past 7 days from all logs in the 'logs' directory.\nfind ~/logs -type f -exec grep \"error\" {} \\; | grep -E \"$(date --date='7 days ago' +'%Y-%m-%d')|$(date +'%Y-%m-%d')\" | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"project_logs\" in your home directory containing multiple log files with a \".log\" extension. Each log file contains lines with timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique dates appear across all the log files in the directory.",
        "explanation": "To solve this problem, you need to extract the date part from each line of all \".log\" files in the \"project_logs\" directory, store them uniquely, and count how many unique dates there are. Consider using tools like `awk`, `sort`, and `uniq` to help with text processing.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/project_logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"2023-10-01 12:00:00\\n2023-10-02 13:45:00\\n2023-10-01 14:30:00\" > ~/project_logs/log1.log\necho -e \"2023-10-03 15:20:00\\n2023-10-04 16:15:00\\n2023-10-02 17:50:00\" > ~/project_logs/log2.log\necho -e \"2023-10-01 18:25:00\\n2023-10-03 19:40:00\\n2023-10-05 20:55:00\" > ~/project_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/project_logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing various text files with log entries. Your task is to count the total number of unique IP addresses from all log files within this directory. Assume each line in the log files contains one IP address.",
        "explanation": "To solve this problem, you need to iterate over all files in the \"logs\" directory, extract IP addresses from each file, and collect them into a set to ensure uniqueness. Finally, count the number of unique IP addresses by determining the size of this set.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat logs/* | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir logs\necho -e \"192.168.1.1\\n172.16.0.2\\n192.168.1.1\" > logs/log1.txt\necho -e \"10.0.0.3\\n172.16.0.2\\n10.0.0.4\" > logs/log2.txt\necho -e \"192.168.1.5\\n10.0.0.3\\n192.168.1.6\" > logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat logs/* | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to count the number of lines in all text files within your current directory that contain the word \"Linux\". Consider only files with the \".txt\" extension.",
        "explanation": "To solve this problem, you should first list all files with a \".txt\" extension in your current directory. Then use a command like `grep` to search for occurrences of the word \"Linux\" within these files. Finally, count the number of lines that contain this word across all relevant files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count lines containing 'Linux' in .txt files.\ngrep -i 'Linux' *.txt | wc -l\n```",
        "create": {
            "init": "# Create a few sample text files\necho -e \"Welcome to Linux\\nThis is a test file\\nLearning Linux is fun\" > file1.txt\necho -e \"Linux is powerful\\nAnother line without keyword\\nLinux again here\" > file2.txt\necho -e \"No Linux here\\nJust random text\" > file3.txt\n\n# Add some non-text files for distraction\ntouch file4.log file5.dat"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count lines containing 'Linux' in .txt files.\ngrep -i 'Linux' *.txt | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that were modified in the last 7 days and have a file size greater than 50KB.",
        "explanation": "To solve this problem, you need to list all files in your home directory, filter out those modified in the last 7 days, and check their size to ensure it is greater than 50KB. Use `find` command with appropriate options for modification time and size. You can use `wc -l` to count the filtered files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +50k | wc -l\n```",
        "create": {
            "init": "# No initialization required"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +50k | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all '.txt' files within your home directory and its subdirectories, excluding empty lines.",
        "explanation": "To solve this problem, you should recursively search for all '.txt' files starting from your home directory. For each file found, count the number of non-empty lines. Sum these counts to obtain the final result. You can use tools like `find` to locate files and `grep` or `awk` to filter out empty lines while counting.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -name '*.txt' -exec grep -v '^$' {} \\; | wc -l\n```",
        "create": {
            "init": "# No initialization required."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -name '*.txt' -exec grep -v '^$' {} \\; | wc -l"
        }
    },
    {
        "description": "In your home directory, there are multiple text files with names starting from \"log_\" containing various system logs. Filter out all lines in these files that include the word \"ERROR\" and count how many unique IP addresses appear in these error lines. You should output the final count of unique IP addresses.",
        "explanation": "To solve this problem, you need to first identify all text files starting with \"log_\" in your home directory. Then, use a combination of `grep` to filter out lines containing \"ERROR\", and `awk` or `sed` to extract IP addresses from those lines. Finally, use `sort` and `uniq` to find and count the number of unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all log files starting with 'log_' and process each file\ngrep 'ERROR' ~/log_* | awk '{for(i=1;i<=NF;i++) if ($i ~ /^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+$/) print $i}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create sample log files with various entries including some error messages with IP addresses\necho -e \"INFO: Connection established\\nERROR: Failed login attempt from 192.168.1.1\\nINFO: User logged out\" > ~/log_1.txt\necho -e \"ERROR: Timeout occurred at 10.0.0.5\\nINFO: File uploaded\\nERROR: Disk space low at 192.168.1.1\" > ~/log_2.txt\necho -e \"ERROR: Unauthorized access attempt from 172.16.0.3\\nINFO: System rebooted\" > ~/log_3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all log files starting with 'log_' and process each file\ngrep 'ERROR' ~/log_* | awk '{for(i=1;i<=NF;i++) if ($i ~ /^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+$/) print $i}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all `.txt` files located in the `/home/student/documents/` directory, including subdirectories. Only count files that contain the word \"Linux\" at least once. You must perform this task directly in the shell without writing a standalone script.",
        "explanation": "To solve this problem, you can use a combination of `find`, `grep`, and `wc` commands. First, use `find` to locate all `.txt` files within the specified directory and its subdirectories. Then, pipe these results to `xargs grep -l \"Linux\"` to filter for files containing the word \"Linux\". Finally, use `xargs wc -l` to count the lines in these filtered files. Ensure that your command handles spaces and special characters in filenames.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents/ -type f -name \"*.txt\" | xargs grep -l \"Linux\" | xargs wc -l | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "mkdir -p /home/student/documents/subdir1\nmkdir -p /home/student/documents/subdir2\n\necho -e \"Linux is great.\\nOperating systems are essential.\" > /home/student/documents/file1.txt\necho -e \"I love working with Linux.\\nIt is powerful.\" > /home/student/documents/file2.txt\necho -e \"Windows can be quite different.\" > /home/student/documents/file3.txt\n\necho -e \"The Linux kernel is open source.\\nMany developers contribute.\" > /home/student/documents/subdir1/file4.txt\necho -e \"Some prefer macOS instead of Linux.\" > /home/student/documents/subdir2/file5.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents/ -type f -name \"*.txt\" | xargs grep -l \"Linux\" | xargs wc -l | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "Count the number of lines in all `.txt` files located in the `/home/student/documents` directory that contain the word \"Linux\", ignoring case sensitivity.",
        "explanation": "To solve this problem, you need to iterate over all `.txt` files in the specified directory and use tools like `grep` to search for lines containing \"Linux\" without regard to case. You can use `wc -l` to count these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'linux' /home/student/documents/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho -e \"Linux is great.\\nI love using Linux.\\nOperating systems are fun.\" > /home/student/documents/file1.txt\necho -e \"Windows and MacOS\\nlinux kernel\\nLINUX environment variables\" > /home/student/documents/file2.txt\necho -e \"This is a text file.\\nAnother line here.\\nNo mention of linux.\" > /home/student/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'linux' /home/student/documents/*.txt | wc -l"
        }
    },
    {
        "description": "In your home directory, you will find a folder named `project_logs` containing various log files with the `.log` extension. Each log file contains timestamped entries with different status codes like `ERROR`, `WARNING`, and `INFO`. Your task is to count how many times the `ERROR` status appears across all `.log` files in the `project_logs` directory.",
        "explanation": "To solve this problem, you need to use a combination of bash commands to navigate to the `project_logs` directory, read through each `.log` file, filter out lines containing the word \"ERROR\", and count these occurrences. Use tools like `grep`, `wc`, and a loop or find command for iterating over files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/project_logs\ngrep -r \"ERROR\" *.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"2023-10-01 10:00:00 ERROR Something went wrong\\n2023-10-01 10:05:00 INFO All good\" > ~/project_logs/system1.log\necho -e \"2023-10-02 11:00:00 WARNING Check this out\\n2023-10-02 11:05:00 ERROR Failure detected\" > ~/project_logs/system2.log\necho -e \"2023-10-03 12:00:00 INFO Initialization complete\\n2023-10-03 12:30:00 ERROR An error occurred\" > ~/project_logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/project_logs\ngrep -r \"ERROR\" *.log | wc -l"
        }
    },
    {
        "description": "Find and count all unique words in the file `/home/student/words.txt`, excluding any numeric strings, and output the total count of these unique non-numeric words.",
        "explanation": "To solve this problem, you need to read the contents of `/home/student/words.txt`, filter out numeric strings, extract unique non-numeric words, and then count them. You can use utilities like `grep` to exclude numeric strings, `tr` or `awk` to split text into words, `sort` and `uniq` to find unique items, and finally `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '\\b[a-zA-Z]+\\b' /home/student/words.txt | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student\ncat <<EOF >/home/student/words.txt\nhello world 123 linux kernel 456 ubuntu 789 open source 101112 shell bash scripting python java\nEOF"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '\\b[a-zA-Z]+\\b' /home/student/words.txt | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to count the total number of lines containing the word \"error\" in all text files located within the \"/var/logs\" directory and its subdirectories. Assume all files have read permissions.",
        "explanation": "To solve this problem, you should use the `grep` command with the `-r` option to recursively search through directories. The `-c` option will help count occurrences in each file. You may then use a combination of `awk`, `sed`, or other shell utilities to sum up these counts.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count lines containing \"error\" in all text files under /var/logs and subdirectories.\ngrep -r --include \\*.log -c 'error' /var/logs | awk -F':' '{sum += $2} END {print sum}'\n```",
        "create": {
            "init": "# Create /var/logs directory and sample log files\nmkdir -p /var/logs/subdir1\nmkdir -p /var/logs/subdir2\n\n# Create some sample log files with varying content\necho -e \"info: process started\\nerror: failed to start\\nwarning: low memory\\nerror: disk full\" > /var/logs/app.log\necho -e \"debug: initializing\\ninfo: configuration loaded\\nerror: timeout occurred\" > /var/logs/subdir1/sys.log\necho -e \"info: user login successful\\nerror: unauthorized access attempt\\ninfo: session terminated\" > /var/logs/subdir2/access.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count lines containing \"error\" in all text files under /var/logs and subdirectories.\ngrep -r --include \\*.log -c 'error' /var/logs | awk -F':' '{sum += $2} END {print sum}'"
        }
    },
    {
        "description": "In your home directory, there is a file named `data.txt` containing multiple lines of text. Each line consists of an integer followed by a string. Your task is to find the sum of all integers in the file and output the result.",
        "explanation": "To solve this problem, you need to read each line from the `data.txt` file, extract the integer from each line, and compute their total sum. You can use utilities like `awk` or `cut` to help you extract and process data from each line.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{sum += $1} END {print sum}' ~/data.txt\n```",
        "create": {
            "init": "echo -e \"42 apple\\n10 banana\\n23 cherry\\n5 date\" > ~/data.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{sum += $1} END {print sum}' ~/data.txt"
        }
    },
    {
        "description": "You have been given a directory named \"log_files\" in your home directory, which contains multiple log files. Each log file uses the format \"YYYY-MM-DD_app.log\". Your task is to count the total number of lines that contain the word \"ERROR\" across all log files that were generated in September 2023.",
        "explanation": "To solve this problem, you need to navigate to the \"log_files\" directory and filter out files that match the pattern indicating they are from September 2023 (i.e., \"2023-09-??_app.log\"). You can then use tools like `grep` to search for lines containing the word \"ERROR\" and `wc -l` to count these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR' ~/log_files/2023-09-* | wc -l\n```",
        "create": {
            "init": "mkdir ~/log_files\necho -e \"INFO: All systems operational\\nERROR: Failed to start service\\nINFO: Retrying...\\nERROR: Service still not started\\nINFO: Giving up.\" > ~/log_files/2023-09-15_app.log\necho -e \"INFO: Scheduled maintenance\\nERROR: Maintenance failed\\nINFO: Rescheduling...\" > ~/log_files/2023-09-20_app.log\necho -e \"INFO: Backup completed successfully\\nERROR: Backup verification failed\" > ~/log_files/2023-09-30_app.log\necho -e \"INFO: User login successful\\nWARN: Low disk space\" > ~/log_files/2023-08-31_app.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR' ~/log_files/2023-09-* | wc -l"
        }
    },
    {
        "description": "Determine the total number of lines containing the word \"error\" in all `.log` files within the `/var/logs` directory and its subdirectories.",
        "explanation": "To solve this problem, you need to search through all `.log` files within `/var/logs` and its subdirectories for lines containing the word \"error\". You can use `find` to locate all `.log` files and then `grep` to count matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/logs -type f -name \"*.log\" -exec grep -ci error {} \\; | awk '{total += $1} END {print total}'\n```",
        "create": {
            "init": "mkdir -p /var/logs/subdir\necho -e \"This is a test log.\\nAn error occurred.\\nEverything is fine.\" > /var/logs/test1.log\necho -e \"No errors here.\\nError detected again.\" > /var/logs/test2.log\necho -e \"Random line\\nAnother error.\" > /var/logs/subdir/test3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/logs -type f -name \"*.log\" -exec grep -ci error {} \\; | awk '{total += $1} END {print total}'"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all `.log` files located in your home directory and its subdirectories. Ensure that hidden directories are also included in your search.",
        "explanation": "To solve this problem, you need to use a combination of find commands to locate all `.log` files, including those within hidden directories, and grep commands to search for lines containing the word \"error\". The wc command can then be used to count these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -name \"*.log\" | xargs grep -h 'error' | wc -l\n```",
        "create": {
            "init": "# Create sample log files with different contents\nmkdir -p ~/test_logs/.hidden_dir\necho -e \"This is a test\\nThere is an error here\\nAnother line\" > ~/test_logs/test1.log\necho -e \"Error found\\nNo issues\\nAnother error\" > ~/test_logs/test2.log\necho -e \"Everything is fine\\nNo error here\" > ~/test_logs/.hidden_dir/test3.log\necho -e \"Error again\\nFinal test error\" > ~/test_logs/.hidden_dir/test4.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -name \"*.log\" | xargs grep -h 'error' | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory, containing multiple log files with varying extensions. Your task is to count the total number of unique IP addresses across all files that have a \".log\" extension. You may assume that each line in the \".log\" files contains a valid IP address.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"logs\" directory in your home directory.\n2. Identify all files with a \".log\" extension.\n3. Extract all IP addresses from these files.\n4. Use a method to ensure only unique IP addresses are counted.\n5. Output the total count of these unique IP addresses.\n\nHints:\n- You can use tools like `grep` or `awk` to extract IP addresses.\n- Consider using `sort` and `uniq` to filter out duplicate IPs.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to logs directory\ncd ~/logs\n\n# Find all unique IPs in .log files\ngrep -hEo '([0-9]{1,3}\\.){3}[0-9]{1,3}' *.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.0.1\\n192.168.0.2\\n192.168.0.3\" > ~/logs/access1.log\necho -e \"192.168.0.2\\n192.168.0.4\\n192.168.0.5\" > ~/logs/access2.log\necho -e \"10.0.0.1\\n10.0.0.*\\n10 .  0 .  2 . 1 \\n192 .   168 . 1 .   100 \\n172 .   16 .   * \\nINVALID_IP_ADDRESS\" > ~/logs/errors.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to logs directory\ncd ~/logs\n\n# Find all unique IPs in .log files\ngrep -hEo '([0-9]{1,3}\\.){3}[0-9]{1,3}' *.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Determine the total number of lines containing the word \"error\" in all `.log` files located within your home directory, and output only this integer.",
        "explanation": "To solve this problem, you need to search for the word \"error\" within all `.log` files in your home directory. You can use the `grep` command to find occurrences of \"error,\" and then count these lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' ~/test*.log | wc -l\n```",
        "create": {
            "init": "# Create sample log files with varying contents in the user's home directory.\necho -e \"This is a test log.\\nAn error occurred.\\nProcess completed.\" > ~/test1.log\necho -e \"Starting process...\\nError detected.\\nProcess aborted.\" > ~/test2.log\necho -e \"All systems operational.\\nNo errors found here.\" > ~/test3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' ~/test*.log | wc -l"
        }
    },
    {
        "description": "Count the total number of lines of code in all Python files (.py) located in your home directory and its subdirectories, considering only files that contain the word \"import\".",
        "explanation": "To solve this problem, you need to recursively search for all Python files in your home directory and its subdirectories. You can use `find` to locate these files and `grep` to filter out files containing the word \"import\". Then, use `wc -l` to count the lines of code in each file and sum them up.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -name \"*.py\" | xargs grep -l \"import\" | xargs wc -l | awk '{total += $1} END {print total}'\n```",
        "create": {
            "init": "# Create some sample Python files in the home directory for testing\nmkdir -p ~/test_dir/subdir\necho -e \"import os\\nprint('Hello')\" > ~/test_dir/file1.py\necho -e \"# This is a comment\\nx = 5\\nimport sys\" > ~/test_dir/subdir/file2.py\necho \"print('No import here')\" > ~/test_dir/file3.py"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -name \"*.py\" | xargs grep -l \"import\" | xargs wc -l | awk '{total += $1} END {print total}'"
        }
    },
    {
        "description": "You are given a directory named `logfiles` containing multiple log files with a `.log` extension. Each log file contains records of user activities in the format \"timestamp,username,action\". Your task is to identify how many unique users have performed actions in these logs over the past 7 days from today. Output just the number of unique users.",
        "explanation": "To solve this problem, you need to filter out the records from the past 7 days based on their timestamp. Then, extract and count the distinct usernames from these records. You can use tools like `find`, `xargs`, `grep`, `awk` or `cut`, and `sort` combined with `uniq` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files within 'logfiles', filter entries from the last 7 days,\n# extract usernames and count unique ones.\nfind logfiles -name '*.log' | xargs grep \"^$(date -d '7 days ago' '+%Y-%m-%d')\".. | cut -d',' -f2 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p logfiles\n# Create sample log files with some data\necho -e \"2023-10-20,user1,login\\n2023-10-22,user2,logout\\n2023-10-24,user1,login\" > logfiles/log1.log\necho -e \"2023-10-23,user3,login\\n2023-10-21,user2,login\\n2023-10-25,user4,logout\" > logfiles/log2.log\necho -e \"2023-10-18,user5,logout\\n2023-10-19,user6,login\" > logfiles/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files within 'logfiles', filter entries from the last 7 days,\n# extract usernames and count unique ones.\nfind logfiles -name '*.log' | xargs grep \"^$(date -d '7 days ago' '+%Y-%m-%d')\".. | cut -d',' -f2 | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all `.log` files located in your home directory and its subdirectories, excluding hidden directories.",
        "explanation": "To solve this problem, you need to search for `.log` files recursively within your home directory. Use `grep` to find occurrences of the word \"error\", and then count the number of lines that contain this word. Be sure to exclude hidden directories from your search.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files excluding hidden directories and search for 'error'\nfind ~ -path ~/.hidden_logs -prune -o -name \"*.log\" -print | xargs grep -i 'error' | wc -l\n```",
        "create": {
            "init": "# Create sample log files with varying content\nmkdir -p ~/logs/subdir\necho -e \"Info: All systems go\\nError: Disk quota exceeded\" > ~/logs/system.log\necho -e \"Warning: Low memory\\nError: Out of memory\" > ~/logs/subdir/memory.log\necho -e \"Notice: Scheduled maintenance\\nError: Network unreachable\" > ~/logs/network.log\n\n# Create a hidden directory with a log file that should be ignored\nmkdir -p ~/.hidden_logs\necho -e \"Error: Unauthorized access attempt\" > ~/.hidden_logs/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files excluding hidden directories and search for 'error'\nfind ~ -path ~/.hidden_logs -prune -o -name \"*.log\" -print | xargs grep -i 'error' | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a subdirectory named \"logs\" containing multiple log files with \".log\" extensions. Count the total number of lines across all these log files that contain the word \"error\", ignoring case sensitivity.",
        "explanation": "To solve this problem, you need to navigate into the \"logs\" directory and search through all files with a \".log\" extension for lines containing the word \"error\". You can use `grep` with the `-i` option to ignore case sensitivity and combine it with `wc -l` to count the number of matching lines. Summing these counts will give you the total number of lines containing \"error\".\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"This is an error line.\\nAnother normal line.\" > ~/logs/file1.log\necho -e \"ERROR detected here.\\nNothing wrong here.\" > ~/logs/file2.log\necho -e \"No issues.\\nYet another Error!\" > ~/logs/file3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all text files in the directory `/home/student/documents`, excluding any files with names that start with 'temp' or contain the word 'backup'. You are only allowed to use bash commands and must not write any scripts.",
        "explanation": "To solve this problem, you can use a combination of `find` to locate relevant files, `grep` or `wc` to count lines, and pipes to filter and aggregate results. First, use `find` to list all text files in `/home/student/documents`, then exclude those starting with 'temp' or containing 'backup'. Finally, count lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -name \"*.txt\" ! -name \"temp*\" ! -name \"*backup*\" | xargs wc -l | grep total | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho \"This is a sample file.\" > /home/student/documents/file1.txt\necho \"Another example line.\" > /home/student/documents/file2.txt\necho \"temporary data\" > /home/student/documents/tempfile.txt\necho \"Backup information\" > /home/student/documents/backup_notes.txt\necho \"Important details\" > /home/student/documents/important_info.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -name \"*.txt\" ! -name \"temp*\" ! -name \"*backup*\" | xargs wc -l | grep total | awk '{print $1}'"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing various system log files with extensions \".log\". Your task is to find the total number of lines across all these log files which contain the word \"error\" (case insensitive). Assume there are multiple log files and their contents could be large, so efficiency is crucial.",
        "explanation": "To solve this problem, you need to perform the following steps:\n1. Navigate to the \"logs\" directory in your home folder.\n2. Use a combination of `grep` to search for lines containing \"error\" (case insensitive) in each \".log\" file.\n3. Count the number of matching lines using appropriate command-line utilities.\n4. Sum up the counts from all files to get the total number of error occurrences.\n\nHints: \n- Use `grep -i` for case-insensitive search.\n- `wc -l` can count lines.\n- Consider using `find` or `ls` to list all \".log\" files if needed, and use loops or xargs for processing multiple files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep -i 'error' *.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"This is a test log.\\nError found here.\\nAnother line.\" > ~/logs/system1.log\necho -e \"No errors here.\\nERROR detected!\\nYet another line.\" > ~/logs/system2.log\necho -e \"Everything ok.\\nAn error occurred.\\nNo issues.\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep -i 'error' *.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a file named \"server_logs.txt\" containing log entries each specifying a timestamp and a server status. Your task is to determine how many unique days are recorded in this log file. Note that the timestamps are in the format \"YYYY-MM-DD HH:MM:SS\".",
        "explanation": "To solve this problem, you need to extract the date part from each timestamp in the \"server_logs.txt\" file, filter out duplicates to find unique dates, and then count the number of these unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract dates from timestamps and count unique ones\nawk '{print $1}' ~/server_logs.txt | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample server_logs.txt with various log entries\ncat <<EOL > ~/server_logs.txt\n2023-10-01 12:00:00 Server started\n2023-10-01 12:30:00 Server running\n2023-10-02 13:00:00 Server running\n2023-10-02 14:00:00 Server stopped\n2023-10-03 15:00:00 Server maintenance\n2023-10-03 16:00:00 Maintenance completed\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract dates from timestamps and count unique ones\nawk '{print $1}' ~/server_logs.txt | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory that contains multiple log files. Each log file has lines of text, and each line contains an IP address followed by a timestamp and a message. Your task is to count how many unique IP addresses have accessed the system across all log files. Assume each line in the log files is formatted as follows: \"IP_ADDRESS TIMESTAMP MESSAGE\". You should perform this task using shell commands.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"logs\" directory.\n2. Concatenate all log files to process them together.\n3. Use `awk` or `cut` to extract the IP addresses from each line.\n4. Sort the extracted IP addresses and use `uniq` with the `-c` option to count unique occurrences.\n5. Finally, count how many unique IP addresses there are.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the logs directory\ncd ~/logs\n\n# Extract and count unique IP addresses across all logs\ncat *.txt | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a logs directory in the user's home directory\nmkdir -p ~/logs\n\n# Create sample log files with IP addresses\necho -e \"192.168.1.1 2023-10-01T12:00:00Z User login\\n192.168.1.2 2023-10-01T12:05:00Z User logout\" > ~/logs/log1.txt\necho -e \"192.168.1.1 2023-10-01T12:10:00Z User login\\n192.168.1.3 2023-10-01T12:15:00Z User access resource\" > ~/logs/log2.txt\necho -e \"192.168.1.4 2023-10-01T12:20:00Z User login\\n192.168.1.2 2023-10-01T12:25:00Z User access resource\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to the logs directory\ncd ~/logs\n\n# Extract and count unique IP addresses across all logs\ncat *.txt | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory containing multiple log files with the \".log\" extension. Each file may contain multiple lines, each line being a timestamp followed by a log message. Your task is to count how many log entries were created on the date \"2023-10-01\". The date format in the logs is \"YYYY-MM-DD\". Assume all timestamps are in UTC.",
        "explanation": "To solve this problem, you need to navigate to the \"log_files\" directory and use tools like `grep` or `awk` to filter out lines that contain the specific date \"2023-10-01\". You can then use `wc -l` to count the number of matching lines across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '2023-10-01' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-09-30 12:00:00 Log entry one\\n2023-10-01 13:45:00 Log entry two\\n2023-10-02 14:20:00 Log entry three\" > ~/log_files/log1.log\necho -e \"2023-10-01 08:15:00 Log entry four\\n2023-09-29 11:30:00 Log entry five\" > ~/log_files/log2.log\necho -e \"No logs here\\nJust some text\\nAnother line\\nAnd more text\" > ~/log_files/log3.txt\necho -e \"Random text\\n2023-10-01 23:59:59 Final log of the day\" > ~/log_files/log4.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '2023-10-01' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a directory named \"logs\" containing multiple log files with the \".log\" extension. Each file contains lines of text where each line starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Count how many lines contain the word \"ERROR\" in all the log files combined and output only this integer count.",
        "explanation": "To solve this problem, you need to navigate to your home directory and then access the \"logs\" directory. Use a command that can iterate over all \".log\" files, search for lines containing the word \"ERROR\", and count these occurrences. A useful approach is to use commands like `grep` to filter out lines with \"ERROR\" and `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Navigate to the logs directory and count lines containing 'ERROR'\ncd ~/logs\ngrep -r \"ERROR\" *.log | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create a logs directory in the student's home folder\nmkdir -p ~/logs\n\n# Create sample log files with mixed content\necho -e \"2023-12-01 10:00:00 INFO Start of log\\n2023-12-01 10:05:00 ERROR Failed to connect\\n2023-12-01 10:10:00 INFO End of log\" > ~/logs/log1.log\necho -e \"2023-12-02 11:00:00 INFO Start of log\\n2023-12-02 11:05:00 ERROR Disk full\\n2023-12-02 11:10:00 ERROR Timeout occurred\\n2023-12-02 11:15:00 INFO End of log\" > ~/logs/log2.log\necho -e \"2023-12-03 09:30:00 ERROR Network unreachable\\n2023-12-03 09:35:00 INFO Task completed successfully\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Navigate to the logs directory and count lines containing 'ERROR'\ncd ~/logs\ngrep -r \"ERROR\" *.log | wc -l"
        }
    },
    {
        "description": "You need to count the number of files in your home directory that have been modified in the last 7 days and whose names contain the string \"project\".",
        "explanation": "To solve this problem, you can use the `find` command with appropriate options. The `-mtime` option allows you to filter files based on modification time, and you can use `-name` to match filenames containing specific strings. Combine these options to find relevant files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script to count files modified in the last 7 days containing \"project\" in their name.\nfind ~/test_directory -type f -mtime -7 -name \"*project*\" | wc -l\n```",
        "create": {
            "init": "# Create sample files in the student's home directory for testing\nmkdir -p ~/test_directory\n\ntouch ~/test_directory/project1.txt\ntouch ~/test_directory/project2.txt\ntouch ~/test_directory/otherfile.txt\n\n# Modify timestamps: project1.txt has been modified within last 7 days; others not.\ntouch -m -d \"$(date)\" ~/test_directory/project1.txt\ntouch -m -d \"$(date --date='10 days ago')\" ~/test_directory/project2.txt\ntouch -m -d \"$(date --date='20 days ago')\" ~/test_directory/otherfile.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script to count files modified in the last 7 days containing \"project\" in their name.\nfind ~/test_directory -type f -mtime -7 -name \"*project*\" | wc -l"
        }
    },
    {
        "description": "You need to analyze the log files in \"/var/log/myapp\" directory. Count the number of unique IP addresses that have made requests to the server today. Assume the log entries are in the format \"YYYY-MM-DD HH:MM:SS IP_ADDRESS REQUEST_INFO\". You should only consider logs from today's date.",
        "explanation": "To solve this problem, you will need to:\n1. Identify today's date using a command like `date`.\n2. Use `grep` or `awk` to filter out log entries that match today's date.\n3. Extract IP addresses from these filtered entries.\n4. Use `sort` and `uniq` commands to find and count unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Get today's date in YYYY-MM-DD format\ntoday=$(date '+%Y-%m-%d')\n\n# Filter logs for today, extract IPs, sort them and count unique ones\ngrep \"^$today\" /var/log/myapp/access.log | awk '{print $3}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create a directory for logs if not exists\nmkdir -p /var/log/myapp\n\n# Generate sample log files with different dates and IPs for testing\necho -e \"2023-10-01 12:00:00 192.168.0.1 GET /index.html\\n2023-10-01 12:05:00 192.168.0.2 POST /submit\\n2023-10-02 13:00:00 192.168.0.1 GET /about.html\\n$(date '+%Y-%m-%d %H:%M:%S') 192.168.0.3 GET /contact.html\" > /var/log/myapp/access.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Get today's date in YYYY-MM-DD format\ntoday=$(date '+%Y-%m-%d')\n\n# Filter logs for today, extract IPs, sort them and count unique ones\ngrep \"^$today\" /var/log/myapp/access.log | awk '{print $3}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to count the number of lines in all `.txt` files within your home directory that contain the word \"Linux\", regardless of case sensitivity.",
        "explanation": "To solve this problem, you can use a combination of `grep` to search for the word \"Linux\" case-insensitively and `wc -l` to count the number of lines. First, locate all `.txt` files within your home directory using `find`. Then, apply `grep -i \"Linux\"` on each file to filter lines containing the word \"Linux\". The output from `grep` can be piped into `wc -l` to get the final count.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\ngrep -i \"Linux\" ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Create some sample .txt files in the home directory for testing\necho -e \"Welcome to Linux\\nThis is a test file\\nLINUX is powerful\" > ~/file1.txt\necho -e \"Another Linux file\\nlinux is everywhere\\nNo match here\" > ~/file2.txt\necho -e \"Just another line\\nWithout Linux mention\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\ngrep -i \"Linux\" ~/file*.txt | wc -l"
        }
    },
    {
        "description": "You are required to find the total number of lines across all `.txt` files in a directory named `documents` located in your home directory. The `documents` directory contains subdirectories and you should include files from these subdirectories as well. Ensure that only `.txt` files are counted, and symbolic links should not be followed.",
        "explanation": "To solve this problem, you need to navigate through the `documents` directory and its subdirectories, identifying all `.txt` files. You can use the `find` command to locate these files, combined with options to ensure symbolic links are not followed. Then, use tools like `wc -l` to count the lines in each file and sum them up to get the total number of lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/documents -type f -name \"*.txt\" ! -type l | xargs wc -l | grep total | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p ~/documents/subdir1 ~/documents/subdir2\necho \"Line 1\" > ~/documents/file1.txt\necho -e \"Line 1\\nLine 2\" > ~/documents/file2.txt\necho \"This is a test.\" > ~/documents/subdir1/file3.txt\necho -e \"Hello\\nWorld\" > ~/documents/subdir2/file4.txt\nln -s ~/documents/file1.txt ~/documents/link_to_file1.txt # Symbolic link should be ignored.\ntouch ~/documents/file5.md # This is a markdown file and should not be counted."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/documents -type f -name \"*.txt\" ! -type l | xargs wc -l | grep total | awk '{print $1}'"
        }
    },
    {
        "description": "In your home directory, you will find a folder called 'logs' containing multiple log files named 'access.log', 'error.log', and others. Count how many unique IP addresses have accessed the system according to the 'access.log' file.",
        "explanation": "You can use tools like `awk` or `grep` to extract the IP addresses from the 'access.log' file, then use `sort` and `uniq` to count unique occurrences. The IP addresses are typically found at the beginning of each line in an access log.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{print $1}' ~/logs/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/access.log\n192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \"GET /index.html HTTP/1.0\" 200 2326\n192.168.1.2 - - [10/Oct/2023:14:55:36 +0000] \"GET /about.html HTTP/1.0\" 200 1234\n192.168.1.3 - - [10/Oct/2023:15:55:36 +0000] \"GET /contact.html HTTP/1.0\" 404 5678\n192.168.1.1 - - [11/Oct/2023:16:55:36 +0000] \"POST /form HTTP/1.0\" 200 3456\n192.168.1.4 - - [12/Oct/2023:17:55:36 +0000] \"GET /home HTTP/1.0\" 200 7890\nEOL\n\ncat <<EOL > ~/logs/error.log\n[Wed Oct 11 16:32:20 2023] [error] [client 192.168.1.x] File does not exist:\n[Wed Oct 12 17:45:00 2023] [error] [client unknown] Failed opening required:\nEOL\n\n# Additional log files can be added here if needed."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{print $1}' ~/logs/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked to find out the total number of lines across all `.txt` files located in your home directory, but only count lines that contain the word \"Linux\". You should also ensure that empty lines are not counted.",
        "explanation": "To solve this problem, you will need to use a combination of `grep` to search for the word \"Linux\" and exclude empty lines, then use `wc -l` to count the number of lines. You might want to use a loop or find command to handle multiple `.txt` files in your home directory.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files and filter lines containing 'Linux', excluding empty lines, then count them.\nfind ~ -name \"*.txt\" -exec grep -v \"^$\" {} \\; | grep \"Linux\" | wc -l\n```",
        "create": {
            "init": "# Create sample .txt files with varied content\necho -e \"Linux is great\\nWelcome\\n\\nLinux OS\\n\" > ~/file1.txt\necho -e \"Operating systems\\nare cool\\nLinux kernel\\n\" > ~/file2.txt\necho -e \"\\nThis is a test file\\nLinux distributions vary\\n\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files and filter lines containing 'Linux', excluding empty lines, then count them.\nfind ~ -name \"*.txt\" -exec grep -v \"^$\" {} \\; | grep \"Linux\" | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all .txt files in your home directory that contain the word \"Linux\".",
        "explanation": "To solve this problem, you need to search through each .txt file in your home directory for lines containing the word \"Linux\". You can use tools like `grep` to filter and count these lines. This task requires iterating over multiple files and aggregating results.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count lines containing 'Linux' across all .txt files in home directory\ngrep -i \"Linux\" ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample text files in the user's home directory\necho -e \"This is Linux\\nAnother line\" > ~/file1.txt\necho -e \"No mention here\\nLinux is great\" > ~/file2.txt\necho -e \"Just a Linux line\\nAnother one\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count lines containing 'Linux' across all .txt files in home directory\ngrep -i \"Linux\" ~/file*.txt | wc -l"
        }
    },
    {
        "description": "Count how many unique words are present in all text files within the \"documents\" directory located in your home directory, ignoring case sensitivity.",
        "explanation": "To solve this problem, you need to find all text files within the \"documents\" directory and read their contents. Convert all words to lowercase to ensure case insensitivity, then extract and count unique words across all files. Consider using tools like `find`, `tr`, `sort`, and `uniq` in combination.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/documents -type f -name \"*.txt\" -exec cat {} + | tr '[:upper:]' '[:lower:]' | tr -cs 'a-z' '\\n' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/documents\ncat <<EOL > ~/documents/file1.txt\nHello world! This is a test file.\nEOL\n\ncat <<EOL > ~/documents/file2.txt\nAnother test document with WORDS and more words.\nEOL\n\ncat <<EOL > ~/documents/file3.txt\nHELLO again, world. Testing uniqueness of Words here.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/documents -type f -name \"*.txt\" -exec cat {} + | tr '[:upper:]' '[:lower:]' | tr -cs 'a-z' '\\n' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all `.log` files located in your home directory and output the total count.",
        "explanation": "To solve this problem, you need to search recursively for `.log` files within your home directory, then use tools like `grep` to count lines containing the word \"error\". You can combine `find`, `grep`, and `wc -l` commands to achieve this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -name \"*.log\" -exec grep -i 'error' {} \\; | wc -l\n```",
        "create": {
            "init": "# Create sample log files with some lines containing \"error\"\nmkdir -p ~/logs\necho -e \"This is a test log.\\nNo errors here.\" > ~/logs/test1.log\necho -e \"Error occurred at line 1.\\nAnother error here.\" > ~/logs/test2.log\necho -e \"All operations successful.\\nNo errors found.\" > ~/logs/test3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -name \"*.log\" -exec grep -i 'error' {} \\; | wc -l"
        }
    },
    {
        "description": "In your home directory, find all files that have been modified in the last 7 days and contain the word \"TODO\" within them. Count how many such files exist and provide the total number as your answer.",
        "explanation": "You can solve this problem by using the `find` command to locate files modified within the last 7 days in your home directory. Then, use `grep` to search for the word \"TODO\" within these files. Counting these matches will give you the answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all files modified in last 7 days containing \"TODO\"\nfind ~ -type f -mtime -7 | xargs grep -l \"TODO\" | wc -l\n```",
        "create": {
            "init": "# Create sample files in the home directory for testing\nmkdir -p ~/test_files\necho \"This is a test file with a TODO item.\" > ~/test_files/file1.txt\necho \"No todo here.\" > ~/test_files/file2.txt\necho \"Another file with TODO item.\" > ~/test_files/file3.txt\n\n# Set modification time of a couple of files to within last 7 days\ntouch -d '2 days ago' ~/test_files/file1.txt\ntouch -d '10 days ago' ~/test_files/file2.txt\ntouch -d '5 days ago' ~/test_files/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all files modified in last 7 days containing \"TODO\"\nfind ~ -type f -mtime -7 | xargs grep -l \"TODO\" | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and contain the word \"TODO\" within them.",
        "explanation": "To solve this problem, you need to first list all files in your home directory and check their modification dates. You can use the `find` command with the `-mtime` option to filter files modified in the last 7 days. Then, use `grep` or similar tools to search for occurrences of the word \"TODO\" within these files. Finally, count how many such files exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 -exec grep -l \"TODO\" {} \\; | wc -l\n```",
        "create": {
            "init": "# Create some test files with various modification dates and contents.\ntouch ~/testfile1.txt\necho \"This is a TODO task.\" > ~/testfile1.txt\n\ntouch ~/testfile2.txt\necho \"No tasks here.\" > ~/testfile2.txt\n\n# Modify file dates: testfile1 modified recently, testfile2 not.\ntouch -d '3 days ago' ~/testfile1.txt\ntouch -d '10 days ago' ~/testfile2.txt\n\n# Add more files for testing.\necho \"Yet another TODO note.\" > ~/recent_todo.txt\ntouch -d '5 days ago' ~/recent_todo.txt\n\necho \"Old TODO task.\" > ~/old_todo.txt\ntouch -d '15 days ago' ~/old_todo.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 -exec grep -l \"TODO\" {} \\; | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named \".secret_numbers\" containing integers separated by new lines. Count how many of these integers are prime numbers.",
        "explanation": "To solve this problem, you need to read the contents of the hidden file \".secret_numbers\" in your home directory, iterate over each integer, check if it is a prime number, and count the total number of prime numbers. A prime number is an integer greater than 1 that has no divisors other than 1 and itself. You can use utilities like `cat`, `grep`, or `awk` to read and process the file contents, and implement a logic to determine if a number is prime.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Initialize a counter for prime numbers\nprime_count=0\n\n# Function to check if a number is prime\nis_prime() {\n  local num=$1\n  if (( num <= 1 )); then return 1; fi\n  for (( i=2; i*i<=num; i++ )); do\n    if (( num % i == 0 )); then return 1; fi\n  done\n  return 0\n}\n\n# Read each line from the .secret_numbers file and count primes\nwhile read -r number; do\n  if is_prime \"$number\"; then\n    ((prime_count++))\n  fi\ndone < ~/.secret_numbers\n\n# Output the count of prime numbers as result for evaluation \necho $prime_count\n```",
        "create": {
            "init": "# Create the .secret_numbers file in the home directory with random integers\necho -e \"2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\" > ~/.secret_numbers"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Initialize a counter for prime numbers\nprime_count=0\n\n# Function to check if a number is prime\nis_prime() {\n  local num=$1\n  if (( num <= 1 )); then return 1; fi\n  for (( i=2; i*i<=num; i++ )); do\n    if (( num % i == 0 )); then return 1; fi\n  done\n  return 0\n}\n\n# Read each line from the .secret_numbers file and count primes\nwhile read -r number; do\n  if is_prime \"$number\"; then\n    ((prime_count++))\n  fi\ndone < ~/.secret_numbers\n\n# Output the count of prime numbers as result for evaluation \necho $prime_count"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and contain the word \"TODO\" within them. Ensure that you do not count directories or symbolic links.",
        "explanation": "To solve this problem, you need to first filter files in your home directory based on their modification time using the `find` command with the `-mtime` option. Then, for each file found, use a command like `grep` to check if the content contains the word \"TODO\". Finally, count how many such files exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all regular files in home directory modified in last 7 days containing \"TODO\"\nfind ~ -type f -mtime -7 | xargs grep -l \"TODO\" | wc -l\n```",
        "create": {
            "init": "# Create sample files and directories for testing\nmkdir -p ~/test_files\necho \"TODO: This is a task\" > ~/test_files/file1.txt\necho \"This is just a note\" > ~/test_files/file2.txt\necho \"Another TODO item\" > ~/test_files/file3.txt\n\n# Set modification times for test purposes\ntouch -mt 202310250000 ~/test_files/file1.txt # Modified 5 days ago\ntouch -mt 202310200000 ~/test_files/file2.txt # Modified more than 7 days ago\ntouch -mt 202310260000 ~/test_files/file3.txt # Modified recently\n\nln -s ~/test_files/file1.txt ~/test_files/link_to_file1 # Create a symbolic link"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all regular files in home directory modified in last 7 days containing \"TODO\"\nfind ~ -type f -mtime -7 | xargs grep -l \"TODO\" | wc -l"
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all text files within the current directory and its subdirectories, ignoring case.",
        "explanation": "To solve this problem, you need to search through all text files in the current directory and its subdirectories. Use a combination of `find`, `grep`, and `wc` commands. The `find` command will help locate all `.txt` files, while `grep` can be used with the `-i` option to ignore case when searching for \"error\". Finally, use `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind . -type f -name \"*.txt\" | xargs grep -i \"error\" | wc -l\n```",
        "create": {
            "init": "# Create some sample directories and text files for testing\nmkdir -p test_dir/subdir\necho -e \"This is an error.\\nAnother line.\" > test_dir/file1.txt\necho -e \"Everything is fine.\\nNo error here.\" > test_dir/subdir/file2.txt\necho -e \"ERROR occurred.\\nCheck this line.\" > test_dir/subdir/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find . -type f -name \"*.txt\" | xargs grep -i \"error\" | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that were modified in the last 7 days and are larger than 1MB.",
        "explanation": "To solve this problem, you need to use `find` command to search for files based on modification time and size. The `-mtime` option can be used to specify files modified within the last 7 days, and `-size` option to filter files larger than 1MB. You will also need to count the resulting files using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the number of unique IP addresses that have accessed a web server. The access logs are located in the file `/var/log/access.log`. Each line in this file contains an IP address, followed by other details. You need to count how many distinct IP addresses are present in the log file.",
        "explanation": "To solve this problem, you can use tools like `cut` to extract the IP address from each line, `sort` to organize them, and `uniq` to filter out duplicates. Finally, you can use `wc -l` to count the number of unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract and count unique IP addresses from access.log\ncut -d' ' -f1 /var/log/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample access log file for testing\necho -e \"192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \\\"GET / HTTP/1.1\\\" 200 612\\n192.168.1.2 - - [10/Oct/2023:13:56:00 +0000] \\\"GET / HTTP/1.1\\\" 200 612\\n192.168.1.3 - - [10/Oct/2023:13:57:20 +0000] \\\"POST /login HTTP/1.1\\\" 302 0\\n192.168.1.2 - - [10/Oct/2023:14:00:01 +0000] \\\"GET / HTTP/1.1\\\" 200 612\" > /var/log/access.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract and count unique IP addresses from access.log\ncut -d' ' -f1 /var/log/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines that contain the word \"error\" in all `.log` files located in the `/var/logs` directory on your Linux system. You should ignore case sensitivity when counting occurrences.",
        "explanation": "To solve this problem, you need to search through all files with a `.log` extension in the `/var/logs` directory. Use a command that searches for the keyword \"error\" without considering case sensitivity. Count each line where \"error\" appears, and then sum these counts across all `.log` files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create /var/logs directory if it does not exist\nmkdir -p /var/logs\n\n# Create sample log files with some lines containing the word \"error\"\necho -e \"This is a test log\\nError occurred here\\nAll systems go\\nERROR detected again\" > /var/logs/sample1.log\necho -e \"No issues found\\nThis line has an error\\nAnother ERROR in logs\" > /var/logs/sample2.log\necho -e \"Everything fine\\nAn error might occur here soon\\nNothing else to report\" > /var/logs/sample3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there are several text files with random names. Some of these files contain numbers on each line. Count the total number of lines across all files that contain the number \"42\" and output that count.",
        "explanation": "To solve this problem, you need to search through all text files in your home directory for lines containing the number \"42\". You can use tools like `grep` to filter these lines and then use `wc -l` to count them. Note that the files might have different extensions, so ensure you include only text files in your search.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find and count lines containing '42' in text files in home directory\ngrep -r '42' ~/*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample text files with random names\necho -e \"42\\n56\\n78\" > ~/random1.txt\necho -e \"23\\n42\\n89\" > ~/random2.txt\necho -e \"90\\n12\\n34\" > ~/random3.txt\necho -e \"42\\n42\\n42\" > ~/random4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find and count lines containing '42' in text files in home directory\ngrep -r '42' ~/*.txt | wc -l"
        }
    },
    {
        "description": "Count how many files in your home directory have the \".txt\" extension and contain the word \"Linux\" at least once. You need to consider both hidden and visible files.",
        "explanation": "To solve this problem, you should first navigate to your home directory, then use a combination of commands like `find` to locate all \".txt\" files, and `grep` to search for the word \"Linux\" within those files. Ensure that you include hidden files by using appropriate options in the `find` command.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -name \"*.txt\" -exec grep -l \"Linux\" {} \\; | wc -l\n```",
        "create": {
            "init": "touch ~/example1.txt\necho \"This is a file about Linux.\" > ~/example1.txt\n\ntouch ~/example2.txt\necho \"No mention of the keyword here.\" > ~/example2.txt\n\ntouch ~/.hidden_example3.txt\necho \"Another hidden Linux reference.\" > ~/.hidden_example3.txt\n\ntouch ~/.hidden_example4.txt\necho \"Just some random text.\" > ~/.hidden_example4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -name \"*.txt\" -exec grep -l \"Linux\" {} \\; | wc -l"
        }
    },
    {
        "description": "You have a directory named \"project_logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains error messages, warnings, and regular information logs. Your task is to count the total number of lines that contain the word \"ERROR\" (case-sensitive) across all these log files and provide the count as your answer.",
        "explanation": "To solve this problem, you can use a combination of shell commands such as `grep` to search for lines containing \"ERROR\", and then use `wc -l` to count the number of matching lines. You need to ensure that you only consider files with a \".log\" extension in the specified directory.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/project_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"INFO: System started\\nERROR: Failed to load module\\nWARNING: Low memory\\nERROR: Disk not found\" > ~/project_logs/log1.log\necho -e \"INFO: Connection established\\nINFO: User logged in\\nERROR: Timeout occurred\\nERROR: Invalid input\" > ~/project_logs/log2.log\necho -e \"WARNING: Configuration deprecated\\nINFO: Update completed\\nERROR: Out of memory\" > ~/project_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/project_logs/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_files\" located in your home directory. This directory contains various files of different types and extensions. Your task is to find out how many unique file extensions are present in this directory, ignoring any hidden files (those starting with a dot). Output the number of unique file extensions.",
        "explanation": "To solve this problem, you should first list all files in the \"project_files\" directory while excluding hidden files. Then extract the file extensions, which are the characters following the last dot in the filename. Use a combination of `find`, `awk`, or similar tools to gather these extensions and finally determine how many unique ones exist using `sort` and `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all non-hidden files and extract their extensions, then count unique ones.\nfind ~/project_files -type f ! -name '.*' | awk -F '.' '{if (NF>1) print $NF}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_files\ntouch ~/project_files/file1.txt\ntouch ~/project_files/file2.log\ntouch ~/project_files/image.jpg\ntouch ~/project_files/archive.tar.gz\ntouch ~/project_files/.hiddenfile\ntouch ~/project_files/script.sh"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# List all non-hidden files and extract their extensions, then count unique ones.\nfind ~/project_files -type f ! -name '.*' | awk -F '.' '{if (NF>1) print $NF}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all text files in your home directory that contain the word \"Linux\" (case-insensitive).",
        "explanation": "To solve this problem, you need to search for the word \"Linux\" in a case-insensitive manner across all text files within your home directory. You can use tools like `grep` with appropriate flags to perform a recursive search, and then count the lines that match. Ensure you handle hidden files and directories appropriately.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example script that counts lines containing 'Linux' in all text files in home directory.\ngrep -iR 'Linux' ~ --include=\"*.txt\" | wc -l\n```",
        "create": {
            "init": "# Create some sample text files in the home directory for testing.\necho -e \"This is a Linux system.\\nLearning about operating systems.\" > ~/file1.txt\necho -e \"LINUX powers many servers.\\nIt's used worldwide.\" > ~/file2.txt\necho -e \"Unix-like OS include Linux.\\nOpen-source software is key.\" > ~/file3.txt\n# Add some hidden files with relevant content.\nmkdir ~/hidden_dir\necho -e \"Hidden treasures of Linux.\\nInvisible information.\" > ~/hidden_dir/.hidden_file.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example script that counts lines containing 'Linux' in all text files in home directory.\ngrep -iR 'Linux' ~ --include=\"*.txt\" | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with the extension \".log\". Each log file records several events, and each event is timestamped in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to calculate how many unique dates are present across all log files in the \"logs\" directory. Assume that the date format within each log file is consistent and follows the specified format.",
        "explanation": "To solve this problem, you need to extract dates from each line of every log file in the \"logs\" directory. Consider using tools like `awk` or `sed` to parse out just the date portion (YYYY-MM-DD) from each line. Then, collect all these dates into a list and use another tool like `sort` with `uniq` to filter out unique dates, counting them afterward.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -name \"*.log\" | xargs awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 Event A\\n2023-10-01 13:00:00 Event B\\n2023-10-02 14:30:00 Event C\" > ~/logs/log1.log\necho -e \"2023-10-01 15:30:00 Event D\\n2023-10-03 16:45:00 Event E\\n2023-10-03 17:50:00 Event F\" > ~/logs/log2.log\necho -e \"2023-09-30 18:20:00 Event G\\n2023-09-29 19:25:00 Event H\\n2023-09-29 20:30:00 Event I\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -name \"*.log\" | xargs awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Find the number of files in your home directory that were last modified more than 7 days ago, and have a size greater than 50KB.",
        "explanation": "To solve this problem, you can use the `find` command to search for files based on their modification time and size. The `-mtime` option can be used to specify files modified more than a certain number of days ago, and the `-size` option allows filtering by file size. Combine these options to locate the files that fulfill both conditions. You will need to count the number of matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/test_files\nfind . -type f -mtime +7 -size +50k | wc -l\n```",
        "create": {
            "init": "# Create some sample files in the home directory with varying modification times and sizes for testing.\nmkdir -p ~/test_files\ncd ~/test_files\n\n# Create files with different modification times and sizes\ntouch -d '10 days ago' file1.txt\necho \"This is a test file.\" > file1.txt\n\ntouch -d '5 days ago' file2.txt\ndd if=/dev/zero of=file2.txt bs=1K count=60\n\ntouch -d '20 days ago' file3.txt\ndd if=/dev/zero of=file3.txt bs=1K count=100\n\ntouch -d '8 days ago' file4.txt\ndd if=/dev/zero of=file4.txt bs=1K count=30\n\ntouch -d '15 days ago' file5.txt\ndd if=/dev/zero of=file5.txt bs=1K count=200"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/test_files\nfind . -type f -mtime +7 -size +50k | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple log files with various extensions. Count the total number of lines across all files with a \".log\" extension and report the sum.",
        "explanation": "To solve this problem, you need to navigate to the \"log_files\" directory and use shell commands to filter out only files with the \".log\" extension. Then, by using tools like `wc -l`, count the number of lines in each of these files and sum them up to get the total count.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/log_files -type f -name \"*.log\" | xargs wc -l | grep total | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"Error: Missing file\\nWarning: Low disk space\\nError: Out of memory\" > ~/log_files/system.log\necho -e \"Info: User login\\nInfo: File saved\\nError: Permission denied\" > ~/log_files/user_activity.log\necho -e \"Debug: Checking network\\nDebug: Network stable\" > ~/log_files/network_debug.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/log_files -type f -name \"*.log\" | xargs wc -l | grep total | awk '{print $1}'"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all `.log` files located in the `/var/logs/` directory, excluding files that are larger than 5MB.",
        "explanation": "To solve this problem, you need to navigate to the `/var/logs/` directory and filter out the `.log` files larger than 5MB. Then, you should search for occurrences of the word \"error\" in each of the remaining `.log` files and count the total number of lines containing this term across all these files. You can use utilities such as `find`, `xargs`, `grep`, and `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/logs/ -type f -name \"*.log\" ! -size +5M | xargs grep -i \"error\" | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs/\necho -e \"This is a test log.\\nNo error here.\\nAnother line without error.\" > /var/logs/test1.log\necho -e \"Error found.\\nStill an error.\\nYet another error line.\" > /var/logs/test2.log\ndd if=/dev/zero of=/var/logs/bigfile.log bs=1M count=6\ndd if=/dev/zero of=/var/logs/smallfile.log bs=1M count=4\necho -e \"Error should not be counted from bigfile.log.\" >> /var/logs/bigfile.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/logs/ -type f -name \"*.log\" ! -size +5M | xargs grep -i \"error\" | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Each file logs events in the format \"YYYY-MM-DD HH:MM:SS Event_Message\". Your task is to find out how many unique dates are logged across all these files. Assume that each log file contains entries for multiple dates, and some dates may be repeated across different files.",
        "explanation": "To solve this problem, you need to read through all the \".log\" files in the \"logs\" directory, extract the date part from each log entry, and determine how many unique dates appear across all files. You can use tools like `awk` or `sed` to extract the date portion from each line and `sort` alongside `uniq` to count distinct entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 12:00:00 User logged in\\n2023-01-02 13:30:00 User logged out\" > ~/logs/log1.log\necho -e \"2023-01-02 15:45:00 System rebooted\\n2023-01-03 16:20:00 User logged in\" > ~/logs/log2.log\necho -e \"2023-01-03 17:50:00 Disk check started\\n2023-01-04 18:25:00 Disk check completed\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, find all files that have been modified in the last 7 days and are larger than 1MB. Count how many such files exist.",
        "explanation": "To solve this problem, use the `find` command to search for files in your home directory based on the modification time and size criteria. You can use options like `-mtime -7` to find files modified within the last 7 days and `-size +1M` to filter files larger than 1MB. Finally, use `wc -l` to count the number of lines returned by `find`, which corresponds to the number of matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# Since no specific file setup is needed, this is empty."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the `.log` extension. Each log file contains timestamped entries. Your task is to find out which file has the highest number of entries for a specific date, \"2023-10-15\". You should count only unique timestamps for that day.",
        "explanation": "To solve this problem, you need to iterate over each `.log` file in the \"logs\" directory, extract entries for the specified date \"2023-10-15\", and count unique timestamps. Finally, determine which file has the most unique entries for that date.\n\nYou can use this command pattern to perform the task:\n\n```bash\nmax_entries=0\nmax_file=\"\"\nfor file in ~/logs/*.log; do \n    count=$(grep \"^2023\\-10\\-15\" \"$file\" | awk '{print $2}' | sort | uniq | wc -l)\n    if [ \"$count\" -gt \"$max_entries\" ]; then \n        max_entries=$count \n        max_file=$(basename \"$file\")\n    fi \ndone \n\necho $max_file # Output will be \"log2.log\"\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/log1.log\n2023-10-14 08:00:00 Event A\n2023-10-15 09:00:00 Event B\n2023-10-15 09:30:00 Event C\n2023-10-15 09:30:00 Event D\n2023-10-16 10:00:00 Event E\nEOL\n\ncat <<EOL > ~/logs/log2.log\n2023-10-13 07:45:00 Event F\n2023-10-15 08:45:00 Event G\n2023-10-15 09:15:00 Event H\n2023-10-15 09:45:00 Event I\n2023-10-15 09:45:00 Event J\nEOL\n\ncat <<EOL > ~/logs/log3.log\n2023-10-12 06:30:00 Event K\n2023-10-14 07:50:00 Event L \nEOL\n\n# Add more log files as needed to increase complexity."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "max_entries=0\nmax_file=\"\"\nfor file in ~/logs/*.log; do \n    count=$(grep \"^2023\\-10\\-15\" \"$file\" | awk '{print $2}' | sort | uniq | wc -l)\n    if [ \"$count\" -gt \"$max_entries\" ]; then \n        max_entries=$count \n        max_file=$(basename \"$file\")\n    fi \ndone \n\necho $max_file # Output will be \"log2.log\""
        }
    },
    {
        "description": "Count the number of lines containing the word \"error\" in all \".log\" files within your home directory and its subdirectories, where the lines must be case-insensitive.",
        "explanation": "To solve this problem, you need to recursively search for all \".log\" files starting from your home directory. Use a combination of \"find\", \"grep\", and other utilities to count the occurrences of the word \"error\" in a case-insensitive manner across these files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -name \"*.log\" -exec grep -i 'error' {} \\; | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"Error occurred\\nAll good\\nAnother error\" > ~/logs/app1.log\necho -e \"Everything is fine\\nERROR detected\\nMinor issue\" > ~/logs/app2.log\nmkdir -p ~/logs/subdir\necho -e \"No issues here\\nError found again\\nCritical Error\" > ~/logs/subdir/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -name \"*.log\" -exec grep -i 'error' {} \\; | wc -l"
        }
    },
    {
        "description": "You need to determine the total number of lines that contain the word \"error\" in all `.log` files located in your home directory, excluding any files named `ignore.log`.",
        "explanation": "To solve this problem, you can use a combination of utilities such as `grep` and `wc`. First, use `find` to locate all `.log` files within your home directory. Then, filter out the file named `ignore.log`. Next, use `grep` to search for the word \"error\" in each remaining file and pipe the output into `wc -l` to count the total lines containing \"error\".\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files except ignore.log and count lines containing 'error'\nfind ~ -maxdepth 1 -type f -name \"*.log\" ! -name \"ignore.log\" | xargs grep -i 'error' | wc -l\n```",
        "create": {
            "init": "# Create sample .log files in the user's home directory\necho -e \"Error: Something went wrong\\nInfo: All systems go\\nWarning: Low battery\" > ~/file1.log\necho -e \"Info: Startup complete\\nError: Failed to load module\\nError: Disk full\" > ~/file2.log\necho -e \"Debug: Starting process\\nError: Network unreachable\" > ~/file3.log\necho -e \"Error: Unauthorized access attempt\\nInfo: User logged out\" > ~/ignore.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files except ignore.log and count lines containing 'error'\nfind ~ -maxdepth 1 -type f -name \"*.log\" ! -name \"ignore.log\" | xargs grep -i 'error' | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all text files within your home directory that contain the word \"Linux\" and were modified within the last 7 days.",
        "explanation": "To solve this problem, you need to perform multiple tasks: First, filter out text files within your home directory. Then, check each file's modification date to ensure it's within the last 7 days. Finally, go through each file and count the lines that contain the word \"Linux\". You can use utilities like `find` to identify files based on modification time, `grep` for searching specific words in files, and `wc -l` for counting lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all text files modified in the last 7 days and containing \"Linux\"\nfind ~ -type f -name \"*.txt\" -mtime -7 | xargs grep -i \"Linux\" | wc -l\n```",
        "create": {
            "init": "# Create some sample text files in the home directory for testing\necho -e \"This is a test file.\\nLinux is an operating system.\" > ~/file1.txt\necho -e \"Another file with Linux mentioned.\\nJust a random line.\" > ~/file2.txt\necho -e \"No mention here.\\nStill a test file.\" > ~/file3.txt\n\n# Modify timestamps to simulate recent modification\ntouch -d '5 days ago' ~/file1.txt\ntouch -d '2 days ago' ~/file2.txt\ntouch -d '10 days ago' ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all text files modified in the last 7 days and containing \"Linux\"\nfind ~ -type f -name \"*.txt\" -mtime -7 | xargs grep -i \"Linux\" | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days and contain the word \"Linux\" within their contents.",
        "explanation": "To solve this problem, you need to first identify files in your home directory that were modified within the last 7 days. You can use the `find` command with appropriate options to filter these files based on their modification time. Then, for each file found, use `grep` to check if the word \"Linux\" is present within its contents. Finally, count how many such files are there.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution that counts files modified in last 7 days containing \"Linux\"\nfind ~ -type f -mtime -7 | xargs grep -l 'Linux' | wc -l\n```",
        "create": {
            "init": "# Create sample files in the user's home directory for testing purposes\nmkdir -p ~/test_files\necho \"This is a Linux file.\" > ~/test_files/file1.txt\necho \"No mention of Linux here.\" > ~/test_files/file2.txt\necho \"Another file mentioning Linux.\" > ~/test_files/file3.txt\ntouch -d '8 days ago' ~/test_files/old_file.txt # This file should not be counted\n\n# Move all test files into the home directory for students to work on\nmv ~/test_files/* ~/\nrm -rf ~/test_files"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution that counts files modified in last 7 days containing \"Linux\"\nfind ~ -type f -mtime -7 | xargs grep -l 'Linux' | wc -l"
        }
    },
    {
        "description": "Count the number of lines in each \".txt\" file within the \"/home/student/documents\" directory that contain the word \"Linux\", and return the total count across all files.",
        "explanation": "To solve this problem, you should iterate over each \".txt\" file in the specified directory, search for lines containing the word \"Linux\", and count those lines. Finally, sum up the counts from all files to obtain the total.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'Linux' /home/student/documents/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho -e \"Linux is great.\\nI love Linux.\\nWelcome to Ubuntu.\" > /home/student/documents/file1.txt\necho -e \"This is a test file.\\nLinux is powerful.\\nAnother Linux line.\" > /home/student/documents/file2.txt\necho -e \"No mention here.\\nNothing about Linux.\" > /home/student/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'Linux' /home/student/documents/*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that were modified within the last 7 days and have a file size greater than 1MB.",
        "explanation": "To solve this problem, you need to navigate to your home directory and use a combination of shell commands to list files, filter them based on modification date, and their file size. You can use `find` command with appropriate options like `-mtime`, `-size`, and other necessary flags to achieve this. An example approach would involve using `find` to locate files modified within the last 7 days, then further filter those results for files larger than 1MB.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "In your home directory, there's a file named \"processes.txt\" which contains a list of process IDs (one per line). Your task is to filter out and count how many of these processes are currently running on the system.",
        "explanation": "To solve this problem, you need to loop through each process ID listed in the \"processes.txt\" file and check if it corresponds to a currently running process using tools like `ps` or `grep`. Count the number of process IDs that are found to be active.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script.\ncount=0\nwhile read pid; do\n  if ps -p $pid > /dev/null 2>&1; then\n    ((count++))\n  fi\ndone < ~/processes.txt\necho $count\n```",
        "create": {
            "init": "# Create a file named \"processes.txt\" in the user's home directory with sample data.\necho -e \"1234\\n5678\\n91011\\n121314\\n151617\" > ~/processes.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script.\ncount=0\nwhile read pid; do\n  if ps -p $pid > /dev/null 2>&1; then\n    ((count++))\n  fi\ndone < ~/processes.txt\necho $count"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"project_logs\" containing several log files with the \".log\" extension. Each log file contains multiple lines of text. Your task is to find out how many lines contain the word \"ERROR\" (case-sensitive) across all these \".log\" files in the \"project_logs\" directory.",
        "explanation": "To solve this problem, you need to iterate over each \".log\" file in the \"project_logs\" directory, search for lines containing the word \"ERROR\", and count those lines. You can use tools like `grep` to filter lines and `wc` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR' ~/project_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"INFO: Process started\\nERROR: Failed to load module\\nINFO: Module loaded successfully\\nERROR: Timeout occurred\" > ~/project_logs/log1.log\necho -e \"DEBUG: Starting service\\nERROR: Service failed to start\\nINFO: Service started successfully\\nWARNING: Low disk space\" > ~/project_logs/log2.log\necho -e \"INFO: Connection established\\nERROR: Connection lost\\nDEBUG: Retrying connection\\nINFO: Connection successful\" > ~/project_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR' ~/project_logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all text files located in the \"documents\" directory whose names contain the word \"report\" and were last modified within the past 30 days.",
        "explanation": "To solve this problem, you need to navigate to the \"documents\" directory, filter out files containing \"report\" in their name, and check their modification date. You can use `find` with options for filtering by name and modification date. After locating these files, use `wc -l` to count the number of lines in each file and sum them up.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind documents -name '*report*.txt' -mtime -30 | xargs wc -l | tail -n1 | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p documents\ntouch documents/report_1.txt\ntouch documents/report_2.txt\ntouch documents/summary_report.txt\ntouch documents/old_report.txt\n\n# Modify dates so that only 'report_1.txt' and 'summary_report.txt' are updated within 30 days.\ntouch -d \"$(date +'%Y-%m-%d' -d '-7 days')\" documents/report_1.txt\ntouch -d \"$(date +'%Y-%m-%d' -d '-25 days')\" documents/summary_report.txt\n\n# Add content to files for line counting.\necho -e \"Line 1\\nLine 2\\nLine 3\" > documents/report_1.txt\necho -e \"Line 1\\nLine 2\" > documents/summary_report.txt\necho -e \"Old line 1\\nOld line 2\\nOld line 3\\nOld line 4\" > documents/old_report.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find documents -name '*report*.txt' -mtime -30 | xargs wc -l | tail -n1 | awk '{print $1}'"
        }
    },
    {
        "description": "Count the number of files in your home directory that were modified in the last 7 days and have a size greater than 1MB. Do not include hidden files.",
        "explanation": "To solve this problem, you need to use the `find` command to filter out files based on their modification time and size. The `-mtime` option can be used to specify files modified within a certain number of days, while the `-size` option filters by file size. You can combine these options with logical operators to create complex queries. Hidden files (those starting with a dot) can be excluded by using appropriate pathname patterns.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 -size +1M ! -name \".*\" | wc -l\n```",
        "create": {
            "init": "# This script is empty because no special initialization is required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 -size +1M ! -name \".*\" | wc -l"
        }
    },
    {
        "description": "Count how many files in your home directory have the \".txt\" extension, and contain the word \"Linux\" at least once.",
        "explanation": "To solve this problem, you need to first list all files in your home directory with a \".txt\" extension. Then, check each file for the presence of the word \"Linux\". You can use tools like `grep` to search within files. The final count should be the number of files that meet these criteria.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files and count those containing the word \"Linux\"\ngrep -l 'Linux' ~/*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample .txt files in the student's home directory\necho 'Hello Linux' > ~/file1.txt\necho 'This is a test file' > ~/file2.txt\necho 'Linux operating system' > ~/file3.txt\necho 'Another example file' > ~/example.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files and count those containing the word \"Linux\"\ngrep -l 'Linux' ~/*.txt | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your current working directory. The directory contains multiple text files with server log entries in the format \"YYYY-MM-DD HH:MM:SS [LOG_LEVEL] message\". Your task is to determine how many unique dates are present across all log files within this directory that have at least one log entry with a \"[ERROR]\" level.",
        "explanation": "To solve this problem, you need to:\n1. Traverse through all the files in the \"log_files\" directory.\n2. Extract lines containing \"[ERROR]\" and note their date component (the first 10 characters).\n3. Collect these dates into a set to ensure uniqueness.\n4. Count the number of unique dates and output that count.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '\\[ERROR\\]' log_files/* | cut -d' ' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p log_files\necho -e \"2023-01-01 12:00:00 [INFO] Server started\\n2023-01-01 13:00:00 [ERROR] Failed to connect\\n2023-01-02 14:00:00 [WARN] Low memory\" > log_files/log1.txt\necho -e \"2023-01-03 15:00:00 [INFO] User login\\n2023-01-03 16:30:45 [ERROR] Disk full\\n2023-01-04 17:20:35 [ERROR] Service crashed\" > log_files/log2.txt\necho -e \"2023-01-04 18:45:22 [INFO] Backup complete\\n2023-01-05 19:55:33 [WARN] High CPU usage\" > log_files/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '\\[ERROR\\]' log_files/* | cut -d' ' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there are multiple text files with different extensions. Count how many lines contain the word \"error\" (case-insensitive) across all these text files and provide the total count.",
        "explanation": "To solve this problem, you need to search for the word \"error\" within each file in your home directory that has a `.txt` extension. You can use tools like `grep` to accomplish this task across multiple files efficiently. The key is to ensure that the search is case-insensitive and that you sum up all the occurrences from each file.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use grep to count lines containing 'error' across all .txt files in the home directory\ngrep -i 'error' ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample text files in the user's home directory for testing\necho -e \"This is an Error.\\nNo issues here.\" > ~/file1.txt\necho -e \"Something went wrong.\\nAn error occurred!\" > ~/file2.txt\necho -e \"Error: File not found.\\nEverything is fine.\" > ~/file3.txt\necho -e \"All systems operational.\\nNo ERROR detected.\" > ~/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use grep to count lines containing 'error' across all .txt files in the home directory\ngrep -i 'error' ~/file*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of lines in all text files (*.txt) within your home directory that contain the word \"Linux\" (case-sensitive).",
        "explanation": "To solve the problem, you can use the `grep` command to search for the word \"Linux\" in each text file and count the occurrences. You should iterate over all text files in your home directory using a loop or find command, and aggregate the count of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count lines containing 'Linux' in all .txt files within home directory.\ngrep -r 'Linux' ~/ | grep '.txt:' | wc -l\n```",
        "create": {
            "init": "# Creating sample text files with varying content\nmkdir -p ~/sample_texts\necho -e \"This is a Linux operating system.\\nWelcome to Linux tutorial.\" > ~/sample_texts/file1.txt\necho -e \"Learning about Linux.\\nLinux is powerful.\" > ~/sample_texts/file2.txt\necho -e \"Other content here.\\nNo mention of Linux.\" > ~/sample_texts/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count lines containing 'Linux' in all .txt files within home directory.\ngrep -r 'Linux' ~/ | grep '.txt:' | wc -l"
        }
    },
    {
        "description": "You have a directory named \"project_logs\" in your home directory containing multiple log files. Each log file has entries in the format \"[timestamp] [log_level] [message]\". Your task is to find out how many times the log level \"ERROR\" appears across all the files in this directory. Note that you should only count unique error messages, meaning if an identical error message appears multiple times, it should only be counted once.",
        "explanation": "To solve this problem, you need to list all files in the \"project_logs\" directory and then extract lines containing the log level \"ERROR\". After retrieving these lines, you need to filter out unique messages associated with the \"ERROR\" log level and finally count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h 'ERROR' ~/project_logs/*.txt | awk '{$1=$2=\"\"; print $0}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\ncat <<EOL > ~/project_logs/log1.txt\n[2023-10-01 10:00:00] INFO Starting process\n[2023-10-01 11:00:00] ERROR Failed to connect to database\n[2023-10-01 12:00:00] WARNING Disk space low\n[2023-10-01 13:00:00] ERROR Failed to connect to database\nEOL\n\ncat <<EOL > ~/project_logs/log2.txt\n[2023-10-02 09:30:00] INFO Process completed successfully\n[2023-10-02 10:15:00] ERROR Network timeout occurred\n[2023-10-02 11:45:00] ERROR Failed to connect to database\nEOL\n\ncat <<EOL > ~/project_logs/log3.txt\n[2023-10-03 08:20:00] WARNING Memory usage high\n[2023-10-03 09:05:00] ERROR Out of memory error occurred \n[2023-10-03 09:50:00] ERROR Network timeout occurred \nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h 'ERROR' ~/project_logs/*.txt | awk '{$1=$2=\"\"; print $0}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to count the number of regular files in your home directory that have been modified within the last 7 days and whose size is greater than 1MB.",
        "explanation": "To solve this problem, you can use the `find` command to search for files based on modification time (`-mtime`) and size (`-size`). The `-type f` option ensures that only regular files are considered. You will need to specify the parameters for modification time being less than or equal to 7 days ago and file size being greater than 1MB. The output should be filtered to show only the count of such files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# Create some sample files in the home directory for testing\ntouch ~/file1.txt\ntouch ~/file2.txt\ndd if=/dev/zero of=~/largefile1.txt bs=1M count=2\ndd if=/dev/zero of=~/largefile2.txt bs=1M count=3\n\n# Modify dates for testing purposes\ntouch -mt $(date -d '8 days ago' +%m%d%H%M) ~/file1.txt\ntouch -mt $(date -d '2 days ago' +%m%d%H%M) ~/largefile1.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "In your home directory, there are several text files. Count the total number of lines across all text files that contain the word \"error\".",
        "explanation": "You can solve this problem by using `grep` to search for the word \"error\" and then use `wc` to count the lines. First, locate all text files in your home directory using a pattern like '*.txt', then apply `grep` with the '-i' flag for case-insensitive matching across these files, and use `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\ngrep -i \"error\" ~/file*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample text files for testing in home directory\necho -e \"This is an error line.\\nThis is another line.\" > ~/file1.txt\necho -e \"Error occurred here.\\nNo issues here.\" > ~/file2.txt\necho -e \"Everything looks good.\\nError found again.\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\ngrep -i \"error\" ~/file*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days. Only consider regular files, ignoring directories and symbolic links.",
        "explanation": "To solve this problem, students need to list all regular files in their home directory and filter out those modified within the last 7 days. The `find` command can be used with the `-type f` option to ensure only regular files are considered, along with the `-mtime` option to specify modification time.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind \"$HOME\" -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# This script is empty as no initialization is required."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find \"$HOME\" -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You need to count the number of files in your home directory that contain the word \"Linux\" in their content, regardless of file type, and exclude any hidden files (those starting with a dot).",
        "explanation": "To solve this problem, you can use the 'grep' command to search for the word \"Linux\" within files. You can also use 'find' to list all non-hidden files in your home directory and then filter them using 'grep'. Remember to exclude hidden files by adjusting the find command options.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# First, find all non-hidden files in the home directory.\n# Then, use grep to search those files for the word \"Linux\".\nfind ~ -type f ! -name \".*\" -exec grep -l \"Linux\" {} + | wc -l\n```",
        "create": {
            "init": "# No initialization required as students will use their own home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# First, find all non-hidden files in the home directory.\n# Then, use grep to search those files for the word \"Linux\".\nfind ~ -type f ! -name \".*\" -exec grep -l \"Linux\" {} + | wc -l"
        }
    },
    {
        "description": "You need to count the total number of lines across all `.txt` files present in the `/home/student/documents` directory and its subdirectories, but only include files that contain the word \"Linux\" at least once.",
        "explanation": "To solve this problem, you can use the `find` command to locate all `.txt` files in the specified directory and its subdirectories. Then, use `grep` to check if each file contains the word \"Linux\". If a file contains \"Linux\", use `wc -l` to count the lines in that file. Finally, sum up all line counts from these filtered files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files containing 'Linux' and count total lines.\nfind /home/student/documents -type f -name \"*.txt\" | while read file; do \n  if grep -q 'Linux' \"$file\"; then \n    wc -l < \"$file\"\n  fi \ndone | awk '{sum+=$1} END {print sum}'\n```",
        "create": {
            "init": "# Create directories and sample .txt files for testing.\nmkdir -p /home/student/documents/subdir1\nmkdir -p /home/student/documents/subdir2\n\n# Create sample .txt files with varying content.\necho -e \"Hello Linux\\nWelcome to Ubuntu.\" > /home/student/documents/file1.txt\necho -e \"This is a test file.\\nJust some random text.\" > /home/student/documents/file2.txt\necho -e \"Another Linux line.\\nAnd another one.\" > /home/student/documents/subdir1/file3.txt\necho -e \"No mention of Linux here.\" > /home/student/documents/subdir2/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files containing 'Linux' and count total lines.\nfind /home/student/documents -type f -name \"*.txt\" | while read file; do \n  if grep -q 'Linux' \"$file\"; then \n    wc -l < \"$file\"\n  fi \ndone | awk '{sum+=$1} END {print sum}'"
        }
    },
    {
        "description": "You are given a directory named \"project_files\" in your home directory, which contains various subdirectories and files. Some of these files have the \".log\" extension. Your task is to find all the \".log\" files and calculate their total combined line count. Provide the total number of lines as your answer.",
        "explanation": "To solve this problem, you need to navigate through the \"project_files\" directory and its subdirectories to locate all files with a \".log\" extension. You can use commands like `find` to list these files and then utilize `wc -l` to count the number of lines in each file. Summing up these counts will give you the total line count.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/project_files -type f -name \"*.log\" | xargs wc -l | grep total | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p ~/project_files/subdir1\nmkdir -p ~/project_files/subdir2\n\necho -e \"Log entry 1\\nLog entry 2\\nLog entry 3\" > ~/project_files/log1.log\necho -e \"Another log entry\" > ~/project_files/log2.log\necho -e \"Subdirectory log entry 1\\nSubdirectory log entry 2\" > ~/project_files/subdir1/log3.log\necho -e \"More logs here\\nEven more logs\" > ~/project_files/subdir2/log4.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/project_files -type f -name \"*.log\" | xargs wc -l | grep total | awk '{print $1}'"
        }
    },
    {
        "description": "You are tasked with determining the total number of lines of code (LOC) in all Python files within a specific directory, including its subdirectories. The directory is named \"project\" and is located in your home directory. Your goal is to count only the non-empty lines that are not comments (assuming comments start with '#').",
        "explanation": "To solve this problem, you need to recursively search for all Python files (*.py) within the \"project\" directory. For each file, read its contents and filter out empty lines and those starting with a '#' character. Finally, count the remaining lines to get the total LOC.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/project -name \"*.py\" | xargs cat | grep -v '^\\s*$' | grep -v '^\\s*#' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project/subdir\necho -e \"# This is a comment\\n\\nprint('Hello World')\\n# Another comment\\nprint('Another line')\" > ~/project/script1.py\necho -e \"import os\\n# Comment line\\ndef foo():\\n    pass\\n\\nfoo()\" > ~/project/subdir/script2.py\necho -e \"\\n# Just a comment line\\n\" > ~/project/subdir/empty_script.py"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/project -name \"*.py\" | xargs cat | grep -v '^\\s*$' | grep -v '^\\s*#' | wc -l"
        }
    },
    {
        "description": "You have a directory called \"logs\" in your home directory containing multiple log files with the extension \".log\". Each log file contains timestamped entries. Your task is to count how many unique IP addresses appear across all log files for the date \"2023-10-01\".",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"logs\" directory.\n2. Use a combination of `grep` to filter out lines from the logs that match the date \"2023-10-01\".\n3. Extract IP addresses from these lines using tools like `awk`, `sed`, or `cut`.\n4. Use `sort` and `uniq` to deduplicate IP addresses.\n5. Count the number of unique IPs using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep '2023-10-01' *.log | awk '{print $NF}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 192.168.1.1\\n2023-10-01 13:00:00 192.168.1.2\\n2023-10-02 14:00:00 192.168.1.1\" > ~/logs/log1.log\necho -e \"2023-10-01 15:30:00 192.168.1.3\\n2023-10-03 16:45:00 192.168.1.4\\n2023-10-01 17:50:00 192.168.1.2\" > ~/logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep '2023-10-01' *.log | awk '{print $NF}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that have been modified in the last 7 days. Ignore directories and hidden files.",
        "explanation": "To solve this problem, you can use the `find` command which is very powerful for file searching based on specific criteria. You need to specify your home directory as the search path and use the `-type f` option to ensure only files are considered (and not directories). Moreover, you can use the `-mtime` option with a negative number to find files modified within the last 7 days. Hidden files can be ignored by excluding those that start with a dot.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 ! -name \".*\" | wc -l\n```",
        "create": {
            "init": "# No initialization required, assuming students have some files in their home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 ! -name \".*\" | wc -l"
        }
    },
    {
        "description": "Count the total number of files (excluding directories) in your home directory that have been modified within the last 7 days.",
        "explanation": "To solve this problem, you can use the `find` command to search for files in your home directory with modification times within the last 7 days. Use `-type f` to exclude directories from the count and `-mtime -7` to filter based on modification time. You can then use `wc -l` to count the number of lines returned, which corresponds to the number of files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No specific initialization is required as students will work within their existing home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You have a directory named \"project_files\" in your home directory containing multiple text files. Each file contains various lines of text with different lengths. Your task is to identify the longest line across all files in this directory and return its length in characters.",
        "explanation": "To solve this problem, you will need to iterate through all the files in the \"project_files\" directory, read each line from these files, determine the length of each line, and track the longest one encountered. You can use a combination of bash utilities such as `find`, `xargs`, `wc`, and `awk` to accomplish this. Consider using a loop or command substitution for efficient processing.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/project_files -type f -exec cat {} + | awk '{ if (length > max) max = length } END { print max }'\n```",
        "create": {
            "init": "mkdir -p ~/project_files\necho -e \"This is a sample text file.\\nIt contains several lines.\\nThe lines vary in length.\" > ~/project_files/file1.txt\necho -e \"Here is another file.\\nIt also has multiple lines,\\nbut which line is the longest?\" > ~/project_files/file2.txt\necho -e \"Sometimes lines are short,\\nsometimes they are unexpectedly long!\" > ~/project_files/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/project_files -type f -exec cat {} + | awk '{ if (length > max) max = length } END { print max }'"
        }
    },
    {
        "description": "In your home directory, there is a file named `system_logs.txt` which contains logs of various system events, each event on a new line and each line follows the format: `YYYY-MM-DD HH:MM:SS [EVENT_TYPE] Description of the event`. You need to count how many \"ERROR\" events occurred on the most recent day in the log file. Assume the log is sorted chronologically.",
        "explanation": "To solve this problem, you should first identify the date of the last event in the `system_logs.txt` file by reading its last line. Then, filter out all lines that contain \"ERROR\" for this specific date and count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Get the most recent date from the last line of system_logs.txt\nrecent_date=$(tail -n 1 ~/system_logs.txt | awk '{print $1}')\n\n# Count how many ERROR events occurred on that date\ngrep \"$recent_date\" ~/system_logs.txt | grep \"\\[ERROR\\]\" | wc -l\n```",
        "create": {
            "init": "cat <<EOL > ~/system_logs.txt\n2023-10-01 12:34:56 [INFO] System started.\n2023-10-01 13:00:00 [ERROR] Disk not found.\n2023-10-02 14:20:00 [WARNING] High memory usage.\n2023-10-02 15:30:45 [ERROR] Network timeout.\n2023-10-03 16:45:12 [INFO] System check complete.\n2023-10-03 18:22:33 [ERROR] Failed to connect to server.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Get the most recent date from the last line of system_logs.txt\nrecent_date=$(tail -n 1 ~/system_logs.txt | awk '{print $1}')\n\n# Count how many ERROR events occurred on that date\ngrep \"$recent_date\" ~/system_logs.txt | grep \"\\[ERROR\\]\" | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple log files with the \".log\" extension. Your task is to find the total number of unique IP addresses that appear in these log files. Assume each line in a log file begins with an IP address and there are no comment lines or headers.",
        "explanation": "To solve this problem, you can use a combination of bash commands such as `cat`, `awk`, `sort`, and `uniq`. First, concatenate all the \".log\" files into one stream using `cat`. Then, use `awk` to extract the IP addresses from the beginning of each line. Pipe this output through `sort` to organize them, and finally use `uniq` to filter out duplicates, counting them with the `wc -l` command.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Concatenate all log files, extract IPs, sort them, remove duplicates and count unique entries.\ncat ~/log_files/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create a directory for log files\nmkdir -p ~/log_files\n\n# Create example log files with random IP addresses\necho -e \"192.168.1.1 - Log entry 1\\n192.168.1.2 - Log entry 2\\n192.168.1.3 - Log entry 3\" > ~/log_files/log1.log\necho -e \"192.168.1.2 - Log entry 4\\n192.168.1.4 - Log entry 5\\n192.168.1.5 - Log entry 6\" > ~/log_files/log2.log\necho -e \"192.168.1.3 - Log entry 7\\n192.168.1.6 - Log entry 8\\n192.168.1.7 - Log entry 9\" > ~/log_files/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Concatenate all log files, extract IPs, sort them, remove duplicates and count unique entries.\ncat ~/log_files/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_files\" in your home directory containing various files. Your task is to find out how many lines contain the word \"Linux\" (case-insensitive) across all text files in this directory. Ignore any non-text files.",
        "explanation": "To solve this problem, you should iterate over each file in the \"project_files\" directory, check if it is a text file, and then search for lines containing the word \"Linux\" (case-insensitive). You can use tools like `grep` for pattern matching and `file` command to determine if a file is a text file.\n\nYou can use this command pattern to perform the task:\n\n```bash\ntotal_lines=$(find ~/project_files -type f ! -name \"*.png\" | xargs grep -i 'Linux' | wc -l)\necho $total_lines\n```",
        "create": {
            "init": "mkdir -p ~/project_files\necho -e \"Linux is great.\\nI love Linux.\\nHello world.\" > ~/project_files/file1.txt\necho -e \"This is a test.\\nlinux kernel development.\" > ~/project_files/file2.txt\necho -e \"Random binary data: \\x89PNG\\r\\n\\x1A\\n\\x00\\x00\\x00\\rIHDR\" > ~/project_files/image.png\ntouch ~/project_files/empty.txt\necho -e \"Another line with Linux.\\nAnd one more linux line.\" > ~/project_files/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "total_lines=$(find ~/project_files -type f ! -name \"*.png\" | xargs grep -i 'Linux' | wc -l)\necho $total_lines"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains lines of text, and some lines include IP addresses in the format \"XXX.XXX.XXX.XXX\". Your task is to find out how many unique IP addresses are present across all the log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to read each log file in the \"logs\" directory, extract all IP addresses, and then determine the count of unique IP addresses. You can use tools like `grep` to extract IPs and `sort` and `uniq` to find unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"Error at 192.168.1.1\\nConnection from 10.0.0.1\\nRetrying 192.168.1.1\" > ~/logs/server1.log\necho -e \"Login attempt from 172.16.0.2\\nSuccess from 192.168.1.2\\nLogout 172.16.0.2\" > ~/logs/server2.log\necho -e \"Access from 10.0.0.3\\nAttempt by 192.168.1.3\\nFailed login from 10.\\nError at 10.\" > ~/logs/server3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of unique file extensions present in your home directory, including subdirectories.",
        "explanation": "To solve this problem, you need to recursively list all files in your home directory and extract the file extensions. Then, filter out duplicates to count only unique extensions. You can use commands like `find`, `awk`, and `sort` combined with `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all files recursively in the home directory\nfind ~/ -type f | \n# Extract file extensions using awk\nawk -F. 'NF>1{print $NF}' | \n# Sort and remove duplicates\nsort | uniq | \n# Count unique extensions\nwc -l\n```",
        "create": {
            "init": "# No initialization needed, as the student's home directory already contains files."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# List all files recursively in the home directory\nfind ~/ -type f | \n# Extract file extensions using awk\nawk -F. 'NF>1{print $NF}' | \n# Sort and remove duplicates\nsort | uniq | \n# Count unique extensions\nwc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file may contain multiple lines, and some lines are duplicate across different files. Your task is to count the total number of unique lines across all the log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you can use a combination of Linux utilities such as `cat`, `sort`, and `uniq`. First, concatenate all the log files using `cat` to create a single stream of lines. Then, sort these lines with `sort` to bring duplicates together. Finally, use `uniq` to filter out duplicates and count the number of unique lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"Error: File not found\\nWarning: Disk space low\\nInfo: Operation successful\" > ~/logs/log1.log\necho -e \"Warning: Disk space low\\nDebug: Variable x = 10\\nInfo: Operation successful\" > ~/logs/log2.log\necho -e \"Error: File not found\\nDebug: Variable x = 10\\nCritical: System crash!\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all `.txt` files located within the `/home/student/documents` directory and its subdirectories that contain the word \"Linux\", ignoring case.",
        "explanation": "To solve this problem, you can use the `grep` command to search for occurrences of the word \"Linux\" in each `.txt` file, using the `-i` option to ignore case. The `wc -l` command can then be used to count the number of lines outputted by `grep`. To ensure all files are searched recursively, use a combination of `find`, `grep`, and `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -name \"*.txt\" | xargs grep -i \"Linux\" | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents/subdir1\nmkdir -p /home/student/documents/subdir2\n\necho \"Linux Operating System\" > /home/student/documents/file1.txt\necho \"Introduction to linux\" > /home/student/documents/subdir1/file2.txt\necho \"No mention here\" > /home/student/documents/subdir1/file3.txt\necho \"LINUX tutorial\" > /home/student/documents/subdir2/file4.txt\necho \"linux commands overview\" > /home/student/documents/subdir2/file5.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -name \"*.txt\" | xargs grep -i \"Linux\" | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" with multiple log files containing server access logs. Your task is to find out the total number of unique IP addresses that accessed the server in these logs. Assume each line of a log file contains an IP address at the beginning followed by other information. You need to count only IPv4 addresses.",
        "explanation": "To solve this problem, you need to read all log files in the \"logs\" directory, extract IP addresses from each line, and determine which ones are unique. You can use grep or awk to extract IPs and sort combined with uniq to filter out duplicates. Remember to only consider IPv4 addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' logs/* | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p logs\necho -e \"192.168.1.1 GET /index.html\\n10.0.0.1 POST /form\\n172.16.0.1 GET /home\" > logs/log1.txt\necho -e \"192.168.1.2 GET /about\\n172.16.0.1 GET /contact\\n10.0.0.2 POST /submit\" > logs/log2.txt\necho -e \"192.168.1.3 GET /faq\\n192 168 1 3 broken record\\n10 0 0 3 malformed ip\" > logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' logs/* | sort | uniq | wc -l"
        }
    },
    {
        "description": "In the current directory, there are multiple text files containing various sentences. Count how many unique words appear across all these text files, considering a word to be any sequence of characters separated by whitespace or punctuation. Ignore case and treat all words as lowercase.",
        "explanation": "To solve this problem, you should read each text file in the current directory, extract words from each file by splitting on whitespace and punctuation, normalize them to lowercase, and keep track of unique words using a data structure like a set. After processing all files, count the number of unique words stored in the set.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Initialize an empty set to store unique words\ndeclare -A unique_words\n\n# Loop through each text file in the current directory\nfor file in *.txt; do\n  # Read each line from the file\n  while IFS= read -r line; do\n    # Convert line to lowercase and replace punctuation with spaces using sed\n    normalized_line=$(echo \"$line\" | tr '[:upper:]' '[:lower:]' | sed 's/[[:punct:]]/ /g')\n    \n    # Split line into words and add them to the set of unique words\n    for word in $normalized_line; do\n      unique_words[\"$word\"]=1\n    done\n    \n  done < \"$file\"\ndone\n\n# Count the number of keys (unique words) in the associative array and output it\necho \"${#unique_words[@]}\"\n```",
        "create": {
            "init": "# Create sample text files with sentences for students to work on\necho \"The quick brown fox jumps over the lazy dog.\" > file1.txt\necho \"A journey of a thousand miles begins with a single step.\" > file2.txt\necho \"To be or not to be that is the question.\" > file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Initialize an empty set to store unique words\ndeclare -A unique_words\n\n# Loop through each text file in the current directory\nfor file in *.txt; do\n  # Read each line from the file\n  while IFS= read -r line; do\n    # Convert line to lowercase and replace punctuation with spaces using sed\n    normalized_line=$(echo \"$line\" | tr '[:upper:]' '[:lower:]' | sed 's/[[:punct:]]/ /g')\n    \n    # Split line into words and add them to the set of unique words\n    for word in $normalized_line; do\n      unique_words[\"$word\"]=1\n    done\n    \n  done < \"$file\"\ndone\n\n# Count the number of keys (unique words) in the associative array and output it\necho \"${#unique_words[@]}\""
        }
    },
    {
        "description": "In your home directory, there is a text file named \"system_logs.txt\" with various log entries. Your task is to count how many unique IP addresses appear in this log file. You should ignore any lines that do not contain IP addresses.",
        "explanation": "To solve this problem, you should first identify lines containing IP addresses using a regular expression. Then extract these IP addresses and store them in a list or set to remove duplicates. Finally, count the number of unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/system_logs.txt | sort | uniq | wc -l\n```",
        "create": {
            "init": "echo -e \"192.168.0.1 - - [10/Oct/2023:13:55:36 +0000] \\\"GET /index.html HTTP/1.1\\\" 200 1043\\n\\\n203.0.113.5 - - [10/Oct/2023:13:56:02 +0000] \\\"POST /form HTTP/1.1\\\" 200 2326\\n\\\n198.51.100.2 - - [10/Oct/2023:13:57:45 +0000] \\\"GET /images/logo.png HTTP/1.1\\\" 404 103\\n\\\n203.0.113.5 - - [10/Oct/2023:14:01:22 +0000] \\\"GET /index.html HTTP/1.1\\\" 200 1043\\n\\\n198.51.100.2 - - [10/Oct/2023:14:02:12 +0000] \\\"POST /login HTTP/1.1\\\" 401 2134\\n\\\n192-168-0-2.example.com - - [10/Oct/2023:14:03:16 +0000] \\\"GET /home HTTP/1.x\\\" 500 1024\" > ~/system_logs.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/system_logs.txt | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with \".log\" extension. Each log file contains lines with timestamps in the format \"YYYY-MM-DD HH:MM:SS Message\". Count the number of messages that occurred in the month of January 2023 across all log files, and provide the total count.",
        "explanation": "To solve this problem, you need to filter out lines from all \".log\" files within the \"logs\" directory that match the date pattern for January 2023 (i.e., lines starting with \"2023-01\"). You can use tools like `grep` to search for these specific patterns and then use `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"^2023-01\" ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/log1.log\n2023-01-01 12:34:56 Message A\n2023-01-15 14:21:34 Message B\n2023-02-10 11:00:00 Message C\nEOL\n\ncat <<EOL > ~/logs/log2.log\n2022-12-31 23:59:59 Message D\n2023-01-05 08:45:23 Message E\n2023-03-01 07:30:00 Message F\nEOL\n\ncat <<EOL > ~/logs/log3.log\n2023-01-10 09:15:42 Message G\n2024-01-20 18:22:12 Message H\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"^2023-01\" ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple `.log` files. Count how many unique IP addresses appear across all files in this directory. Assume IP addresses are in the format \"xxx.xxx.xxx.xxx\".",
        "explanation": "To solve the problem, you need to extract IP addresses from each log file, combine them into a single list, and then count the number of unique entries. You can use utilities like `grep`, `awk`, or `sed` to extract IP addresses, `sort` to organize them, and `uniq` to count unique occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE \"[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+\" ~/log_files/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"192.168.1.1\\n10.0.0.1\\n192.168.1.2\" > ~/log_files/file1.log\necho -e \"10.0.0.1\\n172.16.0.5\\n192.168.1.2\" > ~/log_files/file2.log\necho -e \"192.168.1.3\\n172.16.0.5\\n10.0.0.2\" > ~/log_files/file3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE \"[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+\" ~/log_files/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that contain the word \"Linux\" within their content. Ignore hidden files (those starting with a dot).",
        "explanation": "To solve this problem, you can use the `grep` command to search for the word \"Linux\" inside each file in your home directory. Use `find` to locate all non-hidden files and then pipe them into `grep`. You should exclude directories and hidden files from your search.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example script to count the number of files containing the word \"Linux\"\nfind ~ -type f ! -name '.*' -exec grep -l 'Linux' {} + | wc -l\n```",
        "create": {
            "init": "# Create sample files in the student's home directory for testing purposes\necho \"This is a Linux system.\" > ~/file1.txt\necho \"Learning Linux commands.\" > ~/file2.txt\necho \"Operating systems are fun.\" > ~/file3.txt\necho \"The word Linux appears here too.\" > ~/file4.md\necho \"Another file without the keyword.\" > ~/notes/file5.log\nmkdir -p ~/notes && echo \"Linux kernel notes.\" > ~/notes/linux_notes.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example script to count the number of files containing the word \"Linux\"\nfind ~ -type f ! -name '.*' -exec grep -l 'Linux' {} + | wc -l"
        }
    },
    {
        "description": "You are tasked to find the total number of lines in all text files within a directory named \"logs\" located in your home directory. Additionally, these files may be compressed in .gz format and you need to count lines from both regular text files and compressed ones.",
        "explanation": "To solve this problem, you should:\n1. Navigate to the \"logs\" directory.\n2. List all files and determine which ones are regular text files and which are compressed (.gz).\n3. Use `wc -l` to count lines in regular text files.\n4. Use `zcat` or `zless | wc -l` to count lines in compressed .gz files.\n5. Sum all the line counts from both types of files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ntotal_lines=0\n\nfor file in *.txt; do\n  if [ -f \"$file\" ]; then\n    total_lines=$((total_lines + $(wc -l < \"$file\")))\n  fi\ndone\n\nfor gzfile in *.txt.gz; do\n  if [ -f \"$gzfile\" ]; then\n    total_lines=$((total_lines + $(zcat \"$gzfile\" | wc -l)))\n  fi\ndone\n\necho $total_lines # Outputs: 6 (since each file has 2 lines)\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"This is a sample log file.\\nIt contains multiple lines.\" > ~/logs/log1.txt\necho -e \"Another log file\\nWith more content.\" > ~/logs/log2.txt\ngzip -c ~/logs/log1.txt > ~/logs/log1.txt.gz\ngzip -c ~/logs/log2.txt > ~/logs/log2.txt.gz"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ntotal_lines=0\n\nfor file in *.txt; do\n  if [ -f \"$file\" ]; then\n    total_lines=$((total_lines + $(wc -l < \"$file\")))\n  fi\ndone\n\nfor gzfile in *.txt.gz; do\n  if [ -f \"$gzfile\" ]; then\n    total_lines=$((total_lines + $(zcat \"$gzfile\" | wc -l)))\n  fi\ndone\n\necho $total_lines # Outputs: 6 (since each file has 2 lines)"
        }
    },
    {
        "description": "Find and count the number of files in your home directory and its subdirectories that have been modified in the last 7 days, excluding hidden files.",
        "explanation": "To solve this problem, you need to use the `find` command to search for files within your home directory. The `-type f` option will ensure you are looking for regular files. The `-mtime -7` option will help filter out files that have been modified in the last 7 days. Additionally, you'll need to exclude hidden files which can be achieved by specifying a pattern to exclude filenames starting with a dot.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/ -type f -mtime -7 ! -name \".*\" | wc -l\n```",
        "create": {
            "init": "# No initialization is required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/ -type f -mtime -7 ! -name \".*\" | wc -l"
        }
    },
    {
        "description": "In your home directory, there are various types of files such as text files, image files, and executable binaries. Your task is to determine the total disk usage of all text files (with extensions .txt or .md) in bytes within a directory called \"docs\" inside your home directory. Ensure that you include only regular files and exclude any symbolic links or directories.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"docs\" directory within your home directory.\n2. Use the `find` command to locate all regular files with extensions .txt or .md.\n3. Pipe the list of found files into `du` (disk usage) with appropriate flags to sum their sizes.\n4. Filter out directories and symbolic links using `-type f` with `find`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/docs\nfind . -type f \\( -name \"*.txt\" -o -name \"*.md\" \\) -exec du -b {} + | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "mkdir -p ~/docs\necho \"This is a sample text file.\" > ~/docs/file1.txt\necho \"Another example of a markdown file.\" > ~/docs/file2.md\nln -s ~/docs/file1.txt ~/docs/symlink.txt  # Create a symbolic link which should not be counted\necho \"Binary content\" > ~/docs/executable.bin\nchmod +x ~/docs/executable.bin           # Make it an executable binary file"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/docs\nfind . -type f \\( -name \"*.txt\" -o -name \"*.md\" \\) -exec du -b {} + | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" in all \".log\" files within the \"/var/logs/\" directory, but exclude any lines that also contain the word \"debug\".",
        "explanation": "To solve this problem, you need to search through all \".log\" files in the \"/var/logs/\" directory. You can use `grep` to find lines containing \"error\" and then use `grep` again with the `-v` flag to exclude lines containing \"debug\". Finally, count these filtered lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Search for 'error' but exclude 'debug' in .log files and count occurrences\ngrep 'error' /var/logs/*.log | grep -v 'debug' | wc -l\n```",
        "create": {
            "init": "# Create a temporary directory for logs\nmkdir -p /var/logs/\n\n# Create sample log files with various entries\necho -e \"error: something went wrong\\ninfo: all systems operational\\nerror: unable to connect\\ndebug: connection attempt failed\\nerror: timeout occurred\\ninfo: maintenance scheduled\" > /var/logs/system.log\n\necho -e \"debug: failed login attempt\\nerror: user authentication failed\\ninfo: user logged out\\nerror: file not found\\ndebug: file read operation failed\" > /var/logs/auth.log\n\necho -e \"info: started backup process\\nerror: backup process failed\\ndebug: backup script error\\nerror: insufficient storage space\" > /var/logs/backup.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Search for 'error' but exclude 'debug' in .log files and count occurrences\ngrep 'error' /var/logs/*.log | grep -v 'debug' | wc -l"
        }
    },
    {
        "description": "Count the number of files in the \"/var/log\" directory that have been modified in the last 7 days.",
        "explanation": "You can use the `find` command to search for files in a specific directory and filter them based on their modification time. The `-mtime` option allows you to specify the number of days since last modification, and using `-type f` ensures you're counting only files. Combining these options will help you find and count the relevant files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No initialization required as /var/log is a standard directory in Linux systems."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You are tasked with determining the total number of lines containing the word \"error\" in all text files located within your home directory, including those within subdirectories. You should not count duplicate lines.",
        "explanation": "To solve this problem, you will need to use a combination of commands to search for files, check their contents for occurrences of the word \"error\", and ensure that each occurrence is counted only once, even if it appears in multiple files or locations. Consider using `find` to locate files, `grep` to search for lines containing \"error\", and `sort` with `uniq` to remove duplicates.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -name '*.txt' -exec grep 'error' {} + | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/test_dir/subdir\necho -e \"This is a test file\\nAn error occurred\\nAnother line\" > ~/test_file.txt\necho -e \"An error occurred\\nSame error again\\nDifferent content\" > ~/test_dir/test_file2.txt\necho -e \"Error in process\\nJust some text\\nError in process\" > ~/test_dir/subdir/test_file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -name '*.txt' -exec grep 'error' {} + | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the number of files in your home directory that were modified within the last 7 days, and contain the word \"TODO\" in their content.",
        "explanation": "To solve this problem, first you need to find files in your home directory that have been modified within the last 7 days. You can use the `find` command with the `-mtime` parameter for this purpose. Then, for each file found, you can use `grep` to search for the word \"TODO\" in its content. Finally, count how many such files exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find files modified within the last 7 days containing \"TODO\"\nfind ~ -type f -mtime -7 | xargs grep -l \"TODO\" | wc -l\n```",
        "create": {
            "init": "# Create sample files in the user's home directory for testing\ntouch ~/example1.txt\necho \"TODO: Finish homework\" > ~/example1.txt\n\ntouch ~/example2.txt\necho \"This is a test file.\" > ~/example2.txt\n\ntouch ~/example3.md\necho \"TODO: Update documentation\" > ~/example3.md\n\n# Change modification time to 5 days ago for some files\ntouch -m -d '5 days ago' ~/example1.txt\n\n# Leave one file unchanged to have recent modification time"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find files modified within the last 7 days containing \"TODO\"\nfind ~ -type f -mtime -7 | xargs grep -l \"TODO\" | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in the `documents` directory, excluding any lines that contain the word \"error\".",
        "explanation": "To solve this problem, you need to iterate through each `.txt` file within the `documents` directory. Use tools like `grep` to filter out lines containing the word \"error\" and then count the remaining lines using `wc -l`. Sum up the line counts from each file to get the total.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -v \"error\" documents/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p documents\necho -e \"This is a test.\\nNo errors here.\" > documents/file1.txt\necho -e \"Another test line.\\nError found.\" > documents/file2.txt\necho -e \"All clear.\\nProceed with caution.\\nError again.\" > documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -v \"error\" documents/*.txt | wc -l"
        }
    },
    {
        "description": "Count the number of text files in your home directory that contain the word \"Linux\" at least once. You must only consider files with a \".txt\" extension.",
        "explanation": "To solve this problem, you need to search through all text files (.txt) in your home directory and check each file's content for the occurrence of the word \"Linux\". You can use tools like `grep` to search within files and `find` to locate files with a specific extension. The goal is to count how many such files meet the criteria.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files in the home directory and count those containing 'Linux'.\nfind ~ -type f -name \"*.txt\" -exec grep -l \"Linux\" {} \\; | wc -l\n```",
        "create": {
            "init": "# Create some sample text files in the user's home directory.\necho \"Linux is great.\" > ~/file1.txt\necho \"This is a test file.\" > ~/file2.txt\necho \"The Linux kernel is open-source.\" > ~/file3.txt\necho \"Operating systems are fun.\" > ~/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files in the home directory and count those containing 'Linux'.\nfind ~ -type f -name \"*.txt\" -exec grep -l \"Linux\" {} \\; | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" located in your home directory, containing multiple log files with a \".log\" extension. Each log file contains timestamps and various events. Your task is to count the number of unique dates present across all the log files in this directory. Consider each line in a log file starts with a date in the format \"YYYY-MM-DD\". Please provide only the integer count as your answer.",
        "explanation": "To solve this problem, you need to extract all unique dates from multiple log files within the specified directory. You can use commands like `cat` to concatenate all files, `awk` or `cut` to extract date parts, `sort` to sort them, and finally `uniq` to find unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 Event1\\n2023-01-02 Event2\\n2023-01-01 Event3\" > ~/logs/log1.log\necho -e \"2023-01-03 Event4\\n2023-01-02 Event5\" > ~/logs/log2.log\necho -e \"2023-01-04 Event6\\n2023-01-03 Event7\\n2023-01-05 Event8\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"log_files\" in your home directory. This directory contains several compressed log files with the \".gz\" extension. Your task is to determine how many unique IP addresses are present across all the log files combined. Assume each log file has lines where the first field is an IP address, and the fields are separated by spaces.",
        "explanation": "To solve this problem, you need to perform the following steps:\n1. Decompress all \".gz\" files in the \"log_files\" directory.\n2. Extract the first field (IP address) from each line of every decompressed file.\n3. Collect all unique IP addresses from these extracted fields.\n4. Count how many unique IP addresses exist.\n\nYou can use utilities like `gunzip`, `awk`, `sort`, and `uniq` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/log_files\n\n# Decompress all .gz files in the current directory\ngunzip *.gz\n\n# Extract IP addresses, sort them, get unique ones, and count them\nawk '{print $1}' log* | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"192.168.1.1 user1 action\\n192.168.1.2 user2 action\\n192.168.1.3 user3 action\" | gzip > ~/log_files/log1.gz\necho -e \"192.168.1.2 user4 action\\n192.168.1.4 user5 action\\n192.168.1.5 user6 action\" | gzip > ~/log_files/log2.gz\necho -e \"192.168.1.6 user7 action\\n192.168.1.7 user8 action\\n192.168.1.3 user9 action\" | gzip > ~/log_files/log3.gz"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/log_files\n\n# Decompress all .gz files in the current directory\ngunzip *.gz\n\n# Extract IP addresses, sort them, get unique ones, and count them\nawk '{print $1}' log* | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Your task is to count how many unique IP addresses have accessed the system, as tracked by these log files. Each line in a log file follows the format: \"[Date] [Time] [IP Address] [Request Details]\". You must perform this task using bash commands without writing any scripts or saving intermediate results in files.",
        "explanation": "To solve this problem, you need to extract the IP addresses from each log file, consolidate them into one list, and then count the unique entries. You can use tools like `grep` or `awk` to extract IPs, `sort` to organize them, and `uniq` to filter out duplicates before counting.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $3}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/access1.log\n2023-10-01 12:00:01 192.168.0.1 GET /index.html\n2023-10-01 12:05:23 192.168.0.2 POST /form.html\n2023-10-01 12:15:45 192.168.0.1 GET /about.html\nEOL\n\ncat <<EOL > ~/logs/access2.log\n2023-10-02 09:00:11 192.168.0.3 GET /contact.html\n2023-10-02 09:05:27 192.168.0.4 POST /login.html\n2023-10-02 09:15:49 192.168.0.2 GET /home.html\nEOL\n\ncat <<EOL > ~/logs/access3.log\n2023-10-03 18:20:21 192.168.0.5 GET /dashboard.html\n2023-10-03 18:25:33 192.168.0.1 POST /logout.html\n2023-10-03 18:35:55 192.168.0.6 GET /profile.html\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $3}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Each file records server access logs in the format: `<IP_ADDRESS> - - [<DATE>] \"GET /<RESOURCE> HTTP/1.1\" <STATUS_CODE> <SIZE>`. Your task is to find out how many unique IP addresses have accessed the server successfully (i.e., status code 200) across all log files.",
        "explanation": "To solve this problem, you need to process each log file in the \"logs\" directory and extract the IP addresses associated with successful requests (status code 200). Use utilities like `grep` to filter lines with status code 200, `awk` or `cut` to extract IP addresses, and `sort` along with `uniq` to count unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | grep 'HTTP/1\\.1\\\" 200' | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"192.168.1.1 - - [01/Oct/2023:10:00:00] \\\"GET /index.html HTTP/1.1\\\" 200 1024\" > ~/logs/access1.log\necho \"192.168.1.2 - - [01/Oct/2023:10:05:00] \\\"GET /about.html HTTP/1.1\\\" 404 512\" >> ~/logs/access1.log\necho \"192.168.1.3 - - [01/Oct/2023:11:00:00] \\\"GET /contact.html HTTP/1.1\\\" 200 256\" >> ~/logs/access2.log\necho \"192.168.1.2 - - [01/Oct/2023:12:00:00] \\\"GET /home.html HTTP/1.1\\\" 200 2048\" > ~/logs/access3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | grep 'HTTP/1\\.1\\\" 200' | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with varying extensions (e.g., .log, .txt). Your task is to count the total number of lines across all \".log\" files, but only for those lines that contain the word \"ERROR\". How many such lines are there?",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and filter out all files with the \".log\" extension. Then, for each file, use a command to search for lines containing the word \"ERROR\". Count these lines across all \".log\" files to get your answer. You can use utilities like `grep`, `wc`, and shell expansion techniques.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep 'ERROR' *.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: This is an info message\\nERROR: This is an error message\\nDEBUG: This is a debug message\" > ~/logs/system.log\necho -e \"ERROR: Another error occurred\\nWARNING: This is a warning\\nERROR: Yet another error found\" > ~/logs/application.log\necho -e \"INFO: Starting service\\nINFO: Service running smoothly\\nERROR: Service failed unexpectedly\" > ~/logs/service.log\necho -e \"This file should not be counted for errors.\\nIt has no '.log' extension.\" > ~/logs/readme.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep 'ERROR' *.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named `log_files` in your home directory, which contains multiple log files with the extension `.log`. Each log file contains several lines of text. Your task is to find out how many unique IP addresses have accessed the system across all these log files. Assume that each line in the log files starts with an IP address followed by other information.",
        "explanation": "To solve this problem, you need to iterate through all the `.log` files in the `log_files` directory and extract the IP addresses from each line. You can use tools like `grep`, `awk`, or `sed` to isolate the IP addresses from each line. Once you have a list of all IP addresses, use a tool like `sort` and `uniq` to filter out duplicate entries and count the number of unique IPs.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/log_files/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"192.168.1.1 User logged in\\n192.168.1.2 User logged out\\n192.168.1.3 Error occurred\" > ~/log_files/log1.log\necho -e \"192.168.1.2 User logged in\\n192.168.1.4 User logged out\\n192.168.1.5 Error occurred\" > ~/log_files/log2.log\necho -e \"192.168.1.3 User logged in\\n192.168.1.6 User logged out\\n192.168.1.7 Error occurred\" > ~/log_files/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/log_files/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple text files with log entries. Each log entry consists of a timestamp and a message, formatted as \"YYYY-MM-DD HH:MM:SS - Message\". Your task is to find out how many error messages (\"ERROR\") occurred on the 15th day of any month. You can assume all timestamps are in the same year.",
        "explanation": "To solve this problem, you need to iterate over each file in the \"logs\" directory and search for occurrences of the word \"ERROR\" within any log entry that starts with a date having \"-15\". You can use utilities like `grep` or `awk` to filter and count these entries effectively.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^[0-9]\\{4\\}-[0-9]\\{2\\}-15 .*ERROR' ~/logs/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-15 08:00:00 - ERROR An error occurred\\n2023-01-15 09:00:00 - INFO All systems operational\\n2023-02-14 10:00:00 - ERROR Another error\\n2023-02-15 11:00:00 - ERROR Yet another error\" > ~/logs/log1.txt\necho -e \"2023-03-15 12:30:45 - ERROR Critical failure\\n2023-04-16 13:45:20 - WARNING Low disk space\\n2023-05-15 14:55:30 - ERROR Major issue detected\" > ~/logs/log2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^[0-9]\\{4\\}-[0-9]\\{2\\}-15 .*ERROR' ~/logs/*.txt | wc -l"
        }
    },
    {
        "description": "You need to determine the total number of lines across all `.txt` files in your home directory, including those in subdirectories. However, only count lines that contain the word \"Linux\" (case-sensitive).",
        "explanation": "To solve this problem, you can use a combination of `find` to locate all `.txt` files in your home directory, and `grep` to filter lines containing the word \"Linux\". Finally, use `wc -l` to count these lines. Consider using a pipe (`|`) to chain these commands together effectively.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script: Find all .txt files and count lines with 'Linux'\nfind ~ -name \"*.txt\" -type f -exec grep -H 'Linux' {} \\; | wc -l\n```",
        "create": {
            "init": "# Create sample .txt files with content for testing\nmkdir -p ~/test_dir/subdir\necho -e \"This is a Linux file.\\nAnother line.\" > ~/test_dir/file1.txt\necho -e \"Linux is great.\\nJust another line.\" > ~/test_dir/file2.txt\necho -e \"No mention here.\" > ~/test_dir/subdir/file3.txt\necho -e \"Yet another Linux line.\" > ~/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script: Find all .txt files and count lines with 'Linux'\nfind ~ -name \"*.txt\" -type f -exec grep -H 'Linux' {} \\; | wc -l"
        }
    },
    {
        "description": "You have a directory named `logs` in your home directory containing multiple log files with the `.log` extension. Each log file contains lines of text, where each line is either an informational message starting with \"INFO\", a warning message starting with \"WARN\", or an error message starting with \"ERROR\". Your task is to count the total number of error messages that appear across all log files in the `logs` directory and report this number.",
        "explanation": "To solve this problem, you need to iterate through all the `.log` files in the `logs` directory. For each file, use a command-line utility like `grep` to filter out lines that start with \"ERROR\". Count these lines using another utility such as `wc -l`, and keep a running total of these counts across all log files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -name \"*.log\" -exec grep \"^ERROR\" {} \\; | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO Starting process\\nERROR Failed to initialize\\nWARN Low memory\" > ~/logs/system1.log\necho -e \"ERROR Disk not found\\nINFO Process completed\\nERROR Timeout occurred\" > ~/logs/system2.log\necho -e \"WARN High CPU usage\\nINFO System rebooted\\nERROR Connection lost\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -name \"*.log\" -exec grep \"^ERROR\" {} \\; | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains entries in the format \"[YYYY-MM-DD HH:MM:SS] [ERROR/WARN/INFO] Message\". Your task is to count how many \"ERROR\" messages are present across all log files in this directory and output that number.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory, iterate over each \".log\" file, and search for lines containing the keyword \"ERROR\". You can use tools like `grep` to filter these lines and then count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep -r \"\\[ERROR\\]\" *.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"[2023-09-15 10:00:01] [ERROR] Failed to connect to database.\" > ~/logs/app1.log\necho \"[2023-09-15 10:05:23] [INFO] Connection established.\" >> ~/logs/app1.log\necho \"[2023-09-15 11:00:45] [WARN] High memory usage detected.\" >> ~/logs/app1.log\necho \"[2023-09-15 12:01:19] [ERROR] Timeout occurred during data retrieval.\" >> ~/logs/app1.log\n\necho \"[2023-09-16 14:15:00] [INFO] Daily backup completed successfully.\" > ~/logs/app2.log\necho \"[2023-09-16 14:20:31] [ERROR] Unable to write to disk.\" >> ~/logs/app2.log\necho \"[2023-09-16 14:30:42] [WARN] Low disk space warning.\" >> ~/logs/app2.log\n\n# More log files can be added similarly if needed."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep -r \"\\[ERROR\\]\" *.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"project_logs\" in your home directory. This directory contains numerous log files with the extension \".log\". Your task is to find the total number of unique IP addresses that have accessed the system, as indicated by entries in these log files. Each log entry follows the format: \"IP_ADDRESS - [timestamp] - message\". You need to count how many distinct IP addresses appear across all log files.",
        "explanation": "To solve this problem, you will need to iterate over each \".log\" file within the \"project_logs\" directory. For each file, extract the IP address from each line, and store these IPs in a set to automatically handle uniqueness. After processing all files, count the number of unique entries in your collection (set) of IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{print $1}' ~/project_logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"192.168.1.1 - [2023-10-05 14:23:01] - User login\\n192.168.1.2 - [2023-10-05 14:25:13] - Access denied\\n192.168.1.1 - [2023-10-05 14:30:45] - File uploaded\" > ~/project_logs/access1.log\necho -e \"192.168.2.5 - [2023-10-06 09:12:23] - User login\\n172.16.0.4 - [2023-10-06 09:15:42] - File download\\n192.168.2.5 - [2023-10-06 09:20:18] - File deleted\" > ~/project_logs/access2.log\necho -e \"10.0.0.7 - [2023-10-07 17:45:21] - System rebooted\\n172.16.0.4 - [2023-10-07 17:47:33] - User logout\\n192.168.1.1 - [2023-10-07 17:50:44] - Error reported\" > ~/project_logs/access3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{print $1}' ~/project_logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing multiple log files with various extensions. Your task is to count the total number of lines across all files in this directory that contain the word \"ERROR\". Additionally, only consider files that have a \".log\" extension.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"logs\" directory.\n2. Use a command like `find` or `ls` to list all files with the \".log\" extension.\n3. Use `grep` to search for the word \"ERROR\" in these files.\n4. Count the number of lines that contain the word \"ERROR\".\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd logs\ngrep -r 'ERROR' *.log | wc -l\n```",
        "create": {
            "init": "mkdir -p logs\necho -e \"INFO: System boot\\nERROR: Failed to load module\\nINFO: Module loaded successfully\" > logs/system.log\necho -e \"NOTICE: User login\\nWARNING: Low disk space\\nERROR: Disk read failure\" > logs/user_activity.log\necho -e \"DEBUG: Variable x = 42\\nERROR: Null pointer exception\" > logs/debug.log\necho -e \"INFO: Scheduled task completed\\nNOTICE: Configuration updated\" > logs/maintenance.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd logs\ngrep -r 'ERROR' *.log | wc -l"
        }
    },
    {
        "description": "You are given a directory `/var/logs`, which contains various log files with different extensions. Your task is to identify the total number of lines across all `.log` files in this directory that contain the word \"ERROR\". Assume that the logs can be large, and performance might be a factor.",
        "explanation": "To solve this problem, you need to navigate to the `/var/logs` directory and use tools like `grep` to search for lines containing the word \"ERROR\" within `.log` files. You can leverage `grep -r` for recursive search combined with `wc -l` to count lines. Be sure to filter only `.log` files before performing your count.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd /var/logs\ngrep -r \"ERROR\" *.log | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nINFO: Scheduled maintenance\" > /var/logs/system.log\necho -e \"DEBUG: Starting process\\nERROR: Out of memory\\nDEBUG: Process ended\" > /var/logs/app.log\necho -e \"WARNING: High CPU usage\\nINFO: Service started\" > /var/logs/network.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd /var/logs\ngrep -r \"ERROR\" *.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with various extensions. Each log file contains timestamped entries in the format \"[YYYY-MM-DD HH:MM:SS] Message\". Your task is to find out how many entries across all log files were made on the most recent date present in any of the logs. You should only consider entries from files with a \".log\" extension.",
        "explanation": "To solve this problem, you need to first identify the most recent date across all entries in the \".log\" files within the \"logs\" directory. Once you have determined this date, count how many entries are recorded for that specific date across all these files. This will require extracting dates from each entry, comparing them to find the latest one, and then counting occurrences of this date.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Extract dates from .log files and find the most recent one\nlatest_date=$(grep -hoP '\\[\\d{4}-\\d{2}-\\d{2}' ~/logs/*.log | tr -d '[' | sort | uniq | tail -n1)\n\n# Count number of entries with this latest date in .log files\ncount=$(grep -hocP \"\\[$latest_date\" ~/logs/*.log | awk '{s+=$1} END {print s}')\n\n# Output the result which is number of entries on most recent date\necho $count\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create the logs directory if it doesn't exist\nmkdir -p ~/logs\n\n# Create sample log files with various extensions\necho -e \"[2023-10-01 10:00:00] Start process\\n[2023-10-02 14:30:00] Process running\\n[2023-10-03 18:45:00] Process completed\" > ~/logs/process.log\necho -e \"[2023-09-29 08:15:00] System boot\\n[2023-10-02 12:00:00] User login\" > ~/logs/system.log\necho -e \"[2023-09-28 20:20:20] Error occurred\\n[2023-09-29 21:25:25] Error resolved\" > ~/logs/error.txt\n\n# You can add more logs or different types of logs as needed."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Extract dates from .log files and find the most recent one\nlatest_date=$(grep -hoP '\\[\\d{4}-\\d{2}-\\d{2}' ~/logs/*.log | tr -d '[' | sort | uniq | tail -n1)\n\n# Count number of entries with this latest date in .log files\ncount=$(grep -hocP \"\\[$latest_date\" ~/logs/*.log | awk '{s+=$1} END {print s}')\n\n# Output the result which is number of entries on most recent date\necho $count"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with the extension \".log\". Your task is to determine the total number of unique IP addresses across all these log files. Consider only valid IPv4 addresses for this task.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and process each \".log\" file to extract IP addresses. You can use tools like `grep` or `awk` to search for patterns that match IPv4 addresses. Once you have extracted these addresses, store them in a set or use `sort` and `uniq` commands to find the unique ones. Finally, count the number of unique IPs and provide that as your answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Navigate to the logs directory\ncd ~/logs\n\n# Extract all IPs from .log files, filter valid IPv4 format, sort and get unique ones, then count them.\ngrep -hoE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' *.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create a 'logs' directory in the user's home directory\nmkdir -p ~/logs\n\n# Generate sample log files with random IPs for testing\necho -e \"192.168.1.1\\n10.0.0.2\\n172.16.0.5\\n192.168.1.1\" > ~/logs/access.log\necho -e \"10.0.0.3\\n192.168.1.2\\n172.16.0.5\\n255.255.255.\" > ~/logs/error.log\necho -e \"192-168-1-3\\n10:0:0:4\\ninvalid.ip.address\" > ~/logs/misc.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Navigate to the logs directory\ncd ~/logs\n\n# Extract all IPs from .log files, filter valid IPv4 format, sort and get unique ones, then count them.\ngrep -hoE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' *.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named `system_logs` in your home directory containing multiple `.log` files. Your task is to find the total number of unique IP addresses that have accessed the system, as recorded in these logs. Assume that each log entry begins with an IP address, and all entries are space-separated. You may assume there are no IPv6 addresses.",
        "explanation": "To solve this problem, you need to iterate over each `.log` file in the `system_logs` directory and extract the IP addresses from the beginning of each line. You can use tools like `awk`, `sort`, and `uniq` to process and count unique IP addresses. First, use `awk` to extract the first column (IP address) from each log file's entries. Then sort those IPs and use `uniq` to filter out duplicates. Finally, count the number of unique entries using either `wc -l` or by piping into another command that counts lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/system_logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/system_logs\necho \"192.168.1.1 UserA accessed resource X\" > ~/system_logs/access1.log\necho \"192.168.1.2 UserB accessed resource Y\" >> ~/system_logs/access1.log\necho \"192.168.1.3 UserC accessed resource Z\" >> ~/system_logs/access1.log\necho \"192.168.1.2 UserD accessed resource A\" > ~/system_logs/access2.log\necho \"192.168.1.4 UserE accessed resource B\" >> ~/system_logs/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/system_logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in the `/home/student/documents` directory and its subdirectories that contain the word \"Linux\". You must perform this task using only `grep`, `find`, and other basic shell utilities without using any scripting languages like Python or Perl.",
        "explanation": "To solve this problem, you need to search for the word \"Linux\" within `.txt` files located in the specified directory and its subdirectories. Use the `find` command to locate all `.txt` files, then apply `grep` with appropriate options to count occurrences of lines containing \"Linux\". Summing up these counts will give you the total number of such lines across all relevant files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -name \"*.txt\" | xargs grep -i 'Linux' | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents/subdir1\nmkdir -p /home/student/documents/subdir2\n\necho -e \"This is a Linux file.\\nSecond line.\" > /home/student/documents/file1.txt\necho -e \"Another line.\\nLinux is here again.\" > /home/student/documents/file2.txt\necho -e \"Not mentioning it here.\" > /home/student/documents/subdir1/file3.txt\necho -e \"Just one mention: Linux.\" > /home/student/documents/subdir2/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -name \"*.txt\" | xargs grep -i 'Linux' | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all `.txt` files located in the `/var/logs/` directory and its subdirectories that contain the word \"ERROR\". You should consider only those `.txt` files which are not empty.",
        "explanation": "To solve this problem, you need to search through all `.txt` files within the `/var/logs/` directory and its subdirectories. You can use the `find` command to list all non-empty `.txt` files, then use `xargs` along with `grep` to filter out lines containing \"ERROR\". Finally, use `wc -l` to count these lines across all relevant files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/logs -type f -name \"*.txt\" ! -size 0 -print0 | xargs -0 grep -h 'ERROR' | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs/subdir1 /var/logs/subdir2\necho \"INFO: System started\" > /var/logs/log1.txt\necho \"ERROR: Disk failure\" > /var/logs/subdir1/log2.txt\necho \"\" > /var/logs/subdir1/empty.txt\necho \"ERROR: Network issue\" >> /var/logs/subdir2/log3.txt\necho \"ERROR: System crash\" >> /var/logs/subdir2/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/logs -type f -name \"*.txt\" ! -size 0 -print0 | xargs -0 grep -h 'ERROR' | wc -l"
        }
    },
    {
        "description": "In the \"logs\" directory on your system, there is a file named \"system.log\" containing various log entries. Your task is to identify how many unique IP addresses have made requests to the system in the past 7 days. The log entries follow the format: \"[Date] [Time] [IP Address] [Message]\". You need to count and report the number of unique IP addresses.",
        "explanation": "To solve this problem, you should first filter out log entries from the past 7 days by checking their dates. Then extract the IP address from each of these filtered entries, store them in a list or set, and finally count how many unique IP addresses are present in that period.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Get current date and calculate date range for past 7 days.\ncurrent_date=$(date +%Y-%m-%d)\nstart_date=$(date -d \"$current_date -7 days\" +%Y-%m-%d)\n\n# Extract relevant lines from the log file within last seven days.\nawk -v start=\"$start_date\" '$1 >= start {print $0}' logs/system.log | \n\n# Extract IP addresses and find unique ones.\nawk '{print $3}' | sort | uniq |\n\n# Count unique IP addresses.\nwc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create logs directory and system.log file with sample data\n\nmkdir -p logs\n\ncat > logs/system.log <<EOL\n2023-10-01 12:00:00 192.168.1.1 User logged in\n2023-10-02 13:30:25 192.168.1.2 File uploaded\n2023-10-03 08:45:12 192.168.1.3 Error occurred\n2023-10-04 09:15:00 192.168.1.4 User logged out\n2023-10-05 14:22:45 192.168.1.2 Password changed\n2023-10-06 11:33:33 192.168.1.5 New device registered\n2023-10-07 16:44:12 192.168.1.6 Security alert raised\nEOL\n\n# Adjust system date for testing purposes (if needed)\n# date -s \"2023-10-07\""
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Get current date and calculate date range for past 7 days.\ncurrent_date=$(date +%Y-%m-%d)\nstart_date=$(date -d \"$current_date -7 days\" +%Y-%m-%d)\n\n# Extract relevant lines from the log file within last seven days.\nawk -v start=\"$start_date\" '$1 >= start {print $0}' logs/system.log | \n\n# Extract IP addresses and find unique ones.\nawk '{print $3}' | sort | uniq |\n\n# Count unique IP addresses.\nwc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"project_data\" containing multiple text files. Each file contains a list of numbers (one number per line). Your task is to determine the total sum of all numbers across all files in this directory. You need to ensure that the sum includes only positive numbers, and ignore any negative numbers or non-numeric lines.",
        "explanation": "To solve this problem, you should navigate to the \"project_data\" directory and iterate over each text file. For each file, read through the content line by line, checking if each line contains a positive number. If it does, add that number to a running total sum. Ignore any lines with non-numeric data or negative numbers.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Navigate to project_data directory\ncd ~/project_data\n\n# Initialize total sum variable\ntotal_sum=0\n\n# Loop through each file in the directory\nfor file in *.txt; do\n    # Read each line in the current file\n    while IFS= read -r line; do\n        # Check if the line is a positive integer using regex matching\n        if [[ $line =~ ^[0-9]+$ ]]; then \n            # Sum up the positive integers only\n            total_sum=$((total_sum + line))\n        fi \n    done < \"$file\"\ndone\n\n# Output the final result which will be matched against student submission.\necho $total_sum  # Should output: 169 for provided example files.\n```",
        "create": {
            "init": "#!/bin/bash\n# Create project_data directory in the home directory\nmkdir -p ~/project_data\n\n# Create sample text files with random numbers\necho -e \"12\\n-3\\n45\\nabc\\n7\" > ~/project_data/file1.txt\necho -e \"20\\n30\\n-5\\nxyz\\n10\" > ~/project_data/file2.txt\necho -e \"-6\\n8\\n15\\ndefg\\n22\" > ~/project_data/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Navigate to project_data directory\ncd ~/project_data\n\n# Initialize total sum variable\ntotal_sum=0\n\n# Loop through each file in the directory\nfor file in *.txt; do\n    # Read each line in the current file\n    while IFS= read -r line; do\n        # Check if the line is a positive integer using regex matching\n        if [[ $line =~ ^[0-9]+$ ]]; then \n            # Sum up the positive integers only\n            total_sum=$((total_sum + line))\n        fi \n    done < \"$file\"\ndone\n\n# Output the final result which will be matched against student submission.\necho $total_sum  # Should output: 169 for provided example files."
        }
    },
    {
        "description": "You have a directory called \"project_data\" in your home directory, which contains multiple text files. Each file may contain some lines with the word \"ERROR\". Your task is to count the total number of lines that contain the word \"ERROR\" across all files in this directory, ignoring case sensitivity.",
        "explanation": "To solve this problem, you need to go through each file in the \"project_data\" directory and search for lines containing the word \"ERROR\". You should use a command that can handle case-insensitive searching. Aggregate the number of matching lines from all files to get the final count.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' ~/project_data/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_data\necho -e \"This is a sample line.\\nERROR: something went wrong.\\nAnother line.\" > ~/project_data/file1.txt\necho -e \"error: failed to load.\\nSome other information.\" > ~/project_data/file2.txt\necho -e \"No issues here.\\nError found on this line.\" > ~/project_data/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' ~/project_data/*.txt | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple log files with the extension \".log\". Each log file contains timestamped entries. Count how many log entries occurred during the month of January across all these log files. The timestamps are formatted as \"YYYY-MM-DD HH:MM:SS\".",
        "explanation": "To solve this problem, you need to iterate through each \".log\" file in the \"log_files\" directory and search for lines that contain timestamps from the month of January. You can use a combination of `grep` to search for lines starting with \"YYYY-01-\" (where YYYY is any year) and `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -rh '^....-01-' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-01-15 12:34:56 Log entry 1\\n2023-02-15 13:45:56 Log entry 2\\n2023-01-16 14:34:56 Log entry 3\" > ~/log_files/sample1.log\necho -e \"2022-01-10 09:20:30 Log entry A\\n2022-03-05 10:21:30 Log entry B\\n2022-01-22 11:22:30 Log entry C\" > ~/log_files/sample2.log\necho -e \"2021-04-12 08:44:50 Log entry X\\n2021-01-28 18:00:00 Log entry Y\" > ~/log_files/sample3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -rh '^....-01-' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory that contains multiple log files with various extensions (e.g., .log, .txt). Your task is to count the number of unique IP addresses found in all .log files within this directory. Assume each line in the log files may contain an IP address.",
        "explanation": "To solve this problem, you need to:\n1. Use the `find` command to locate all .log files within the \"log_files\" directory.\n2. Use tools like `grep` or `awk` to extract potential IP addresses from these files.\n3. Utilize `sort` and `uniq` to filter out unique IP addresses.\n4. Finally, count these unique IP addresses using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/log_files -type f -name \"*.log\" | xargs grep -oE '([0-9]{1,3}\\.){3}[0-9]{1,3}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\ncat <<EOL > ~/log_files/access1.log\n192.168.1.1 - - [10/Oct/2023:13:55:36] \"GET /index.html HTTP/1.0\"\n192.168.1.2 - - [10/Oct/2023:13:55:37] \"POST /submit HTTP/1.0\"\n192.168.1.1 - - [10/Oct/2023:13:55:38] \"GET /home HTTP/1.0\"\nEOL\n\ncat <<EOL > ~/log_files/server.log\n172.16.0.5 - - [10/Oct/2023:14:00:00] \"GET /dashboard HTTP/1.0\"\n172.16.0.6 - - [10/Oct/2023:14:00:01] \"POST /update HTTP/1.0\"\n172.16.0.5 - - [10/Oct/2023:14:00:02] \"GET /status HTTP/1.0\"\nEOL\n\ncat <<EOL > ~/log_files/readme.txt\nThis is a readme file and does not contain any log entries.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/log_files -type f -name \"*.log\" | xargs grep -oE '([0-9]{1,3}\\.){3}[0-9]{1,3}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"project_logs\" containing several log files with the \".log\" extension. Each log file contains multiple lines of text, and some lines include the word \"ERROR\". Your task is to count the total number of lines across all these log files that contain the word \"ERROR\". Assume all log files are plain text and use case-sensitive matching for \"ERROR\".",
        "explanation": "To solve this problem, you can use a combination of `grep` to search for lines containing the word \"ERROR\" and `wc -l` to count the number of such lines. The command should be executed in such a way that it processes all log files within the \"project_logs\" directory.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"ERROR\" ~/project_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"INFO: Starting process\\nERROR: Failed to start\\nINFO: Process completed\" > ~/project_logs/log1.log\necho -e \"DEBUG: Initializing\\nINFO: Running checks\\nERROR: Check failed\\nERROR: Something went wrong\" > ~/project_logs/log2.log\necho -e \"WARNING: Low disk space\\nINFO: Disk check completed\" > ~/project_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"ERROR\" ~/project_logs/*.log | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"data_logs\" in your home directory containing multiple text files with various extensions. Your task is to count the total number of lines across all files that have the \".log\" extension, but only include lines that contain the word \"ERROR\".",
        "explanation": "To solve this problem, you need to navigate to the \"data_logs\" directory and identify files with the \".log\" extension. For each of these files, filter out lines containing the word \"ERROR\" and count them. Summing up these counts from all relevant files will give you the final answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h 'ERROR' ~/data_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/data_logs\necho -e \"INFO: Start\\nERROR: Failed to load\\nINFO: Retry succeeded\" > ~/data_logs/system1.log\necho -e \"ERROR: Disk not found\\nWARNING: Low memory\\nERROR: Timeout occurred\" > ~/data_logs/system2.log\necho -e \"INFO: User logged in\\nINFO: User logged out\" > ~/data_logs/system3.txt\necho -e \"ERROR: Connection lost\\nERROR: Authentication failed\" > ~/data_logs/errors.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h 'ERROR' ~/data_logs/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named `/assignment` containing multiple text files and subdirectories. Your task is to determine the total number of lines across all text files directly within the `/assignment` directory, excluding any lines from text files in its subdirectories.",
        "explanation": "To solve this problem, you need to use Linux command-line utilities to count the lines only in files that are directly located in the specified directory. You can use tools like `find`, `wc`, and `grep` to achieve this by first listing all the relevant text files using `find` with appropriate options, and then counting their lines with `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use find to list only regular files directly in the `/assignment` directory,\n# then pipe them through xargs and wc to count lines.\nfind /assignment -maxdepth 1 -type f -name \"*.txt\" | xargs wc -l | grep total | awk '{print $1}'\n```",
        "create": {
            "init": "# Create the /assignment directory\nmkdir -p /assignment\n\n# Create some text files with random content\necho -e \"Hello World\\nThis is a test file\\nWith multiple lines\" > /assignment/file1.txt\necho -e \"Another file\\nWith some content\" > /assignment/file2.txt\n\n# Create a subdirectory with additional files (these should not be counted)\nmkdir -p /assignment/subdir\necho -e \"This is inside a subdirectory\\nAnd should not be counted\" > /assignment/subdir/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use find to list only regular files directly in the `/assignment` directory,\n# then pipe them through xargs and wc to count lines.\nfind /assignment -maxdepth 1 -type f -name \"*.txt\" | xargs wc -l | grep total | awk '{print $1}'"
        }
    },
    {
        "description": "You have a directory named \"project_files\" in your home directory containing various files and subdirectories. Your task is to count the total number of lines across all text files (.txt) that are directly within the \"project_files\" directory (not in its subdirectories). Consider only the files with a \".txt\" extension.",
        "explanation": "To solve this problem, you will need to navigate to the \"project_files\" directory, list all files with a \".txt\" extension, and count the number of lines in each file. You can use commands like `find`, `wc`, and `grep` to achieve this. Note that you should avoid counting lines from text files located in any subdirectories within \"project_files\".\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/project_files\nfind . -maxdepth 1 -name \"*.txt\" -exec wc -l {} + | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "mkdir -p ~/project_files\necho -e \"Line 1\\nLine 2\\nLine 3\" > ~/project_files/file1.txt\necho -e \"Line A\\nLine B\" > ~/project_files/file2.txt\necho -e \"This is a test line.\" > ~/project_files/testfile.docx\nmkdir -p ~/project_files/subdir\necho -e \"Subdir Line 1\\nSubdir Line 2\" > ~/project_files/subdir/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/project_files\nfind . -maxdepth 1 -name \"*.txt\" -exec wc -l {} + | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "You are provided with a directory named `process_logs` containing multiple log files. Each log file records the start time and end time of various processes in the format: \"ProcessID StartTime EndTime\". You need to determine which process has the longest execution time across all log files in this directory. You should output only the ProcessID of that process.",
        "explanation": "To solve this problem, you need to iterate through each file in the `process_logs` directory and read each line to extract the ProcessID, StartTime, and EndTime. Calculate the execution time for each process by subtracting StartTime from EndTime. Keep track of the maximum execution time encountered and its corresponding ProcessID. In case of a tie (two or more processes having the same maximum execution time), you should choose the first one encountered.\n\nYou can use this command pattern to perform the task:\n\n```bash\nmax_time=0\nmax_pid=\"\"\nfor file in process_logs/*; do\n    while read line; do\n        pid=$(echo $line | awk '{print $1}')\n        start=$(echo $line | awk '{print $2}')\n        end=$(echo $line | awk '{print $3}')\n        duration=$((end - start))\n        if [ $duration -gt $max_time ]; then\n            max_time=$duration\n            max_pid=$pid\n        fi\n    done < \"$file\"\ndone\n\necho \"$max_pid\"\n```",
        "create": {
            "init": "mkdir -p process_logs\necho -e \"101 1615468800 1615472400\\n102 1615480000 1615483600\" > process_logs/log1.txt\necho -e \"201 1615490000 1615493600\\n202 1615500000 1615507200\" > process_logs/log2.txt\necho -e \"301 1615510000 1615517200\\n302 1615520000 1615528000\" > process_logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "max_time=0\nmax_pid=\"\"\nfor file in process_logs/*; do\n    while read line; do\n        pid=$(echo $line | awk '{print $1}')\n        start=$(echo $line | awk '{print $2}')\n        end=$(echo $line | awk '{print $3}')\n        duration=$((end - start))\n        if [ $duration -gt $max_time ]; then\n            max_time=$duration\n            max_pid=$pid\n        fi\n    done < \"$file\"\ndone\n\necho \"$max_pid\""
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory, which contains multiple log files with the \".log\" extension. Each log file contains various logged events in the format: `timestamp - event_type - message`. Your task is to count the total number of unique event types across all log files in the \"log_files\" directory and output that number.",
        "explanation": "To solve this problem, you need to process each \".log\" file in the \"log_files\" directory. You can use tools like `grep` or `awk` to extract the event types from each line. Then, use `sort` and `uniq` to find unique event types and count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the home directory where the \"log_files\" directory is located.\ncd ~ \n\n# Extract all event types from each .log file and find unique ones.\ngrep '^[0-9]' log_files/*.log | awk '{print $4}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\ncat <<EOL > ~/log_files/system.log\n2023-10-01 10:00:00 - ERROR - Failed to load module\n2023-10-01 10:05:00 - INFO - Module loaded successfully\n2023-10-01 10:10:00 - WARN - Low memory warning\nEOL\n\ncat <<EOL > ~/log_files/application.log\n2023-10-01 11:00:00 - INFO - User logged in\n2023-10-01 11:05:00 - ERROR - Database connection failed\n2023-10-01 11:15:00 - DEBUG - Debugging mode active\nEOL\n\ncat <<EOL > ~/log_files/security.log\n2023-10-01 12:00:00 - ALERT - Unauthorized access attempt detected\n2023-10-01 12:05:00 - INFO - Security protocols updated successfully\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to the home directory where the \"log_files\" directory is located.\ncd ~ \n\n# Extract all event types from each .log file and find unique ones.\ngrep '^[0-9]' log_files/*.log | awk '{print $4}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_files\" in your home directory, which contains multiple text files. Each file consists of lines with varying lengths. Your task is to determine the total number of lines across all files in this directory that contain the word \"error\" (case-insensitive). You may assume that the directory only contains text files and no subdirectories.",
        "explanation": "To solve this problem, you should iterate over each file in the \"project_files\" directory, read each line of the file, and check if it contains the word \"error\" in any case (e.g., ERROR, Error). Use utilities like `grep` with case-insensitive flag to filter such lines and then count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all lines containing 'error' (case-insensitive) and count them.\ngrep -i 'error' ~/project_files/* | wc -l\n```",
        "create": {
            "init": "# Create project_files directory\nmkdir -p ~/project_files\n\n# Create sample text files with random content\necho -e \"This is a test line.\\nAnother line.\\nError: something went wrong.\" > ~/project_files/file1.txt\necho -e \"No issues here.\\nJust a warning.\\nERROR found!\" > ~/project_files/file2.txt\necho -e \"All clear.\\nNothing to report here.\" > ~/project_files/file3.txt\necho -e \"An error occurred.\\nPlease check logs for ERROR details.\" > ~/project_files/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all lines containing 'error' (case-insensitive) and count them.\ngrep -i 'error' ~/project_files/* | wc -l"
        }
    },
    {
        "description": "On your Linux system, there is a directory named `project_logs` in your home directory containing multiple log files with the `.log` extension. Each log file contains lines of text where each line starts with a timestamp followed by a message. Your task is to find out how many unique error messages (lines that contain the word \"ERROR\") exist in all the log files combined. Provide the count of these unique error messages.",
        "explanation": "To solve this problem, you should first locate all the `.log` files within the `project_logs` directory. Then, filter out lines containing the word \"ERROR\" from each file. Using tools like `grep`, `awk`, or `sed` can help extract these lines efficiently. Once you have all error messages extracted, use a tool like `sort` and `uniq` to count only distinct error messages across all logs.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h 'ERROR' ~/project_logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho \"2023-10-01 12:00:00 INFO Starting process\" > ~/project_logs/log1.log\necho \"2023-10-01 12:01:00 ERROR Failed to start service\" >> ~/project_logs/log1.log\necho \"2023-10-01 12:02:00 ERROR Configuration missing\" >> ~/project_logs/log1.log\necho \"2023-10-02 13:00:00 INFO Running diagnostics\" > ~/project_logs/log2.log\necho \"2023-10-02 13:01:00 ERROR Disk space low\" >> ~/project_logs/log2.log\necho \"2023-10-02 13:02:00 ERROR Failed to start service\" >> ~/project_logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h 'ERROR' ~/project_logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" (case-insensitive) in all `.log` files located in the `/var/logs/student_logs` directory. You should consider only files that are non-empty and were last modified within the past 7 days.",
        "explanation": "To solve this problem, you'll need to use several bash commands together. Start by listing all `.log` files in the `/var/logs/student_logs` directory. Use `find` with conditions to filter out only those files that are non-empty and have been modified in the last 7 days. Then, for each of these files, use `grep -i \"error\"` to search for lines containing \"error\" (ignoring case) and use `wc -l` to count these lines. Finally, sum up all counts from each file.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find .log files modified within the last 7 days and are non-empty.\nfiles=$(find /var/logs/student_logs -type f -name \"*.log\" ! -empty -mtime -7)\n\ntotal_lines=0\n\nfor file in $files; do\n  # Count lines with 'error' case-insensitively in each file.\n  count=$(grep -i \"error\" \"$file\" | wc -l)\n  \n  # Sum up counts from all eligible log files.\n  total_lines=$((total_lines + count))\ndone\n\necho $total_lines\n```",
        "create": {
            "init": "#!/bin/bash\n# Create directories if they don't exist\nmkdir -p /var/logs/student_logs\n\n# Create some log files with different scenarios\necho -e \"Error: Something went wrong\\nInfo: All is good\\nERROR: Critical failure\" > /var/logs/student_logs/file1.log\necho -e \"Warning: This is a warning\\nerror: Minor issue detected\" > /var/logs/student_logs/file2.log\necho -e \"\" > /var/logs/student_logs/empty_file.log\n\n# Touch some old logs (older than 7 days)\ntouch -d '10 days ago' /var/logs/student_logs/old_file.log\n\n# Modify timestamps of valid logs within 7 days.\ntouch /var/logs/student_logs/file1.log\ntouch /var/logs/student_logs/file2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find .log files modified within the last 7 days and are non-empty.\nfiles=$(find /var/logs/student_logs -type f -name \"*.log\" ! -empty -mtime -7)\n\ntotal_lines=0\n\nfor file in $files; do\n  # Count lines with 'error' case-insensitively in each file.\n  count=$(grep -i \"error\" \"$file\" | wc -l)\n  \n  # Sum up counts from all eligible log files.\n  total_lines=$((total_lines + count))\ndone\n\necho $total_lines"
        }
    },
    {
        "description": "You are given a directory named \"project_files\" containing multiple text files. Some of these files may contain duplicate lines. Your task is to count the total number of unique lines across all files in the \"project_files\" directory. You should ignore case when determining uniqueness, meaning 'Line' and 'line' should be considered the same.",
        "explanation": "To solve this problem, you need to iterate over each file in the \"project_files\" directory, read its contents, and collect all unique lines regardless of case sensitivity. This can be done using utilities like `cat`, `sort`, `uniq`, and `tr` to normalize line cases and find unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Concatenate all files, convert to lowercase, sort, remove duplicates and count unique lines.\ncat project_files/* | tr '[:upper:]' '[:lower:]' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create the project_files directory\nmkdir -p project_files\n\n# Create some sample text files with potential duplicate lines\necho -e \"Hello World\\nhello world\\nHELLO WORLD\\nUnique Line 1\\nCommon Line\" > project_files/file1.txt\necho -e \"Another Unique Line\\nCOMMON LINE\\ncommon line\\nNew Line\" > project_files/file2.txt\necho -e \"Duplicate Line\\nduplicate line\\nAnother Unique Line Again\" > project_files/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Concatenate all files, convert to lowercase, sort, remove duplicates and count unique lines.\ncat project_files/* | tr '[:upper:]' '[:lower:]' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory `/var/logs/` containing multiple log files with the extension `.log`. Each log file contains lines in the format: `YYYY-MM-DD HH:MM:SS [LOG_LEVEL] Message`. Your task is to count how many log entries in total are of the `[ERROR]` level across all `.log` files in this directory.",
        "explanation": "To solve this problem, you need to iterate through each `.log` file in the `/var/logs/` directory and filter out lines that contain `[ERROR]`. You can use utilities such as `grep` to search for `[ERROR]` entries and `wc -l` to count them. Summing up these counts will give you the total number of `[ERROR]` entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ntotal_errors=$(grep -r '\\[ERROR\\]' /var/logs/*.log | wc -l)\necho $total_errors\n```",
        "create": {
            "init": "mkdir -p /var/logs/\necho -e \"2023-01-01 12:00:00 [INFO] Starting process\\n2023-01-01 12:05:00 [ERROR] Something went wrong\\n2023-01-01 12:10:00 [WARN] Low memory\" > /var/logs/system.log\necho -e \"2023-01-02 14:00:00 [INFO] Process running smoothly\\n2023-01-02 14:05:00 [ERROR] Failed to connect\\n2023-01-02 14:10:00 [DEBUG] Debugging information\" > /var/logs/network.log\necho -e \"2023-01-03 16:00:00 [ERROR] Disk space low\\n2023-01-03 16:05:00 [INFO] Cleanup started\" > /var/logs/storage.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "total_errors=$(grep -r '\\[ERROR\\]' /var/logs/*.log | wc -l)\necho $total_errors"
        }
    },
    {
        "description": "You have a directory named `logs` in your home directory that contains multiple `.log` files. Each log file records various events, and each line in a log file starts with a timestamp in the format `YYYY-MM-DD HH:MM:SS`. Your task is to determine how many unique dates are present across all the log files. Assume that the timestamps are always valid and well-formed.",
        "explanation": "To solve this problem, you need to perform several steps:\n1. Navigate to the `logs` directory.\n2. Extract the date portion from each line of every `.log` file.\n3. Collect all unique dates from these lines.\n4. Count the number of unique dates.\n\nYou can use utilities such as `awk`, `cut`, `sort`, and `uniq` to accomplish this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\n\n# Extract dates, sort them, get unique values, count them.\nawk '{print $1}' *.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create the logs directory\nmkdir -p ~/logs\n\n# Create sample log files with timestamps\ncat > ~/logs/log1.log <<EOL\n2023-10-01 12:00:00 Event A occurred\n2023-10-01 15:30:00 Event B occurred\n2023-10-02 09:45:00 Event C occurred\nEOL\n\ncat > ~/logs/log2.log <<EOL\n2023-10-02 11:20:00 Event D occurred\n2023-10-03 14:15:00 Event E occurred\n2023-10-03 18:40:00 Event F occurred\nEOL\n\ncat > ~/logs/log3.log <<EOL\n2023-10-04 07:00:00 Event G occurred\n2023-10-05 08:30:00 Event H occurred\n2023-10-01 22:15:00 Event I occurred\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\n\n# Extract dates, sort them, get unique values, count them.\nawk '{print $1}' *.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple text files with log entries. Each entry is formatted as \"YYYY-MM-DD HH:MM:SS [ERROR] Description of the error\". Your task is to count how many unique dates have error logs in this directory. Note that the date should be extracted from each log entry.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and extract the date portion (YYYY-MM-DD) from each line that contains \"[ERROR]\". Use tools like `grep` to filter lines with \"[ERROR]\", `cut` or `awk` to extract dates, and finally use `sort` and `uniq` to count unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep \"\\[ERROR\\]\" *.txt | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/log1.txt\n2023-01-01 12:00:00 [ERROR] Something went wrong.\n2023-01-02 13:15:10 [INFO] All systems operational.\n2023-01-02 14:20:30 [ERROR] Failed to connect.\n2023-01-03 09:45:50 [ERROR] Missing file detected.\nEOL\n\ncat <<EOL > ~/logs/log2.txt\n2023-01-03 10:25:20 [WARNING] Low disk space.\n2023-01-04 16:30:00 [ERROR] Unauthorized access attempt.\n2023-01-05 11:00:00 [INFO] System rebooted successfully.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep \"\\[ERROR\\]\" *.txt | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Identify the total number of unique file types (based on file extensions) present in the \"/var/log\" directory and subdirectories. Exclude files without an extension from your count.",
        "explanation": "To solve this problem, you need to traverse through the \"/var/log\" directory and its subdirectories, listing all files. You can then extract the extensions of these files, filter out any files that do not have an extension, and finally count the unique extensions. Tools like `find`, `awk`, `grep`, `sort`, and `uniq` will be helpful here.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all files in /var/log, extract their extensions, exclude those without an extension,\n# sort them uniquely, and count the number of unique extensions.\n\nfind /var/log -type f | awk -F. '/\\./ {print $NF}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# No initialization script is necessary as it uses existing system logs."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all files in /var/log, extract their extensions, exclude those without an extension,\n# sort them uniquely, and count the number of unique extensions.\n\nfind /var/log -type f | awk -F. '/\\./ {print $NF}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.config`. Your task is to count the number of unique words that appear in this file. Words are separated by spaces, and you should ignore case differences (e.g., \"Word\" and \"word\" should be considered the same).",
        "explanation": "To solve this problem, you need to first locate the hidden file `.config` in your home directory. Then, read its contents while converting all text to lowercase to ensure case-insensitivity. Afterward, split the contents into individual words and determine the number of unique words using a set or similar method.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\ntr '[:upper:]' '[:lower:]' < ~/.config | tr -s ' ' '\\n' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a hidden .config file in each student's home directory with sample content\ncat <<EOL > ~/.config\nThis is a test configuration File.\nThe purpose of this CONFIG file is for testing.\nTesting is important for validation.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\ntr '[:upper:]' '[:lower:]' < ~/.config | tr -s ' ' '\\n' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files, each named in the format \"log_YYYYMMDD.txt\", where YYYYMMDD represents the date of the logs. Your task is to find out how many unique IP addresses accessed the server on the date \"20230115\". Assume that each line in the log files follows the pattern \"IP_Address - - [Timestamp] Request\", where IP_Address represents an IPv4 address.",
        "explanation": "To solve this problem, you need to filter out entries from the file \"log_20230115.txt\" and extract unique IP addresses. You can use commands such as `grep` to target lines by date if necessary (though not needed here since we know the exact file), `awk` or `cut` to isolate IP addresses, and `sort` combined with `uniq` to determine uniqueness.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{print $1}' ~/logs/log_20230115.txt | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat > ~/logs/log_20230115.txt <<EOL\n192.168.1.1 - - [15/Jan/2023:10:00:00 +0000] \"GET /index.html HTTP/1.1\"\n192.168.1.2 - - [15/Jan/2023:10:05:00 +0000] \"POST /form HTTP/1.1\"\n192.168.1.3 - - [15/Jan/2023:10:10:00 +0000] \"GET /contact.html HTTP/1.1\"\n192.168.1.2 - - [15/Jan/2023:10:20:00 +0000] \"GET /index.html HTTP/1.1\"\n192.168.1.4 - - [15/Jan/2023:11:00:00 +0000] \"GET /about.html HTTP/1.1\"\n192.168.1.5 - - [15/Jan/2023:11:30:00 +0000] \"GET /shop.html HTTP/1.1\"\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{print $1}' ~/logs/log_20230115.txt | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines across all `.txt` files in the `/home/student/documents` directory and its subdirectories. You must only count lines from files that have been modified in the last 7 days. Filter out any empty lines before counting.",
        "explanation": "To solve this problem, you need to navigate through the `/home/student/documents` directory and its subdirectories to identify all `.txt` files. Then, check each file's modification date to ensure it falls within the last 7 days. Use a combination of `find`, `xargs`, `grep`, and `wc` utilities to filter out empty lines and count the total number of non-empty lines in these files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -name \"*.txt\" -mtime -7 | xargs grep . | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents/subdir1\nmkdir -p /home/student/documents/subdir2\n\necho -e \"Hello\\n\\nWorld\" > /home/student/documents/file1.txt\necho -e \"This is a test\\n\\n\" > /home/student/documents/file2.txt\necho -e \"\\nAnother test line\" > /home/student/documents/subdir1/file3.txt\necho -e \"More tests\\nAnd more\\n\" > /home/student/documents/subdir2/file4.txt\n\n# Update modification time for recent files\ntouch -d \"2 days ago\" /home/student/documents/file1.txt\ntouch -d \"6 days ago\" /home/student/documents/file2.txt\n\n# These files should not be counted as they fall outside of 7-day window or are empty:\ntouch -d \"8 days ago\" /home/student/documents/subdir1/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -name \"*.txt\" -mtime -7 | xargs grep . | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory that contains multiple log files with the \".log\" extension. Each log file consists of timestamps and various event messages recorded throughout the day. Your task is to count the total number of unique IP addresses that appear in these log files. Assume each line in the log files starts with an IP address followed by a timestamp and a message.",
        "explanation": "To solve this problem, you need to extract the IP addresses from each line of all the log files within the \"logs\" directory, filter out duplicates to get unique IPs, and then count how many unique IP addresses there are. You can use commands like `cat`, `awk`, `sort`, and `uniq` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 2023-10-01 12:00:00 Event A\\n192.168.1.2 2023-10-01 12:05:00 Event B\\n192.168.1.1 2023-10-01 12:10:00 Event C\" > ~/logs/log1.log\necho -e \"192.168.1.3 2023-10-01 13:00:00 Event D\\n192.168.1.2 2023-10-01 13:05:00 Event E\\n192.168.1.4 2023-10-01 13:10:00 Event F\" > ~/logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"company_data\" in your home directory containing multiple subdirectories for each department (e.g., \"sales\", \"engineering\", \"hr\"). Inside each department directory, you will find text files that log employee work hours in the format \"employee_name_hours.log\". Your task is to find out the total number of unique employees across all departments who have logged more than 40 hours in any given week. Assume each log file contains lines with the format: \"WeekStartDate HoursLogged\" (e.g., \"2023-01-01 45\").",
        "explanation": "To solve this problem, you should first list all the log files within the subdirectories of \"company_data\". For each file, parse the contents to identify weeks where an employee logged more than 40 hours. Track unique employees across different departments and count how many meet this criterion.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all log files and their contents\nfind ~/company_data -type f -name \"*.log\" | while read file; do awk '$2 > 40 {print FILENAME}' $file; done | sed 's#.*/##' | cut -d'_' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/company_data/{sales,engineering,hr}\necho -e \"2023-01-01 45\\n2023-01-08 38\\n2023-01-15 42\" > ~/company_data/sales/alice_hours.log\necho -e \"2023-01-01 41\\n2023-01-08 36\" > ~/company_data/engineering/bob_hours.log\necho -e \"2023-01-15 39\\n2023-01-22 45\" > ~/company_data/hr/charlie_hours.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# List all log files and their contents\nfind ~/company_data -type f -name \"*.log\" | while read file; do awk '$2 > 40 {print FILENAME}' $file; done | sed 's#.*/##' | cut -d'_' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing the system log files in the `/var/log` directory. Specifically, you need to determine how many unique IP addresses have attempted to access the system as recorded in `auth.log` for failed login attempts. You should consider only those entries that mention \"Failed password\". Your answer should be the count of these unique IP addresses.",
        "explanation": "To solve this problem, you will need to interact with the file located at `/var/log/auth.log`. Use tools like `grep` to filter lines containing \"Failed password\", and then extract the IP addresses using `awk` or another text processing tool. Finally, utilize `sort` and `uniq` to count the number of distinct IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script that counts unique IPs from failed login attempts.\ngrep \"Failed password\" /var/log/auth.log | awk '{print $(NF-3)}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Creating a sample auth.log file with failed login attempts for testing.\nmkdir -p /var/log\ncat <<EOL > /var/log/auth.log\nJan  1 00:00:01 ubuntu sshd[12345]: Failed password for invalid user test from 192.168.1.10 port 22 ssh2\nJan  1 00:01:01 ubuntu sshd[12346]: Failed password for invalid user admin from 192.168.1.20 port 22 ssh2\nJan  1 00:02:01 ubuntu sshd[12347]: Failed password for invalid user guest from 192.168.1.10 port 22 ssh2\nJan  1 00:03:01 ubuntu sshd[12348]: Failed password for root from 192.168.1.30 port 22 ssh2\nJan  1 00:04:01 ubuntu sshd[12349]: Failed password for invalid user test from 192.168.1.40 port 22 ssh2\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script that counts unique IPs from failed login attempts.\ngrep \"Failed password\" /var/log/auth.log | awk '{print $(NF-3)}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there are several log files with the \".log\" extension. Each log file contains multiple lines, and each line records a timestamp followed by an event description. Your task is to find out how many unique events occurred on the most recent day for which there is a recorded event. You should consider only the date part of the timestamp in \"YYYY-MM-DD\" format.",
        "explanation": "To solve this problem, you can start by listing all the \".log\" files in your home directory. Then, extract and sort all timestamps to identify the most recent date. Once you have identified this date, filter out lines from all log files that match it, extract unique event descriptions, and count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\n\n# Find all .log files in the home directory\nfiles=$(find ~ -maxdepth 1 -name \"*.log\")\n\n# Extract all timestamps and sort them to find the most recent date\nmost_recent_date=$(awk '{print $1}' $files | sort | uniq | tail -n1)\n\n# Filter lines matching the most recent date and count unique events\nunique_event_count=$(grep \"$most_recent_date\" $files | awk '{$1=\"\"; print $0}' | sort | uniq | wc -l)\n\necho $unique_event_count\n```",
        "create": {
            "init": "# Create sample log files in the user's home directory for testing\necho -e \"2023-10-01 12:00:01 Event A\\n2023-10-02 14:45:00 Event B\\n2023-10-02 15:30:00 Event C\" > ~/event1.log\necho -e \"2023-10-01 09:05:12 Event D\\n2023-10-03 08:22:45 Event A\\n2023-10-03 11:19:22 Event E\" > ~/event2.log\necho -e \"2023-10-02 17:11:55 Event F\\n2023-10-03 12:34:56 Event G\\n2023-10-03 13:47:23 Event H\" > ~/event3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\n\n# Find all .log files in the home directory\nfiles=$(find ~ -maxdepth 1 -name \"*.log\")\n\n# Extract all timestamps and sort them to find the most recent date\nmost_recent_date=$(awk '{print $1}' $files | sort | uniq | tail -n1)\n\n# Filter lines matching the most recent date and count unique events\nunique_event_count=$(grep \"$most_recent_date\" $files | awk '{$1=\"\"; print $0}' | sort | uniq | wc -l)\n\necho $unique_event_count"
        }
    },
    {
        "description": "In your home directory, find all text files that were modified in the last 7 days and contain the word \"Linux\". Count the total number of lines across these files. Your answer should be the total count of lines.",
        "explanation": "To solve this problem, you need to perform a few steps: \n1. List all text files in your home directory that have been modified in the last 7 days. You can use `find` with options like `-mtime` and `-name \"*.txt\"`.\n2. Use `grep` to filter out files containing the word \"Linux\".\n3. Count the number of lines in those filtered files using tools like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all text files modified within the last 7 days containing \"Linux\"\ntotal_lines=$(find ~ -maxdepth 1 -name \"*.txt\" -mtime -7 | xargs grep -l \"Linux\" | xargs wc -l | tail -n 1 | awk '{print $1}')\necho $total_lines\n```",
        "create": {
            "init": "# Create some example text files for testing\necho \"This is a test file related to Linux.\" > ~/test1.txt\necho \"Another file with Linux content.\" > ~/test2.txt\necho \"No relevant content here.\" > ~/test3.txt\n\n# Set modification times for demonstration purposes (last 7 days)\ntouch -m -d '3 days ago' ~/test1.txt\ntouch -m -d '5 days ago' ~/test2.txt\ntouch -m -d '8 days ago' ~/test3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all text files modified within the last 7 days containing \"Linux\"\ntotal_lines=$(find ~ -maxdepth 1 -name \"*.txt\" -mtime -7 | xargs grep -l \"Linux\" | xargs wc -l | tail -n 1 | awk '{print $1}')\necho $total_lines"
        }
    },
    {
        "description": "You are tasked to find out how many files within the '/var/log' directory have been modified in the last 7 days. Only count regular files, not directories or symbolic links.",
        "explanation": "To solve this problem, you can use the `find` command. The `-type f` option ensures only regular files are considered. The `-mtime -7` option filters files modified in the last 7 days. You can use a combination of commands to count these files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Using find to locate and count regular files modified in the last 7 days\ncount=$(find /var/log -type f -mtime -7 | wc -l)\necho $count\n```",
        "create": {
            "init": "# No initialization is required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Using find to locate and count regular files modified in the last 7 days\ncount=$(find /var/log -type f -mtime -7 | wc -l)\necho $count"
        }
    },
    {
        "description": "You need to find out the total size of all the files in your home directory that have been modified in the last 7 days. Provide your answer in a human-readable format (e.g., KB, MB).",
        "explanation": "To solve this problem, you can use the `find` command with appropriate options to search for files modified in the last 7 days. Then, use `du` or similar commands to calculate their total size. The `-exec` option of `find` or piping to `xargs` can be useful for processing each file found.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find and sum sizes of files modified within the last 7 days in human-readable format\n\nfind ~ -maxdepth 1 -type f -mtime -7 -exec du -ch {} + | grep total$ | cut -f1\n```",
        "create": {
            "init": "# Create some sample files with different modification times\nmkdir -p ~/test_files\ntouch ~/test_files/file1.txt\nsleep 1\ntouch -d \"3 days ago\" ~/test_files/file2.txt\nsleep 1\ntouch -d \"10 days ago\" ~/test_files/file3.txt\n\n# Add random content to each file to give them size\necho \"Sample content for file1\" > ~/test_files/file1.txt\necho \"Sample content for file2\" > ~/test_files/file2.txt\necho \"Sample content for file3\" > ~/test_files/file3.txt\n\n# Move these test files to the home directory for evaluation simplicity.\nmv ~/test_files/* ~/\nrm -r ~/test_files/"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "# Find and sum sizes of files modified within the last 7 days in human-readable format\n\nfind ~ -maxdepth 1 -type f -mtime -7 -exec du -ch {} + | grep total$ | cut -f1"
        }
    },
    {
        "description": "You are given a directory called \"logs\" in your home directory that contains multiple log files. Count how many distinct IP addresses have accessed the server, considering only those logs from files modified in the last 7 days.",
        "explanation": "To solve this problem, you need to perform several steps:  \n1. List all files in the \"logs\" directory and filter out those that have been modified more than 7 days ago using `find`.  \n2. Extract all unique IP addresses from the remaining log files. Each line in these log files begins with an IP address. You can use `awk` or `grep` to extract these addresses.  \n3. Use `sort` and `uniq` to ensure the list of IPs is distinct, then count them with `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find log files modified within the last 7 days and extract distinct IPs.\nfind ~/logs -type f -mtime -7 | xargs cat | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create logs directory and example log files with various modification times\n\nmkdir -p ~/logs\n\n# Create some log files\necho \"192.168.0.1 GET /index.html\" > ~/logs/log1.txt\necho \"10.0.0.5 POST /submit-form\" > ~/logs/log2.txt\necho \"172.16.0.3 GET /about.html\" > ~/logs/log3.txt\n\n# Touch command to modify timestamps of some files\ntouch -d \"2 days ago\" ~/logs/log1.txt\ntouch -d \"10 days ago\" ~/logs/log2.txt # This file should be ignored due to modification time\ntouch -d \"4 days ago\" ~/logs/log3.txt\n\n# Add more entries to existing logs for complexity\necho \"192.168.0.1 POST /login.html\" >> ~/logs/log1.txt\necho \"172.16.0.4 GET /contact.html\" >> ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find log files modified within the last 7 days and extract distinct IPs.\nfind ~/logs -type f -mtime -7 | xargs cat | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are required to find the total number of lines containing the word \"error\" (case-insensitive) in all `.log` files within a directory named `logs` located in your home directory. The task must be accomplished without altering any files, and you should ensure that only `.log` files are considered.",
        "explanation": "To solve this problem, you should:\n1. Navigate to the `logs` directory in your home directory.\n2. Use a combination of commands like `grep`, `find`, and `wc` to search for the word \"error\" in all `.log` files.\n3. Ensure that the search is case-insensitive and count how many lines contain the word \"error\".\n\nHints:\n- Use `find` to locate all `.log` files within the directory.\n- Utilize `grep -i` for case-insensitive search.\n- Use `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\nfind . -name \"*.log\" | xargs grep -i \"error\" | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"This is an error.\\nNo issues here.\\nAnother Error.\" > ~/logs/file1.log\necho -e \"Everything is fine.\\nERROR detected.\" > ~/logs/file2.log\necho -e \"Silent log.\" > ~/logs/silent.log\necho -e \"Error found\\nagain an error\" > ~/logs/errorfile.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\nfind . -name \"*.log\" | xargs grep -i \"error\" | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logfiles\" in your home directory containing several log files with a \".log\" extension. Each log file contains timestamps and messages. Your task is to find the total number of unique error messages (lines containing the word \"ERROR\") across all log files in this directory. Consider only case-sensitive matches for the word \"ERROR\".",
        "explanation": "To solve this problem, you need to iterate over each \".log\" file in the \"logfiles\" directory, search for lines that contain the exact string \"ERROR\", extract these lines, and then identify unique error messages from them. You can use tools like `grep`, `sort`, and `uniq` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR' ~/logfiles/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-10-01 10:00:00 INFO Starting process\\n2023-10-01 10:01:00 ERROR Unexpected shutdown\\n2023-10-01 10:02:00 INFO Process restarted\\n2023-10-01 10:03:00 ERROR Missing configuration file\" > ~/logfiles/app1.log\necho -e \"2023-10-02 11:00:00 WARNING Low memory\\n2023-10-02 11:05:00 ERROR Disk space critical\\n2023-10-02 11:06:00 INFO Memory freed\\n2023-10-02 11:07:00 ERROR Unexpected shutdown\" > ~/logfiles/app2.log\necho -e \"2023-09-30 09:30:00 ERROR Network timeout\\n2023-09-30 09:31:00 INFO Reconnecting\\n2023-09-30 09:32:00 ERROR Network timeout\" > ~/logfiles/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR' ~/logfiles/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" that contains multiple log files with the extension \".log\". Each log file contains timestamped entries of various events in the format \"YYYY-MM-DD HH:MM:SS - Event Message\". Your task is to find out how many unique days have entries in these log files. Assume the directory is located in your home directory.",
        "explanation": "To solve this problem, you need to extract the date part from each line in all the \".log\" files within the \"logs\" directory. You can use tools like `grep`, `awk`, or `sed` to parse and extract dates, and then use `sort` and `uniq` to count unique dates. Make sure to navigate to your home directory first if you're not already there.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep -hoE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' *.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 - Event A\\n2023-10-02 13:30:00 - Event B\\n2023-10-01 14:45:00 - Event C\" > ~/logs/log1.log\necho -e \"2023-10-03 09:15:00 - Event D\\n2023-10-02 16:20:00 - Event E\" > ~/logs/log2.log\necho -e \"2023-10-04 11:05:00 - Event F\\n2023-10-03 18:50:00 - Event G\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep -hoE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' *.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "On your Ubuntu system, find all files larger than 1MB in the /var/log directory that have been modified in the last 7 days. Count how many such files exist and provide the total number.",
        "explanation": "To solve this problem, you can use the `find` command with appropriate options to filter files by size and modification time. The `-size +1M` option helps to filter files larger than 1MB, and `-mtime -7` helps to find files modified within the last 7 days. Use `wc -l` to count the number of lines (files) returned by the `find` command.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -size +1M -mtime -7 | wc -l\n```",
        "create": {
            "init": "# Ensure there are some log files for testing purposes.\nmkdir -p /var/log/test_logs\ndd if=/dev/zero of=/var/log/test_logs/large_file1.log bs=2M count=1\ntouch -m -d \"3 days ago\" /var/log/test_logs/large_file1.log\ndd if=/dev/zero of=/var/log/test_logs/small_file.log bs=500K count=1\ntouch -m -d \"10 days ago\" /var/log/test_logs/small_file.log\ndd if=/dev/zero of=/var/log/test_logs/large_file2.log bs=2M count=1\ntouch -m -d \"5 days ago\" /var/log/test_logs/large_file2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/log -type f -size +1M -mtime -7 | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with a \".log\" extension. Each log file contains timestamped entries. Identify the most recent entry across all \".log\" files and output the date and time of this entry in the format \"YYYY-MM-DD HH:MM:SS\". Ensure that log entries are formatted consistently to allow for accurate comparisons.",
        "explanation": "To solve this problem, you should first navigate to the \"logs\" directory. Then, you can use utilities like `find` to list all \".log\" files and `cat` or `grep` to extract lines from these files. Use `sort` or similar tools to identify the most recent timestamp among all entries. Remember that timestamps are assumed to be in a parsable format (e.g., \"YYYY-MM-DD HH:MM:SS\"). Finally, print out just the most recent timestamp.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -name \"*.log\" -exec cat {} + | sort | tail -n 1 | awk '{print $1, $2}'\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 10:00:00 First entry\\n2023-02-01 12:30:00 Another entry\" > ~/logs/log1.log\necho -e \"2023-03-01 09:15:00 Entry\\n2023-04-01 14:45:00 Latest entry here\" > ~/logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "find ~/logs -name \"*.log\" -exec cat {} + | sort | tail -n 1 | awk '{print $1, $2}'"
        }
    },
    {
        "description": "You are tasked with analyzing log files in your home directory to determine network anomalies. Specifically, count how many times the IP address \"192.168.1.1\" appears in all `.log` files within your home directory, but only consider occurrences where the IP address is followed by the status code \"404\". Ensure your solution accounts for case sensitivity and ignores any other parts of the logs.",
        "explanation": "To solve this problem, you need to search through all `.log` files in your home directory for lines containing both the specific IP address \"192.168.1.1\" and the status code \"404\". You can use a combination of `grep` to search for lines that match both criteria and `wc -l` to count these occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find occurrences of '192.168.1.1' followed by '404' across all .log files in the home directory\ngrep '192\\.168\\.1\\.1.*404' ~/*.log | wc -l\n```",
        "create": {
            "init": "# Create sample .log files with relevant entries in the student's home directory\necho -e \"192.168.1.1 - - [10/Oct/2023:13:55:36] \\\"GET /index.html HTTP/1.0\\\" 200\\n192.168.1.1 - - [10/Oct/2023:13:56:01] \\\"GET /about.html HTTP/1.0\\\" 404\\n172.16.0.5 - - [10/Oct/2023:13:56:01] \\\"GET /contact.html HTTP/1.0\\\" 404\" > ~/example.log\necho -e \"192.168.2.50 - - [11/Oct/2023:14:22:59] \\\"POST /submit HTTP/1.0\\\" 500\\n192.168.1.1 - - [11/Oct/2023:14:23:01] \\\"GET /home.html HTTP/1.0\\\" 404\\n192.168.x.x - no valid ip here\" > ~/another_example.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find occurrences of '192.168.1.1' followed by '404' across all .log files in the home directory\ngrep '192\\.168\\.1\\.1.*404' ~/*.log | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" (case-insensitive) across all `.log` files in the `/var/logs` directory, but exclude lines that contain the word \"debug\" (case-insensitive).",
        "explanation": "To solve this problem, you can leverage the `grep` command with options for case-insensitive search and inverse matching. First, use `grep -i` to search for lines containing \"error\" in all `.log` files and then pipe it through `grep -vi` to exclude lines containing \"debug\". Finally, use `wc -l` to count the number of resulting lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' /var/logs/*.log | grep -vi 'debug' | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs\necho -e \"Error: something failed\\nDebug: minor issue\\nERROR: major failure\" > /var/logs/app1.log\necho -e \"System started\\nDEBUG: initialization complete\\nerror detected\" > /var/logs/system.log\necho -e \"error warning\\nall systems go\\nError in module\\nDebug mode active\" > /var/logs/status.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' /var/logs/*.log | grep -vi 'debug' | wc -l"
        }
    },
    {
        "description": "You are tasked with finding out how many unique words are present in a text file named \"sample.txt\" located in the current directory. Consider words to be case-insensitive and ignore punctuation.",
        "explanation": "To solve this problem, you need to read the contents of \"sample.txt\", convert all text to lowercase, remove any punctuation, split the text into individual words, and then count the number of unique words. You can use tools like `tr`, `sed`, `sort`, `uniq`, and `wc` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat sample.txt | tr '[:upper:]' '[:lower:]' | tr -d '[:punct:]' | tr ' ' '\\n' | sort | uniq | wc -l\n```",
        "create": {
            "init": "echo \"Hello, World! This is a test. Hello world.\" > sample.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat sample.txt | tr '[:upper:]' '[:lower:]' | tr -d '[:punct:]' | tr ' ' '\\n' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have been provided with a directory named \"log_files\" in your home directory containing multiple log files with the extension \".log\". Each log file contains timestamped entries in the format \"YYYY-MM-DD HH:MM:SS - Event Message\". Your task is to determine the number of unique dates present across all log files. Assume no broken or irregular lines exist in the logs.",
        "explanation": "To solve this problem, you should read through each log file in the \"log_files\" directory, extract the date from each entry, and keep track of unique dates. You can use tools like `cat`, `awk`, `sort`, and `uniq` to filter and count these unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/log_files -type f -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-10-01 12:00:00 - System start\\n2023-10-01 12:05:00 - User login\\n2023-10-02 08:00:00 - Scheduled backup\" > ~/log_files/system.log\necho -e \"2023-10-01 09:30:00 - Disk check\\n2023-10-03 11:45:00 - Update installed\" > ~/log_files/maintenance.log\necho -e \"2023-10-02 14:20:00 - Error reported\\n2023-10-03 15:22:00 - Error resolved\\n2023-10-04 17:50:00 - User logout\" > ~/log_files/errors.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/log_files -type f -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_files\" containing various files of different types (e.g., .txt, .log, .conf, .sh). Your task is to find and count the number of unique file extensions present in this directory, excluding hidden files. Consider only files directly within \"project_files\" and not in any subdirectories.",
        "explanation": "To solve this problem, you need to list all files in the \"project_files\" directory, extract their extensions, and count how many unique extensions exist. You can use commands like `ls`, `awk`, `grep`, or `sed` to filter and process file names. Remember to exclude hidden files (those starting with a dot) from your consideration.\n\nYou can use this command pattern to perform the task:\n\n```bash\nls project_files | grep -v '^\\.' | awk -F. '{if (NF>1) print $NF}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p project_files\ntouch project_files/file1.txt project_files/file2.txt\ntouch project_files/readme.md project_files/config.conf\ntouch project_files/script.sh project_files/data.log\ntouch project_files/.hidden_file .hidden_file_in_root"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "ls project_files | grep -v '^\\.' | awk -F. '{if (NF>1) print $NF}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logfiles\" in your home directory that contains various log files with the \".log\" extension. Each log file records events with timestamps, and some lines include the keyword \"ERROR\". Your task is to count how many lines contain the keyword \"ERROR\" across all log files in the \"logfiles\" directory. You must use shell commands to accomplish this.",
        "explanation": "To solve this problem, you can use a combination of `grep` and `wc` commands. First, use `grep` to search for lines containing \"ERROR\" within all \".log\" files in the \"logfiles\" directory. Then, pipe the result to `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/logfiles/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-10-01 12:00:00 INFO Start\\n2023-10-01 12:05:00 ERROR Something went wrong\\n2023-10-01 12:10:00 INFO Continue\\n2023-10-01 12:15:00 ERROR Another issue detected\" > ~/logfiles/app1.log\necho -e \"2023-10-02 13:00:00 INFO Start\\n2023-10-02 13:30:00 ERROR Failed operation\\n2023-10-02 14:00:00 INFO Normal operation\\n2023-10-02 14:30:00 ERROR Critical failure\" > ~/logfiles/app2.log\necho -e \"2023-10-03 15:00:00 INFO Begin session\\n2023-10-03 15:20:00 WARNING Low memory\\n2023-10-03 15:40:00 ERROR Memory leak detected\\n2023-10-03 16:00:00 INFO Session ended\" > ~/logfiles/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/logfiles/*.log | wc -l"
        }
    },
    {
        "description": "You have been provided with a directory named \"logs\" containing numerous log files with the \".log\" extension. Each log file contains multiple lines, and some lines contain IP addresses in the standard IPv4 format (e.g., 192.168.1.1). Your task is to count how many unique IP addresses appear across all these log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to iterate over each log file in the \"logs\" directory, extract all IPv4 addresses from each file, and determine the number of unique IPs across all files. You can use tools like `grep` or `awk` for pattern matching to identify IP addresses and `sort` combined with `uniq` to count them uniquely.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '([0-9]{1,3}\\.){3}[0-9]{1,3}' logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir logs\necho -e \"Connection from 192.168.1.1\\nConnection from 10.0.0.2\\nConnection from 192.168.1.1\" > logs/log1.log\necho -e \"Error at 172.16.0.3\\nUser login from 10.0.0.2\\nAccess granted to 192.168.1.4\" > logs/log2.log\necho -e \"Attempted access by 192.168.1.5\\nError at 172.16.0.3\\nUser logout from 10.0.0.x\" > logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '([0-9]{1,3}\\.){3}[0-9]{1,3}' logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to find the total number of lines across all `.txt` files in the `/home/ubuntu/textfiles` directory that contain the word \"Linux\". Only count lines where \"Linux\" appears as a standalone word, case-sensitive.",
        "explanation": "To solve this problem, you need to iterate through all `.txt` files in the specified directory and search for lines containing the word \"Linux\" as a standalone word. You can use `grep` with appropriate options to match whole words and count occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -w 'Linux' /home/ubuntu/textfiles/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/ubuntu/textfiles\necho -e \"This line mentions Linux.\\nThis one doesn't.\\nAnother Linux line.\" > /home/ubuntu/textfiles/file1.txt\necho -e \"A line with linux but not Linux.\\nJust another line.\\nLinux here again.\" > /home/ubuntu/textfiles/file2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -w 'Linux' /home/ubuntu/textfiles/*.txt | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named \".filedata\" containing several lines of text. Some lines are duplicated multiple times. Count the number of unique lines in this file without considering case differences (i.e., treat \"Line\" and \"line\" as the same).",
        "explanation": "To solve this problem, you need to read the contents of the \".filedata\" file, convert all lines to lowercase to ignore case differences, and then identify unique lines. You can use a combination of `cat`, `tr`, `sort`, and `uniq` commands to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/.filedata | tr '[:upper:]' '[:lower:]' | sort | uniq | wc -l\n```",
        "create": {
            "init": "echo -e \"Apple\\nBanana\\napple\\nBANANA\\nCherry\\ncherry\\nDate\\ndate\\ndate\" > ~/.filedata"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/.filedata | tr '[:upper:]' '[:lower:]' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"system_logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains various system activity logs with timestamps. Your task is to count the total number of error entries (lines containing the word \"ERROR\") across all these log files and report the count.",
        "explanation": "To solve this problem, you need to search through all files in the \"system_logs\" directory for lines that contain the word \"ERROR\" and count them. You can achieve this by using tools like `grep` to filter lines containing \"ERROR\" and `wc` to count them. You will need to handle multiple files at once, which may involve using shell globbing patterns or looping through each file.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/system_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/system_logs\necho \"2023-10-01 10:00:00 INFO Starting system check\" > ~/system_logs/log1.log\necho \"2023-10-01 10:05:00 ERROR Failed to load module\" >> ~/system_logs/log1.log\necho \"2023-10-01 11:00:00 INFO System running smoothly\" >> ~/system_logs/log1.log\necho \"2023-10-02 09:30:00 ERROR Connection timeout\" > ~/system_logs/log2.log\necho \"2023-10-02 09:45:00 WARNING Disk usage high\" >> ~/system_logs/log2.log\necho \"2023-10-02 09:50:00 ERROR Disk write failure\" >> ~/system_logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/system_logs/*.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple log files with the \".log\" extension. Your task is to find the total number of unique IP addresses that made requests recorded in these log files. Each line in a log file begins with an IP address followed by a space and other details. Assume each file contains multiple lines and there are no empty lines.",
        "explanation": "To solve this problem, you need to go through each log file, extract the IP addresses, and count the unique ones. Start by listing all \".log\" files in the \"log_files\" directory, then use tools like `awk` or `cut` to extract the first field (the IP address) from each line of these files. Finally, use `sort` and `uniq` to filter out duplicate IP addresses and count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/log_files/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"192.168.1.1 GET /index.html\\n192.168.1.2 POST /form\\n192.168.1.1 GET /about.html\" > ~/log_files/access1.log\necho -e \"192.168.1.3 GET /home\\n192.168.1.4 PUT /upload\\n192.168.1.2 POST /form\" > ~/log_files/access2.log\necho -e \"192.168.1.5 DELETE /remove\\n192.168.1.3 GET /home\\n10.0.0.5 PATCH /update\" > ~/log_files/access3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/log_files/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"data_files\" containing multiple text files. Each file contains lines of text where some lines begin with the word \"ERROR\". Your task is to find out how many unique lines start with \"ERROR\" across all the files in the \"data_files\" directory. Note that the comparison should be case-sensitive.",
        "explanation": "To solve this problem, you can use a combination of bash utilities like `grep`, `sort`, and `uniq`. Start by using `grep` to filter out lines that begin with \"ERROR\". Then, sort these lines to bring duplicates together, and finally use `uniq` to count the number of unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^ERROR' ~/data_files/* | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/data_files\necho -e \"INFO: Initialization complete\\nERROR: Disk full\\nWARNING: High memory usage\\nERROR: Disk full\" > ~/data_files/file1.txt\necho -e \"ERROR: Connection lost\\nINFO: User logged in\\nERROR: Connection lost\\nDEBUG: Cache cleared\" > ~/data_files/file2.txt\necho -e \"ERROR: Disk full\\nINFO: Backup completed\\nERROR: Unauthorized access\" > ~/data_files/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^ERROR' ~/data_files/* | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"logs\" containing multiple text files with server logs. Each file has entries in the format: `YYYY-MM-DD HH:MM:SS [INFO|ERROR|WARN] Message`. Your task is to find out how many unique dates have ERROR entries across all files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to go through each log file, extract lines containing \"ERROR\", and then parse the unique dates from these lines. The solution involves using tools like `grep` for filtering lines with \"ERROR\", `awk` or `cut` for extracting the date part, and `sort` along with `uniq` to determine unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Go to logs directory and process files to find unique error dates.\ncd ~/logs\n\n# Find lines with 'ERROR', extract date, get unique dates, and count them.\ngrep \"ERROR\" *.txt | cut -d' ' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create 'logs' directory in home\nmkdir -p ~/logs\n\n# Create sample log files\ncat <<EOL > ~/logs/log1.txt\n2023-10-01 12:00:00 [INFO] System started\n2023-10-01 12:05:00 [ERROR] Disk full\n2023-10-02 14:00:00 [WARN] High memory usage\n2023-10-03 16:30:00 [ERROR] Network timeout\nEOL\n\ncat <<EOL > ~/logs/log2.txt\n2023-10-01 18:15:00 [INFO] User login\n2023-10-02 09:15:00 [ERROR] Unauthorized access attempt\n2023-10-04 11:45:00 [INFO] File uploaded successfully\nEOL\n\ncat <<EOL > ~/logs/log3.txt\n2023-10-02 20:20:20 [ERROR] Service unavailable\n2023-10-05 22:22:22 [WARN] Low disk space\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Go to logs directory and process files to find unique error dates.\ncd ~/logs\n\n# Find lines with 'ERROR', extract date, get unique dates, and count them.\ngrep \"ERROR\" *.txt | cut -d' ' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_data\" in your home directory, containing multiple text files. Each file contains lines with timestamps and error messages in the format \"YYYY-MM-DD HH:MM:SS: [ERROR] Message\". Your task is to count how many error messages occurred on the current date, assuming the system date is set correctly. Provide only the integer count as your answer.",
        "explanation": "To solve this problem, you need to:\n1. Retrieve the current date using `date` command.\n2. Search through all text files in the \"project_data\" directory for lines that start with today's date.\n3. Count these lines and output the final count.\n\nHints:\n- Use `grep` to filter lines by today's date.\n- Use `wc -l` to count matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ntoday=$(date '+%Y-%m-%d')\ngrep \"^$today\" ~/project_data/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_data\necho -e \"2023-10-01 12:00:00: [ERROR] An example error\\n2023-10-02 14:32:10: [ERROR] Another error\\n2023-10-03 15:45:30: [ERROR] Yet another error\" > ~/project_data/log1.txt\necho -e \"2023-10-01 16:05:00: [ERROR] Example error two\\n2023-10-03 17:22:42: [ERROR] More errors\" > ~/project_data/log2.txt\n# Add more example logs as needed"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "today=$(date '+%Y-%m-%d')\ngrep \"^$today\" ~/project_data/*.txt | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with the extension \".log\". Each log file contains lines of text where some lines start with the timestamp in the format \"[YYYY-MM-DD HH:MM:SS]\". Your task is to count how many unique dates (YYYY-MM-DD) appear in all the log files combined. Ignore any lines that do not start with a timestamp.",
        "explanation": "To solve this problem, you need to traverse through each log file in the \"logs\" directory and extract the dates from lines that begin with a timestamp. Use tools like `grep` or `awk` to filter out these lines, then extract the date part. Finally, use `sort` and `uniq` to find and count the unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Go into logs directory\ncd ~/logs\n\n# Extract unique dates from all .log files and count them\ngrep -hoP '^\\[\\d{4}-\\d{2}-\\d{2}' *.log | cut -c 2- | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create logs directory\nmkdir -p ~/logs\n\n# Create sample log files with timestamps\necho -e \"[2023-10-01 12:00:00] Log entry 1\\n[2023-10-01 13:00:00] Log entry 2\\nRandom text\" > ~/logs/log1.log\necho -e \"[2023-10-02 14:30:23] Log entry A\\nSome other random line\\n[2023-10-02 15:45:30] Log entry B\" > ~/logs/log2.log\necho -e \"[2023-10-03 16:55:47] Another log entry\\n[2023-10-01 17:20:59] Yet another log entry\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Go into logs directory\ncd ~/logs\n\n# Extract unique dates from all .log files and count them\ngrep -hoP '^\\[\\d{4}-\\d{2}-\\d{2}' *.log | cut -c 2- | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to find out how many files in the `/var/log` directory were modified in the last 7 days, considering only regular files and excluding any subdirectories or symbolic links.",
        "explanation": "To solve this problem, you need to navigate to the `/var/log` directory and use a combination of `find`, `-type f`, and `-mtime` commands. The `find` command will help you filter regular files, while `-mtime -7` will identify those modified in the last 7 days. Count these files using a suitable method like piping the output to `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd /var/log\nfind . -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No specific initialization is needed for this problem as we are using system logs present in /var/log."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd /var/log\nfind . -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files. Each log file contains lines with timestamps and error levels (INFO, WARN, ERROR). Your task is to count how many lines have the error level \"ERROR\" across all log files in the \"logs\" directory. Output just the integer count of such lines.",
        "explanation": "To solve this problem, you can use a combination of `grep` and `wc` commands. Use `grep` to search for lines containing the string \"ERROR\" in all files within the \"logs\" directory and then pipe the result to `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"ERROR\" ~/logs | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 INFO Start process\\n2023-10-01 12:05:00 ERROR Unexpected behavior\\n2023-10-01 12:10:00 WARN Low memory\\n2023-10-01 12:15:00 ERROR Failed to connect\" > ~/logs/log1.txt\necho -e \"2023-10-02 09:00:00 INFO Process running\\n2023-10-02 09:30:00 ERROR Disk full\\n2023-10-02 09:45:00 INFO Process completed\" > ~/logs/log2.txt\necho -e \"2023-10-03 08:20:00 WARN High CPU usage\\n2023-10-03 08:45:00 ERROR Network timeout\\n2023-10-03 09:15:00 INFO Restarting service\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"ERROR\" ~/logs | wc -l"
        }
    },
    {
        "description": "You need to determine how many unique words are contained in all `.txt` files within the `/home/student/documents` directory. For this problem, consider words as sequences of alphabetic characters only, case-insensitively (e.g., \"Word\" and \"word\" should be considered the same). Ignore any non-alphabetic characters.",
        "explanation": "To solve this problem, you should first navigate to the `/home/student/documents` directory and list all `.txt` files available. Use a combination of tools such as `cat`, `tr`, `sort`, `uniq`, and `wc -l` to process these files. The key steps include reading all text content from the files, transforming uppercase letters to lowercase for uniformity, removing non-alphabetic characters, sorting the words, filtering out duplicates, and finally counting how many unique words exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat /home/student/documents/*.txt | \\\ntr '[:upper:]' '[:lower:]' | \\\ntr -cs '[:alpha:]' '\\n' | \\\nsort | \\\nuniq | \\\nwc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents\necho \"Hello World! This is a test document.\" > /home/student/documents/file1.txt\necho \"Another test document: hello again.\" > /home/student/documents/file2.txt\necho \"Unique WORD example.\" > /home/student/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat /home/student/documents/*.txt | \\\ntr '[:upper:]' '[:lower:]' | \\\ntr -cs '[:alpha:]' '\\n' | \\\nsort | \\\nuniq | \\\nwc -l"
        }
    },
    {
        "description": "You are tasked with analyzing log files in the `/var/logs/access` directory. Each log file contains HTTP access records with the format `IP_ADDRESS - - [DATE] \"REQUEST_METHOD URL\" STATUS_CODE SIZE`. Your goal is to determine how many unique IP addresses made GET requests that resulted in a 200 status code across all log files in this directory.",
        "explanation": "To solve this problem, you need to iterate over each log file in the `/var/logs/access` directory, extract lines where the request method is GET and the status code is 200, then collect all unique IP addresses from those lines. Finally, count these unique IP addresses and provide that count as your answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '\"GET' /var/logs/access/* | grep '200' | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs/access\necho '192.168.1.1 - - [12/Oct/2023:07:55:36 +0000] \"GET /index.html\" 200 1024' > /var/logs/access/log1.txt\necho '192.168.1.2 - - [12/Oct/2023:08:12:15 +0000] \"POST /form\" 404 512' >> /var/logs/access/log1.txt\necho '192.168.1.3 - - [12/Oct/2023:09:20:10 +0000] \"GET /home\" 200 2048' >> /var/logs/access/log2.txt\necho '192.168.1.1 - - [12/Oct/2023:10:05:45 +0000] \"GET /page\" 500 256' >> /var/logs/access/log2.txt\necho '192.168.1.4 - - [12/Oct/2023:11:22:33 +0000] \"GET /contact\" 200 1024' >> /var/logs/access/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '\"GET' /var/logs/access/* | grep '200' | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"project_logs\" containing multiple log files with the extension \".log\". Each log file contains entries in the format \"YYYY-MM-DD HH:MM:SS: [LEVEL] Message\". Your task is to determine how many error-level (\"[ERROR]\") log entries are present across all these files. Ensure that you only count lines that contain \"[ERROR]\" and ignore case sensitivity.",
        "explanation": "To solve this problem, you need to search through all the \".log\" files in the \"project_logs\" directory for lines containing \"[ERROR]\" (case-insensitive). You can use utilities like `grep` with the `-i` option for case-insensitive matching and `wc -l` to count the number of matched lines. This requires iterating over all relevant files in a specified directory.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i \"\\[error\\]\" ~/project_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\ncat <<EOL > ~/project_logs/log1.log\n2023-10-01 10:00:00: [INFO] System startup.\n2023-10-01 11:00:00: [ERROR] Disk space low.\n2023-10-01 12:00:00: [WARNING] High memory usage.\nEOL\n\ncat <<EOL > ~/project_logs/log2.log\n2023-10-02 13:00:00: [ERROR] Failed to connect to server.\n2023-10-02 14:00:00: [INFO] Connection established.\n2023-10-02 15:00:00: [error] User login failed.\nEOL\n\ncat <<EOL > ~/project_logs/log3.log\n2023-10-03 16:00:00: [DEBUG] Debugging mode enabled.\n2023-10-03 17:00:00; [ERROR] Unexpected shutdown.\n2023-10-03 18;30;30; [info]; Service restarted.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i \"\\[error\\]\" ~/project_logs/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_data\" in your home directory, which contains multiple log files with the \".log\" extension. Each log file contains error messages with varying severity levels: \"INFO\", \"WARN\", and \"ERROR\". Your task is to count the total number of lines across all files that contain the word \"ERROR\". You should ignore case sensitivity when counting.",
        "explanation": "To solve this problem, you need to use shell commands to navigate through the files in the \"log_data\" directory and search for lines containing the word \"ERROR\" in any case. You can use tools like `grep` to search for matching lines and `wc -l` to count them. The key is to ensure that your search is case-insensitive.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' ~/log_data/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_data\necho -e \"INFO: System started\\nWARN: Low memory\\nERROR: Disk not found\\ninfo: Update available\\nError: Connection lost\" > ~/log_data/system1.log\necho -e \"error: File missing\\nINFO: User login\\nwarn: High CPU usage\\nERROR: Network down\" > ~/log_data/system2.log\necho -e \"warn: Disk space low\\ninfo: Scheduled maintenance\\nError occurred while saving data\" > ~/log_data/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' ~/log_data/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Each log file contains lines of text where each line has a timestamp, a log level (INFO, WARNING, ERROR), and a message. Your task is to count the total number of ERROR logs across all these files.",
        "explanation": "To solve this problem, you need to iterate through each \".log\" file within the \"logs\" directory and filter out lines that contain the string \"ERROR\". You can use utilities like `grep` to search for \"ERROR\" in these files and then use `wc -l` to count how many such instances are found. Remember to handle multiple files efficiently using wildcards or loop structures.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"ERROR\" ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 10:00:00 INFO Starting process\\n2023-10-01 10:05:00 ERROR Process failed\\n2023-10-01 10:10:00 INFO Process restarted\" > ~/logs/system1.log\necho -e \"2023-10-02 09:30:00 WARNING Low disk space\\n2023-10-02 09:45:00 ERROR Disk write failure\\n2023-10-02 09:50:00 INFO Disk cleanup started\" > ~/logs/system2.log\necho -e \"2023-10-03 08:15:00 INFO User login\\n2023-10-03 08:20:00 ERROR Failed login attempt\\n2023-10-03 08:25:00 WARNING High CPU usage\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"ERROR\" ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You need to find out how many unique IP addresses have accessed the web server logs stored in a file named `access.log` located in your current directory. Consider only those entries that resulted in an HTTP status code of 200.",
        "explanation": "To solve this problem, you need to perform the following steps:\n1. Use a command like `grep` or `awk` to filter lines with HTTP status code 200 from the `access.log`.\n2. Extract the IP addresses from these filtered lines.\n3. Use a tool like `sort` and `uniq` to find the unique IP addresses.\n4. Count these unique IP addresses using commands such as `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Filter lines with status code 200, extract IPs, sort them uniquely, and count them.\ngrep 'HTTP\\/1\\.1\\\" 200' access.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample access.log file with various entries\ncat <<EOL > access.log\n192.168.1.10 - - [01/Jan/2023:12:00:01 +0000] \"GET /index.html HTTP/1.1\" 200 1024\n192.168.1.11 - - [01/Jan/2023:12:00:02 +0000] \"POST /form HTTP/1.1\" 404 512\n192.168.1.10 - - [01/Jan/2023:12:00:03 +0000] \"GET /about.html HTTP/1.1\" 200 2048\n192.168.2.15 - - [01/Jan/2023:12:00:04 +0000] \"GET /index.html HTTP/1.1\" 403 256\n172.16.0.5 - - [01/Jan/2023:12:00:05 +0000] \"GET /contact.html HTTP/1.1\" 200 4096\n172.16.0.5 - - [01/Jan/2023:12:00:06 +0000] \"GET /home.html HTTP/1.1\" 301 512\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Filter lines with status code 200, extract IPs, sort them uniquely, and count them.\ngrep 'HTTP\\/1\\.1\\\" 200' access.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"system_logs\" in your home directory containing various log files with different extensions. Your task is to count the total number of lines across all \".log\" files in this directory that contain the word \"ERROR\". Assume that the word is case-sensitive and appears exactly as \"ERROR\".",
        "explanation": "To solve this problem, you need to use a combination of bash commands to navigate through the files, filter out \".log\" files, search for occurrences of the word \"ERROR\", and then count these lines. Consider using `find` to locate all \".log\" files, `grep` to search for lines containing \"ERROR\", and `wc -l` to count those lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/system_logs -name \"*.log\" | xargs grep 'ERROR' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/system_logs\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nINFO: Backup completed\" > ~/system_logs/system_status.log\necho -e \"WARNING: High memory usage\\nERROR: Unable to connect to server\\nINFO: Connection re-established\" > ~/system_logs/network.log\necho -e \"DEBUG: User login successful\\nERROR: Failed login attempt\\nDEBUG: User logout successful\" > ~/system_logs/security.log\necho -e \"NOTICE: System reboot scheduled\\nINFO: Update installed successfully\" > ~/system_logs/update.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/system_logs -name \"*.log\" | xargs grep 'ERROR' | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logfiles\" in your home directory containing multiple log files. Each log file contains timestamps and various log levels (INFO, WARN, ERROR). Your task is to count how many ERROR entries exist across all log files in the \"logfiles\" directory.",
        "explanation": "To solve this problem, you need to navigate into the \"logfiles\" directory and use tools like `grep` to search for lines containing the word \"ERROR\". The `wc -l` command can be used to count the number of matching lines. Redirect or pipe these results as necessary to accumulate counts from all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"ERROR\" ~/logfiles | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-10-01 10:00:00 INFO Start process\\n2023-10-01 10:05:00 ERROR Failed to start service\\n2023-10-01 10:15:00 WARN Low memory\\n2023-10-01 11:00:00 INFO Process running smoothly\" > ~/logfiles/log1.txt\necho -e \"2023-10-02 12:00:00 ERROR Disk full\\n2023-10-02 12:30:00 INFO Disk cleanup started\\n2023-10-02 13:00:00 ERROR Network timeout\" > ~/logfiles/log2.txt\necho -e \"2023-10-03 09:45:00 WARN High CPU usage\\n2023-10-03 09:50:00 INFO CPU usage normalized\\n2023-10-03 09:55:00 ERROR Could not connect to database\" > ~/logfiles/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"ERROR\" ~/logfiles | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logfiles\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains lines of text, and some lines include the keyword \"ERROR\". Count how many times the keyword \"ERROR\" appears across all these log files. Please note that the search should be case-sensitive.",
        "explanation": "To solve this problem, you need to search for the keyword \"ERROR\" in each file within the \"logfiles\" directory. You can use the `grep` command with appropriate options to count occurrences of a specific word across multiple files. Summing these counts will provide the total number of occurrences of \"ERROR\".\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -roh 'ERROR' ~/logfiles/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"INFO Start process\\nERROR Failed to start\\nINFO Retrying\\n\" > ~/logfiles/app1.log\necho -e \"WARNING Disk space low\\nERROR Out of memory\\nERROR Disk failure\\n\" > ~/logfiles/app2.log\necho -e \"INFO Process completed successfully\\nDEBUG Variable x=10\\n\" > ~/logfiles/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -roh 'ERROR' ~/logfiles/*.log | wc -l"
        }
    },
    {
        "description": "You have a directory named `project_logs` in your home directory containing numerous log files with the `.log` extension. Your task is to determine the total number of error messages across all log files. An error message is defined as any line in a log file that contains the word \"ERROR\". Assume each log file follows a common format where each line is either informational, warning, or an error message.",
        "explanation": "To solve this problem, you will need to search through all `.log` files within the `project_logs` directory and count lines that contain the word \"ERROR\". You can use command-line utilities such as `grep` to filter out these lines and then use commands like `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -R \"ERROR\" ~/project_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"INFO: System started\\nERROR: Failed to load module\\nWARNING: Low disk space\" > ~/project_logs/log1.log\necho -e \"INFO: User login\\nERROR: Connection timeout\\nERROR: Disk read error\" > ~/project_logs/log2.log\necho -e \"WARNING: Memory usage high\\nINFO: Scheduled task completed\" > ~/project_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -R \"ERROR\" ~/project_logs/*.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"project_logs\" in your home directory containing multiple text files. Each file logs the operations performed by an application over different days. Your task is to find out on which day (YYYY-MM-DD format) the highest number of errors occurred. An error is defined as any line containing the word \"ERROR\". Assume all log files are formatted with each line starting with a timestamp in the format \"[YYYY-MM-DD HH:MM:SS]\".",
        "explanation": "To solve this problem, you need to iterate over all files in the \"project_logs\" directory and count how many times the word \"ERROR\" appears for each date. You can use tools like `grep` to filter lines containing \"ERROR\", and `awk` or `cut` to extract dates from those lines. Then, aggregate these counts per date and determine which date has the maximum count of errors.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/project_logs\n\n# Count errors per day using grep and awk, then sort and find max.\ngrep 'ERROR' * | awk -F'[ \\\\[\\\\]]' '{print $2}' | cut -d ' ' -f1 | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho \"[2023-01-01 12:00:00] INFO Starting process\" > ~/project_logs/log1.txt\necho \"[2023-01-01 12:05:00] ERROR Failed to start module A\" >> ~/project_logs/log1.txt\necho \"[2023-01-02 13:00:00] INFO Process running\" > ~/project_logs/log2.txt\necho \"[2023-01-02 13:10:00] ERROR Module B crashed\" >> ~/project_logs/log2.txt\necho \"[2023-01-02 13:15:00] ERROR Module C crashed\" >> ~/project_logs/log2.txt\necho \"[2023-01-03 14:00:00] INFO Process completed successfully\" > ~/project_logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "cd ~/project_logs\n\n# Count errors per day using grep and awk, then sort and find max.\ngrep 'ERROR' * | awk -F'[ \\\\[\\\\]]' '{print $2}' | cut -d ' ' -f1 | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple .log files. Each file records server access logs with each line formatted as \"timestamp - status_code - URL\". Count how many times the status code \"404\" appears across all the .log files in the \"log_files\" directory.",
        "explanation": "To solve this problem, you need to iterate through each .log file within the \"log_files\" directory and read its contents. Use a combination of tools such as `grep` to filter lines containing the status code \"404\", and then use `wc -l` to count how many lines match this pattern. Sum up these counts for all files to get the total occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '404' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-10-01 10:00:00 - 200 - /home\\n2023-10-01 10:05:00 - 404 - /not-found\\n2023-10-01 10:10:00 - 200 - /about\" > ~/log_files/access1.log\necho -e \"2023-10-02 11:00:00 - 404 - /missing\\n2023-10-02 11:05:00 - 500 - /error\\n2023-10-02 11:15:00 - 404 - /not-found-again\" > ~/log_files/access2.log\necho -e \"2023-10-03 12:30:00 - 200 - /index\\n2023-10-03 12:35:00 - 200 - /contact\\n2023-10-03 12:40:00 - 404 - /lost-page\" > ~/log_files/access3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '404' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.configurations` that contains several lines of text. Each line consists of a key-value pair separated by an equal sign (`=`). Your task is to identify how many unique keys are present in this file and count the number of times each unique key occurs. Your answer should only include the number of unique keys.",
        "explanation": "To solve this problem, you need to:\n1. Use the `grep` command to locate the `.configurations` file in your home directory.\n2. Use `awk` or `cut` to extract keys from each line (the text before the `=` sign).\n3. Use `sort` and `uniq` commands to count and list out unique keys.\n4. Finally, use the `wc -l` command or another counting method to determine how many unique keys are present.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extracting all keys from .configurations file, sorting them,\n# getting unique ones and counting them.\ncat ~/.configurations | cut -d'=' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "echo \"user=admin\" > ~/.configurations\necho \"theme=dark\" >> ~/.configurations\necho \"autoupdate=true\" >> ~/.configurations\necho \"user=guest\" >> ~/.configurations\necho \"language=en\" >> ~/.configurations"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extracting all keys from .configurations file, sorting them,\n# getting unique ones and counting them.\ncat ~/.configurations | cut -d'=' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "In the current directory, you have several text files with random content. Your task is to count and output the total number of words across all files that contain the string \"Linux\". You should only consider files with a \".txt\" extension, and you must ignore any hidden files (files starting with a dot).",
        "explanation": "To solve this problem, you need to iterate over all the text files in the current directory, checking each file for occurrences of the string \"Linux\". For each occurrence found, count the words in that file. A good approach would be to use `grep` to search for lines containing \"Linux\" and then `wc` to count words.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count total number of words in all .txt files containing 'Linux'\ntotal_words=0\n\nfor file in *.txt; do\n  if grep -q 'Linux' \"$file\"; then\n    word_count=$(wc -w < \"$file\")\n    total_words=$((total_words + word_count))\n  fi\ndone\n\necho $total_words  # Output will be matched against student's answer using integer-match()\n```",
        "create": {
            "init": "# Create several .txt files with random content\necho -e \"This is a test file about Linux systems.\\nIt has multiple lines.\" > file1.txt\necho -e \"Another line mentioning Linux here.\\nAnd some other unrelated text.\" > file2.txt\necho -e \"No mention of the keyword here.\" > file3.txt\necho -e \"Linux is mentioned once in this sentence.\" > file4.txt\n\n# Create hidden text files that should not be counted\necho -e \"Hidden Linux reference.\\nShould not count.\" > .hidden1.txt\n\n# Create non-text files that should not be counted\ntouch image.png video.mp4 data.bin"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count total number of words in all .txt files containing 'Linux'\ntotal_words=0\n\nfor file in *.txt; do\n  if grep -q 'Linux' \"$file\"; then\n    word_count=$(wc -w < \"$file\")\n    total_words=$((total_words + word_count))\n  fi\ndone\n\necho $total_words  # Output will be matched against student's answer using integer-match()"
        }
    },
    {
        "description": "Identify and count the number of unique IP addresses that have accessed the web server by analyzing the log file named `access.log` located in the `/var/log/apache2/` directory on your Linux system. Assume that each entry in the log file follows the common log format.",
        "explanation": "To solve this problem, you need to extract IP addresses from each line in the `access.log` file. You can achieve this by using tools like `awk`, `sed`, or `grep`. Once you extract all IP addresses, you will need to sort them and use a command like `uniq` to filter out duplicate entries. Finally, count these unique entries using a command like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example script to count unique IPs accessing the web server.\nawk '{print $1}' /var/log/apache2/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create sample access.log file for testing\nmkdir -p /var/log/apache2/\ncat <<EOL > /var/log/apache2/access.log\n192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \"GET /index.html HTTP/1.1\" 200 1043\n192.168.1.2 - - [10/Oct/2023:13:56:01 +0000] \"POST /form HTTP/1.1\" 200 532\n192.168.1.3 - - [10/Oct/2023:13:57:15 +0000] \"GET /about.html HTTP/1.1\" 404 720\n192.168.1.4 - - [10/Oct/2023:13:58:21 +0000] \"GET /index.html HTTP/1.1\" 200 1043\n192.168.1.2 - - [10/Oct/2023:14:00:05 +0000] \"GET /contact.html HTTP/1.1\" 200 2145\n192.168.1.4 - - [10/Oct/2023:14:02:47 +0000] \"GET /index.html HTTP/1.1\" 304 -\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example script to count unique IPs accessing the web server.\nawk '{print $1}' /var/log/apache2/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains several log files with the \".log\" extension. Each log file contains multiple lines, and each line starts with a date in the format \"YYYY-MM-DD\". Find out how many unique dates are present across all the log files combined. Assume that the log files may contain thousands of lines and some lines might be duplicates.",
        "explanation": "To solve this problem, you need to extract the date from each line of every \".log\" file in the \"logs\" directory, aggregate all these dates, and then count how many unique dates exist. Consider using commands like `cat`, `awk`, `sort`, and `uniq` to achieve this task efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 Entry 1\\n2023-01-02 Entry 2\\n2023-01-03 Entry 3\\n2023-01-02 Entry 2\\n2023-01-04 Entry 4\" > ~/logs/log1.log\necho -e \"2023-01-03 Another entry\\n2023-01-05 New entry\\n2023-01-06 New day\\n2023-01-05 Repeat entry\" > ~/logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines that contain the word \"Linux\" (case-insensitive) within all `.txt` files located in the `/home/student/logs` directory and its subdirectories. Assume that you have read and write permission in this directory. Provide just the integer count as your answer.",
        "explanation": "To solve this problem, you need to recursively search through all `.txt` files in the specified directory and its subdirectories. You can use the `grep` command with options to perform a case-insensitive search and count the occurrences. Combining `find`, `xargs`, or using `grep` alone with recursive options will help achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -iR \"Linux\" /home/student/logs/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/logs/subdir1\nmkdir -p /home/student/logs/subdir2\necho -e \"Linux is great.\\nI love Linux.\" > /home/student/logs/file1.txt\necho -e \"Learning Linux is fun.\\nlinux kernel.\" > /home/student/logs/subdir1/file2.txt\necho -e \"Linux distributions vary.\" > /home/student/logs/subdir2/file3.txt\necho -e \"No mention here.\" > /home/student/logs/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -iR \"Linux\" /home/student/logs/*.txt | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"server_logs\" in your home directory that contains multiple log files with the \".log\" extension. Each log file contains lines of text where each line represents a different user action in the format \"timestamp - user_id - action_type\". Your task is to determine how many unique users have performed actions across all these log files. Assume that each user_id is unique and represents a distinct user.",
        "explanation": "To solve this problem, you need to extract all the user IDs from each log file within the \"server_logs\" directory and identify the unique ones. You can use tools such as `grep` or `awk` to parse and filter out the user IDs, and then utilize utilities like `sort` and `uniq` to count the distinct entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/server_logs/*.log | awk '{print $4}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/server_logs\necho -e \"2023-10-01 10:00:00 - user1 - login\\n2023-10-01 10:05:00 - user2 - logout\\n2023-10-01 10:15:00 - user1 - upload\" > ~/server_logs/log1.log\necho -e \"2023-10-02 11:00:00 - user3 - download\\n2023-10-02 11:20:00 - user2 - login\\n2023-10-02 11:30:00 - user4 - upload\" > ~/server_logs/log2.log\necho -e \"2023-10-03 09:45:00 - user5 - modify\\n2023-10-03 09:50:00 - user6 - delete\\n2023-10-03 09:55:00 - user1 - logout\" > ~/server_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/server_logs/*.log | awk '{print $4}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory. This directory contains multiple log files with the extension \".log\". Your task is to identify the file that has the highest number of lines containing the word \"ERROR\" (case-sensitive) and output just the name of that file without its path.",
        "explanation": "To solve this problem, you need to iterate over all files in the \"logs\" directory, count how many times the word \"ERROR\" appears in each file, and determine which file has the highest count. You can use tools like `grep` to search for \"ERROR\" and `wc -l` to count lines. Once you have these counts, compare them and print out only the name of the file with the highest count.\n\nYou can use this command pattern to perform the task:\n\n```bash\nmax_errors=0\nfile_with_max_errors=\"\"\nfor logfile in ~/logs/*.log; do\n  error_count=$(grep -c 'ERROR' \"$logfile\")\n  if [ \"$error_count\" -gt \"$max_errors\" ]; then\n    max_errors=$error_count\n    file_with_max_errors=$(basename \"$logfile\")\n  fi\ndone\necho \"$file_with_max_errors\"\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nINFO: Running backup\" > ~/logs/system1.log\necho -e \"INFO: User login successful\\nERROR: Memory leak detected\\nERROR: Network timeout\\nINFO: Session ended\" > ~/logs/system2.log\necho -e \"INFO: Application started\\nERROR: Failed to connect to database\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "max_errors=0\nfile_with_max_errors=\"\"\nfor logfile in ~/logs/*.log; do\n  error_count=$(grep -c 'ERROR' \"$logfile\")\n  if [ \"$error_count\" -gt \"$max_errors\" ]; then\n    max_errors=$error_count\n    file_with_max_errors=$(basename \"$logfile\")\n  fi\ndone\necho \"$file_with_max_errors\""
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with the extension \".log\". Each log file contains timestamped entries. Your task is to count the total number of unique IP addresses that appear across all these log files. Each line in the log files begins with an IP address followed by a timestamp and message. The output should be only the integer count of unique IP addresses.",
        "explanation": "To solve this problem, you need to process each log file in the \"logs\" directory, extract the IP addresses from each line, and then use a set or similar mechanism to determine the unique IP addresses. Finally, count these unique IPs and output the total count as an integer.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all unique IPs in all .log files in the logs directory and count them\nawk '{print $1}' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create logs directory\nmkdir -p ~/logs\n\n# Create sample log files with random data\necho -e \"192.168.0.1 2023-10-01 12:00:00 Some entry\\n192.168.0.2 2023-10-01 12:05:00 Some entry\\n192.168.0.1 2023-10-01 12:10:00 Some entry\" > ~/logs/log1.log\necho -e \"192.168.0.3 2023-10-02 13:00:00 Another entry\\n192.168.0.4 2023-10-02 13:15:00 Another entry\\n192.168.0.2 2023-10-02 13:20:00 Another entry\" > ~/logs/log2.log\necho -e \"192.168.0.5 2023-10-03 14:00:00 Yet another entry\\n192.168.0.1 2023-10-03 14:05:00 Yet another entry\\n192.168.0.6 2023-10-03 14:10:00 Yet another entry\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all unique IPs in all .log files in the logs directory and count them\nawk '{print $1}' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory that contains multiple log files with the \".log\" extension. Each log file records different events, and each line of these files starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to determine how many unique dates (in the format \"YYYY-MM-DD\") appear across all log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to extract the date part from each timestamp in all \".log\" files within the \"logs\" directory, collect them, and then determine how many unique dates are present. You can use utilities such as `awk`, `cut`, `sort`, and `uniq` to accomplish this.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/log1.log\n2023-10-01 12:00:00 Event A occurred\n2023-10-01 13:30:00 Event B occurred\n2023-10-02 15:45:00 Event C occurred\nEOL\n\ncat <<EOL > ~/logs/log2.log\n2023-10-03 09:20:00 Event D occurred\n2023-10-02 17:50:00 Event E occurred\n2023-10-04 11:15:00 Event F occurred\nEOL\n\ncat <<EOL > ~/logs/log3.log\n2023-10-01 08:05:00 Event G occurred\n2023-10-03 14:30:00 Event H occurred\n2023-10-05 16:25:00 Event I occurred\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named `log_files` in your home directory, which contains multiple log files with varying extensions. Some of these files have the `.log` extension, while others do not. Your task is to count the total number of lines across all `.log` files in this directory that contain the word \"ERROR\". You must consider all `.log` files directly under `log_files`, but not those in subdirectories.",
        "explanation": "To solve this problem, you need to first list all the files in the `log_files` directory that have a `.log` extension. Next, iterate through these files and use tools like `grep` to search for lines containing the word \"ERROR\". Finally, sum up the counts of such lines from each file to obtain your answer. Commands like `find`, `grep`, and `wc -l` will be useful.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h \"ERROR\" ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"INFO: Start process\\nERROR: Something went wrong\\nINFO: End process\" > ~/log_files/system.log\necho -e \"DEBUG: Loading module\\nINFO: Module loaded successfully\" > ~/log_files/debug.log\necho -e \"WARNING: Disk space low\\nERROR: Unable to write file\" > ~/log_files/storage.log\necho -e \"INFO: User logged in\\nINFO: User logged out\" > ~/log_files/access.log\ntouch ~/log_files/empty_file.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h \"ERROR\" ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory which contains multiple log files with the extension \".log\". Each log file consists of lines that include timestamps and various log levels such as INFO, ERROR, and WARNING. Your task is to count the number of ERROR entries across all the log files in the \"logs\" directory and provide this count as your answer.",
        "explanation": "To solve this problem, you need to traverse through all the files in the \"logs\" directory, filter out lines containing the word \"ERROR\", and then count these lines. You may use utilities like `grep` to search for patterns within files and `wc -l` to count lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 10:00:00 INFO Start process\\n2023-10-01 10:02:00 ERROR Failed to start\\n2023-10-01 10:03:00 INFO Retrying\" > ~/logs/system1.log\necho -e \"2023-10-01 11:00:00 WARNING Disk space low\\n2023-10-01 11:05:00 ERROR Unable to write file\" > ~/logs/system2.log\necho -e \"2023-10-01 12:00:00 INFO Process running\\n2023-10-01 12:30:00 ERROR Connection lost\\n2023-10-01 12:45:00 INFO Process completed\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory containing multiple log files with a \".log\" extension. Each log file contains various timestamped entries in the format \"YYYY-MM-DD HH:MM:SS - [INFO/ERROR/WARNING] - message\". Your task is to determine the total number of \"ERROR\" entries across all log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory in your home folder and search for lines that contain the word \"ERROR\". You can use `grep` to filter these lines from each file. Then, you count how many such lines exist across all files. This requires combining outputs from multiple files and then counting them.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs/ -name \"*.log\" | xargs grep 'ERROR' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 - INFO - System start\\n2023-10-01 12:05:00 - ERROR - Failed to connect\\n2023-10-01 12:10:00 - WARNING - Low disk space\\n2023-10-01 12:15:00 - ERROR - Timeout occurred\" > ~/logs/system1.log\necho -e \"2023-10-02 13:00:00 - INFO - User login\\n2023-10-02 13:05:00 - ERROR - Unauthorized access attempt\\n2023-10-02 13:15:00 - ERROR - Disk error\" > ~/logs/system2.log\necho -e \"2023-10-03 14:20:00 - INFO - Service started\\n2023-10-03 14:30:00 - WARNING - High memory usage\\n2023-10-03 14:40:00 - ERROR – Connection lost\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs/ -name \"*.log\" | xargs grep 'ERROR' | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a file named \"system_logs.txt\" containing multiple lines of log entries. Each line starts with a date in the format YYYY-MM-DD. Your task is to count how many unique dates have at least one log entry mentioning the word \"ERROR\". You are not allowed to use any programming languages or write any scripts; you must interact directly with the shell.",
        "explanation": "To solve this problem, you can use tools like `grep` to filter out lines containing \"ERROR\", then use `cut` or `awk` to extract the date part from those lines. Finally, use `sort` and `uniq` to determine the number of unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"ERROR\" ~/system_logs.txt | cut -d' ' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "cat <<EOL > ~/system_logs.txt\n2023-01-01 Some info message\n2023-01-01 ERROR: Something went wrong\n2023-01-02 Another info message\n2023-01-03 ERROR: Another error occurred\n2023-01-03 ERROR: Yet another issue\n2023-01-04 Info only message\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"ERROR\" ~/system_logs.txt | cut -d' ' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory containing multiple log files with the extension \".log\". Each log file contains timestamped entries. Your task is to find the log entry with the latest timestamp across all log files and output it. Assume that each log entry is on a new line and begins with a standard ISO 8601 date format (YYYY-MM-DDTHH:MM:SS).",
        "explanation": "To solve this problem, you need to iterate over each \".log\" file in the \"log_files\" directory, parse each line to extract timestamps, and determine which log entry has the most recent timestamp. You can use `find` to locate the files, `cat` or `while read` to process them, and `sort` or `awk` for comparing dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/log_files -name \"*.log\" -exec cat {} + | sort | tail -n 1 | awk '{print $0}'\n# The output should be:\n# 2023-10-03T08:20:00 Log entry D\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho \"2023-10-01T12:00:00 Log entry A\" > ~/log_files/log1.log\necho \"2023-10-02T15:30:00 Log entry B\" >> ~/log_files/log1.log\necho \"2023-09-29T09:45:00 Log entry C\" > ~/log_files/log2.log\necho \"2023-10-03T08:20:00 Log entry D\" >> ~/log_files/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "find ~/log_files -name \"*.log\" -exec cat {} + | sort | tail -n 1 | awk '{print $0}'\n# The output should be:\n# 2023-10-03T08:20:00 Log entry D"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory. This directory contains multiple log files with the extension \".log\". Each log file records events in the format \"YYYY-MM-DD HH:MM:SS EventType: Message\". Your task is to count how many error events (EventType \"ERROR\") occurred on the current date across all log files. Report just the integer count of errors.",
        "explanation": "To solve this problem, you should first identify today's date using the `date` command. Then, navigate to the \"logs\" directory and use tools like `grep` or `awk` to filter out lines that contain today's date and have an \"ERROR\" event type. Count these lines using utilities such as `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Get today's date in YYYY-MM-DD format\ntoday=$(date +%Y-%m-%d)\n\n# Navigate to logs directory\ncd ~/logs\n\n# Count error entries for today across all log files\nerror_count=$(grep \"$today.*ERROR\" *.log | wc -l)\n\n# Output the count of errors\necho $error_count\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 INFO: System started\\n2023-10-02 13:30:00 ERROR: Disk full\\n2023-10-03 14:45:00 ERROR: Network down\\n2023-11-01 15:00:00 INFO: Rebooted\" > ~/logs/system1.log\necho -e \"2023-11-01 16:30:00 ERROR: Out of memory\\n2023-11-01 17:45:00 ERROR: Permission denied\" > ~/logs/system2.log\n# Add more dummy data if needed for testing."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Get today's date in YYYY-MM-DD format\ntoday=$(date +%Y-%m-%d)\n\n# Navigate to logs directory\ncd ~/logs\n\n# Count error entries for today across all log files\nerror_count=$(grep \"$today.*ERROR\" *.log | wc -l)\n\n# Output the count of errors\necho $error_count"
        }
    },
    {
        "description": "You are given a directory named \"project_logs\" in your home directory containing several log files with the \".log\" extension. Each log file contains multiple entries, and each entry is a single line. Your task is to find out how many unique IP addresses have accessed the system according to these logs. The IP addresses follow the standard IPv4 format (e.g., 192.168.1.1).",
        "explanation": "To solve this problem, you need to perform the following steps:\n1. Navigate to the \"project_logs\" directory.\n2. Use a command such as `grep` or `awk` to extract all IP addresses from each of the log files.\n3. Make sure that you only consider lines where an IP address appears in the format of four octets separated by dots.\n4. Use a tool like `sort` along with `uniq` to filter out duplicate IP addresses and count how many unique ones there are.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to project_logs directory\ncd ~/project_logs\n\n# Extract all valid IPv4 addresses, sort them and count unique ones\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' *.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create project_logs directory in home\nmkdir -p ~/project_logs\n\n# Create sample log files with various entries including IPs\necho -e \"User login from 192.168.1.1\\nFile accessed by 10.0.0.5\\nConnection attempt from 192.168.1.1\\nError logged from 172.16.0.3\" > ~/project_logs/logfile1.log\necho -e \"Service started at 10:00AM\\nIP check for 203.0.113.5\\nSuccessful request by 8.8.8.8\\nUser login from 192.168 .1 .10\" > ~/project_logs/logfile2.log\necho -e \"Ping received from 172 .16 .0 .3\\nAdmin access via 203 .0 .113 .6\\nRoutine checkup completed\" > ~/project_logs/logfile3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to project_logs directory\ncd ~/project_logs\n\n# Extract all valid IPv4 addresses, sort them and count unique ones\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' *.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_files\" in your home directory containing various types of files. Your task is to count the total number of lines across all `.txt` files in this directory that contain the word \"error\" (case-insensitive). You should ensure that only `.txt` files directly within the \"project_files\" directory are considered, and subdirectories should be ignored.",
        "explanation": "To solve this problem, you can use a combination of `find`, `grep`, and `wc` commands. First, use `find` to list all `.txt` files in the \"project_files\" directory. Then, use `grep` with the `-i` option to search for lines containing the word \"error\" in a case-insensitive manner. Finally, pipe these results into `wc -l` to count the total number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/project_files -maxdepth 1 -type f -name \"*.txt\" | xargs grep -i 'error' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_files\necho -e \"This is an example.\\nError found here.\\nAnother line.\" > ~/project_files/file1.txt\necho -e \"No issues here.\\nJust some text.\" > ~/project_files/file2.txt\necho -e \"error on this line.\\nAnother error.\" > ~/project_files/file3.txt\necho -e \"All good here.\" > ~/project_files/note.md"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/project_files -maxdepth 1 -type f -name \"*.txt\" | xargs grep -i 'error' | wc -l"
        }
    },
    {
        "description": "You are tasked with determining the total number of unique words found across all text files in the current directory. You should ignore case differences (e.g., \"Word\" and \"word\" should be considered the same) and exclude any punctuation from your word counts.",
        "explanation": "To solve this problem, you will need to perform several steps:\n1. Use a command like `find` or `ls` to list all text files in the current directory.\n2. Use tools such as `cat`, `tr`, or `sed` to read these files and process their contents.\n3. Convert all text to lowercase using a tool like `tr`.\n4. Remove punctuation using commands like `tr` or `sed`.\n5. Split the text into individual words, again using tools such as `tr`.\n6. Use a command like `sort` followed by `uniq` to count distinct words.\n7. Finally, use tools like `wc -l` to count the number of unique words.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\n\n# List all .txt files and concatenate their contents\ncat *.txt | \n\n# Convert all text to lowercase\ntr '[:upper:]' '[:lower:]' | \n\n# Remove punctuation\ntr -d '[:punct:]' | \n\n# Split into words (one per line)\ntr ' ' '\\n' |\n\n# Sort and find unique words\nsort | uniq |\n\n# Count lines (unique words)\nwc -l\n```",
        "create": {
            "init": "# Creating sample text files in the current directory for testing\n\necho \"Hello world! This is a test file.\" > file1.txt\necho \"Another line in the WORLD of tests.\" >> file1.txt\n\necho \"Testing is fun: isn't it? Yes, it is!\" > file2.txt\necho \"Fun times with TEST cases.\" >> file2.txt\n\n# End of initialization script"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\n\n# List all .txt files and concatenate their contents\ncat *.txt | \n\n# Convert all text to lowercase\ntr '[:upper:]' '[:lower:]' | \n\n# Remove punctuation\ntr -d '[:punct:]' | \n\n# Split into words (one per line)\ntr ' ' '\\n' |\n\n# Sort and find unique words\nsort | uniq |\n\n# Count lines (unique words)\nwc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple log files with different extensions. Count the total number of lines across all \".log\" files in this directory that contain the word \"ERROR\".",
        "explanation": "To solve this problem, you should navigate to the \"log_files\" directory and use a combination of bash commands like `grep` to search for the word \"ERROR\" in files with a \".log\" extension. You can then use `wc -l` to count the total number of lines. Finally, sum up these counts to get the total number.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"INFO: All systems go\\nERROR: Something went wrong\\nINFO: Starting process\" > ~/log_files/system1.log\necho -e \"ERROR: Failed to start\\nWARN: Low memory\\nERROR: Disk full\" > ~/log_files/system2.log\necho -e \"DEBUG: Initializing\\nINFO: Running diagnostics\\nERROR: Timeout occurred\" > ~/log_files/system3.txt\necho -e \"INFO: Checking logs\\nERROR: Out of memory\\nDEBUG: Log entry end\" > ~/log_files/system4.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "You need to count the total number of lines across all `.txt` files in the `/var/log` directory that contain the string \"error\" (case-insensitive). Ensure you only consider files directly within `/var/log`, not in any subdirectories.",
        "explanation": "To solve this problem, you'll need to:\n1. List all `.txt` files within the `/var/log` directory.\n2. Use a tool like `grep` to filter lines containing the word \"error\", ignoring case.\n3. Count these lines across all files.\n\nHere are some hints:\n- Use `ls` or `find` to list relevant files.\n- Combine `grep -i` with `wc -l` to count matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all .txt files and filter out lines containing \"error\", then count them\ngrep -i 'error' /var/log/*.txt | wc -l\n```",
        "create": {
            "init": "# Create sample .txt log files in /var/log for testing\nmkdir -p /var/log\necho -e \"This is a test log\\nERROR: something went wrong\\nAll good here\" > /var/log/test1.txt\necho -e \"No issues detected\\nError: minor glitch\\nCheck complete\" > /var/log/test2.txt\necho -e \"Everything operational\\nNo errors found\" > /var/log/operational.txt\n\n# Ensure no subdirectories contain .txt files for simplicity"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# List all .txt files and filter out lines containing \"error\", then count them\ngrep -i 'error' /var/log/*.txt | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with a \".log\" extension. Your task is to find out how many unique IP addresses have accessed the server, as recorded in these log files. Assume each line of the log files starts with an IP address. You need to count and report the number of unique IP addresses.",
        "explanation": "To solve this problem, you will need to navigate to the \"logs\" directory and use command-line tools to extract, sort, and count unique IP addresses from all \".log\" files. Useful commands include `cat`, `awk`, `sort`, and `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ncat *.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 GET /index.html\\n192.168.1.2 POST /form\\n192.168.1.1 GET /contact.html\" > ~/logs/access1.log\necho -e \"10.0.0.5 GET /home\\n172.16.0.3 PUT /upload\\n10.0.0.5 DELETE /remove\" > ~/logs/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ncat *.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing several text files with various logs. Each log entry in these files starts with a timestamp in the format \"[YYYY-MM-DD HH:MM:SS]\". Your task is to find out how many log entries there are in total across all files for today’s date. Assume today’s date is 2023-10-12.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and then use grep or awk to filter entries that match today’s date (2023-10-12) from each file. You can count these entries using wc -l or another suitable command.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"\\[2023\\-10\\-12\" ~/logs/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"[2023-10-11 12:00:00] Log entry 1\n[2023-10-12 09:00:00] Log entry 2\n[2023-10-12 14:30:21] Log entry 3\" > ~/logs/log1.txt\n\necho \"[2023-10-12 08:45:00] Log entry A\n[2023-10-11 19:24:51] Log entry B\" > ~/logs/log2.txt\n\necho \"[2023-10-13 01:15:42] Future log entry\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"\\[2023\\-10\\-12\" ~/logs/*.txt | wc -l"
        }
    },
    {
        "description": "You have a directory named `project_logs` in your home directory containing multiple log files with the `.log` extension. Each log file contains lines of text, where some lines include timestamps in the format `[YYYY-MM-DD HH:MM:SS]`. Your task is to count how many lines across all these log files contain timestamps from the year 2023.",
        "explanation": "To solve this problem, you need to iterate over each `.log` file in the `project_logs` directory, extract lines that contain timestamps, and then filter those that specifically have a year of 2023. You can use tools like `grep` to search for patterns and `wc -l` to count matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -hr '\\[2023' ~/project_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\ncat > ~/project_logs/log1.log <<EOL\n[2022-12-31 23:59:59] End of year event\n[2023-01-01 00:00:01] New year celebration\nNo timestamp here\n[2023-03-15 10:30:00] User logged in\nEOL\n\ncat > ~/project_logs/log2.log <<EOL\nAnother line without a timestamp\n[2023-06-21 14:45:30] Summer solstice event\nRandom content here\n[2024-01-01 12:00:00] Happy New Year!\nEOL\n\ncat > ~/project_logs/log3.log <<EOL\nSome initial setup [2020-11-11 11:11:11]\nNo date here either [2019-09-09 09:09:09]\nLook at this one [2023-07-04 18:45:17]\nYet another example [2023-08-14 22:22:22]\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -hr '\\[2023' ~/project_logs/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files. Each file contains timestamped entries with different levels of logging such as INFO, WARN, ERROR, and DEBUG. Your task is to find out how many ERROR entries are present across all the log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and use bash utilities to count lines containing the word \"ERROR\". You can use tools like `grep` to search for the keyword across multiple files and `wc -l` to count the number of occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/logs | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 10:00:00 INFO Application started\\n2023-10-01 10:05:00 ERROR Failed to connect\\n2023-10-01 10:10:00 WARN Low memory\" > ~/logs/log1.txt\necho -e \"2023-10-01 11:00:00 DEBUG Initializing module\\n2023-10-01 11:15:00 ERROR Timeout occurred\\n2023-10-01 11:20:00 INFO Task completed\" > ~/logs/log2.txt\necho -e \"2023-10-02 09:00:00 INFO User logged in\\n2023-10-02 09:30:00 ERROR Disk full\\n2023-10-02 09:40:00 WARN High CPU usage\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/logs | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing the contents of log files stored in the `/var/log/myapp` directory. Your goal is to determine how many unique IP addresses have accessed the application today. Please note that each log file is named in the format `access-YYYYMMDD.log`, and you should only consider today's log file for this task. Assume today's date is 20231012 (YYYYMMDD format) and each line in the log file starts with an IP address followed by other details. Use bash commands to accomplish this task.",
        "explanation": "To solve this problem, you need to filter out today's log file from the `/var/log/myapp` directory using a date-specific pattern (`access-20231012.log`). Then, extract all IP addresses from this file by reading each line and isolating the first element (the IP address). Finally, use a command to count unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{print $1}' /var/log/myapp/access-20231012.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/log/myapp\necho -e \"192.168.1.1 user1 [12/Oct/2023:10:00:00 +0000] \\\"GET / HTTP/1.1\\\" 200 1234\\n192.168.1.2 user2 [12/Oct/2023:10:05:00 +0000] \\\"POST /submit HTTP/1.1\\\" 404 5678\\n192.168.1.3 user3 [12/Oct/2023:10:15:00 +0000] \\\"GET /dashboard HTTP/1.1\\\" 200 3456\\n192.168.1.2 user2 [12/Oct/2023:11:00:00 +0000] \\\"GET /settings HTTP/1.0\\\" 200 432\" > /var/log/myapp/access-20231012.log\n# Additional logs for other dates\necho -e \"10.0.0.5 user4 [11/Oct/2023:09:00:00 +0000] \\\"GET /home HTTP/1.1\\\" 200 6789\" > /var/log/myapp/access-20231011.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{print $1}' /var/log/myapp/access-20231012.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains lines in the format: \"[timestamp] [log_level] - [message]\". You need to find out how many times the log level \"ERROR\" appears across all these log files. Provide your answer as an integer.",
        "explanation": "To solve this problem, you should first navigate to the \"log_files\" directory and then use a combination of text processing utilities like `grep`, `awk`, or `sed` to filter out lines with the \"ERROR\" log level. You can use `grep` to search for the term \"ERROR\", and then count the occurrences using commands like `wc -l` which counts the number of lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\ncat <<EOL > ~/log_files/app1.log\n[2023-01-01 10:00:00] INFO - Application started\n[2023-01-01 10:05:00] ERROR - Failed to connect to database\n[2023-01-01 10:15:00] WARN - Low memory warning\n[2023-01-01 10:20:00] ERROR - Timeout occurred during operation\nEOL\n\ncat <<EOL > ~/log_files/app2.log\n[2023-01-02 12:00:00] INFO - New session created\n[2023-01-02 12:30:00] ERROR - Invalid user input detected\n[2023-01-02 13:00:00] INFO - Session terminated normally\nEOL\n\ncat <<EOL > ~/log_files/app3.log\n[2023-01-03 14:45:00] WARN - Disk space running low\n[2023-01-03 15:10:00] ERROR - Unable to save file, permission denied\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the `.log` extension. Each file contains timestamps and various log messages. Your task is to count how many unique dates (in the format YYYY-MM-DD) appear across all log files in this directory and provide the number as your answer.",
        "explanation": "To solve this problem, you should first list all the `.log` files in the \"logs\" directory. Then, extract all the dates from each file based on the timestamp format YYYY-MM-DD. After extracting, collect all unique dates and count them to get the final answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -name \"*.log\" -exec cat {} \\; | grep -oP '\\d{4}-\\d{2}-\\d{2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat > ~/logs/log1.log <<EOL\n2023-10-01 12:00:00 INFO Starting process A\n2023-10-02 13:00:00 ERROR Process A failed\n2023-10-01 14:00:00 INFO Retrying process A\nEOL\n\ncat > ~/logs/log2.log <<EOL\n2023-10-03 09:30:00 INFO Starting process B\n2023-10-02 16:45:00 WARN Process B slow response\n2023-10-04 11:20:00 INFO Process B completed successfully \nEOL\n\ncat > ~/logs/log3.log <<EOL\n2023-09-30 08:15:00 INFO Maintenance window started \n2023-09-30 19:45:00 INFO Maintenance window ended \nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -name \"*.log\" -exec cat {} \\; | grep -oP '\\d{4}-\\d{2}-\\d{2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are required to count the number of unique IP addresses that have accessed the web server, as recorded in the log file named `access.log` located in your home directory. You should output only the total count of these unique IP addresses.",
        "explanation": "To solve this problem, you can use standard Linux command-line utilities. First, extract all IP addresses from the `access.log` file using a tool like `awk`. Then, use `sort` to sort them and `uniq` to filter out duplicates. Finally, use `wc -l` to count the number of unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract IP addresses, sort them and get unique ones, then count them.\nawk '{print $1}' ~/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample access log file with multiple entries\ncat <<EOL > ~/access.log\n192.168.1.1 - - [01/Jan/2023:10:15:32 +0000] \"GET /index.html HTTP/1.1\" 200 1024\n192.168.1.2 - - [01/Jan/2023:10:16:45 +0000] \"POST /form HTTP/1.1\" 200 512\n192.168.1.3 - - [01/Jan/2023:10:17:23 +0000] \"GET /contact.html HTTP/1.1\" 404 256\n192.168.1.2 - - [01/Jan/2023:10:18:53 +0000] \"GET /about.html HTTP/1.1\" 200 1024\n192.168.1.4 - - [01/Jan/2023:10:19:12 +0000] \"GET /home.html HTTP/1.1\" 200 2048\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract IP addresses, sort them and get unique ones, then count them.\nawk '{print $1}' ~/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory. This directory contains multiple log files with a \".log\" extension. Each log file records different system events, and each line in the log files starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique dates (in \"YYYY-MM-DD\" format) appear across all the log files combined.",
        "explanation": "To solve this problem, you need to extract the date portion from each line of each log file, then collect all unique dates. This can be done by using tools like `awk` to parse and extract the date, and `sort` combined with `uniq` to filter out duplicates. Finally, count the number of unique dates using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:01 Event1\\n2023-10-02 13:30:45 Event2\\n2023-10-01 14:15:22 Event3\" > ~/logs/system1.log\necho -e \"2023-10-03 09:00:00 Event4\\n2023-10-02 11:45:00 Event5\\n2023-10-04 12:30:00 Event6\" > ~/logs/system2.log\necho -e \"2023-10-05 08:20:00 Event7\\n2023-10-03 17:50:32 Event8\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Each log file contains lines of text where each line starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\" followed by a message. Your task is to find out how many unique days (in YYYY-MM-DD format) are recorded across all these log files. You should execute commands directly in the shell to achieve this.",
        "explanation": "To solve this problem, you need to extract the date part from each line of every log file, filter out duplicates, and count the number of unique dates. This can be achieved using tools like `grep`, `awk`, `sort`, and `uniq`. First, use `grep` or another tool to pull out lines from the files. Then use `awk` to extract just the date portion (first 10 characters) of each line. Use `sort` and `uniq` to eliminate duplicate dates and finally count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all unique days across all log files\nawk '{print substr($0,1,10)}' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create logs directory in home if it doesn't exist\nmkdir -p ~/logs\n\n# Create sample log files with timestamps and messages\necho -e \"2023-01-01 12:00:00 Log entry one\\n2023-01-02 14:30:00 Log entry two\\n2023-01-03 09:15:00 Log entry three\" > ~/logs/log1.log\necho -e \"2023-01-02 16:45:00 Another entry\\n2023-01-04 11:05:00 Yet another entry\" > ~/logs/log2.log\necho -e \"2023-01-03 18:25:00 More entries\\n2023-01-05 08:55:00 Final entry\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all unique days across all log files\nawk '{print substr($0,1,10)}' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named `project_logs` which contains several log files with the `.log` extension. Each log file contains multiple entries in the format \"YYYY-MM-DD HH:MM:SS - [LEVEL] - Message\". Your task is to count the total number of error entries across all log files in this directory. An error entry is denoted by \"[ERROR]\" within the log entry. Assume that the `project_logs` directory is located in your home directory.",
        "explanation": "To solve this problem, you need to navigate to the `project_logs` directory and search for all lines containing \"[ERROR]\" in each `.log` file. You can utilize commands such as `grep` to filter these lines and then use `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"\\[ERROR\\]\" ~/project_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho \"2023-10-01 12:00:00 - [INFO] - System boot\" > ~/project_logs/system.log\necho \"2023-10-01 12:01:00 - [ERROR] - Failed to start service\" >> ~/project_logs/system.log\necho \"2023-10-01 12:02:00 - [INFO] - Service running\" >> ~/project_logs/system.log\necho \"2023-10-01 12:03:00 - [ERROR] - Connection timeout\" >> ~/project_logs/system.log\n\necho \"2023-10-02 14:00:00 - [INFO] - User login\" > ~/project_logs/application.log\necho \"2023-10-02 14:01:00 - [ERROR] - Null pointer exception\" >> ~/project_logs/application.log\necho \"2023-10-02 14:02:00 - [WARN] - Low memory\" >> ~/project_logs/application.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"\\[ERROR\\]\" ~/project_logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the total number of files and directories in the \"/var/log\" directory that were modified in the last 7 days. Provide just the count as your answer.",
        "explanation": "To solve this problem, you need to use a combination of `find`, `wc`, and other command-line utilities. The `find` command can be used to search for files and directories modified in the last 7 days (`-mtime -7`). You can then pipe the output of `find` into `wc -l` to count the number of lines, which corresponds to the number of files and directories found.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use find to locate files/directories modified in the last 7 days and count them.\nfind /var/log -type f,d -mtime -7 | wc -l\n```",
        "create": {
            "init": "# No specific initialization required; an empty script is provided."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use find to locate files/directories modified in the last 7 days and count them.\nfind /var/log -type f,d -mtime -7 | wc -l"
        }
    },
    {
        "description": "In the current directory, there are multiple text files named `access_log1`, `access_log2`, ..., `access_logN` that contain web server access logs. Each line in these logs follows the common log format: \"IP_ADDRESS - - [DATE] \"REQUEST\" STATUS_CODE SIZE\". Your task is to find and report the total number of unique IP addresses across all these log files. You must perform this task directly in the shell, without writing a script.",
        "explanation": "To solve this problem, you need to extract all unique IP addresses from each log file and then count them. You can use tools like `awk`, `sort`, and `uniq` to process each file. Start by reading the contents of all access logs using a command like `cat access_log*`. Use `awk` to extract only the IP addresses (the first field). Then, sort these IPs and pipe them into `uniq` to remove duplicates. Finally, use a command like `wc -l` to count how many unique IPs exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution using shell commands\n\n# Combine all log files, extract IP addresses, sort them, filter unique ones and count.\ncat access_log* | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create sample log files for initialization\necho '192.168.1.1 - - [01/Jan/2023:10:00:00 +0000] \"GET /index.html HTTP/1.1\" 200 1024' > access_log1\necho '192.168.1.2 - - [01/Jan/2023:10:05:00 +0000] \"POST /form.html HTTP/1.1\" 404 2048' >> access_log1\necho '192.168.1.3 - - [01/Jan/2023:10:15:00 +0000] \"GET /about.html HTTP/1.1\" 200 512' > access_log2\necho '192.168.1.2 - - [01/Jan/2023:10:20:00 +0000] \"GET /contact.html HTTP/1.1\" 200 256' >> access_log2"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution using shell commands\n\n# Combine all log files, extract IP addresses, sort them, filter unique ones and count.\ncat access_log* | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with the \".log\" extension. Count how many unique IP addresses have accessed the system, as recorded in these log files. Assume that IP addresses are in the standard format (e.g., 192.168.1.1). You should only consider IPs from lines starting with \"Accessed by\".",
        "explanation": "To solve this problem, you need to process each log file within the \"logs\" directory. Look for lines that start with \"Accessed by\" and extract the IP address from each of these lines. Once you have a list of all IP addresses, use a tool like `sort` and `uniq` to count only unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"^Accessed by\" ~/logs/*.log | awk '{print $3}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"Accessed by 192.168.1.1\\nAccessed by 10.0.0.2\\nFailed login attempt\\nAccessed by 192.168.1.1\" > ~/logs/logfile1.log\necho \"Accessed by 172.16.0.3\\nError report\\nAccessed by 10.0.0.2\" > ~/logs/logfile2.log\necho \"Warning: Low disk space\\nAccessed by 192.168.1.4\" > ~/logs/logfile3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"^Accessed by\" ~/logs/*.log | awk '{print $3}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named `logfiles` in your home directory containing multiple `.log` files. Each log file contains various system event logs with timestamps. Your task is to find out the total number of unique IP addresses that have accessed the system across all log files. Assume each access is logged in the format: `[timestamp] Access from IP: xxx.xxx.xxx.xxx`. You should only consider lines that match this pattern.",
        "explanation": "To solve this problem, you need to first navigate to the `logfiles` directory and read all the `.log` files. Use a combination of `grep` to extract lines matching the specified pattern, followed by `awk` or `sed` to isolate the IP addresses. Finally, use tools like `sort` and `uniq` to count unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"Access from IP:\" ~/logfiles/*.log | awk '{print $NF}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\ncat <<EOL > ~/logfiles/access1.log\n[2023-10-01 10:00:00] Access from IP: 192.168.1.1\n[2023-10-01 11:00:00] Access from IP: 192.168.1.2\nEOL\n\ncat <<EOL > ~/logfiles/access2.log\n[2023-10-01 12:00:00] Access from IP: 192.168.1.2\n[2023-10-01 13:00:00] Access from IP: 192.168.1.3\nEOL\n\ncat <<EOL > ~/logfiles/access3.log\n[2023-10-01 14:00:00] Access from IP: 192.168.1.4\n[2023-10-01 15:00:00] Access from IP: 192.168.1.1\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"Access from IP:\" ~/logfiles/*.log | awk '{print $NF}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"data_logs\" in your home directory containing multiple text files with various extensions. Some of these files have a \".log\" extension and contain timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find the earliest timestamp from all the \".log\" files and provide it as your answer. Assume all timestamps are valid and formatted correctly.",
        "explanation": "To solve this problem, you need to navigate to the \"data_logs\" directory and search through all \".log\" files for timestamps. You can use tools like `grep` to extract lines containing timestamps, then use `sort` to sort them, and finally use `head` to get the earliest timestamp.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/data_logs\ngrep -hoE '^[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}' *.log | sort | head -n 1\n```",
        "create": {
            "init": "mkdir -p ~/data_logs\necho \"2023-10-01 14:23:00\" > ~/data_logs/file1.log\necho \"2023-09-25 09:15:30\" > ~/data_logs/file2.log\necho \"This is a random line\" > ~/data_logs/file3.txt\necho \"2023-10-02 18:47:22\" > ~/data_logs/file4.log\necho \"Another random line\" > ~/data_logs/file5.txt\necho \"2023-08-30 12:00:00\" > ~/data_logs/file6.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "cd ~/data_logs\ngrep -hoE '^[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}' *.log | sort | head -n 1"
        }
    },
    {
        "description": "In the current directory, there is a file named `access.log` which contains web server access logs. Each line in the log represents a single HTTP request and is formatted as follows: `IP_ADDRESS - - [DATE] \"REQUEST\" STATUS_CODE SIZE`. You need to identify how many unique IP addresses have made requests that resulted in a 404 error code. Provide the count of these unique IP addresses.",
        "explanation": "To solve this problem, you should first filter out lines from the `access.log` that contain the status code 404. Then, extract the IP addresses from these filtered lines and determine how many unique IP addresses there are.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '404' access.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "cat <<EOL > access.log\n192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \"GET /index.html HTTP/1.1\" 200 1024\n192.168.1.2 - - [10/Oct/2023:13:56:40 +0000] \"GET /about.html HTTP/1.1\" 404 512\n192.168.1.3 - - [10/Oct/2023:13:57:15 +0000] \"POST /submit-form HTTP/1.1\" 404 256\n192.168.1.2 - - [10/Oct/2023:13:58:20 +0000] \"GET /contact.html HTTP/1.1\" 200 2048\n192.168.1.4 - - [10/Oct/2023:14:00:05 +0000] \"GET /not-found.html HTTP/1.1\" 404 128\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '404' access.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have been provided with a directory named \"logfiles\" located in your home directory. This directory contains multiple log files with names following the pattern \"logfile_YYYYMMDD.txt\", where YYYYMMDD represents the date of the log entry. Your task is to determine the total number of unique IP addresses that appear in all log files within this directory. Each line in the log files starts with an IP address, followed by other log details. To simplify, assume each line contains only one IP address and there are no duplicate entries within a single file.",
        "explanation": "To solve this problem, you need to first extract all IP addresses from every file in the \"logfiles\" directory. Then, consolidate these IP addresses into a single list to identify and count the unique ones. This can be achieved using a combination of `cat`, `awk`, `sort`, and `uniq` commands.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logfiles/logfile_*.txt | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"192.168.1.1 - User login\\n10.0.0.2 - Access granted\\n192.168.1.3 - Connection established\" > ~/logfiles/logfile_20230101.txt\necho -e \"10.0.0.2 - User login\\n172.16.0.4 - Access denied\\n192.168.1.5 - Connection reset\" > ~/logfiles/logfile_20230102.txt\necho -e \"192.168.1.1 - User logout\\n10.0.0.6 - System reboot\\n172.16.0.4 - Connection established\" > ~/logfiles/logfile_20230103.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logfiles/logfile_*.txt | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"project_data\" containing multiple text files. Each file contains a list of numbers separated by new lines. Your task is to find the sum of all unique numbers across all these files. The result should be an integer representing this sum.",
        "explanation": "To solve this problem, you need to iterate through each file in the \"project_data\" directory, read all the numbers from each file, and collect them into a single set to ensure uniqueness. After collecting all the unique numbers, calculate their sum and output it as an integer.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Collect all unique numbers from each file in project_data directory\nunique_numbers=$(cat ~/project_data/* | sort -n | uniq)\n\n# Calculate the sum of these unique numbers\nsum=0\nfor num in $unique_numbers; do\n  sum=$((sum + num))\ndone\n\n# Output the result (just the integer)\necho $sum\n```",
        "create": {
            "init": "mkdir -p ~/project_data\necho -e \"10\\n20\\n30\\n40\" > ~/project_data/file1.txt\necho -e \"30\\n40\\n50\\n60\" > ~/project_data/file2.txt\necho -e \"60\\n70\\n80\\n90\" > ~/project_data/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Collect all unique numbers from each file in project_data directory\nunique_numbers=$(cat ~/project_data/* | sort -n | uniq)\n\n# Calculate the sum of these unique numbers\nsum=0\nfor num in $unique_numbers; do\n  sum=$((sum + num))\ndone\n\n# Output the result (just the integer)\necho $sum"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory containing multiple log files with various extensions. Your task is to find and count the number of unique IP addresses found across all the \".log\" files in this directory. Assume that each log entry contains an IP address at the beginning of the line.",
        "explanation": "To solve this problem, you need to first filter out all files with the \".log\" extension within the \"logs\" directory. Then, you will extract IP addresses from these files, ensuring to handle duplicates by counting only unique IP addresses. The process involves using tools such as `grep` to search for patterns that match IP address formats and `sort` combined with `uniq` to count distinct entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -hoE '([0-9]{1,3}\\.){3}[0-9]{1,3}' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 - User accessed\\n10.0.0.2 - User logged in\\n192.168.1.1 - User logged out\" > ~/logs/access.log\necho -e \"172.16.0.5 - Error occurred\\n192.168.1.1 - Connection refused\\n10.0.0.2 - Error fixed\" > ~/logs/error.log\necho -e \"10.0.0.2 - Data processed\\n172.16.0.5 - Data saved\" > ~/logs/process.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -hoE '([0-9]{1,3}\\.){3}[0-9]{1,3}' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory called \"logs\" in your home directory containing multiple log files with a \".log\" extension. Each log file contains lines with timestamps, error levels (INFO, WARN, ERROR), and messages. Your task is to count the total number of ERROR entries across all log files in the \"logs\" directory. Assume all logs are in plain text format.",
        "explanation": "To solve this problem, you need to iterate over each \".log\" file in the \"logs\" directory, extract lines containing \"ERROR\", and count them. You can use tools like `grep` to filter lines and `wc -l` to count them. Combine these steps using a loop or leverage `find` with `xargs` for efficiency.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -name '*.log' | xargs grep 'ERROR' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 10:00:00 INFO System started\\n2023-10-01 10:05:00 ERROR Failed to load module\\n2023-10-01 10:10:00 WARN Low memory\" > ~/logs/system1.log\necho -e \"2023-10-02 11:00:00 INFO User login\\n2023-10-02 11:05:00 ERROR Disk space low\\n2023-10-02 11:06:00 ERROR Network timeout\\n2023-10-02 11:07:00 INFO User logout\" > ~/logs/system2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -name '*.log' | xargs grep 'ERROR' | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing a log file named `system.log` located in the `/var/logs` directory. Your goal is to count how many times the keyword \"ERROR\" appears in this log file. Ensure that your solution accounts for case sensitivity (i.e., \"error\" and \"ERROR\" should be treated differently).",
        "explanation": "To solve this problem, you can use tools like `grep` to search for occurrences of the keyword \"ERROR\" in the log file. Use the appropriate flags to ensure case sensitivity is preserved. Then, you can use `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -w 'ERROR' /var/logs/system.log | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs\necho -e \"INFO: System started\\nERROR: Disk not found\\nINFO: User logged in\\nerror: Connection lost\\nWARNING: High memory usage\\nERROR: Timeout occurred\" > /var/logs/system.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -w 'ERROR' /var/logs/system.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with a \".log\" extension. Each log file contains various entries with timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to identify the most recent log entry across all these files and return the entire line containing this timestamp. Assume all log files are well-formed and contain at least one valid entry.",
        "explanation": "To solve this problem, you need to iterate over all \".log\" files within the \"logs\" directory, extract timestamps from each line, compare them to find the most recent one, and then return the corresponding line. You can use tools like `find` to locate all \".log\" files, `grep` or `awk` to extract lines and timestamps, and `sort` or custom comparison logic to ascertain the most recent timestamp.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -name \"*.log\" | xargs grep -h \"\" | sort | tail -n 1\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-09-01 12:00:00 Log entry A\\n2023-09-01 13:00:00 Log entry B\" > ~/logs/file1.log\necho -e \"2023-10-01 10:30:00 Log entry C\\n2023-10-02 11:45:00 Log entry D\" > ~/logs/file2.log\necho -e \"2023-08-15 09:15:00 Log entry E\\n2023-11-03 14:20:00 Log entry F\" > ~/logs/file3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "find ~/logs -name \"*.log\" | xargs grep -h \"\" | sort | tail -n 1"
        }
    },
    {
        "description": "Count the total number of unique words used in all `.txt` files present in the `/home/student/documents/` directory. You should consider words to be case-insensitive and ignore any punctuation. Ensure the results are sorted alphabetically.",
        "explanation": "To solve this problem, you can use a combination of several bash utilities such as `find`, `cat`, `tr`, `sort`, `uniq`, and `wc`. First, locate all `.txt` files in the specified directory using `find`. Then, concatenate their contents with `cat`. Use `tr` to convert all text to lowercase and remove punctuation. Finally, sort the words alphabetically, filter out unique entries with `uniq`, and count them using `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all .txt files, concatenate their contents,\n# convert to lowercase, remove punctuation,\n# sort alphabetically, find unique words,\n# and count them.\nfind /home/student/documents/ -type f -name \"*.txt\" \\\n    -exec cat {} + | tr '[:upper:]' '[:lower:]' | tr -d '[:punct:]' | \\\n    tr ' ' '\\n' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create directory structure and sample text files\nmkdir -p /home/student/documents/\necho \"Hello World! This is a test file.\" > /home/student/documents/file1.txt\necho \"Another line here: Testing, testing.\" >> /home/student/documents/file1.txt\necho \"Unique Words Count Example.\" > /home/student/documents/file2.txt\necho \"Example of a test file.\" >> /home/student/documents/file2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all .txt files, concatenate their contents,\n# convert to lowercase, remove punctuation,\n# sort alphabetically, find unique words,\n# and count them.\nfind /home/student/documents/ -type f -name \"*.txt\" \\\n    -exec cat {} + | tr '[:upper:]' '[:lower:]' | tr -d '[:punct:]' | \\\n    tr ' ' '\\n' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory called \"project_logs\" in your home directory containing multiple log files with the extension \".log\". Each log file contains timestamps followed by error messages. Your task is to find out how many unique error messages are present across all log files in the \"project_logs\" directory. You can ignore the timestamps and only consider lines that start with \"ERROR:\". Count these unique error messages.",
        "explanation": "To solve this problem, you'll need to iterate over each log file in the \"project_logs\" directory, extract lines starting with \"ERROR:\", and collect all unique messages. Consider using utilities like `grep` to filter lines, `sed` or `awk` to strip timestamps, and `sort` combined with `uniq` to find unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^ERROR:' ~/project_logs/*.log | sed 's/^.*ERROR://g' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"2023-10-01 10:00:00 ERROR: File not found\\n2023-10-01 10:05:00 INFO: Task completed\\n2023-10-01 10:15:00 ERROR: Network timeout\" > ~/project_logs/log1.log\necho -e \"2023-10-02 11:00:00 ERROR: File not found\\n2023-10-02 11:05:00 WARNING: Low disk space\\n2023-10-02 11:15:00 ERROR: Access denied\" > ~/project_logs/log2.log\necho -e \"2023-10-03 12:00:00 INFO: User login\\n2023-10-03 12:05:00 ERROR: Network timeout\\n2023-10-03 12:15:00 ERROR: Access denied\" > ~/project_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^ERROR:' ~/project_logs/*.log | sed 's/^.*ERROR://g' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory. Each file inside this directory contains lines of text, and each line represents a log entry with a timestamp followed by a status code (e.g., 200, 404, 500). Your task is to count how many times the status code \"404\" appears across all files within the \"logfiles\" directory. You need to output this count as an integer.",
        "explanation": "To solve this problem, you can use utilities like `grep` to filter lines containing the status code \"404\", and then use `wc -l` to count these lines across all files in the specified directory. The command should be executed directly in the shell.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -rh '404' ~/logfiles | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-10-01 12:00:00 200\\n2023-10-01 12:05:00 404\\n2023-10-01 12:10:00 500\" > ~/logfiles/log1.txt\necho -e \"2023-10-02 13:00:00 404\\n2023-10-02 13:15:00 200\\n2023-10-02 13:20:00 404\" > ~/logfiles/log2.txt\necho -e \"2023-10-03 14:30:00 500\\n2023-10-03 14:35:00 404\\n2023-10-03 14:40:00 200\" > ~/logfiles/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -rh '404' ~/logfiles | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with a \".log\" extension. Each log file contains lines of text with timestamps and messages. Your task is to find out how many unique error codes appear across all the log files. An error code is defined as any word that starts with \"ERR\" followed by digits, e.g., \"ERR123\". Count the number of unique error codes.",
        "explanation": "To solve this problem, you need to first navigate to the \"logs\" directory and identify all files with a \".log\" extension. You can use `grep` to search for patterns matching error codes (words starting with \"ERR\" followed by digits) within these files. Use `sort` and `uniq` utilities to filter out unique error codes and finally count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep -o -h 'ERR[0-9]\\+' *.log | sort | uniq | wc -l # Outputs only the count of unique error codes.\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/log1.log\n2023-10-01 12:00:00 ERR001 Failed to connect to database\n2023-10-01 12:05:00 INFO User logged in successfully\n2023-10-01 12:10:00 ERR002 Unable to reach server\n2023-10-01 12:15:00 ERR001 Failed to connect to database\nEOL\n\ncat <<EOL > ~/logs/log2.log\n2023-10-02 13:00:00 ERR003 File not found\n2023-10-02 13:05:00 WARN Low disk space\n2023-10-02 13:10:00 ERR002 Unable to reach server\n2023-10-02 13:15:00 INFO Backup completed successfully\nEOL\n\ncat <<EOL > ~/logs/log3.log\n2023-10-03 14:00:00 CRIT System overheated shutting down immediately!\n2023-10-03 14:05:00 ERR004 Memory allocation failed\n2023-10-03 14:15:00 INFO System rebooted successfully \nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep -o -h 'ERR[0-9]\\+' *.log | sort | uniq | wc -l # Outputs only the count of unique error codes."
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" containing multiple text files. Each file contains log entries in the format \"YYYY-MM-DD HH:MM:SS [LOG_LEVEL] Message\". Your task is to count how many ERROR level log entries exist across all files in the \"logs\" directory. Assume each file can have any number of lines and might not have any ERROR logs.",
        "explanation": "To solve this problem, you need to read through each file in the \"logs\" directory, extract lines that contain \"[ERROR]\", and count them. You can use utilities like `grep` to filter out ERROR logs and `wc -l` to count the number of matching lines. Combining these commands with others like `find` or loops can help you iterate through files efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind logs -type f -exec grep -ho \"\\[ERROR\\]\" {} + | wc -l\n```",
        "create": {
            "init": "mkdir logs\necho -e \"2023-10-05 10:23:45 [INFO] System started\\n2023-10-05 11:00:01 [ERROR] Disk full\\n2023-10-05 12:47:33 [WARN] High memory usage\" > logs/log1.txt\necho -e \"2023-10-06 09:15:00 [ERROR] Network down\\n2023-10-06 09:16:22 [INFO] Network restored\\n2023-10-06 09:17:55 [ERROR] Network down again\" > logs/log2.txt\necho -e \"2023-10-07 14:03:21 [INFO] Backup completed\\n2023-10-07 14:04:45 [ERROR] Backup corrupted\\n2023-10-07 14:05:00 [INFO] Retrying backup\" > logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find logs -type f -exec grep -ho \"\\[ERROR\\]\" {} + | wc -l"
        }
    },
    {
        "description": "In your home directory, there's a folder named \"logs\" containing multiple .log files. These log files contain records of different events with timestamps. Your task is to determine the total number of unique event types recorded across all the .log files in the \"logs\" directory. Each line in a log file represents an event and starts with an event type followed by a timestamp and other details. Event types are alphanumeric strings without spaces.",
        "explanation": "To solve this problem, you should first navigate to the \"logs\" directory in your home folder. Then, you need to extract all unique event types from each .log file and count them collectively. This requires reading each line of the log files, isolating the event type (the first word), and maintaining a set of these types to ensure uniqueness before counting them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\nawk '{print $1}' *.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"LOGIN 2023-10-01 10:00:00 UserA\\nLOGOUT 2023-10-01 11:00:00 UserA\\nLOGIN 2023-10-01 12:30:00 UserB\" > ~/logs/events1.log\necho -e \"LOGIN 2023-10-02 09:15:00 UserC\\nERROR 2023-10-02 09:45:00 System\\nSHUTDOWN 2023-10-02 23:59:59 Maintenance\" > ~/logs/events2.log\necho -e \"STARTUP 2023-10-03 06:30:00 System\\nERROR 2023-10-03 07:20:00 System\\nLOGOUT 2023-10-03 08:50:00 UserB\" > ~/logs/events3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\nawk '{print $1}' *.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple .log files. Each file represents logs from different services on a server. Your task is to determine how many unique IP addresses have accessed the server across all these log files. Consider each line in a log file that starts with an IP address followed by a space. Ignore lines that do not start with a valid IPv4 address.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"logs\" directory within your home directory.\n2. Use tools like `grep` and `awk` to extract potential IP addresses from each log file.\n3. Filter out invalid entries by ensuring they match the IPv4 format.\n4. Collect all valid IP addresses from across all files and identify unique ones using tools like `sort` and `uniq`.\n5. Count the number of unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the logs directory\ncd ~/logs\n\n# Extract lines starting with a potential IPv4 address, validate format, sort and count unique entries.\ngrep -hoP '^\\d{1,3}(\\.\\d{1,3}){3}' *.log | awk '$1 ~ /^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+$/' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/service1.log\n192.168.0.1 User login successful\n10.0.0.5 Error: Unable to connect\n255 Invalid entry here\n192.168.0.1 Another access attempt\nEOL\n\ncat <<EOL > ~/logs/service2.log\n172.16.0.7 Data processed successfully\n192.168 Invalid log line\n10 Another invalid entry\n172.16 Invalid again\n10 Invalid still\n172.16 0 8 Extra spaces here too \nEOL\n\ncat <<EOL > ~/logs/service3.log\n203 No valid IP here either \n172 Invalid but looks close \n203 No valid IP here either \n11 2 13 Yet another invalid  \n123 Invalid as well   \n11 Valid?\n203 No valid IP here either \n192 256 Also invalid  \n11 Valid?\nNone of these are valid!\nYes, None of them!\nNope! Not even one!\nDone.\n203 No valid IP here either \nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to the logs directory\ncd ~/logs\n\n# Extract lines starting with a potential IPv4 address, validate format, sort and count unique entries.\ngrep -hoP '^\\d{1,3}(\\.\\d{1,3}){3}' *.log | awk '$1 ~ /^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+$/' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the most frequently used command on your system. To do this, you must analyze the `.bash_history` file located in your home directory to determine which command appears the most. You should filter out any commands that contain spaces or special characters (e.g., `&&`, `|`). Provide the name of the command as your answer.",
        "explanation": "To solve this problem, you need to extract commands from your `.bash_history` file and count their occurrences. Use tools like `awk` or `cut` to isolate the first word of each line (the command itself), then use a combination of `grep`, `sort`, and `uniq` to filter out commands containing spaces or special characters, and finally determine which of these occurs most frequently.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script:\ncat ~/.bash_history | awk '{print $1}' | grep -v '[ &|]' | sort | uniq -c | sort -nr | head -n 1 | awk '{print $2}'\n```",
        "create": {
            "init": "# Initialization script: Creating a sample .bash_history for testing.\necho -e \"ls\\ncd ..\\ngit status\\nls -la\\ncat myfile.txt\\necho 'Hello'\\nls\\nls\" > ~/.bash_history"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "# Example solution script:\ncat ~/.bash_history | awk '{print $1}' | grep -v '[ &|]' | sort | uniq -c | sort -nr | head -n 1 | awk '{print $2}'"
        }
    },
    {
        "description": "You are given a directory named \"logs\" within your home directory containing multiple log files with the extension \".log\". Each log file contains entries in the format \"YYYY-MM-DD HH:MM:SS [ERROR] Message\". Your task is to find out how many unique dates (YYYY-MM-DD) there are across all the log files that contain at least one \"[ERROR]\" entry. Please note that the entries might not be sorted by date or time within each file, and some files might not contain any \"[ERROR]\" entries.",
        "explanation": "To solve this problem, you need to iterate through each \".log\" file in the \"logs\" directory and extract dates from lines that contain \"[ERROR]\". Collect these dates into a set to ensure uniqueness. Finally, count the number of unique dates in the set.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files in logs directory.\ncd ~/logs\n\n# Extract unique dates with ERROR entries.\ngrep \"\\[ERROR\\]\" *.log | cut -d' ' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 08:00:00 [INFO] System started\\n2023-10-01 09:00:00 [ERROR] Disk full\\n2023-10-02 10:00:00 [WARNING] High CPU usage\" > ~/logs/system1.log\necho -e \"2023-10-03 11:30:00 [ERROR] Network down\\n2023-10-04 12:15:00 [INFO] Backup completed\\n2023-10-03 13:45:00 [ERROR] Memory leak detected\" > ~/logs/system2.log\necho -e \"2023-10-05 14:55:00 [INFO] User login\\n2023-10-05 15:05:00 [ERROR] Unauthorized access attempt\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files in logs directory.\ncd ~/logs\n\n# Extract unique dates with ERROR entries.\ngrep \"\\[ERROR\\]\" *.log | cut -d' ' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains lines of text, and some lines contain timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique days (in the format \"YYYY-MM-DD\") are present across all these log files. Assume there might be duplicate entries within or across files.",
        "explanation": "To solve this problem, you need to extract all the timestamps from each \".log\" file within the \"log_files\" directory, then parse out the date component (the \"YYYY-MM-DD\" part). Collect these dates and determine how many unique dates exist by using tools like `grep`, `awk`, `sort`, and `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract dates from all log files, sort them, remove duplicates, and count unique entries.\ngrep -hoE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' ~/log_files/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-10-01 12:00:00\\n2023-10-01 13:00:00\\n2023-10-02 09:30:00\\nSome other text\" > ~/log_files/log1.log\necho -e \"2023-10-02 14:20:00\\nAnother line\\n2023-10-03 16:45:20\" > ~/log_files/log2.log\necho -e \"Random text\\n2023-10-04 11:15:05\\nMore random text\" > ~/log_files/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract dates from all log files, sort them, remove duplicates, and count unique entries.\ngrep -hoE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' ~/log_files/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a directory named \"log_files\" containing multiple log files with the \".log\" extension. Each log file contains several lines of text. Your task is to identify how many unique IP addresses are present across all these log files. An IP address is formatted as four groups of one to three digits separated by periods (e.g., 192.168.0.1). Consider only valid IPv4 addresses.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"log_files\" directory in your home directory.\n2. Use a combination of shell commands to extract IP addresses from all \".log\" files.\n3. Filter out duplicate IP addresses to determine the count of unique IPs.\n4. Print the number of unique IP addresses.\n\nYou can use utilities like `grep` for pattern matching, `sort`, and `uniq` for filtering duplicates, and `wc -l` for counting lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Navigate to the log_files directory\ncd ~/log_files\n\n# Extract all IP addresses across all .log files, filter unique ones and count them\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' *.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create the log_files directory in the home directory\nmkdir -p ~/log_files\n\n# Populate it with some sample log files containing random IP addresses\necho -e \"Error at 192.168.1.1\\nConnection from 10.0.0.5\\nAttempted access from 172.16.0.10\" > ~/log_files/log1.log\necho -e \"Access granted to 192.168.1.2\\nFailed login from 10.0.0.5\\nPing from 192.168.1.3\" > ~/log_files/log2.log\necho -e \"Session started for 172.16.0.11\\nData sent to 192.168.1.3\\nAlert from 10.x.x.x.invalid\" > ~/log_files/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Navigate to the log_files directory\ncd ~/log_files\n\n# Extract all IP addresses across all .log files, filter unique ones and count them\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' *.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" containing various log files with extensions \".log\". Each log file contains error messages and other logs. Your task is to find and count the total number of unique error messages across all log files in this directory. Assume that an error message starts with the word \"ERROR\" and continues to the end of the line. The task is case-sensitive, meaning \"ERROR\" and \"error\" should be considered different.",
        "explanation": "To solve this problem, you need to navigate through each log file in the \"logfiles\" directory, extract lines that start with \"ERROR\", and collect these lines into a temporary list. Then, determine the unique entries in this list and count them. A combination of `grep`, `sort`, `uniq`, and other text processing tools can be used for this purpose.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all unique ERROR messages across all .log files in the 'logfiles' directory.\ngrep '^ERROR' logfiles/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a directory named 'logfiles' if it doesn't exist\nmkdir -p logfiles\n\n# Create example log files with various error messages\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nWARNING: High CPU usage\\nERROR: Disk space low\" > logfiles/system.log\necho -e \"ERROR: Failed to connect to server\\nINFO: Connection established\\nERROR: Failed to connect to server\\nDEBUG: Connection retrying\" > logfiles/network.log\necho -e \"INFO: User login successful\\nERROR: Unauthorized access attempt detected\\nWARNING: Password attempt failed\" > logfiles/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all unique ERROR messages across all .log files in the 'logfiles' directory.\ngrep '^ERROR' logfiles/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains entries with timestamps and messages in the format \"YYYY-MM-DD HH:MM:SS - Message\". Your task is to count how many unique dates (in YYYY-MM-DD format) appear across all log files in this directory.",
        "explanation": "To solve this problem, you need to:\n1. List all the log files in the \"logs\" directory.\n2. Extract the dates from each line of these files.\n3. Collect all unique dates across all log files.\n4. Count the number of these unique dates.\n\nHints:\n- You can use `grep` to extract lines matching a pattern.\n- `awk` or `cut` can be used to extract specific portions of each line (e.g., date).\n- Use `sort` and `uniq` to get unique values.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Combine all lines from .log files, extract dates, sort them, get unique ones and count them\nfind ~/logs/ -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create logs directory if it doesn't exist\nmkdir -p ~/logs\n\n# Create example log files with sample data\necho -e \"2023-03-01 12:00:00 - Event A\\n2023-03-02 13:30:00 - Event B\\n2023-03-01 14:45:00 - Event C\" > ~/logs/log1.log\necho -e \"2023-03-02 09:15:00 - Event D\\n2023-03-03 10:30:00 - Event E\\n2023-03-04 11:45:00 - Event F\" > ~/logs/log2.log\necho -e \"2023-03-04 16:20:00 - Event G\\n2023-03-05 17:35:00 - Event H\\n2023-03-01 18:50:00 - Event I\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Combine all lines from .log files, extract dates, sort them, get unique ones and count them\nfind ~/logs/ -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, you have a subdirectory named `project_logs` containing multiple log files with the `.log` extension. Each log file contains entries in the format \"YYYY-MM-DD HH:MM:SS - Message\". Your task is to count how many entries occurred on a specific date (e.g., 2023-04-01) across all these log files. Assume each entry is on a new line.",
        "explanation": "To solve this problem, you need to iterate over each `.log` file in the `project_logs` directory, filter out lines that correspond to the specified date, and then count those lines. You can use tools like `grep` to search for entries with the specific date string and `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '2023-04-01' ~/project_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"2023-04-01 10:00:00 - Started process\\n2023-04-01 12:00:00 - Process checkpoint\\n2023-03-31 09:00:00 - Previous day entry\" > ~/project_logs/log1.log\necho -e \"2023-04-01 15:30:00 - Continued process\\n2023-04-02 11:00:00 - Future date entry\" > ~/project_logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '2023-04-01' ~/project_logs/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Your task is to find out how many unique IP addresses accessed the server on October 15, 2023. Assume each log entry starts with the IP address followed by a space and then the timestamp in the format \"[YYYY-MM-DD HH:MM:SS]\". You can assume all timestamps are in UTC.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"logs\" directory.\n2. Use `grep` or similar tools to filter lines containing the specific date \"2023-10-15\".\n3. Extract IP addresses from these filtered lines.\n4. Use `sort` and `uniq` commands to find unique IP addresses.\n5. Count these unique IP addresses using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep \"\\[2023\\-10\\-15\" *.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 [2023-10-15 14:32:21] Some log entry\\n192.168.1.2 [2023-10-15 16:45:00] Another log entry\\n192.168.1.1 [2023-10-15 18:00:35] Yet another log entry\\n192.168.1.3 [2023-10-14 12:34:56] Old log\" > ~/logs/access.log\necho -e \"192.168.1.4 [2023-10-15 20:12:45] Log message\\n192.168.1.2 [2023-10-15 22:18:23] More logs\\n192.168.1.5 [2023-10-13 09:22:11] Older logs\" > ~/logs/server.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep \"\\[2023\\-10\\-15\" *.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there are several subdirectories containing text files with various extensions. Your task is to determine the total number of lines across all text files (files with .txt extension) that contain the word \"Linux\" (case-sensitive). Ensure you search through all subdirectories recursively.",
        "explanation": "To solve this problem, you can use the `find` command to locate all .txt files in your home directory and its subdirectories. Then, use `xargs` to pass these files to `grep`, searching for lines containing the word \"Linux\". Finally, count these lines using `wc -l`. This will require you to combine several commands using pipes.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/test_directory/ -type f -name \"*.txt\" | xargs grep 'Linux' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/test_directory/subdir1\nmkdir -p ~/test_directory/subdir2\n\necho -e \"Linux is great\\nHello World\\nAnother line\" > ~/test_directory/file1.txt\necho -e \"Just a simple file\\nNot much here\" > ~/test_directory/file2.txt\necho -e \"Linux kernel\\nOperating systems are fun\" > ~/test_directory/subdir1/file3.txt\necho -e \"Learning Linux\\nIt is powerful\" > ~/test_directory/subdir2/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/test_directory/ -type f -name \"*.txt\" | xargs grep 'Linux' | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total disk space consumed by files ending with `.log` in a directory called `logs` located in your home directory. Consider only files that have been modified in the last 7 days. Your answer should be provided as a human-readable size (e.g., 3MB, 3072KB).",
        "explanation": "To solve this problem, you should first navigate to the `logs` directory in your home folder. Use the `find` command to list all `.log` files that have been modified within the last 7 days. Then, use the `du` command to calculate their total disk usage and convert it into a human-readable format using appropriate options.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\nfind . -name \"*.log\" -mtime -7 -exec du -ch {} + | grep total$ | cut -f1\n```",
        "create": {
            "init": "mkdir -p ~/logs\ntouch ~/logs/{system.log,error.log,access.log}\n# Modify timestamps to simulate recent changes\ntouch -d \"3 days ago\" ~/logs/system.log\ntouch -d \"5 days ago\" ~/logs/error.log\ntouch -d \"10 days ago\" ~/logs/access.log\n\n# Populate files with some data to consume space\necho \"System log content\" > ~/logs/system.log\necho \"Error log content\" > ~/logs/error.log\necho \"Access log content\" > ~/logs/access.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "cd ~/logs\nfind . -name \"*.log\" -mtime -7 -exec du -ch {} + | grep total$ | cut -f1"
        }
    },
    {
        "description": "In your home directory, there is a hidden log file named `.access.log` that records various access attempts to a server. Each line in this file contains the timestamp of the access attempt and the IP address of the client. Your task is to count how many unique IP addresses tried to access the server on a specific day, which is \"2023-10-15\". Ensure that you only consider completed lines with both date and IP address.",
        "explanation": "To solve this problem, you need to filter out entries from the `.access.log` file for the specified date \"2023-10-15\" and extract unique IP addresses from those lines. You can use utilities like `grep` to filter lines by date, `awk` or `cut` to extract IP addresses, and `sort` combined with `uniq` to count unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '2023-10-15' ~/.access.log | awk '{print $2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "cat <<EOL > ~/.access.log\n2023-10-14 192.168.1.1\n2023-10-15 192.168.1.2\n2023-10-15 192.168.1.2\n2023-10-15 192.168.1.3\n2023-10-16 192.168.1.4\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '2023-10-15' ~/.access.log | awk '{print $2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Determine the total size of all files in your home directory that have been modified within the last 7 days. These files should not be in any subdirectory and should only include regular files (not directories, symlinks, etc.). Provide the answer as a human-readable size.",
        "explanation": "To solve this problem, you need to use a combination of `find`, `stat`, and `du` commands. The `find` command can help locate files modified in the last 7 days with the `-mtime` option. You will need to ensure you're only considering regular files using the `-type f` option. Once you have these files, you can use `du -ch` to calculate their total size in a human-readable format. Make sure to filter out any directories or non-regular file types.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find and calculate the size of regular files modified within last 7 days in home directory.\nfind ~ -maxdepth 1 -type f -mtime -7 -exec du -ch {} + | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "# Create some dummy files for testing\ncd ~\ntouch file1.txt file2.log file3.conf\nsleep 1\ntouch -d \"8 days ago\" oldfile.txt\n\n# Add some content to change their sizes\necho \"Hello World\" > file1.txt\ndd if=/dev/zero of=file2.log bs=1024 count=10 # Creates a 10KB log file\necho \"Configuration settings\" > file3.conf\n\n# Ensure these modifications are reflected\nsync"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "# Find and calculate the size of regular files modified within last 7 days in home directory.\nfind ~ -maxdepth 1 -type f -mtime -7 -exec du -ch {} + | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "In your home directory, there are multiple text files with various extensions (e.g., .txt, .log, .md). You need to find all the files that contain the word \"Linux\" (case-sensitive), count the total number of occurrences of the word \"Linux\" across all these files, and then remove any duplicate lines within each file where \"Linux\" is found. Provide the total count of occurrences as your answer.",
        "explanation": "To solve this problem, you can use `grep` to search for the word \"Linux\" in all text-based files in your home directory. Use `wc -l` to count occurrences. To handle duplicate lines within each file containing \"Linux\", use `uniq`. You should first identify which files contain the word using `grep`, then process each file individually to remove duplicates.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all files containing 'Linux' and count occurrences\ntotal_count=$(grep -rwo 'Linux' ~ --include=\\*.{txt,log,md} | wc -l)\n\n# Remove duplicate lines from these files where 'Linux' is found \nfor file in $(grep -rl 'Linux' ~ --include=\\*.{txt,log,md}); do\n    awk '!seen[$0]++' \"$file\" > temp && mv temp \"$file\"\ndone\n\n# Output total occurrences count as result \necho $total_count\n```",
        "create": {
            "init": "# Create example files in home directory for testing\necho -e \"Welcome to Linux.\\nEnjoy Linux.\\nWelcome to Linux.\" > ~/example1.txt\necho -e \"Linux is powerful.\\nLearn Linux.\" > ~/example2.log\necho -e \"This is a test.\\nNo mention here.\" > ~/example3.md\necho -e \"Start learning.\\nUse Linux wisely.\\nUse Linux wisely.\" > ~/example4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all files containing 'Linux' and count occurrences\ntotal_count=$(grep -rwo 'Linux' ~ --include=\\*.{txt,log,md} | wc -l)\n\n# Remove duplicate lines from these files where 'Linux' is found \nfor file in $(grep -rl 'Linux' ~ --include=\\*.{txt,log,md}); do\n    awk '!seen[$0]++' \"$file\" > temp && mv temp \"$file\"\ndone\n\n# Output total occurrences count as result \necho $total_count"
        }
    },
    {
        "description": "In the current directory, there is a file named `processes.log` which contains a list of process IDs (PIDs), one per line. You need to find out how many of these processes are currently running on the system.",
        "explanation": "To solve this problem, you can use the `ps` command to list all current processes and filter them using the PIDs from `processes.log`. Use tools like `grep` or `awk` to match and count these PIDs against the running processes.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# This example assumes some of these PIDs might be running.\n# First, get the list of current process IDs:\ncurrent_pids=$(ps -e -o pid=)\n\n# Now compare each PID in processes.log with current_pids and count matches:\nrunning_count=0\nwhile read pid; do \n    if echo \"$current_pids\" | grep -qw \"$pid\"; then \n        ((running_count++))\n    fi\ndone < processes.log\n\n# Output the count of running processes\necho $running_count\n```",
        "create": {
            "init": "# Create a processes.log file with some random PIDs\necho -e \"1234\\n5678\\n91011\\n121314\" > processes.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# This example assumes some of these PIDs might be running.\n# First, get the list of current process IDs:\ncurrent_pids=$(ps -e -o pid=)\n\n# Now compare each PID in processes.log with current_pids and count matches:\nrunning_count=0\nwhile read pid; do \n    if echo \"$current_pids\" | grep -qw \"$pid\"; then \n        ((running_count++))\n    fi\ndone < processes.log\n\n# Output the count of running processes\necho $running_count"
        }
    },
    {
        "description": "You have a directory named \"server_logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains timestamped entries of server activity, where each entry is a single line starting with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Find out how many unique dates (in the format \"YYYY-MM-DD\") are there across all these log files.",
        "explanation": "To solve this problem, you need to extract all the timestamps from each log file, isolate the date portion, and then determine how many unique dates are present. You can achieve this by using tools like `cat` or `find` for reading files, `awk` or `cut` for extracting dates, and `sort` along with `uniq` for counting unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/server_logs -name \"*.log\" -exec cat {} + | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/server_logs\necho -e \"2023-03-01 12:00:00 Server started\\n2023-03-01 12:30:00 User logged in\\n2023-03-02 13:00:00 Server shutdown\" > ~/server_logs/log1.log\necho -e \"2023-03-02 14:00:00 Server started\\n2023-03-02 15:30:00 User logged out\\n2023-03-03 16:45:00 Backup completed\" > ~/server_logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/server_logs -name \"*.log\" -exec cat {} + | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden directory named \".project_files\" containing various text files. You need to count the total number of unique words across all files in this directory. A word is defined as any sequence of non-whitespace characters. Ignore case differences (i.e., treat \"Word\" and \"word\" as the same) and exclude numbers from your count.",
        "explanation": "To solve this problem, you will need to:\n1. Access the hidden \".project_files\" directory in your home directory.\n2. Use commands to read through each file and extract words.\n3. Convert all words to lowercase to ensure case insensitivity.\n4. Filter out any numeric sequences (words that consist solely of digits).\n5. Count the unique set of words across all files.\n\nHints: You might find utilities like `find`, `cat`, `tr`, `awk`, and `sort` helpful.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the hidden directory\ncd ~/.project_files\n\n# Combine contents of all files, transform them into lowercase, remove numbers, sort and deduplicate\ncat *.txt | tr '[:upper:]' '[:lower:]' | tr -cs '[:alpha:]' '\\n' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/\".project_files\"\necho \"Hello world 123\" > ~/\".project_files/file1.txt\"\necho \"This is a test file with some TEST data.\" > ~/\".project_files/file2.txt\"\necho \"Another line with 456 numbers and duplicate test Test words.\" > ~/\".project_files/file3.txt\""
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to the hidden directory\ncd ~/.project_files\n\n# Combine contents of all files, transform them into lowercase, remove numbers, sort and deduplicate\ncat *.txt | tr '[:upper:]' '[:lower:]' | tr -cs '[:alpha:]' '\\n' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a file named \"server_logs.txt\" which contains log entries of a server's access logs. Each line in the file represents an individual log entry, formatted as \"IP_ADDRESS - TIMESTAMP - REQUEST_TYPE - RESOURCE\". Your task is to find out how many unique IP addresses made requests to the server on the date \"2023-10-15\".",
        "explanation": "To solve this problem, you need to filter out the lines that contain the date \"2023-10-15\", then extract the IP addresses from these lines, and finally count how many of these IP addresses are unique. You can utilize tools like `grep` for filtering lines by date, `awk` or `cut` for extracting fields (like IP addresses), and `sort` with `uniq` to determine uniqueness.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Filter out lines containing the specific date\ngrep \"2023-10-15\" ~/server_logs.txt | \n# Extract IP addresses (assuming they are always at the start of each line)\nawk '{print $1}' | \n# Sort IPs and remove duplicates\nsort | uniq | \n# Count number of unique IPs\nwc -l\n```",
        "create": {
            "init": "echo -e \"192.168.1.1 - 2023-10-15 12:00:00 - GET - /index.html\\n192.168.1.2 - 2023-10-15 13:00:00 - POST - /form_submit\\n192.168.1.1 - 2023-10-15 14:00:00 - GET - /about.html\\n192.168.2.5 - 2023-10-14 11:30:00 - GET - /contact.html\\n192.168.2.6 - 2023-10-14 16:45:00 - GET - /index.html\" > ~/server_logs.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Filter out lines containing the specific date\ngrep \"2023-10-15\" ~/server_logs.txt | \n# Extract IP addresses (assuming they are always at the start of each line)\nawk '{print $1}' | \n# Sort IPs and remove duplicates\nsort | uniq | \n# Count number of unique IPs\nwc -l"
        }
    },
    {
        "description": "You have a directory named \"logfiles\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains lines of text with timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out which day has the highest number of log entries across all log files. Provide the date in the format \"YYYY-MM-DD\".",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"logfiles\" directory.\n2. Use `grep` or `awk` to extract dates from each line in all \".log\" files.\n3. Count occurrences of each date using utilities like `sort` and `uniq`.\n4. Identify the date with the highest count.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logfiles\ngrep -hEo '^[0-9]{4}-[0-9]{2}-[0-9]{2}' *.log | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-10-01 12:00:01 Event A\\n2023-10-01 12:05:00 Event B\\n2023-10-02 13:15:22 Event C\\n2023-10-02 14:00:42 Event D\" > ~/logfiles/file1.log\necho -e \"2023-10-01 09:45:33 Event E\\n2023-10-03 11:22:21 Event F\\n2023-10-03 11:25:45 Event G\\n2023-10-03 18:30:55 Event H\" > ~/logfiles/file2.log\necho -e \"2023-10-02 08:15:35 Event I\\n2023-10-02 23:59:59 Event J\\n2023-10-04 06:30:00 Event K\" > ~/logfiles/file3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "cd ~/logfiles\ngrep -hEo '^[0-9]{4}-[0-9]{2}-[0-9]{2}' *.log | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'"
        }
    },
    {
        "description": "In the current directory, there are multiple text files with various extensions. Your task is to count the total number of unique words across all files that have a \".txt\" extension. A word is defined as a sequence of alphabetic characters, and it should be considered case-insensitively (e.g., \"Hello\" and \"hello\" are the same word).",
        "explanation": "To solve this problem, you need to list all files with a \".txt\" extension in the current directory. Then, extract words from these files while ignoring case differences and count them uniquely. You can use utilities like `grep`, `tr`, `sort`, `uniq`, and `wc` to accomplish this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all .txt files and process them to find unique words\ncat *.txt | tr '[:upper:]' '[:lower:]' | grep -oE '\\b[a-z]+\\b' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create sample text files in the current directory for testing\necho -e \"Hello world\\nThis is a test file\\nhello again\" > file1.txt\necho -e \"Another test case\\nWith some MORE words\\nWorld peace\" > file2.txt\necho -e \"No TXT here!\" > file3.doc"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# List all .txt files and process them to find unique words\ncat *.txt | tr '[:upper:]' '[:lower:]' | grep -oE '\\b[a-z]+\\b' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing a directory structure under \"/var/log\" to determine the total size of all \".log\" files that were modified in the last seven days. You should output the size in human-readable format (e.g., KB, MB).",
        "explanation": "To solve this problem, you will need to:\n1. Use `find` command to locate all `.log` files in `/var/log` that were modified within the last 7 days.\n2. Pipe the results into `du` with `-ch` option to calculate their total size in human-readable format.\n3. Use `tail -n 1` to extract only the total size line from `du` output.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log/test_logs -name \"*.log\" -mtime -7 -exec du -ch {} + | tail -n 1 | awk '{print $1}'\n```",
        "create": {
            "init": "# Create some sample log files with modification times within and outside of 7 days\nmkdir -p /var/log/test_logs\n\n# Log file modified today\ntouch /var/log/test_logs/today.log\n\n# Log file modified 5 days ago\ntouch -d \"5 days ago\" /var/log/test_logs/five_days_ago.log\n\n# Log file modified 10 days ago\ntouch -d \"10 days ago\" /var/log/test_logs/ten_days_ago.log\n\n# Adding some content to change file sizes\necho \"Sample log content for today\" > /var/log/test_logs/today.log\necho \"Sample log content for five days ago\" > /var/log/test_logs/five_days_ago.log\necho \"Sample log content for ten days ago\" > /var/log/test_logs/ten_days_ago.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "find /var/log/test_logs -name \"*.log\" -mtime -7 -exec du -ch {} + | tail -n 1 | awk '{print $1}'"
        }
    },
    {
        "description": "You have a directory called \"logs\" in your home directory that contains multiple log files with the \".log\" extension. Each log file records entries in the format: \"YYYY-MM-DD HH:MM:SS - [Level] - Message\". Your task is to find out how many ERROR level entries are present across all these log files and provide the count.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and use command-line utilities to search through all \".log\" files for lines that contain \"[ERROR]\". The `grep` command can be particularly useful here. You might also want to use tools like `wc` to count the occurrences of these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"\\[ERROR\\]\" ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"2023-10-01 12:00:00 - [INFO] - System started\" > ~/logs/system.log\necho \"2023-10-01 12:05:00 - [ERROR] - Failed to start service\" >> ~/logs/system.log\necho \"2023-10-01 12:10:00 - [ERROR] - Disk space low\" >> ~/logs/system.log\necho \"2023-10-01 13:00:00 - [INFO] - Service running smoothly\" > ~/logs/application.log\necho \"2023-10-01 13:05:00 - [ERROR] - Connection timeout\" >> ~/logs/application.log\necho \"2023-10-01 13:15:00 - [DEBUG] - Debugging info here\" >> ~/logs/application.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"\\[ERROR\\]\" ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with the \".log\" extension. Each log file has entries that include timestamps, error levels (INFO, WARNING, ERROR), and messages. Your task is to find out how many unique ERROR messages occurred in all the log files combined.",
        "explanation": "To solve this problem, you should first list all the \".log\" files within the \"logs\" directory. Then, extract lines containing the \"ERROR\" level from these files. Finally, filter out duplicates to count how many unique ERROR messages exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | grep 'ERROR' | cut -d' ' -f4- | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 INFO System started\\n2023-10-01 12:30:00 ERROR Disk space low\\n2023-10-01 13:00:00 ERROR Disk space low\\n2023-10-01 14:00:00 WARNING High memory usage\\n2023-10-01 15:00:00 ERROR Network disconnect\" > ~/logs/system1.log\necho -e \"2023-10-02 09:00:00 INFO User login\\n2023-10-02 09:30:00 ERROR Disk space low\\n2023-10-02 09:45:00 ERROR CPU overheating\\n2023-10-02 10:15:00 WARNING Low battery\\n2023-10-02 11:50:00 ERROR Network disconnect\" > ~/logs/system2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | grep 'ERROR' | cut -d' ' -f4- | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory containing multiple log files with varying extensions (e.g., .log, .txt). Your task is to find the total number of occurrences of the word \"ERROR\" across all these files, regardless of their extension. Assume that the word \"ERROR\" is case-sensitive.",
        "explanation": "To solve this problem, you need to search through all files within the \"log_files\" directory and count how many times the word \"ERROR\" appears in each file. You can use utilities like `grep` to search for occurrences and `wc` to count them. Make sure to handle multiple file types and aggregate counts from each file.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -o 'ERROR' ~/log_files/* | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"INFO: System running\\nERROR: Disk full\\nINFO: Cleanup started\" > ~/log_files/system.log\necho -e \"WARNING: Low memory\\nERROR: Out of memory\\nERROR: Swap not configured\" > ~/log_files/memory.log\necho -e \"INFO: Network connected\\nERROR: Connection lost\\nINFO: Retrying connection\" > ~/log_files/network.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -o 'ERROR' ~/log_files/* | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory, which contains multiple log files with various extensions. Your task is to count the total number of unique IP addresses present across all \".log\" files in this directory. Ensure that you only consider IPv4 addresses for this task.",
        "explanation": "To solve this problem, you need to traverse through the \"logs\" directory and extract all lines from files ending with \".log\". Using regular expressions, filter out and capture IPv4 addresses. Finally, use a method to count the unique IPs collected from these files. Tools like `grep`, `awk`, `sort`, and `uniq` can be particularly useful here.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' *.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.0.1 - Log entry 1\\n10.0.0.5 - Log entry 2\\n192.168.0.1 - Log entry 3\" > ~/logs/access.log\necho -e \"172.16.0.3 - Some other log\\n192.168.0.1 - Repeated log\\n8.8.8.8 - Google DNS\" > ~/logs/error.log\necho \"This is not a log file\" > ~/logs/readme.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' *.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked to determine the number of unique IP addresses that have accessed your web server. The server logs are stored in a file named `access.log` located in the `/var/log/apache2/` directory. Your goal is to count how many distinct IP addresses appear in this log file. Assume each line in the `access.log` starts with an IP address followed by other log information.",
        "explanation": "To solve this problem, you need to extract the first column (IP addresses) from each line of the `access.log`, and then find out how many unique IP addresses there are. You can achieve this by using tools like `awk`, `sort`, and `uniq`. First, use `awk` to extract the first column, then sort these IPs and finally use `uniq` with the count option to determine the number of distinct entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{print $1}' /var/log/apache2/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample access.log file with some repeated and unique IP addresses\nmkdir -p /var/log/apache2/\ncat <<EOL > /var/log/apache2/access.log\n192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \"GET / HTTP/1.1\" 200 1234\n192.168.1.2 - - [10/Oct/2023:13:56:01 +0000] \"GET /about HTTP/1.1\" 200 2345\n192.168.1.3 - - [10/Oct/2023:13:56:35 +0000] \"POST /submit HTTP/1.1\" 404 3456\n192.168.1.1 - - [10/Oct/2023:13:57:02 +0000] \"GET /contact HTTP/1.1\" 200 4567\n192.168.1.4 - - [10/Oct/2023:13:58:15 +0000] \"GET /home HTTP/1.1\" 500 5678\n192.168.1.2 - - [10/Oct/2023:13:59:47 +0000] \"GET /privacy HTTP/1.0\" 302 6789\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{print $1}' /var/log/apache2/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a file named `system_logs.txt` containing logs from various system services. Each log entry consists of a timestamp, service name, and a log message. Your task is to find out how many unique services have logged messages in this file. You need to interact with the shell to extract and count these unique service names.",
        "explanation": "To solve this problem, you need to read the contents of `system_logs.txt` and extract the service names from each log entry. Typically, service names will follow a specific pattern or be located at a certain position in each line. Once you've extracted these names, use tools like `sort`, `uniq`, or other text processing utilities available in bash to determine the number of unique service names.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract the second word (service name) from each line and get the unique count.\nawk '{print $2}' ~/system_logs.txt | sort | uniq | wc -l\n```",
        "create": {
            "init": "cat > ~/system_logs.txt <<EOL\n2023-10-01 12:00:00 sshd: Starting session\n2023-10-01 12:05:00 httpd: Handling request\n2023-10-01 12:10:00 sshd: Ending session\n2023-10-01 12:15:00 cron: Running scheduled task\n2023-10-01 12:20:00 httpd: Closing connection\n2023-10-01 12:25:00 dbus-daemon: Message received\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract the second word (service name) from each line and get the unique count.\nawk '{print $2}' ~/system_logs.txt | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory which contains multiple log files with the extension \".log\". Each log file records events with timestamps. Your task is to find out how many unique IP addresses have accessed the system in the month of September 2023 across all these log files. Assume each line in a log file is structured as follows: \"YYYY-MM-DD HH:MM:SS IP_ADDRESS EVENT_DESCRIPTION\".",
        "explanation": "To solve this problem, you need to perform several steps:\n1. Navigate to the \"logs\" directory.\n2. Use a command to search for lines that contain dates from September 2023.\n3. Extract the IP addresses from those lines.\n4. Sort and remove duplicates to find unique IP addresses.\n5. Count the number of unique IP addresses.\n\nHints:\n- You can use tools like `grep` or `awk` for pattern matching and extraction.\n- Use `sort` and `uniq` commands to handle duplication.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep '^2023\\-09' *.log | awk '{print $3}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/access1.log\n2023-09-01 12:45:00 192.168.1.1 User logged in\n2023-09-02 13:00:00 192.168.1.2 User logged out\n2023-09-15 14:30:00 192.168.1.1 User accessed resource\nEOL\n\ncat <<EOL > ~/logs/access2.log\n2023-09-10 16:20:00 192.168.1.3 User logged in\n2023-09-18 18:45:00 192.168.1.4 User logged out\n2023-08-25 19:10:00 192.168.1.5 User attempted login\nEOL\n\ncat <<EOL > ~/logs/access3.log\n2023-09-11 11:15:00 192.168.1.6 User changed password\n2023-09-12 12:50:00 192.168.1.x Invalid attempt from unknown host \nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep '^2023\\-09' *.log | awk '{print $3}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logfiles\" in your home directory containing multiple log files with the extension \".log\". Each log file contains lines of text where each line starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\" followed by a space and then an event description. Your task is to find out how many unique days (in \"YYYY-MM-DD\" format) are present across all these log files.",
        "explanation": "To solve this problem, you need to extract the date part from each line's timestamp in all the \".log\" files within the \"logfiles\" directory. You can do this by using tools like `awk` or `cut` to parse each line and extract the date portion. Then, you should aggregate these dates and count only the unique entries using sorting and deduplication commands such as `sort` and `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all unique dates from all .log files in the 'logfiles' directory\nfind ~/logfiles -name \"*.log\" | xargs awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create the 'logfiles' directory in the user's home directory\nmkdir -p ~/logfiles\n\n# Generate sample log files with timestamps\necho -e \"2023-10-01 12:00:00 Event A\\n2023-10-01 13:45:00 Event B\\n2023-10-02 09:30:00 Event C\" > ~/logfiles/log1.log\necho -e \"2023-10-02 15:20:00 Event D\\n2023-10-03 07:50:00 Event E\\n2023-10-03 22:10:00 Event F\" > ~/logfiles/log2.log\necho -e \"2023-10-01 16:35:00 Event G\\n2023-10-04 11:25:00 Event H\" > ~/logfiles/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all unique dates from all .log files in the 'logfiles' directory\nfind ~/logfiles -name \"*.log\" | xargs awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to find and count the total number of lines across all `.log` files in your home directory that contain the word \"ERROR\". Assume that these log files can be nested within subdirectories, and you must consider all levels of directories within your home directory.",
        "explanation": "To solve this problem, you need to search through your home directory and all its subdirectories for files with the `.log` extension. You can use utilities like `find` to locate these files and then apply `grep` to search for lines containing the word \"ERROR\". Finally, you'll use `wc -l` to count these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -name \"*.log\" | xargs grep -i \"ERROR\" | wc -l\n```",
        "create": {
            "init": "# Create a sample structure in the student's home directory with log files.\nmkdir -p ~/logs/subdir1 ~/logs/subdir2\necho -e \"INFO: Start process\\nERROR: Failed operation\\nINFO: End process\" > ~/logs/app1.log\necho -e \"DEBUG: Initializing\\nERROR: Missing file\\nWARN: Low memory\" > ~/logs/app2.log\necho -e \"ERROR: Disk full\\nINFO: Cleanup done\" > ~/logs/subdir1/app3.log\necho -e \"INFO: No issues detected\" > ~/logs/subdir2/app4.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -name \"*.log\" | xargs grep -i \"ERROR\" | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory containing multiple \".log\" files. Each log file consists of various system events recorded over time. Your task is to find and count the number of unique IP addresses that appear in all the \".log\" files within the \"logs\" directory. Consider only IP addresses from the local network (i.e., those starting with \"192.168\").",
        "explanation": "To solve this problem, you need to traverse through each \".log\" file in the \"logs\" directory, extract valid local network IP addresses (those starting with \"192.168\"), and then find out how many unique IP addresses exist across all files. You can use utilities like `grep` or `awk` for pattern matching and `sort` along with `uniq` to count unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -hoP '192\\.168\\.\\d+\\.\\d+' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 - User logged in\\n192.168.1.2 - Error reported\\n10.0.0.1 - External access detected\\n192.168.1.3 - Disk full warning\" > ~/logs/system1.log\necho -e \"172.16.0.5 - VPN connected\\n192.168.1.2 - User action succeeded\\n192.168.2.4 - New device connected\\n10.0.0.2 - External access detected\" > ~/logs/system2.log\necho -e \"192.168.1.5 - User created\\n8:00:00:00:01:01- Device MAC address found\\n172.xx.xx.xx- Invalid entry format\\n192.x.x.x- Partially formed IP address\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -hoP '192\\.168\\.\\d+\\.\\d+' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named `logs` containing multiple `.log` files. Each log file contains entries with timestamps in the format `YYYY-MM-DD HH:MM:SS`. Your task is to find out the most recent timestamp across all log files in the `logs` directory and return it in the format `YYYY-MM-DD HH:MM:SS`.",
        "explanation": "To solve this problem, you need to iterate through each `.log` file within the `logs` directory, extract timestamps from each line, and determine which timestamp is the most recent. You can use utilities like `find`, `grep`, `awk`, and `sort` to help extract and compare the timestamps. A useful approach is to consolidate all timestamps into a single stream, sort them, and then select the last entry as this represents the most recent timestamp.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind logs -name '*.log' -exec cat {} + | grep -Eo '[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}' | sort | tail -n 1\n```",
        "create": {
            "init": "mkdir -p logs\necho -e \"2023-03-01 12:34:56\\n2023-03-02 13:30:00\" > logs/log1.log\necho -e \"2022-12-31 23:59:59\\n2023-01-01 00:00:00\" > logs/log2.log\necho -e \"2023-03-02 14:25:10\\n2023-03-02 09:15:45\" > logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "find logs -name '*.log' -exec cat {} + | grep -Eo '[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}' | sort | tail -n 1"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.processes_info`. This file contains information about all processes currently running on the system, formatted with each line containing the PID, user, and command (separated by spaces). Your task is to find out how many distinct users are currently running processes where the command contains the string \"python\".",
        "explanation": "To solve this problem, you need to filter lines from the `.processes_info` file that contain the string \"python\" in the command field. Then extract the user field from these lines and determine how many unique users appear in this filtered list.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Filter lines containing 'python', extract user fields, and count unique users.\ngrep 'python' ~/.processes_info | awk '{print $2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a hidden file in the user's home directory with simulated process data\ncat <<EOL > ~/.processes_info\n1234 root /usr/bin/python3 script.py\n5678 alice /usr/local/bin/python app.py\n9101 bob /bin/bash run.sh\n1123 alice /usr/bin/python3 data_analysis.py\n1415 charlie /usr/bin/grep search.txt\n1617 root /usr/bin/python maintenance.py\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Filter lines containing 'python', extract user fields, and count unique users.\ngrep 'python' ~/.processes_info | awk '{print $2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to find out the total combined size of all `.log` files in your home directory and its subdirectories that have been modified in the last 7 days. Use human-readable format for the size.",
        "explanation": "To solve this problem, you will need to use a combination of shell commands to search and filter files based on their modification time and then calculate their combined size. The `find` command can be used to locate files with specific extensions and modification times. The `xargs` command can help in passing these files to another command, such as `du`, which can compute file sizes.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -name \"*.log\" -type f -mtime -7 -print0 | xargs -0 du -ch | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "# Create some test .log files in the student's home directory\nmkdir -p ~/logs/test\n\n# Create some log files with different modification times\ntouch ~/logs/test/log1.log\nsleep 1\ntouch ~/logs/test/log2.log\nsleep 1\ntouch -d \"8 days ago\" ~/logs/test/old_log.log\n\n# Write some data into them for non-zero file sizes\necho \"Log entry 1\" > ~/logs/test/log1.log\necho \"Log entry 2\" > ~/logs/test/log2.log\necho \"Old log entry\" > ~/logs/test/old_log.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "find ~ -name \"*.log\" -type f -mtime -7 -print0 | xargs -0 du -ch | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple text files with random log data. Your task is to determine how many unique IP addresses appear across all these log files. Each log entry in the files contains an IP address at the beginning of the line. You need to count only distinct IP addresses.",
        "explanation": "To solve this problem, you should first navigate to the \"logs\" directory and then extract all the IP addresses from each file. Use tools like `cat`, `grep`, or `awk` to fetch these addresses, and then use commands such as `sort` and `uniq` to filter out duplicates. Finally, count the number of unique entries using a command like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ncat *.txt | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 Log entry 1\\n192.168.1.2 Log entry 2\\n192.168.1.3 Log entry 3\" > ~/logs/log1.txt\necho -e \"192.168.1.2 Log entry A\\n192.168.1.4 Log entry B\\n192.168.1.5 Log entry C\" > ~/logs/log2.txt\necho -e \"192.168.1.6 Another log\\n192.168.1.5 Repeated log\\n10.0.0.1 Unique log\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ncat *.txt | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory that contains several text files with different log records. Each log file follows a naming pattern \"logYYYYMMDD.txt\" where YYYY, MM, and DD represent the year, month, and day respectively. Your task is to count the total number of ERROR entries across all these log files for the month of August 2022.",
        "explanation": "To solve this problem, you need to iterate through each file in the \"logs\" directory that matches the pattern for August 2022 (i.e., files named \"log202208*.txt\"). You should search each file for lines containing the string \"ERROR\" and count these occurrences. Summing these counts across all relevant files will give you the answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR' ~/logs/log202208*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: System started\\nERROR: Failed to load module\\nINFO: Module loaded\\nERROR: Connection lost\" > ~/logs/log20220801.txt\necho -e \"INFO: User login\\nERROR: Disk full\\nERROR: Timeout occurred\" > ~/logs/log20220815.txt\necho -e \"INFO: Scheduled task executed\\nERROR: Memory leak detected\" > ~/logs/log20220820.txt\necho -e \"ERROR: File not found\\nINFO: File created successfully\" > ~/logs/log20220901.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR' ~/logs/log202208*.txt | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"project_data\" in your home directory. This directory contains multiple subdirectories, each with a variety of files. Your task is to find the total number of lines across all text files (*.txt) within this entire directory structure, including all subdirectories. Note that some text files might be empty.",
        "explanation": "To solve this problem, you can use the `find` command to locate all `.txt` files recursively within the \"project_data\" directory. Then, you can utilize `xargs` and `wc -l` to count the number of lines in each file and sum them up for the total line count.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/project_data -type f -name \"*.txt\" | xargs wc -l | tail -n 1 | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p ~/project_data/subdir1\nmkdir -p ~/project_data/subdir2\n\necho -e \"Hello World\\nThis is a test file.\" > ~/project_data/file1.txt\necho -e \"Another test file\\nWith two lines.\" > ~/project_data/subdir1/file2.txt\ntouch ~/project_data/subdir2/empty.txt  # This is an empty file.\necho \"Just one more line.\" > ~/project_data/subdir2/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/project_data -type f -name \"*.txt\" | xargs wc -l | tail -n 1 | awk '{print $1}'"
        }
    },
    {
        "description": "You are tasked with analyzing log files in the \"/var/logs\" directory. Specifically, you need to count how many times the string \"ERROR\" appears in all \".log\" files combined within this directory. Assume that these log files contain various system and application logs. Provide the total count.",
        "explanation": "To solve this problem, you need to use bash commands to navigate through the \"/var/logs\" directory and search for occurrences of the string \"ERROR\" in all \".log\" files. You can achieve this by leveraging tools like `grep` to search within files and `wc` to count occurrences. An example approach is using `grep` with the `-r` option for recursive searches combined with piping into `wc -l` to get the total count.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use grep to find all occurrences of 'ERROR' in .log files, then pipe into wc for counting.\ngrep -r \"ERROR\" /var/logs/*.log | wc -l\n```",
        "create": {
            "init": "# Create a /var/logs directory if it doesn't exist and populate it with sample .log files\nmkdir -p /var/logs\n\n# Create sample log files with varying contents\necho -e \"INFO: System started\\nERROR: Failed to load module\\nINFO: Module loaded successfully\" > /var/logs/system.log\necho -e \"WARNING: High memory usage\\nERROR: Out of memory\\nERROR: Memory leak detected\" > /var/logs/memory.log\necho -e \"INFO: User login successful\\nINFO: User logout successful\" > /var/logs/auth.log\necho -e \"ERROR: Disk full\\nWARNING: Disk nearly full\\nINFO: Disk cleanup completed\" > /var/logs/disk.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use grep to find all occurrences of 'ERROR' in .log files, then pipe into wc for counting.\ngrep -r \"ERROR\" /var/logs/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.myconfig` containing various configuration settings, each on a new line in the format `KEY=VALUE`. Your task is to count how many unique keys start with the letter 'A' and have values that are numeric. You should only consider lines where both the key starts with 'A' and has a numeric value.",
        "explanation": "To solve this problem, you need to process the `.myconfig` file by first filtering out lines that start with an 'A'. Next, check if the value part of these lines is numeric. Finally, count how many unique keys meet both conditions. You can use tools like `grep`, `awk`, `cut`, and `sort` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract lines starting with 'A'\ngrep '^A' ~/.myconfig | \\\n\n# Filter those where the value is numeric using awk\nawk -F '=' '$2 ~ /^[0-9]+$/' | \\\n\n# Extract and sort unique keys \ncut -d '=' -f 1 | sort -u | \\\n\n# Count them using wc -l \nwc -l | tr -d ' '\n```",
        "create": {
            "init": "cat > ~/.myconfig <<EOF\nAPP_PORT=1234\nAPP_NAME=DemoApp\nAPP_VERSION=2.0\nAUDIT_LOGS=enabled\nAPI_LIMIT=10000\nAUTOSAVE_INTERVAL=15\nALERT_THRESHOLD=75\nEOF"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract lines starting with 'A'\ngrep '^A' ~/.myconfig | \\\n\n# Filter those where the value is numeric using awk\nawk -F '=' '$2 ~ /^[0-9]+$/' | \\\n\n# Extract and sort unique keys \ncut -d '=' -f 1 | sort -u | \\\n\n# Count them using wc -l \nwc -l | tr -d ' '"
        }
    },
    {
        "description": "You are given a directory named \"sys_logs\" in your home directory containing multiple log files with the extension \".log\". Your task is to count how many lines in these log files contain the word \"ERROR\" (case-sensitive), and report the total count.",
        "explanation": "To solve this problem, you need to iterate through each \".log\" file in the \"sys_logs\" directory, search for lines containing the string \"ERROR\", and keep a cumulative count of these lines across all files. You can use utilities such as `grep` to search for the word \"ERROR\" and `wc -l` to count the matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/sys_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/sys_logs\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nWARNING: High memory usage\\nERROR: Network connectivity issues\" > ~/sys_logs/system1.log\necho -e \"DEBUG: Starting process\\nINFO: Process running smoothly\\nERROR: Failed to open file\\nERROR: Timeout occurred\" > ~/sys_logs/system2.log\necho -e \"INFO: User login successful\\nWARNING: CPU temperature high\\nDEBUG: Checking configurations\\nINFO: Backup completed successfully\" > ~/sys_logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/sys_logs/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_files\" in your home directory, which contains multiple text files. Each file has random lines of text. Your task is to count the total number of lines across all text files that contain the word \"error\" (case insensitive).",
        "explanation": "To solve this problem, you need to use `grep` with the `-i` flag to perform a case-insensitive search for the word \"error\" across all files in the \"project_files\" directory. Then, use `wc -l` to count the number of matching lines. You might need to combine several bash utilities using pipes.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' ~/project_files/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_files\necho -e \"This is an error\\nNo issues here\\nAnother Error\" > ~/project_files/file1.txt\necho -e \"Error found\\nSomething went wrong\\nAll good\" > ~/project_files/file2.txt\necho -e \"error: failed operation\\nSuccessful execution\" > ~/project_files/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' ~/project_files/*.txt | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory containing various log files with the extension \".log\". Each log file contains lines of text, some of which include IP addresses. Your task is to find and count the number of unique IP addresses across all log files in the \"log_files\" directory.",
        "explanation": "To solve this problem, you need to iterate through each file in the \"log_files\" directory and extract IP addresses. You can use a combination of 'grep' with a regular expression to filter out lines containing IPs and then use 'awk' or 'sed' to isolate them. Once you have all the IPs, utilize 'sort' and 'uniq' commands to identify unique IPs and count them using 'wc -l'.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all files ending with .log in ~/log_files, extract unique IPs, and count them.\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/log_files/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create a directory named \"log_files\" in the home directory\nmkdir -p ~/log_files\n\n# Create sample log files with random IP addresses\ncat <<EOL > ~/log_files/log1.log\nError: Could not connect to 192.168.1.1\nSuccess: Connection established with 10.0.0.5\nWarning: Possible intrusion from 172.16.0.2\nEOL\n\ncat <<EOL > ~/log_files/log2.log\nInfo: User logged in from 192.168.1.2\nError: Failed attempt from 10.0.0.5\nNotice: System update from 172.16.0.3 was successful.\nEOL\n\ncat <<EOL > ~/log_files/log3.log\nAlert: Multiple login attempts from 192.168.1.3\nInfo: Access granted to 192.168.1.1 for maintenance.\nCritical: Unauthorized access detected from 172.16.0.4.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all files ending with .log in ~/log_files, extract unique IPs, and count them.\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' ~/log_files/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named `logs` containing multiple `.log` files. Each log file records server access with timestamps, IP addresses, and request types (GET, POST, etc.). Count the total number of GET requests made in all the log files combined.",
        "explanation": "To solve this problem, you need to navigate through each `.log` file in the `logs` directory and identify lines that represent a GET request. This can be done using tools like `grep` to filter out lines containing \"GET\" and then counting these lines using tools like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"GET\" logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir logs\necho \"127.0.0.1 - - [12/Oct/2023:14:55:36 +0000] \\\"GET /index.html HTTP/1.1\\\" 200 1024\" > logs/access1.log\necho \"192.168.1.10 - - [12/Oct/2023:15:05:12 +0000] \\\"POST /form HTTP/1.1\\\" 404 512\" >> logs/access1.log\necho \"172.16.254.3 - - [12/Oct/2023:15:15:45 +0000] \\\"GET /about HTTP/1.1\\\" 200 2048\" > logs/access2.log\necho \"10.0.0.5 - - [12/Oct/2023:15:25:19 +0000] \\\"GET /contact HTTP/1.1\\\" 200 1024\" >> logs/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"GET\" logs/*.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory, containing several log files with a \".log\" extension. Each log file contains multiple lines, some of which start with the word \"ERROR\". Your task is to count the total number of lines that start with \"ERROR\" across all these log files. Ensure that your answer is an integer representing this count.",
        "explanation": "To solve this problem, you should navigate to the \"logs\" directory in your home directory and use shell commands to identify and count all lines that begin with the word \"ERROR\" in each \".log\" file. You can use tools like `grep` to search for lines starting with \"ERROR\", and `wc -l` to count them. Remember that these operations need to be combined properly using pipes or loops.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Count the number of lines starting with ERROR across all .log files in directory 'logs'\ngrep -r \"^ERROR\" ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create logs directory\nmkdir -p ~/logs\n\n# Create sample log files with random data\ncat <<EOL > ~/logs/log1.log\nINFO: This is an info message.\nWARNING: This is a warning message.\nERROR: This is an error message.\nINFO: Another info line.\nERROR: Another error message.\nEOL\n\ncat <<EOL > ~/logs/log2.log\nDEBUG: Debugging information here.\nERROR: Error occurred while processing request.\nINFO: Info about the request processed successfully.\nERROR: Critical failure in module XYZ.\nEOL\n\ncat <<EOL > ~/logs/log3.log\nINFO: Starting process...\nWARNING: Low memory condition detected.\nDEBUG: Detailed debugging message here.\nINFO: Process completed successfully.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Count the number of lines starting with ERROR across all .log files in directory 'logs'\ngrep -r \"^ERROR\" ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"server_logs\" in your home directory containing multiple log files with names starting with \"access_\" followed by the date in the format YYYYMMDD. Your task is to count the total number of lines across all these log files that contain the string \"ERROR\". You need to find this count by interacting with the shell.",
        "explanation": "To solve this problem, you can use a combination of `grep` and `wc` commands. The `grep -r \"ERROR\" server_logs/` command will recursively search for the string \"ERROR\" in all files within the server_logs directory. You can then pipe this result into `wc -l` to count the total number of matching lines across all log files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"ERROR\" ~/server_logs/ | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/server_logs\necho -e \"INFO Starting server\\nERROR Failed to load module\\nINFO Server ready\" > ~/server_logs/access_20231001.log\necho -e \"INFO User login\\nERROR Timeout occurred\\nERROR Connection lost\" > ~/server_logs/access_20231002.log\necho -e \"WARN Low disk space\\nINFO Backup complete\\nERROR Disk error\" > ~/server_logs/access_20231003.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"ERROR\" ~/server_logs/ | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logfiles\" in your home directory containing multiple log files with different timestamps in their filenames (e.g., access-20231010.log, error-20230915.log). Your task is to find out how many of these log files were modified within the last 7 days. Make sure to consider only the modification time of the files and not their creation time.",
        "explanation": "To solve this problem, you can use the `find` command to search for files in the \"logfiles\" directory that were modified within the last 7 days. The `-mtime` option can be helpful here. Count the number of such files using appropriate command-line utilities like `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Use find command to locate files modified within last 7 days and count them.\nfind ~/logfiles -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create the logfiles directory if it doesn't exist\nmkdir -p ~/logfiles\n\n# Create some sample log files with varying modification times\ntouch -d \"8 days ago\" ~/logfiles/access-20231001.log\ntouch -d \"3 days ago\" ~/logfiles/error-20231006.log\ntouch -d \"1 day ago\" ~/logfiles/access-20231008.log\ntouch -d \"10 days ago\" ~/logfiles/error-20230929.log\ntouch -d \"5 hours ago\" ~/logfiles/access-20231009.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Use find command to locate files modified within last 7 days and count them.\nfind ~/logfiles -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple text files with various log entries. Each log entry has a timestamp in the format `YYYY-MM-DD HH:MM:SS`. Your task is to count how many log entries occur between the dates \"2023-01-01\" and \"2023-12-31\", inclusive. Assume each line in any file is a separate log entry.",
        "explanation": "To solve this problem, you should iterate through all files within the \"logs\" directory, extract each line's timestamp, and check if it falls within the specified date range. You can use tools like `awk`, `grep`, or `sed` for filtering logs by date, and `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -exec awk '/^2023-[0][1][0]-/ || /^2023-[0][2][0]-/ || /^2023-[0][3][0]-/ || /^2023-[0][4][0]-/ || /^2023-[0][5][0]-/ || /^2023-[0][6][0]-/ || /^2023-[0][7][0]-/ || /^2023-[0][8]([^-]|$)/ || /^2023-[09]([^-]|$)/ || /^202311([^-]|$)/ || /^202312([^-]|$)/' {} + | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-15 10:00:00\\n2022-11-25 14:30:00\\n2023-06-20 09:45:00\" > ~/logs/log1.txt\necho -e \"2024-02-15 08:00:00\\n2023-03-10 16:30:00\\n2023-07-22 12:15:00\" > ~/logs/log2.txt\necho -e \"2021-05-10 11:20:00\\n2023-05-17 18:30:00\\n2019-09-09 20:45:00\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -exec awk '/^2023-[0][1][0]-/ || /^2023-[0][2][0]-/ || /^2023-[0][3][0]-/ || /^2023-[0][4][0]-/ || /^2023-[0][5][0]-/ || /^2023-[0][6][0]-/ || /^2023-[0][7][0]-/ || /^2023-[0][8]([^-]|$)/ || /^2023-[09]([^-]|$)/ || /^202311([^-]|$)/ || /^202312([^-]|$)/' {} + | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"logs\" containing multiple log files with the extension \".log\". Your task is to determine how many unique IP addresses have accessed the server, based on the logs. Assume each log file contains lines where each line represents a separate access attempt and starts with an IP address. Count the number of unique IP addresses across all log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you should iterate through all \".log\" files in the \"logs\" directory, extract the IP addresses from each line, and store them in a data structure that automatically handles uniqueness (like a set). Finally, count how many unique IP addresses there are.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p logs\necho -e \"192.168.0.1 - - [01/Jan/2023:00:01:01 +0000] \\\"GET /index.html HTTP/1.1\\\" 200 1024\\n192.168.0.2 - - [01/Jan/2023:00:02:01 +0000] \\\"POST /form HTTP/1.1\\\" 404 512\\n192.168.0.1 - - [01/Jan/2023:00:03:01 +0000] \\\"GET /about.html HTTP/1.1\\\" 200 2048\" > logs/access1.log\necho -e \"172.16.0.5 - - [01/Jan/2023:00:04:01 +0000] \\\"GET /index.html HTTP/1.1\\\" 200 1024\\n10.0.0.7 - - [01/Jan/2023:00:05:01 +0000] \\\"POST /form HTTP/1.1\\\" 404 512\\n192.168.0.2 - - [01/Jan/2023:00:06:01 +0000] \\\"GET /contact.html HTTP/2\\\" 200 4096\" > logs/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "List all the files in your home directory that were modified in the last 7 days and have a file size greater than 1MB. Count how many such files exist.",
        "explanation": "To solve this problem, you can use the `find` command, which allows searching for files based on modification time and size criteria. Use `-mtime -7` to filter files modified in the last 7 days and `-size +1M` to filter files larger than 1MB. Ensure you restrict the search to your home directory by specifying it as the starting point for `find`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.configdata` containing various configuration entries in the format `key=value`. Your task is to count how many unique keys are present in this file. Note that keys are case-sensitive, and the entries may be repeated or shuffled across multiple lines.",
        "explanation": "To solve this problem, you need to:\n1. Use a command to read the contents of the `.configdata` file.\n2. Extract all keys from each line by splitting the string by '='.\n3. Store these keys in a data structure that automatically handles uniqueness (like a set).\n4. Count the number of unique keys.\n\nYou can accomplish this using a combination of `cat`, `cut`, and `sort` commands piped together with other utilities like `uniq` or by using more advanced text processing tools such as `awk`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Read and process the .configdata file to find unique keys\ncat ~/.configdata | cut -d'=' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a hidden file .configdata in the home directory with some example key-value pairs\necho -e \"user=admin\\npassword=1234\\ndomain=example.com\\nuser=root\\ntimezone=UTC\\nlanguage=en\\nUser=guest\" > ~/.configdata"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Read and process the .configdata file to find unique keys\ncat ~/.configdata | cut -d'=' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory called \"project_logs\" containing several log files with extensions \".log\". Each log file contains records of errors and warnings in a specific format: each line starts with either \"ERROR:\" or \"WARNING:\", followed by the message. Your task is to count the total number of \"ERROR\" lines across all log files in this directory.",
        "explanation": "To solve this problem, you need to navigate to the \"project_logs\" directory and use tools like `grep` to search for lines starting with \"ERROR:\". You can combine `grep` with `wc -l` to count the number of matching lines. Ensure you check all files ending with \".log\".\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h \"^ERROR:\" project_logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir project_logs\necho -e \"ERROR: Failed to load module\\nWARNING: Deprecated API usage\\nERROR: Timeout while connecting\\nERROR: Resource not found\" > project_logs/log1.log\necho -e \"WARNING: Low disk space\\nERROR: Unable to access database\\nWARNING: High memory usage\" > project_logs/log2.log\necho -e \"ERROR: Null pointer exception\\nERROR: Segmentation fault\\nWARNING: Unauthorized access attempt\\nERROR: Disk quota exceeded\" > project_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h \"^ERROR:\" project_logs/*.log | wc -l"
        }
    },
    {
        "description": "You are tasked with finding and listing all symbolic links in the `/home/student` directory and its subdirectories. Then, for each symbolic link found, determine if it is broken (i.e., the target file or directory does not exist). Count the number of broken symbolic links and provide that count as your answer.",
        "explanation": "To solve this problem, you can use the `find` command to search for all symbolic links within the specified directory. Use the `-type l` option to filter only symbolic links. To check if a symbolic link is broken, you can use the `test` command or simply navigate through them using tools like `[ -e \"$link\" ]`. By iterating over each found link with a loop or using a combination of commands, you can check their validity and count how many are broken.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student -type l | while read link; do \n  if [ ! -e \"$link\" ]; then \n    echo \"$link\"\n  fi \ndone | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/dir1 /home/student/dir2\nln -s /nonexistent/file /home/student/broken_link1\nln -s /etc/passwd /home/student/valid_link1\nln -s ../dir2/missing_target /home/student/dir1/broken_link2\nln -s .bashrc /home/student/dir2/valid_link2\ntouch /home/student/dir2/existing_file"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student -type l | while read link; do \n  if [ ! -e \"$link\" ]; then \n    echo \"$link\"\n  fi \ndone | wc -l"
        }
    },
    {
        "description": "You have a directory called \"project_logs\" in your home directory containing various log files. Each log file is named in the format \"log_YYYYMMDD.txt\". Your task is to identify and count how many unique IP addresses accessed the server on the most recent date present in these log files. Assume that each line of a log file contains a timestamp followed by an IP address, separated by a space.",
        "explanation": "To solve this problem, you should first determine which is the most recent log file based on its name (date). Then, extract all IP addresses from that file and count how many unique IP addresses are present. You might find commands like `ls`, `sort`, `tail`, `awk`, `uniq` and `wc` helpful for completing this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the project_logs directory\ncd ~/project_logs\n\n# Find the most recent log file by sorting and retrieving the last one\nmost_recent_log=$(ls | sort | tail -n 1)\n\n# Extract unique IP addresses from the most recent log file and count them\nawk '{print $2}' \"$most_recent_log\" | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"2023-10-01 192.168.1.1\\n2023-10-01 192.168.1.2\\n2023-10-01 192.168.1.1\" > ~/project_logs/log_20231001.txt\necho -e \"2023-10-02 192.168.1.3\\n2023-10-02 192.168.1.4\\n2023-10-02 192.168.1.4\" > ~/project_logs/log_20231002.txt\necho -e \"2023-10-03 192.168.1.5\\n2023-10-03 192.168.1.6\\n2023-10-03 192.168.1.5\" > ~/project_logs/log_20231003.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to the project_logs directory\ncd ~/project_logs\n\n# Find the most recent log file by sorting and retrieving the last one\nmost_recent_log=$(ls | sort | tail -n 1)\n\n# Extract unique IP addresses from the most recent log file and count them\nawk '{print $2}' \"$most_recent_log\" | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project\" containing various text files. Your task is to count the total number of lines across all files that contain the word \"error\" (case-insensitive). Ensure your solution handles any number of files in the directory and accounts for subdirectories as well.",
        "explanation": "To solve this problem, you can use a combination of `find`, `grep`, and `wc` commands. First, use `find` to list all text files in the \"project\" directory and its subdirectories. Then, use `grep` with the `-i` option to perform a case-insensitive search for the word \"error\". Finally, pipe this output into `wc -l` to count the total number of lines containing \"error\".\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind project/ -type f -name \"*.txt\" | xargs grep -i 'error' | wc -l\n```",
        "create": {
            "init": "mkdir -p project/subdir1\nmkdir -p project/subdir2\necho -e \"This is an error line.\\nAnother line.\\nError again.\" > project/file1.txt\necho -e \"No issues here.\\nOops, an ERROR occurred.\" > project/file2.txt\necho -e \"Random text.\" > project/subdir1/file3.txt\necho -e \"Yet another Error line.\" > project/subdir2/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find project/ -type f -name \"*.txt\" | xargs grep -i 'error' | wc -l"
        }
    },
    {
        "description": "In your home directory, there are various log files with different extensions such as `.log`, `.txt`, and `.csv`. Your task is to find the total number of unique IP addresses that appear in all `.log` files. You should only consider lines where the IP address appears at the beginning of the line. Assume that valid IP addresses follow the typical IPv4 format (e.g., 192.168.0.1).",
        "explanation": "To solve this problem, you need to:\n1. Use a command to list all `.log` files in your home directory.\n2. Extract IP addresses from each file where they appear at the beginning of a line.\n3. Collect these IPs across all files and determine the unique ones.\n4. Count the number of unique IPs.\n\nYou might consider using `grep` for pattern matching, `awk` or `sed` for text processing, and `sort` and `uniq` to find unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files, extract unique IPs at the start of lines, and count them\ngrep -hE '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' ~/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create sample log files in the user's home directory\necho -e \"192.168.0.1 User logged in\\n10.0.0.5 Failed login attempt\\n172.16.0.10 User logged out\" > ~/access1.log\necho -e \"192.168.0.2 User login successful\\n10.0.0.5 Password changed\\n192.168.0.1 File downloaded\" > ~/access2.log\necho -e \"172.16.0.11 Access denied\\n172.16.\\n192 User login failed\" > ~/error.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files, extract unique IPs at the start of lines, and count them\ngrep -hE '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' ~/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_files\" in your home directory containing various text files and subdirectories. Your task is to find the total number of lines across all text files (with a \".txt\" extension) that contain the word \"Linux\", regardless of case. You should only consider files directly under \"project_files\" and not in any subdirectory.",
        "explanation": "To solve this problem, you need to use a combination of bash commands to navigate to the \"project_files\" directory, list all the files with a \".txt\" extension, search each file for lines containing the word \"Linux\" using grep (with case insensitivity), and finally count the total number of such lines across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'Linux' ~/project_files/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_files\necho -e \"Linux is great.\\nI love using Linux.\\nOpen source is wonderful.\" > ~/project_files/file1.txt\necho -e \"This line does not mention it.\\nBut this one mentions Linux.\" > ~/project_files/file2.txt\necho -e \"Another file without mention.\\nYet another line mentioning linux.\" > ~/project_files/file3.txt\nmkdir -p ~/project_files/subdir\necho -e \"A line about UNIX.\\nLinux again!\" > ~/project_files/subdir/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'Linux' ~/project_files/*.txt | wc -l"
        }
    },
    {
        "description": "You need to find and count the total number of lines across all `.txt` files in the `/var/logs/` directory that contain the word \"ERROR\". Assume all `.txt` files are encoded in UTF-8 and that you have read permissions for these files.",
        "explanation": "To solve this problem, you should use a combination of `grep` to search for lines containing the word \"ERROR\" in each file and `wc -l` to count those lines. You can loop over all `.txt` files in the `/var/logs/` directory using a shell command or utility like `find`. Ensure your search is case-sensitive.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' /var/logs/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs/\necho -e \"INFO: Start\\nERROR: Disk full\\nINFO: End\" > /var/logs/system1.txt\necho -e \"ERROR: Memory leak detected\\nERROR: Network down\" > /var/logs/system2.txt\necho -e \"INFO: Boot complete\\nWARNING: Low battery\" > /var/logs/system3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' /var/logs/*.txt | wc -l"
        }
    },
    {
        "description": "Count the total number of lines across all `.txt` files in your home directory that contain the word \"error\" (case-insensitive). Ensure you handle files with varying character encodings properly.",
        "explanation": "To solve this problem, you need to:\n1. Identify all `.txt` files in your home directory.\n2. Use a command that can search for the word \"error\" in a case-insensitive manner.\n3. Ensure compatibility with different file encodings which might require using `iconv` or similar tools.\n4. Count and sum up the number of lines containing \"error\" from each file.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files in the home directory, convert them to UTF-8 if necessary, \n# then count lines containing 'error' (case-insensitive) and sum these counts.\n\ntotal_lines=$(find ~ -name \"*.txt\" | while read file; do iconv -f ISO-8859-1 -t UTF-8 \"$file\" 2>/dev/null || cat \"$file\"; done | grep -i 'error' | wc -l)\necho $total_lines\n```",
        "create": {
            "init": "# Create sample .txt files with various content and encodings\necho -e \"This is an ERROR line.\\nAnother normal line.\" > ~/sample1.txt\necho -e \"Just another line.\\nError at this point.\" > ~/sample2.txt\niconv -f UTF-8 -t ISO-8859-1 ~/sample1.txt -o ~/sample3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files in the home directory, convert them to UTF-8 if necessary, \n# then count lines containing 'error' (case-insensitive) and sum these counts.\n\ntotal_lines=$(find ~ -name \"*.txt\" | while read file; do iconv -f ISO-8859-1 -t UTF-8 \"$file\" 2>/dev/null || cat \"$file\"; done | grep -i 'error' | wc -l)\necho $total_lines"
        }
    },
    {
        "description": "In the current directory, there are multiple text files with random names. Within these files, some lines contain IP addresses in the format 'xxx.xxx.xxx.xxx'. You need to count how many unique IP addresses are present across all the text files.",
        "explanation": "To solve this problem, you can use a combination of `grep` to extract lines containing the IP addresses and `awk` or `sed` to isolate them. Then, use `sort` and `uniq` to find and count unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract all lines containing potential IPs from all text files\ngrep -Eo '[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' *.txt | \n# Sort the extracted IPs\nsort | \n# Get only unique IPs and count them\nuniq | wc -l\n```",
        "create": {
            "init": "# Create multiple text files with random content and some IP addresses\necho -e \"192.168.1.1\\nSome random text\\n10.0.0.1\" > file1.txt\necho -e \"Another line\\n192.168.1.1\\n172.16.0.5\" > file2.txt\necho -e \"Text without IP\\n10.0.0.1\\n255.255.255.0\" > file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract all lines containing potential IPs from all text files\ngrep -Eo '[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' *.txt | \n# Sort the extracted IPs\nsort | \n# Get only unique IPs and count them\nuniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory, which contains multiple log files with the extension \".log\". Each log file contains lines in the format \"timestamp - level - message\", where level can be one of INFO, WARNING, or ERROR. Your task is to count how many \"ERROR\" messages are present across all log files in the \"logfiles\" directory.",
        "explanation": "To solve this problem, you need to iterate through each \".log\" file in the \"logfiles\" directory and search for lines containing the word \"ERROR\". You can use tools like `grep` to filter these lines and then count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR' ~/logfiles/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-01-01 10:00:00 - INFO - System initialized\\n2023-01-01 10:05:00 - ERROR - Failed to load module\\n2023-01-01 10:10:00 - WARNING - Low memory\\n2023-01-01 10:15:00 - ERROR - Disk not found\" > ~/logfiles/system1.log\necho -e \"2023-02-01 11:00:00 - INFO - User login\\n2023-02-01 11:05:00 - ERROR - Unauthorized access attempt\\n2023-02-01 11:10:00 - INFO - User logout\" > ~/logfiles/system2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR' ~/logfiles/*.log | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing log files in the `/var/logs` directory. Specifically, you need to determine how many unique IP addresses have accessed the server by examining the `access.log` file. Assume each line of `access.log` represents a single access request and contains an IP address as its first field. You should only consider lines that start with a valid IPv4 address.",
        "explanation": "To solve this problem, you will need to filter out lines in the `access.log` that start with a valid IPv4 address and then extract these addresses. After extracting them, you will use a combination of shell commands to identify and count unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract lines starting with a valid IPv4 address using grep and regex pattern matching.\ngrep -Eo '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' /var/logs/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create /var/logs directory if it does not exist\nmkdir -p /var/logs\n\n# Populate access.log with sample data containing various IP addresses\ncat <<EOF > /var/logs/access.log\n192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \"GET /index.html HTTP/1.1\" 200 2326\n192.168.1.2 - - [10/Oct/2023:14:12:11 +0000] \"POST /form HTTP/1.1\" 404 7210\nInvalidEntryHere - [10/Oct/2023:14:22:22 +0000] \"GET /contact.html HTTP/1.1\" 200 1024\n192.168.1.3 - - [10/Oct/2023:15:05:35 +0000] \"DELETE /resource HTTP/1.1\" 403 1032\n192.168.1.2 - - [10/Oct/2023:16:00:00 +0000] \"PUT /upload HTTP/2\" 201 564 \nEOF"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract lines starting with a valid IPv4 address using grep and regex pattern matching.\ngrep -Eo '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' /var/logs/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files. Each log file contains timestamps of events in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique days (YYYY-MM-DD) appear across all these log files.",
        "explanation": "To solve this problem, you need to extract the date portion (YYYY-MM-DD) from every line in each log file within the \"logs\" directory. You can use tools like `awk` or `cut` to parse each line and retrieve the date. Once you have extracted all dates, you should use a tool like `sort` combined with `uniq` to filter out unique dates and finally count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -exec awk '{print $1}' {} + | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 10:15:30\\n2023-10-01 12:20:45\\n2023-10-02 09:00:00\" > ~/logs/log1.txt\necho -e \"2023-10-02 11:15:30\\n2023-10-03 14:22:15\\n2023-10-03 16:18:40\" > ~/logs/log2.txt\necho -e \"2023-10-04 08:45:00\\n2023-10-04 19:05:25\\n2023-10-05 07:30:55\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -exec awk '{print $1}' {} + | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"project_data\" in your home directory that contains multiple subdirectories and files, including hidden ones. Count the total number of lines of text across all files that end with the \".log\" extension, but only include those lines that contain the word \"ERROR\". Note: Do not include lines from hidden files or directories.",
        "explanation": "To solve this problem, you will need to navigate to the \"project_data\" directory and use a combination of find, grep, and wc commands. The find command can help you locate all \".log\" files while ignoring hidden ones. Then, use grep to filter lines containing the word \"ERROR\", and finally count these lines using wc.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/project_data -type f ! -path '*/.*' -name '*.log' | xargs grep 'ERROR' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_data/subdir1\nmkdir -p ~/project_data/subdir2\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nINFO: Backup completed\" > ~/project_data/subdir1/system.log\necho -e \"ERROR: Connection timeout\\nWARNING: High memory usage\\nERROR: Failed login attempt\" > ~/project_data/subdir1/security.log\necho -e \"INFO: Application started\\nERROR: Null pointer exception\\nDEBUG: Variable x=10\" > ~/project_data/subdir2/application.log\ntouch ~/project_data/.hiddenfile.log\necho -e \"# This is a comment line\\nERROR: Critical failure in module X\" > ~/project_data/.dotfile.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/project_data -type f ! -path '*/.*' -name '*.log' | xargs grep 'ERROR' | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory containing multiple text files with different log entries. Each log entry starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to determine how many unique dates are present across all the log files. Assume that each file may have different dates and there can be multiple entries for the same date within a file.",
        "explanation": "To solve this problem, you need to extract the dates from the timestamps at the beginning of each line in all files within the \"log_files\" directory. You can use utilities like `grep`, `awk`, or `sed` to extract these dates. Once you have extracted all dates, you should sort them and use `uniq` to filter out duplicates, then count the number of unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the log_files directory\ncd ~/log_files\n\n# Extract unique dates from all log files and count them\nfind . -type f -exec awk '{print $1}' {} + | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a directory named \"log_files\" in the user's home directory\nmkdir -p ~/log_files\n\n# Create sample log files with random timestamps and entries\necho -e \"2023-03-15 08:23:45 Log entry one\\n2023-03-15 09:34:56 Log entry two\\n2023-03-16 10:45:12 Log entry three\" > ~/log_files/log1.txt\necho -e \"2023-03-16 11:55:21 Log entry four\\n2023-03-17 12:05:33 Log entry five\\n2023-03-17 13:14:44 Log entry six\" > ~/log_files/log2.txt\necho -e \"2023-03-18 14:25:55 Log entry seven\\n2023-03-18 15:36:06 Log entry eight\\n2023-03-19 16:47:17 Log entry nine\" > ~/log_files/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to the log_files directory\ncd ~/log_files\n\n# Extract unique dates from all log files and count them\nfind . -type f -exec awk '{print $1}' {} + | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains error messages, each starting with the keyword \"ERROR:\". Count the total number of distinct error messages across all log files. Note that an error message is considered distinct based on its entire line content after the keyword \"ERROR:\".",
        "explanation": "To solve this problem, you need to filter out lines starting with \"ERROR:\" from each log file, extract the message part following \"ERROR:\", and then determine how many unique messages exist across all files. Use tools like `grep` to find lines containing errors, `cut` or `awk` to isolate the messages, `sort` to sort them, and `uniq` to count distinct entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR:' ~/logs/*.log | cut -d':' -f3- | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: System started\\nERROR: Disk full\\nERROR: Disk full\\nINFO: Maintenance scheduled\" > ~/logs/system1.log\necho -e \"WARNING: High memory usage\\nERROR: Network down\\nERROR: Network down\\nERROR: Disk full\" > ~/logs/system2.log\necho -e \"INFO: Backup completed\\nERROR: CPU overheating\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR:' ~/logs/*.log | cut -d':' -f3- | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a \"logs\" directory containing multiple log files. Each log file contains entries in the format \"YYYY-MM-DD HH:MM:SS [log_level] message\". Your task is to count how many \"ERROR\" level log entries exist across all the files in this directory.",
        "explanation": "To solve this problem, navigate to the \"logs\" directory and use a combination of `grep` and `wc` commands. The `grep` command can be used to filter out lines containing \"[ERROR]\", and `wc -l` will count the number of these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -rh \"\\[ERROR\\]\" logs | wc -l\n```",
        "create": {
            "init": "mkdir logs\necho -e \"2023-10-01 12:00:00 [INFO] System started\\n2023-10-01 12:05:00 [ERROR] Failed to connect to database\\n2023-10-01 12:10:00 [WARN] Low disk space\" > logs/log1.txt\necho -e \"2023-10-02 13:00:00 [ERROR] User authentication failed\\n2023-10-02 13:05:00 [INFO] Data backup completed successfully\" > logs/log2.txt\necho -e \"2023-10-03 14:00:00 [DEBUG] Debugging application\\n2023-10-03 14:05:00 [ERROR] Out of memory error occurred\" > logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -rh \"\\[ERROR\\]\" logs | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing log files from a web server to find out the number of unique IP addresses that have accessed the server. The log files are located in the directory /var/log/webserver/. Each log file is named access_log.YYYYMMDD, where YYYYMMDD represents the date. Your goal is to count the number of unique IP addresses across all log files in this directory.",
        "explanation": "To solve this problem, you need to read through each log file in the /var/log/webserver/ directory, extract the IP addresses, and determine how many unique IPs there are. You can use commands like `cat`, `awk`, `sort`, and `uniq` to process these files. Specifically, you could use `awk` to extract the first column (which contains the IP address), then sort these addresses and use `uniq` to count distinct entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat /var/log/webserver/access_log.* | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/log/webserver/\necho -e \"192.168.0.1 - - [01/Oct/2023:10:00:00 +0000] \\\"GET /index.html HTTP/1.1\\\" 200 1024\\n192.168.0.2 - - [01/Oct/2023:10:05:00 +0000] \\\"GET /about.html HTTP/1.1\\\" 200 2048\\n192.168.0.3 - - [01/Oct/2023:10:15:00 +0000] \\\"GET /contact.html HTTP/1.1\\\" 404 512\" > /var/log/webserver/access_log.20231001\necho -e \"192.168.0.2 - - [02/Oct/2023:11:00:00 +0000] \\\"GET /index.html HTTP/1.1\\\" 200 1024\\n192.168.0.4 - - [02/Oct/2023:11:05:00 +0000] \\\"GET /about.html HTTP/1.1\\\" 200 2048\" > /var/log/webserver/access_log.20231002"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat /var/log/webserver/access_log.* | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are required to find out how many unique IP addresses have accessed the web server from the access logs in the current directory. The log file is named `access.log`. Each line in the log file follows the format: `[IP_ADDRESS] - - [DATE] \"REQUEST_LINE\" STATUS_CODE SIZE`. You should ignore any IP address that appears more than once.",
        "explanation": "To solve this problem, you can use a combination of text processing utilities such as `awk`, `sort`, and `uniq` to extract IP addresses from the log file, sort them, and count only those that appear once. First, use `awk` to extract the first column (IP addresses) from each line. Then, use `sort` to sort these IP addresses. Finally, use `uniq` with appropriate options to filter out unique entries and count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract IPs, sort them, and find unique ones that appear only once.\nawk '{print $1}' access.log | sort | uniq -u | wc -l\n```",
        "create": {
            "init": "# Create an example access.log file in the current directory\ncat <<EOL > access.log\n192.168.1.1 - - [12/Oct/2023:06:25:24 +0000] \"GET /index.html HTTP/1.1\" 200 1024\n192.168.1.2 - - [12/Oct/2023:06:27:35 +0000] \"POST /form HTTP/1.1\" 404 512\n192.168.1.3 - - [12/Oct/2023:06:29:47 +0000] \"GET /about.html HTTP/1.1\" 200 2048\n192.168.1.4 - - [12/Oct/2023:06:30:10 +0000] \"GET /contact.html HTTP/1.1\" 200 1024\n192.168.1.2 - - [12/Oct/2023:06:32:22 +0000] \"GET /index.html HTTP/1.1\" 200 1024\n192.168.1.5 - - [12/Oct/2023:06:33:18 +0000] \"GET /home.html HTTP/1.\" 200 3072\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract IPs, sort them, and find unique ones that appear only once.\nawk '{print $1}' access.log | sort | uniq -u | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple text files with server log data. Each line in these files is a log entry starting with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique dates (in YYYY-MM-DD format) appear across all these log files.",
        "explanation": "To solve this problem, you will need to read through all the files in the \"logs\" directory and extract the date portion from each log entry's timestamp. You can use tools like `grep`, `awk`, or `sed` to extract and manipulate text, and then use commands such as `sort` and `uniq` to filter out unique dates. Finally, count the number of unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -exec awk '{print $1}' {} + | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 10:00:00 Error\\n2023-01-01 11:00:00 Info\\n2023-01-02 12:00:00 Warning\" > ~/logs/log1.txt\necho -e \"2023-01-02 13:00:00 Error\\n2023-01-03 14:30:00 Info\" > ~/logs/log2.txt\necho -e \"2023-01-03 15:45:00 Error\\n2023-01-04 16:50:00 Info\\n2023-01-05 17:55:00 Warning\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -exec awk '{print $1}' {} + | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named `logs` in your home directory containing multiple `.log` files. Each log file consists of entries with timestamps and messages. Your task is to find the total number of unique error messages across all these log files. An error message is identified by lines starting with the keyword \"ERROR\". Consider only the part of the line following \"ERROR\" as the message, ignoring any leading or trailing spaces.",
        "explanation": "To solve this problem, you need to iterate over each `.log` file in the `logs` directory, extract lines starting with \"ERROR\", and collect the unique messages that follow. You can use `grep` to filter out error lines and then use `awk` or `sed` to extract the relevant part of each line. Finally, use utilities like `sort`, `uniq`, and `wc -l` to count unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Navigate to logs directory\ncd ~/logs\n\n# Extract all unique error messages from log files and count them.\ngrep \"^ERROR\" *.log | sed 's/^.*ERROR //' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create logs directory if it doesn't exist\nmkdir -p ~/logs\n\n# Create sample log files\ncat <<EOL > ~/logs/app1.log\n2023-10-01 10:00:00 INFO Starting application\n2023-10-01 10:05:00 ERROR Failed to connect to database\n2023-10-01 11:00:00 ERROR User not found\n2023-10-01 11:05:00 ERROR Failed to connect to database\nEOL\n\ncat <<EOL > ~/logs/app2.log\n2023-10-02 09:30:00 INFO Scheduled task started\n2023-10-02 09:35:00 ERROR File not accessible\n2023-10-02 09:40:00 ERROR User not found\nEOL\n\ncat <<EOL > ~/logs/app3.log\n2023-10-03 08:20:00 INFO Service initiated successfully\n2023-10-03 08:25:00 ERROR Disk quota exceeded \n2023-10-03 08:30:00 ERROR Failed to connect to database \nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Navigate to logs directory\ncd ~/logs\n\n# Extract all unique error messages from log files and count them.\ngrep \"^ERROR\" *.log | sed 's/^.*ERROR //' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple subdirectories, each having several log files with a \".log\" extension. Each log file contains lines of text, some of which might be duplicated across different files. Your task is to count the total number of unique lines present in all the \".log\" files in the \"logs\" directory and its subdirectories. Note that you should ignore case differences and leading/trailing whitespace when determining if two lines are identical.",
        "explanation": "To solve this problem, you need to first locate all the \".log\" files within the \"logs\" directory and its subdirectories using tools like `find`. Then, read and concatenate all these files' content while normalizing them by converting all characters to lowercase and trimming whitespace. Finally, filter out duplicate lines using tools such as `sort` (with options for case-insensitivity) and `uniq`, and count the number of unique lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -name \"*.log\" -exec cat {} + | tr '[:upper:]' '[:lower:]' | sed 's/^[ \\t]*//;s/[ \\t]*$//' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs/subdir1\nmkdir -p ~/logs/subdir2\n\necho \"Error: File not found\\nWarning: Disk space low\\nNotice: Update available\" > ~/logs/subdir1/system.log\necho \"error: file not found\\nWarning: Disk Space Low\\nINFO: Backup completed successfully\" > ~/logs/subdir1/application.log\necho \"ERROR: FILE NOT FOUND\\nNotice: Update available\\ninfo: backup completed successfully\" > ~/logs/subdir2/database.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -name \"*.log\" -exec cat {} + | tr '[:upper:]' '[:lower:]' | sed 's/^[ \\t]*//;s/[ \\t]*$//' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden folder named `.config_files` containing various configuration files with `.conf` extensions. Your task is to find the total number of lines across all these `.conf` files that contain the word \"error\" (case-insensitive). Additionally, filter out any lines that are commented out (lines starting with `#`) before counting. You should provide the final count of such lines.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the hidden folder `.config_files` in your home directory.\n2. Use a command or a series of commands to search through all `.conf` files for lines containing the word \"error\", ignoring case.\n3. Ensure that you exclude any lines that start with `#`, which indicates a comment.\n4. Count these filtered lines and provide the total.\n\nA hint: You can use tools like `grep` for searching, along with options for case insensitivity and excluding matches using regular expressions.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' ~/.config_files/*.conf | grep -v '^#' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/.config_files\necho -e \"This is an error line\\nThis is another line\\n#error in this comment\" > ~/.config_files/file1.conf\necho -e \"#Just a comment\\nAn error occurred here\\nNo issues here\" > ~/.config_files/file2.conf\necho -e \"ERROR found here\\nNo problems detected\" > ~/.config_files/file3.conf"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' ~/.config_files/*.conf | grep -v '^#' | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with a \".log\" extension. Each log file contains lines of text, some of which include timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to count how many unique dates (in the format \"YYYY-MM-DD\") appear across all log files and provide that count.",
        "explanation": "To solve this problem, you need to extract the dates from each line of every log file in the \"logs\" directory. You can use `grep` with regular expressions to find lines containing timestamps, then use `awk` or `sed` to extract just the date portion. Once you have all dates, use `sort` and `uniq` to filter out duplicates and count the unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -hoP '\\d{4}-\\d{2}-\\d{2}' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/log1.log\n2023-10-01 12:00:00 Event A started\n2023-10-02 14:00:00 Event B started\nSome random text\n2023-10-01 16:30:00 Event A ended\nEOL\n\ncat <<EOL > ~/logs/log2.log\n2023-10-01 09:15:00 Initialized system\nError occurred at some time\n2023-10-03 11:45:00 System check complete\n2023-10-02 18:45:00 Shutdown initiated\nEOL\n\ncat <<EOL > ~/logs/log3.log\nNon-timestamped line here.\nAnother plain line.\nYet another non-timestamped line.\n2023-10-04 08:30:00 Maintenance scheduled.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -hoP '\\d{4}-\\d{2}-\\d{2}' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing several log files with the extension \".log\". Each log file contains multiple lines of text. Your task is to determine how many unique IP addresses appear across all these log files. Assume each line in the log files starts with an IP address, followed by a space and then the rest of the log message.",
        "explanation": "To solve this problem, you need to iterate over all \".log\" files in the \"log_files\" directory. For each file, extract the IP addresses from the beginning of each line, and collect them into a set to ensure uniqueness. Finally, count the number of unique IP addresses across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Collect all unique IPs from all log files into a temporary file\nawk '{print $1}' ~/log_files/*.log | sort | uniq > /tmp/unique_ips.txt\n\n# Count unique IPs and print the result\nwc -l < /tmp/unique_ips.txt\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create directory if it doesn't exist\nmkdir -p ~/log_files\n\n# Create sample log files with random IP addresses\necho -e \"192.168.1.1 Connection established\\n192.168.1.2 Connection lost\\n192.168.1.3 Data received\" > ~/log_files/log1.log\necho -e \"192.168.1.2 User login\\n192.168.1.4 File uploaded\\n192.168.1.5 Error occurred\" > ~/log_files/log2.log\necho -e \"192.168.1.3 User logout\\n192.168.1.6 System rebooted\\n192.168.1.7 Alert triggered\" > ~/log_files/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Collect all unique IPs from all log files into a temporary file\nawk '{print $1}' ~/log_files/*.log | sort | uniq > /tmp/unique_ips.txt\n\n# Count unique IPs and print the result\nwc -l < /tmp/unique_ips.txt"
        }
    },
    {
        "description": "You need to find and count the number of unique IP addresses that have accessed the web server by analyzing the log file named `access.log` located in your home directory. The log entries follow the standard Apache log format, and you should only consider lines where the status code is 200.",
        "explanation": "To solve this problem, you can use various command-line utilities. First, filter out lines with a status code of 200 using `grep`. Then, extract the IP addresses from these lines using `awk` or `cut`. After extracting the IPs, sort them and use `uniq` to count distinct entries. This exercise helps you practice filtering and processing text data using powerful Linux tools.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract lines with status code of 200, extract IPs, sort and count unique ones.\ngrep ' 200 ' ~/access.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create an example access.log file in the home directory\ncat <<EOL > ~/access.log\n192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \"GET /index.html HTTP/1.1\" 200 1043\n192.168.1.2 - - [10/Oct/2023:13:55:50 +0000] \"POST /submit HTTP/1.1\" 404 512\n192.168.1.3 - - [10/Oct/2023:14:01:20 +0000] \"GET /about.html HTTP/1.1\" 200 2048\n192.168.1.4 - - [10/Oct/2023:14:02:15 +0000] \"GET /contact.html HTTP/1.1\" 503 1024\n192.168.1.5 - - [10/Oct/2023:14:05:30 +0000] \"GET /home.html HTTP/2\" 200 3072\n192.168.1.6 - - [10/Oct/2023:14:07:45 +0000] \"HEAD /favicon.ico HTTP/2\" 304 -\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract lines with status code of 200, extract IPs, sort and count unique ones.\ngrep ' 200 ' ~/access.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"project_logs\" in your home directory containing multiple text files with log data. Each line in these files represents a single log entry with the following format: \"YYYY-MM-DD HH:MM:SS - LEVEL - Message\". Your task is to count how many ERROR level logs are recorded across all files in this directory. You may assume that each file contains well-formed logs and that there are no subdirectories within \"project_logs\".",
        "explanation": "To solve this problem, you need to traverse through all the text files in the \"project_logs\" directory and search for lines containing the string \"ERROR\". You can use tools like `grep` to filter out these lines and `wc` to count them. It's important to ensure that your command accounts for multiple files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR' ~/project_logs/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"2023-10-01 12:00:00 - INFO - System started\\n2023-10-01 12:05:00 - ERROR - Failed to connect\\n2023-10-01 12:10:00 - WARNING - Low disk space\" > ~/project_logs/log1.txt\necho -e \"2023-10-02 14:20:00 - ERROR - Timeout occurred\\n2023-10-02 15:30:00 - INFO - User login successful\" > ~/project_logs/log2.txt\necho -e \"2023-10-03 08:45:00 - INFO - Backup completed\\n2023-10-03 09:15:00 - ERROR - Disk read error\\n2023-10-03 09:30:00 - ERROR - Network unreachable\" > ~/project_logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR' ~/project_logs/*.txt | wc -l"
        }
    },
    {
        "description": "You need to find out the total number of lines across all `.txt` files located within a directory named `text_files` in your home directory. Assume that there are multiple subdirectories within `text_files`, and you must include all `.txt` files regardless of their depth in the directory structure.",
        "explanation": "To solve this problem, you can use the `find` command to locate all `.txt` files under the `text_files` directory, and then use `xargs` with `wc -l` to count the total number of lines across these files. The combination of these tools allows you to recursively search through directories and efficiently process the results.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/text_files -type f -name \"*.txt\" | xargs wc -l | tail -n 1 | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p ~/text_files/subdir1 ~/text_files/subdir2\necho -e \"Line 1\\nLine 2\" > ~/text_files/file1.txt\necho -e \"Line 1\\nLine 2\\nLine 3\" > ~/text_files/subdir1/file2.txt\necho -e \"Line 1\\nLine 2\\nLine 3\\nLine 4\" > ~/text_files/subdir2/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/text_files -type f -name \"*.txt\" | xargs wc -l | tail -n 1 | awk '{print $1}'"
        }
    },
    {
        "description": "You have a directory named \"project_data\" in your home directory containing multiple text files with random data. Each file contains several lines with numbers separated by spaces. Your task is to find the maximum number present across all files and count how many times this maximum number appears. Provide the count as your final answer.",
        "explanation": "To solve this problem, you need to iterate through each text file in the \"project_data\" directory, extract all numbers, and determine the maximum number among them. Once the maximum number is identified, you should again traverse through all files to count how many times this number appears in total.\n\nYou can use this command pattern to perform the task:\n\n```bash\nmax_number=$(awk '{for(i=1;i<=NF;i++) if($i>max) max=$i} END{print max}' ~/project_data/*)\ncount=$(grep -o \"$max_number\" ~/project_data/* | wc -l)\necho $count\n```",
        "create": {
            "init": "mkdir -p ~/project_data\necho -e \"12 45 78\\n23 89 34\\n56 88 90\" > ~/project_data/file1.txt\necho -e \"67 89 23\\n90 12 45\\n78 56 34\" > ~/project_data/file2.txt\necho -e \"45 67 89\\n90 56 34\\n12 23 78\" > ~/project_data/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "max_number=$(awk '{for(i=1;i<=NF;i++) if($i>max) max=$i} END{print max}' ~/project_data/*)\ncount=$(grep -o \"$max_number\" ~/project_data/* | wc -l)\necho $count"
        }
    },
    {
        "description": "You have been given a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Your task is to determine how many unique IP addresses are present across all log files. Assume each line in a log file begins with an IP address, and the IP addresses are formatted as standard IPv4 addresses.",
        "explanation": "To solve this problem, you need to read through each log file in the \"logs\" directory, extract the IP addresses from each line, and store them in a collection that automatically handles uniqueness, such as a set. Finally, count the number of unique IP addresses stored in this collection.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs/ -type f -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 - Accessed /index.html\\n192.168.1.2 - Accessed /home.html\\n192.168.1.3 - Accessed /contact.html\" > ~/logs/log1.log\necho -e \"192.168.1.2 - Accessed /about.html\\n192.168.1.4 - Accessed /services.html\\n192.168.1.5 - Accessed /products.html\" > ~/logs/log2.log\necho -e \"192.168.1.3 - Accessed /blog.html\\n192.168.1.6 - Accessed /faq.html\\n192.168.1.1 - Accessed /login.html\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs/ -type f -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.logdata` that contains logs with timestamps in the format `YYYY-MM-DD HH:MM:SS`. Your task is to count how many log entries were recorded on \"2023-01-15\" and display only the count.",
        "explanation": "To solve this problem, you would first need to locate the hidden file `.logdata` in your home directory. Then, use tools like `grep` to filter out logs from the specific date \"2023-01-15\". Finally, use `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '2023-01-15' ~/.logdata | wc -l\n```",
        "create": {
            "init": "cat << EOF > ~/.logdata\n2023-01-15 10:00:00 Log entry one\n2023-01-15 12:30:45 Log entry two\n2023-02-20 09:15:30 Some other log\n2023-01-15 18:45:00 Another log entry\nEOF"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '2023-01-15' ~/.logdata | wc -l"
        }
    },
    {
        "description": "You are given a log file named `system.log` in your home directory, which contains multiline entries of system events with timestamps. Each line in the log starts with a timestamp in the format `[YYYY-MM-DD HH:MM:SS]`. Your task is to find out how many unique days have entries in this log file.",
        "explanation": "The problem requires you to parse each line of the log file, extract the date part of the timestamp, and determine how many distinct dates are present. You can achieve this by using tools like `awk`, `cut`, `sort`, and `uniq` to process and filter through the data.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{print $1}' ~/system.log | tr -d '[]' | sort | uniq | wc -l\n```",
        "create": {
            "init": "cat << EOF > ~/system.log\n[2023-10-01 12:00:00] Event A started\n[2023-10-01 13:00:00] Event B completed\n[2023-10-02 09:30:00] Event C started\n[2023-10-03 11:45:00] Event D failed\n[2023-10-03 15:00:00] Event E succeeded\nEOF"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{print $1}' ~/system.log | tr -d '[]' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory, which contains multiple log files with the \".log\" extension. Your task is to find the total number of unique IP addresses present in all these log files. Each line of a log file starts with an IP address (e.g., \"192.168.1.1 - - [timestamp] ...\"). Consider only the first field as the IP address and ignore any other parts of each line.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"log_files\" directory.\n2. Use a command to extract IP addresses from all .log files.\n3. Combine and sort these IP addresses uniquely.\n4. Count the total number of unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/log_files\ncat *.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"192.168.1.1 - - [01/Jan/2023:10:00:00]\\n192.168.1.2 - - [01/Jan/2023:10:05:00]\" > ~/log_files/access_1.log\necho -e \"192.168.1.3 - - [01/Jan/2023:11:00:00]\\n192.168.1.1 - - [01/Jan/2023:11:05:00]\" > ~/log_files/access_2.log\necho \"192.168.2.4 - - [01/Jan/2023:12:00:00]\" > ~/log_files/access_3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/log_files\ncat *.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden directory named \".logs\" containing multiple text files. Each file represents logs generated by different services on your system. Your task is to determine the total number of unique IP addresses that have accessed these services. You should only consider IP addresses in the range \"192.168.x.x\".",
        "explanation": "To solve this problem, you need to search for patterns representing IP addresses in each log file within the \".logs\" directory. Use grep to filter lines containing \"192.168\" and then use awk or similar tools to extract the IP addresses. Finally, sort and use uniq to count distinct entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -hoE '192\\.168\\.[0-9]{1,3}\\.[0-9]{1,3}' $HOME/.logs/* | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p $HOME/.logs\necho \"Error 404 from 192.168.1.2\" > $HOME/.logs/service1.log\necho \"Access granted to 192.168.1.5\" > $HOME/.logs/service2.log\necho \"Connection from 192.168.2.4 failed\" > $HOME/.logs/service3.log\necho \"Attempt from 192.168.1.2 successful\" >> $HOME/.logs/service3.log\necho \"Login from 10.0.0.1 denied\" > $HOME/.logs/service4.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -hoE '192\\.168\\.[0-9]{1,3}\\.[0-9]{1,3}' $HOME/.logs/* | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logfiles\" in your home directory, which contains multiple log files with \".log\" extension. Each log file contains various entries, and each entry starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique dates (in the format \"YYYY-MM-DD\") are present across all the log files in this directory.",
        "explanation": "To solve this problem, you should first list all the log files in the \"logfiles\" directory. Then, extract the date portion from each line's timestamp across all files. You can use tools like `grep` to filter lines and `awk` or `cut` to extract dates. Finally, use `sort` and `uniq` commands to count how many unique dates exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all .log files and extract dates from their entries.\ngrep -hEo '^[0-9]{4}-[0-9]{2}-[0-9]{2}' ~/logfiles/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a 'logfiles' directory in the home directory if it doesn't exist\nmkdir -p ~/logfiles\n\n# Create sample log files with timestamps\necho -e \"2023-04-01 12:00:00 Entry One\\n2023-04-02 13:20:10 Entry Two\" > ~/logfiles/log1.log\necho -e \"2023-04-01 11:45:30 Entry Three\\n2023-04-03 09:15:00 Entry Four\" > ~/logfiles/log2.log\necho -e \"2023-04-02 14:30:20 Entry Five\\n2023-04-03 16:50:40 Entry Six\" > ~/logfiles/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# List all .log files and extract dates from their entries.\ngrep -hEo '^[0-9]{4}-[0-9]{2}-[0-9]{2}' ~/logfiles/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with a \".log\" extension. Each log file contains timestamped entries. Your task is to find the most recent timestamp across all log files and print it in the format \"YYYY-MM-DD HH:MM:SS\". Assume all timestamps are in UTC and follow this exact format.",
        "explanation": "To solve this problem, you need to iterate over all \".log\" files within the \"logs\" directory, extract timestamps from each file, and determine the most recent one. You can use utilities like `grep` to filter lines with timestamps, `sort` to order them, and `tail` to get the most recent entry.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\ngrep -hoP '\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}' ~/logs/*.log | sort | tail -n 1\n```",
        "create": {
            "init": "#!/bin/bash\nmkdir -p ~/logs\necho \"2023-01-01 12:00:00 - Log entry 1\" > ~/logs/log1.log\necho \"2023-01-02 13:00:00 - Log entry 2\" >> ~/logs/log1.log\necho \"2023-01-03 14:00:00 - Log entry 3\" >> ~/logs/log1.log\n\necho \"2023-02-01 10:30:00 - Log entry A\" > ~/logs/log2.log\necho \"2023-02-02 11:30:00 - Log entry B\" >> ~/logs/log2.log\n\necho \"2023-03-05 09:15:00 - Another log message\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "#!/bin/bash\ngrep -hoP '\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}' ~/logs/*.log | sort | tail -n 1"
        }
    },
    {
        "description": "You've been given a directory named \"log_files\" in your home directory containing multiple log files with a \".log\" extension. Each log file records system events with timestamps. Your task is to find out how many unique dates are present across all these logs. For simplicity, assume that each timestamp is formatted as \"YYYY-MM-DD HH:MM:SS\". You need to count only the dates (i.e., the \"YYYY-MM-DD\" part) and provide the number of unique dates.",
        "explanation": "To solve this problem, you need to extract the date portion from each line in all \".log\" files within the \"log_files\" directory, then find and count the unique dates. You can use tools like `grep`, `cut`, `sort`, and `uniq` for this purpose.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/log_files -name \"*.log\" -exec cat {} + | cut -d' ' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-10-01 08:00:00 Event1\\n2023-10-01 09:00:00 Event2\\n2023-10-02 10:00:00 Event3\" > ~/log_files/system1.log\necho -e \"2023-10-01 11:30:00 Event4\\n2023-10-03 12:45:00 Event5\\n2023-10-03 13:50:00 Event6\" > ~/log_files/system2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/log_files -name \"*.log\" -exec cat {} + | cut -d' ' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "In the current directory, you will find a text file named \"system_logs.txt\" containing log entries from various system processes. Each log entry is prefixed with a timestamp in the format 'YYYY-MM-DD HH:MM:SS'. Your task is to determine how many log entries were generated on the most recent day present in the file.",
        "explanation": "To solve this problem, you need to extract all unique dates from the timestamps in the \"system_logs.txt\" and identify the most recent one. Once identified, count how many log entries correspond to that date. You can use utilities such as `awk`, `sort`, `uniq`, `tail`, and `grep` to process the file efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract dates, sort them, find the latest date, and count relevant logs:\nlatest_date=$(awk '{print $1}' system_logs.txt | sort | uniq | tail -n 1)\ngrep -c \"^${latest_date}\" system_logs.txt\n```",
        "create": {
            "init": "# Create a sample \"system_logs.txt\" file with random timestamps and log messages\ncat <<EOL > system_logs.txt\n2023-10-01 12:00:01 Log entry one\n2023-10-02 13:05:02 Log entry two\n2023-10-02 14:23:15 Log entry three\n2023-10-03 09:00:00 Log entry four\n2023-10-03 11:35:45 Log entry five\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract dates, sort them, find the latest date, and count relevant logs:\nlatest_date=$(awk '{print $1}' system_logs.txt | sort | uniq | tail -n 1)\ngrep -c \"^${latest_date}\" system_logs.txt"
        }
    },
    {
        "description": "Count the total number of lines across all text files (.txt) in the \"docs\" directory located in your home directory. Ignore any files that are symbolic links and do not count their lines.",
        "explanation": "To solve this problem, you can use a combination of bash utilities like `find`, `wc`, and `xargs`. First, use `find` to locate all .txt files in the \"docs\" directory while excluding symbolic links. Then, use `xargs` to pass these file paths to `wc -l` which will count the lines in each file. Sum up these line counts to get the total number of lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/docs -type f -name \"*.txt\" ! -type l | xargs wc -l | awk 'END{print $1}'\n```",
        "create": {
            "init": "mkdir -p ~/docs\necho -e \"Line 1\\nLine 2\\nLine 3\" > ~/docs/file1.txt\necho -e \"Hello world\\nAnother line\" > ~/docs/file2.txt\nln -s ~/docs/file1.txt ~/docs/link_to_file1.txt  # Creating a symbolic link"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/docs -type f -name \"*.txt\" ! -type l | xargs wc -l | awk 'END{print $1}'"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory containing multiple log files with various extensions (e.g., .log, .txt). Your task is to count the total number of lines across all files within this directory that contain the word \"ERROR\". Note that the word \"ERROR\" should be case-sensitive and could appear anywhere in a line. Ensure to exclude any subdirectories or hidden files from your count.",
        "explanation": "To solve this problem, you can use the `grep` command to search for lines containing \"ERROR\" in each file within the \"logfiles\" directory. Use the `-r` option with `grep` to recursively search through directories, but make sure to limit it only to files and not directories or hidden files by using appropriate find commands or grep options. The `wc -l` command can then be used to count these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all regular files in the 'logfiles' directory and count lines containing 'ERROR'\nfind ~/logfiles -type f ! -name '.*' | xargs grep -h 'ERROR' | wc -l\n```",
        "create": {
            "init": "# Create a directory called 'logfiles' in the student's home directory\nmkdir -p ~/logfiles\n\n# Create sample log files with different extensions\necho -e \"INFO: System started\\nERROR: Disk full\\nWARNING: High memory usage\" > ~/logfiles/system.log\necho -e \"DEBUG: Starting process\\nERROR: Connection lost\\nINFO: Process completed\" > ~/logfiles/process.txt\necho -e \"INFO: Scheduled task running\\nERROR: File not found\" > ~/logfiles/tasks.log\n\n# Add some more log files without any errors for complexity\necho -e \"INFO: System healthy\\nDEBUG: Checking disk space\" > ~/logfiles/status.log\necho -e \"DEBUG: Network status OK\\nINFO: No issues detected\" > ~/logfiles/network.txt\n\n# Ensure there are no subdirectories or hidden files initially"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all regular files in the 'logfiles' directory and count lines containing 'ERROR'\nfind ~/logfiles -type f ! -name '.*' | xargs grep -h 'ERROR' | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden log file named `.system_log` that records various system events. Your task is to find out how many unique IP addresses attempted to connect to the system in the last 30 days. Additionally, filter out any private IP addresses from your count (such as those in the ranges 10.0.0.0–10.255.255.255, 172.16.0.0–172.31.255.255, and 192.168.0.0–192.168.255.255).",
        "explanation": "To solve this problem, you should first identify and extract all the IP addresses from the `.system_log` file using tools like `grep` or `awk`. Then, use `sort` and `uniq` to filter out duplicate entries and obtain a list of unique IPs within the specified date range (last 30 days). Finally, use pattern matching with tools like `grep` or `sed` to exclude private IP address ranges from this list.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\n\n# Extract all IP addresses ignoring private ranges and count unique ones\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' ~/.system_log | \\\ngrep -Ev '^(10|172\\.(1[6-9]|2[0-9]|3[01])|192\\.168)\\.' | \\\nsort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a hidden log file with simulated data for initialization\ncat <<EOL > ~/.system_log\n2023-09-01 12:34:56 Connection attempt from 192.168.1.10\n2023-09-15 08:21:45 Connection attempt from 203.0.113.5\n2023-09-20 14:22:33 Connection attempt from 198.51.100.2\n2023-09-25 11:11:11 Connection attempt from 172.16.5.4\n2023-10-01 13:44:00 Connection attempt from 8.8.8.8\n2023-10-05 17:30:10 Connection attempt from 203.0..113..5 \nEOL\n\n# Adjust timestamps if necessary depending on current date."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\n\n# Extract all IP addresses ignoring private ranges and count unique ones\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' ~/.system_log | \\\ngrep -Ev '^(10|172\\.(1[6-9]|2[0-9]|3[01])|192\\.168)\\.' | \\\nsort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.user_data` that contains user information in the format \"username:age:email\". Your task is to calculate the average age of all users listed in this file and provide the result rounded to the nearest integer. Ensure that your solution handles any potential empty lines or malformed entries gracefully.",
        "explanation": "To solve this problem, you need to:\n1. Locate and read the hidden `.user_data` file in your home directory.\n2. Filter out any empty lines or malformed entries that do not conform to the \"username:age:email\" format.\n3. Extract the age from each valid line, sum them up, and count the number of valid entries.\n4. Calculate the average age by dividing the total sum of ages by the count of valid entries.\n5. Round this average to the nearest integer for your final answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk -F':' '{\n    if(NF == 3 && $2 ~ /^[0-9]+$/) {\n        sum += $2;\n        count++;\n    }\n} END {\n    if(count > 0) {\n        print int((sum / count) + 0.5);\n    } else {\n        print \"No valid data\";\n    }\n}' ~/.user_data\n```",
        "create": {
            "init": "cat <<EOL > ~/.user_data\njohn_doe:25:johndoe@example.com\njane_smith:30:janesmith@example.com\n\ninvalid_entry_no_colons\nbob_jones:45:bobjones@example.com\nalice_white::alicewhite@example.com\ncharlie_brown:40:charliebrown@example.com\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk -F':' '{\n    if(NF == 3 && $2 ~ /^[0-9]+$/) {\n        sum += $2;\n        count++;\n    }\n} END {\n    if(count > 0) {\n        print int((sum / count) + 0.5);\n    } else {\n        print \"No valid data\";\n    }\n}' ~/.user_data"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with the \".log\" extension. Each log file contains timestamps followed by messages related to system operations. Your task is to count how many unique dates appear across all the log files in the \"logs\" directory. Assume that each timestamp follows the format \"YYYY-MM-DD HH:MM:SS\". You need to interact with the shell to find this count.",
        "explanation": "To solve this problem, you need to extract the date portion (first 10 characters) from each line of all \".log\" files in the \"logs\" directory, then identify and count unique dates. Useful commands for this task include `cut` to extract parts of lines, `sort` and `uniq` for determining unique entries, and `wc -l` for counting lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncut -d ' ' -f1 ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 System started\\n2023-10-02 13:00:00 User login\\n2023-10-02 14:30:00 Backup completed\" > ~/logs/system1.log\necho -e \"2023-10-03 09:15:00 Maintenance scheduled\\n2023-10-01 16:45:00 Update installed\\n2023-10-04 11:20:00 Rebooted system\" > ~/logs/system2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cut -d ' ' -f1 ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing system logs to determine how many unique IP addresses have accessed the web server today. The log files are located in the `/var/log/apache2/` directory and follow the naming convention `access.log.*`. Your answer should be the count of unique IP addresses that appear in all the log files for today.",
        "explanation": "To solve this problem, you need to first identify today's log files based on their modification date. Then, extract IP addresses from these logs. Use utilities such as `find`, `xargs`, `grep`, `awk`, and `sort` to process the files and determine the number of unique IP addresses. You can utilize `date` command to filter by today's logs.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\nTODAY=$(date +%Y%m%d)\nfind /var/log/apache2/ -type f -name \"access.log.*$TODAY*\" \\\n    | xargs grep -oE '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' \\\n    | sort | uniq | wc -l\n```",
        "create": {
            "init": "# This script creates sample log files for today's date\nmkdir -p /var/log/apache2/\nTODAY=$(date +%Y%m%d)\necho \"192.168.1.1 - - [$(date +\"%d/%b/%Y:%H:%M:%S\")] \\\"GET / HTTP/1.1\\\" 200 2326\" > /var/log/apache2/access.log.$TODAY\necho \"192.168.1.2 - - [$(date +\"%d/%b/%Y:%H:%M:%S\")] \\\"GET /about HTTP/1.1\\\" 200 1234\" >> /var/log/apache2/access.log.$TODAY\necho \"10.0.0.5 - - [$(date +\"%d/%b/%Y:%H:%M:%S\")] \\\"POST /login HTTP/1.1\\\" 403 982\" >> /var/log/apache2/access.log.$TODAY\necho \"192.168.1.1 - - [$(date +\"%d/%b/%Y:%H:%M:%S\")] \\\"GET /contact HTTP/1.1\\\" 200 4567\" >> /var/log/apache2/access.log.$TODAY"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\nTODAY=$(date +%Y%m%d)\nfind /var/log/apache2/ -type f -name \"access.log.*$TODAY*\" \\\n    | xargs grep -oE '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' \\\n    | sort | uniq | wc -l"
        }
    },
    {
        "description": "In the current directory, you will find a collection of text files named `file1.txt`, `file2.txt`, ..., up to `file10.txt`. Each file contains several lines with random numbers. Your task is to determine the maximum number present across all these files. You should employ Linux command-line utilities to accomplish this task.",
        "explanation": "To solve this problem, you can use a combination of command-line utilities such as `cat` to concatenate all files together, `sort` to sort the numbers, and `tail` to retrieve the last (largest) number. A hint would be to use pipes (`|`) for chaining commands and efficiently processing data without creating intermediate files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Concatenate all files, sort them numerically, and get the last (maximum) number.\ncat file*.txt | sort -n | tail -n 1\n```",
        "create": {
            "init": "# Create 10 text files with random numbers\nfor i in {1..10}\ndo\n  seq 1 $((RANDOM % 100 + 50)) | shuf > \"file$i.txt\"\ndone"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Concatenate all files, sort them numerically, and get the last (maximum) number.\ncat file*.txt | sort -n | tail -n 1"
        }
    },
    {
        "description": "You are given a directory called `logs` containing multiple log files with the `.log` extension. Each log file contains lines of text, where some lines start with the word \"ERROR\" followed by a timestamp and an error message. Your task is to count the total number of unique error messages in all log files combined. The error message is considered unique if its entire content (excluding \"ERROR\" and timestamp) has not appeared in any other line.",
        "explanation": "To solve this problem, you need to:\n1. Search through each file in the `logs` directory.\n2. Extract lines that start with \"ERROR\".\n3. Remove the \"ERROR\" keyword and timestamp from each line to isolate the error message.\n4. Use a set to track unique error messages and avoid duplicates.\n5. Count the number of unique entries in your set.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract lines starting with ERROR, remove 'ERROR' and timestamps, then count unique messages.\ngrep '^ERROR' logs/*.log | sed 's/^.* [0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\} //' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir logs\necho -e \"INFO 2023-10-01 Starting process\\nERROR 2023-10-01 Unable to connect to database\\nERROR 2023-10-02 Disk not found\\nINFO 2023-10-02 Process completed\\nERROR 2023-10-03 Unable to connect to database\" > logs/app1.log\necho -e \"WARNING 2023-10-01 Low memory\\nERROR 2023-10-02 Disk not found\\nINFO 2023-10-03 Shutdown initiated\\nERROR 2023-10-03 User authentication failed\" > logs/app2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract lines starting with ERROR, remove 'ERROR' and timestamps, then count unique messages.\ngrep '^ERROR' logs/*.log | sed 's/^.* [0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\} //' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with various extensions (.log, .txt, etc.). Each log file contains lines of text, and some lines include the word \"ERROR\". Your task is to count the total number of lines across all files in the \"logs\" directory that contain the word \"ERROR\", ignoring case.",
        "explanation": "To solve this problem, you can use a combination of commands such as `grep` for searching text within files and `wc -l` for counting lines. The `-i` option with `grep` can be used to ignore case sensitivity. You will need to search each file in the \"logs\" directory and add up the results to get the total count.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'ERROR' ~/logs/* | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"This is an error line\\nAnother line\\nYet another ERROR line\" > ~/logs/file1.log\necho -e \"Random text\\nerror message here\\nNo issues here\" > ~/logs/file2.txt\necho -e \"ERROR found\\nSomething else\\nError again\" > ~/logs/file3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'ERROR' ~/logs/* | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.logfile` which contains various system log entries. Your task is to count how many log entries in this file contain the word \"error\" (case-insensitive). You should also filter out duplicate entries before counting.",
        "explanation": "To solve this problem, first locate and read the hidden file `.logfile` in your home directory. Use tools like `grep` to search for the occurrences of the word \"error\" in a case-insensitive manner. Then, use `sort` and `uniq` to remove duplicate log entries before counting them with `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\ngrep -i \"error\" ~/.logfile | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a hidden logfile with sample log data\necho -e \"Error: File not found\\nINFO: System rebooted\\nERROR: Disk full\\nwarning: low battery\\nError: File not found\\nerror: Network issue\\nERROR: Disk full\" > ~/.logfile"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\ngrep -i \"error\" ~/.logfile | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple text files with server log data. Each line in the log files follows the format: \"timestamp - status_code - message\". Your task is to count how many times the status code \"404\" appears across all log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and read each file. Use tools like `grep` or `awk` to search for lines containing the status code \"404\". Then count and sum these occurrences across all files. A combination of `find`, `xargs`, and `grep` can be very helpful for processing multiple files efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs/ -type f | xargs grep '404' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 - 200 - OK\\n2023-10-01 12:01:00 - 404 - Not Found\\n2023-10-01 12:02:00 - 500 - Internal Server Error\" > ~/logs/server1.log\necho -e \"2023-10-02 13:00:00 - 404 - Not Found\\n2023-10-02 13:01:00 - 200 - OK\\n2023-10-02 13:02:00 - 404 - Not Found\" > ~/logs/server2.log\necho -e \"2023-10-03 14:00:00 - 503 - Service Unavailable\\n2023-10-03 14:01:00 - 200 - OK\\n2023-10-03 14:02:00 - 404 - Not Found\" > ~/logs/server3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs/ -type f | xargs grep '404' | wc -l"
        }
    },
    {
        "description": "In the current directory, there is a file named \"server.log\" containing log entries from a web server. Each line in the file follows the format: \"[timestamp] [status_code] [message]\". Your task is to determine how many requests ended with a status code of 404, which generally indicates \"Not Found\". Note that the log file could be very large, so consider using efficient methods to process it.",
        "explanation": "To solve this problem, you need to filter out lines from \"server.log\" that contain the status code 404. You can use tools like `grep` to search for these lines and then count them using `wc -l`. This approach efficiently processes each line for its content without loading the entire file into memory at once.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '404' server.log | wc -l\n```",
        "create": {
            "init": "cat <<EOL > server.log\n[2023-10-01T12:00:00Z] 200 OK\n[2023-10-01T12:01:00Z] 404 Not Found\n[2023-10-01T12:02:00Z] 500 Internal Server Error\n[2023-10-01T12:03:00Z] 404 Not Found\n[2023-10-01T12:04:00Z] 200 OK\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '404' server.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple log files with a \".log\" extension. Your task is to find the largest file by size within this directory, and output its name without the \".log\" extension. Ensure you consider hidden files as well.",
        "explanation": "To solve this problem, navigate to the \"log_files\" directory and list all files (including hidden ones) with a \".log\" extension. Use the `ls` or `find` command to retrieve these files along with their sizes. Sort them by size using `sort`, and identify the largest one. Finally, strip off the \".log\" extension from its name before outputting it.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/log_files\nlargest_file=$(ls -A *.log | xargs du -b | sort -n -r | head -n 1 | awk '{print $2}')\nbasename \"$largest_file\" .log\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho \"Sample log content.\" > ~/log_files/.hidden1.log\ndd if=/dev/zero of=~/log_files/test1.log bs=1024 count=1 &>/dev/null\ndd if=/dev/zero of=~/log_files/test2.log bs=1024 count=2 &>/dev/null\ndd if=/dev/zero of=~/log_files/.hidden2.log bs=1024 count=3 &>/dev/null"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "cd ~/log_files\nlargest_file=$(ls -A *.log | xargs du -b | sort -n -r | head -n 1 | awk '{print $2}')\nbasename \"$largest_file\" .log"
        }
    },
    {
        "description": "You have a directory named `logs` in your home directory containing multiple log files with the `.log` extension. Each log file records system events, with each line starting with a timestamp in the format `YYYY-MM-DD HH:MM:SS`. Your task is to find out how many lines in total across all these log files contain the word \"ERROR\". You must only count lines that are unique across all files (i.e., identical lines should be counted only once).",
        "explanation": "To solve this problem, you need to follow these steps:\n1. Navigate to the `logs` directory.\n2. Use a combination of commands such as `cat`, `grep`, and `sort` to search for lines containing \"ERROR\".\n3. Ensure you eliminate duplicate lines by using commands like `uniq`.\n4. Count the number of unique \"ERROR\" lines using commands like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ncat *.log | grep \"ERROR\" | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create the logs directory in the user's home directory if it doesn't exist\nmkdir -p ~/logs\n\n# Create sample log files with some duplicate and unique ERROR entries\necho -e \"2023-10-01 12:00:00 INFO Starting process\\n2023-10-01 12:01:02 ERROR Failed to start service\\n2023-10-01 12:03:45 WARNING Low disk space\" > ~/logs/system1.log\n\necho -e \"2023-10-02 14:22:30 ERROR Failed to start service\\n2023-10-02 14:25:31 INFO Process completed\\n2023-10-02 14:27:29 ERROR Network unreachable\" > ~/logs/system2.log\n\necho -e \"2023-10-03 16:43:22 ERROR Disk read error\\n2023-10-03 16:44:55 ERROR Network unreachable\\n2023-10-03 16:47:18 INFO Shutdown initiated\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ncat *.log | grep \"ERROR\" | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing system log files to determine how many unique IP addresses attempted to access the server. You should focus on the `/var/log/auth.log` file and count only those entries marked with \"Failed password\" attempts. You need to ensure that your answer is unique IP addresses only.",
        "explanation": "To solve this problem, you will need to parse the `/var/log/auth.log` file, extract lines containing the phrase \"Failed password\", and then extract IP addresses from these lines. After extracting these IPs, deduplicate them by storing them in a set or using a command that naturally handles duplicates.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract lines with \"Failed password\" and cut out the IP address part.\ngrep \"Failed password\" /var/log/auth.log | awk '{print $11}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample auth.log file with various failed login attempts\nmkdir -p /var/log/\ncat <<EOL > /var/log/auth.log\nJan 10 10:00:01 ubuntu sshd[12345]: Failed password for invalid user admin from 192.168.1.2 port 22 ssh2\nJan 10 10:05:15 ubuntu sshd[12346]: Failed password for invalid user guest from 192.168.1.3 port 22 ssh2\nJan 10 11:35:44 ubuntu sshd[12347]: Failed password for root from 192.168.1.4 port 22 ssh2\nJan 11 09:30:12 ubuntu sshd[12348]: Failed password for invalid user test from 192.168.1.5 port 22 ssh2\nJan 11 09:31:00 ubuntu sshd[12349]: Failed password for invalid user test from 192.168.1.5 port 22 ssh2\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract lines with \"Failed password\" and cut out the IP address part.\ngrep \"Failed password\" /var/log/auth.log | awk '{print $11}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with the \".log\" extension. Each log file records server activities and is formatted with lines starting with timestamps (in the format YYYY-MM-DD HH:MM:SS) followed by a string indicating the activity. Your task is to find out how many times the phrase \"ERROR\" appears in all these log files combined. Note that lines could contain multiple instances of \"ERROR\".",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory, read through each \".log\" file, count how many times the phrase \"ERROR\" appears across all files, and sum up this count. You can use tools like `grep` or `awk` to search for and count occurrences of \"ERROR\".\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -roh 'ERROR' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 INFO Starting process\\n2023-10-01 12:05:00 ERROR Failed to connect\\n2023-10-01 12:06:00 ERROR Retry failed\" > ~/logs/server1.log\necho -e \"2023-10-02 13:00:00 INFO Process running\\n2023-10-02 13:05:00 WARN Low memory\\n2023-10-02 13:06:00 ERROR Out of memory\\n2023-10-02 13:07:00 ERROR Disk full\" > ~/logs/server2.log\necho -e \"2023-10-03 14:00:00 INFO Shutdown initiated\\n2023-10-03 14:05:00 ERROR Shutdown error reported\" > ~/logs/server3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -roh 'ERROR' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"project_files\" containing various text files. Your task is to find out how many unique words exist across all files in this directory. Words should be considered case-insensitive and should not include punctuation marks.",
        "explanation": "To solve this problem, you will need to perform several tasks: \n1. Navigate to the \"project_files\" directory in your home directory.\n2. Concatenate all text files to process them together.\n3. Use text processing tools like `tr`, `awk`, or `sed` to clean up the text: converting all words to lowercase and removing punctuation.\n4. Utilize a command like `sort` and `uniq` to identify unique words.\n5. Count these unique words using a tool such as `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/project_files\ncat *.txt | tr '[:upper:]' '[:lower:]' | tr -d '[:punct:]' | tr ' ' '\\n' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_files\necho \"Hello world! Welcome to the Linux challenge.\" > ~/project_files/file1.txt\necho \"The quick brown fox jumps over the lazy dog.\" > ~/project_files/file2.txt\necho \"HELLO again, world!!\" > ~/project_files/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/project_files\ncat *.txt | tr '[:upper:]' '[:lower:]' | tr -d '[:punct:]' | tr ' ' '\\n' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked to find the total number of lines containing the word \"error\" (case-insensitive) from all `.log` files in the `/var/logs` directory. Ensure that you only count lines from files modified in the last 7 days.",
        "explanation": "To solve this problem, first, identify all `.log` files in the `/var/logs` directory that were modified within the last 7 days. Use `find` command with appropriate options to filter these files. Then, for each file, search for lines containing the word \"error\" using `grep`, ensuring it's case-insensitive with the `-i` flag. Count these lines and sum them up to get the total.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/logs -name '*.log' -mtime -7 | xargs grep -i 'error' | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs\necho \"Error: Something went wrong\" > /var/logs/app1.log\necho \"This is a warning\" >> /var/logs/app1.log\necho \"ERROR: Failed to connect\" > /var/logs/app2.log\necho \"System check passed\" >> /var/logs/app2.log\ntouch -d '3 days ago' /var/logs/app1.log\ntouch -d '10 days ago' /var/logs/app2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/logs -name '*.log' -mtime -7 | xargs grep -i 'error' | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory, which contains multiple text files with server log entries. Each log entry is a single line with the format: \"TIMESTAMP LEVEL MESSAGE\", where LEVEL can be INFO, WARN, or ERROR. Your task is to count the total number of ERROR entries across all files in the \"logs\" directory and provide the count as your answer.",
        "explanation": "To solve this problem, you need to efficiently navigate through all text files in the \"logs\" directory and filter out lines containing the word \"ERROR\". You can use tools like `grep` to search for the keyword across multiple files and then use `wc -l` to count the number of matched lines. Consider using wildcard patterns to process all files within the directory.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use grep to find lines containing 'ERROR' and wc -l to count them.\ngrep -r 'ERROR' ~/logs | wc -l\n```",
        "create": {
            "init": "# Create a logs directory in the student's home folder\nmkdir -p ~/logs\n\n# Populate it with sample log files\necho -e \"2023-10-01 12:00:00 INFO Start process\\n2023-10-01 12:01:00 ERROR Failed to start\\n2023-10-01 12:02:00 WARN Low memory\\n2023-10-01 12:03:00 ERROR Disk full\" > ~/logs/server1.log\necho -e \"2023-10-02 13:00:00 INFO Connection established\\n2023-10-02 13:05:00 ERROR Connection lost\\n2023-10-02 13:06:00 INFO Reconnecting\" > ~/logs/server2.log\necho -e \"2023-10-03 14:30:00 WARN CPU usage high\\n2023-10-03 14:35:00 ERROR Timeout occurred\\n2023-10-03 14:36:00 INFO Process completed\" > ~/logs/server3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use grep to find lines containing 'ERROR' and wc -l to count them.\ngrep -r 'ERROR' ~/logs | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a file named \"system_logs.txt\" that contains log entries. Each line in the file represents a log entry with a timestamp and an error level (INFO, WARNING, ERROR). Your task is to count how many ERROR logs occurred on the current date. Assume the date format in the logs is \"YYYY-MM-DD\" and today's date can be obtained using the `date +\"%Y-%m-%d\"` command.",
        "explanation": "To solve this problem, you should first determine today's date using the `date` command with the appropriate format. Then, use tools like `grep` or `awk` to filter out lines from \"system_logs.txt\" that contain both today's date and the \"ERROR\" keyword. Finally, count these lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Get today's date in YYYY-MM-DD format\ntoday=$(date +\"%Y-%m-%d\")\n\n# Count lines containing today's date and \"ERROR\"\nerror_count=$(grep \"$today ERROR\" ~/system_logs.txt | wc -l)\n\n# Output the result\necho $error_count\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create system_logs.txt file with sample data\ncat <<EOL > ~/system_logs.txt\n2023-10-01 INFO Starting system check...\n2023-10-01 WARNING High memory usage detected.\n2023-10-01 ERROR Disk space low.\n2023-10-02 INFO Daily backup started.\n2023-10-02 ERROR Failed to connect to server.\n2023-10-02 ERROR Network timeout.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Get today's date in YYYY-MM-DD format\ntoday=$(date +\"%Y-%m-%d\")\n\n# Count lines containing today's date and \"ERROR\"\nerror_count=$(grep \"$today ERROR\" ~/system_logs.txt | wc -l)\n\n# Output the result\necho $error_count"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory, which contains multiple log files with the extension \".log\". Each log file records timestamps in the format \"YYYY-MM-DD HH:MM:SS\" and some associated event messages. Your task is to count how many unique days (in the format YYYY-MM-DD) are recorded across all these log files.",
        "explanation": "To solve this problem, you should first navigate to the \"logs\" directory and read through all files with the \".log\" extension. Extract the date part (YYYY-MM-DD) from each timestamp line in these files. Collect all unique dates and count them. You can use utilities such as `cat`, `grep`, `awk`, `sed`, `sort`, and `uniq` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ncat *.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-11-01 12:00:00 Event1\\n2023-11-02 13:30:00 Event2\\n2023-11-01 14:45:00 Event3\" > ~/logs/log1.log\necho -e \"2023-11-03 09:15:00 Event4\\n2023-11-01 10:20:00 Event5\\n2023-11-04 16:05:00 Event6\" > ~/logs/log2.log\necho -e \"2023-11-02 08:40:00 Event7\\n2023-11-05 17:55:00 Event8\\n2023-11-03 12:30:00 Event9\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ncat *.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"project_logs\" containing multiple log files with various extensions. These files contain timestamped logs in the format \"YYYY-MM-DD HH:MM:SS - Message\". Your task is to find out how many unique days are represented across all the log files. Consider only those files that end with \".log\" extension.",
        "explanation": "To solve this problem, you need to aggregate lines from all \".log\" files in the \"project_logs\" directory and extract the date portion of each timestamp. You will then determine the number of unique dates across these entries. Use tools like `find`, `cat`, `awk`, and `sort` along with `uniq` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind project_logs -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir project_logs\necho -e \"2023-10-01 12:00:00 - Started process\\n2023-10-02 13:00:00 - Process running\\n2023-10-01 14:00:00 - Process completed\" > project_logs/log1.log\necho -e \"2023-10-03 09:30:00 - Error occurred\\n2023-10-03 15:45:00 - Fixed error\" > project_logs/log2.log\necho -e \"2023-09-30 06:25:00 - Initialization\\n2023-09-29 07:15:00 - Pre-checks complete\" > project_logs/old_log.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find project_logs -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden log file named \".access.log\" which contains entries of IP addresses accessing your web server. Each line in the file consists of an IP address followed by a timestamp. Determine how many unique IP addresses have accessed the server more than 10 times.",
        "explanation": "To solve this problem, you need to extract the IP addresses from the \".access.log\" file and count their occurrences. You can use tools like `awk`, `sort`, `uniq`, and `grep` to perform these operations. First, use `awk` or `cut` to extract the first field (the IP address), then sort the output for easy counting. Use `uniq -c` to count occurrences of each unique IP address, then filter out those that appear more than 10 times using `awk` or another similar tool.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extracting only the IP addresses from the log file and counting them\nawk '{print $1}' ~/.access.log | sort | uniq -c | awk '$1 > 10 {print $2}' | wc -l\n```",
        "create": {
            "init": "# Create a hidden log file with sample data in the user's home directory\ncat <<EOL > ~/.access.log\n192.168.0.1 [2021-01-01 00:00:01]\n192.168.0.2 [2021-01-01 00:01:02]\n192.168.0.1 [2021-01-01 00:02:03]\n192.168.0.3 [2021-01-01 00:03:04]\n192.168.0.4 [2021-01-01 00:04:05]\n192.168.0.2 [2021-01-01 00:05:06]\n192.168.0.3 [2021-01-02 00:06:07]\n192.168.0.1 [2021-02-03 00:07:08]\n192.168.0.x // More lines should be added here with varied repetition for testing\nEOL\n\n# Repeat some IPs more than ten times for testing purposes\nfor i in {11..20}; do echo \"203.$i.$i.$i [2023-$i-$i $i:$i:$i]\" >> ~/.access.log; done"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extracting only the IP addresses from the log file and counting them\nawk '{print $1}' ~/.access.log | sort | uniq -c | awk '$1 > 10 {print $2}' | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.datafile` that contains a list of numbers, each on a new line. Count how many of these numbers are prime and provide the total count.",
        "explanation": "To solve this problem, you need to read the hidden file `.datafile` in your home directory, check each number to determine if it is a prime number, and then count the total number of prime numbers. A prime number is one that is greater than 1 and has no divisors other than 1 and itself. You can use utilities like `grep`, `awk`, or write a small script using tools like `bc` or simple arithmetic in bash to check for primality.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Solution example: Count prime numbers in the .datafile\n\nis_prime() {\n    local num=$1\n    \n    if ((num <= 1)); then \n        return 1 # not prime \n    fi\n    \n    for ((i=2; i*i<=num; i++)); do \n        if ((num % i == 0)); then \n            return 1 # not prime \n        fi \n    done \n    \n    return 0 # prime \n}\n\ncount=0\n\nwhile IFS= read -r number; do \n    if is_prime \"$number\"; then \n        count=$((count + 1)) \n    fi \ndone < ~/.datafile\n\necho $count # Expected output: The integer result (e.g., \"9\")\n```",
        "create": {
            "init": "# Create a hidden file with random numbers for students to process\ncat <<EOL > ~/.datafile\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n13\n17\n19\n23\n29\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Solution example: Count prime numbers in the .datafile\n\nis_prime() {\n    local num=$1\n    \n    if ((num <= 1)); then \n        return 1 # not prime \n    fi\n    \n    for ((i=2; i*i<=num; i++)); do \n        if ((num % i == 0)); then \n            return 1 # not prime \n        fi \n    done \n    \n    return 0 # prime \n}\n\ncount=0\n\nwhile IFS= read -r number; do \n    if is_prime \"$number\"; then \n        count=$((count + 1)) \n    fi \ndone < ~/.datafile\n\necho $count # Expected output: The integer result (e.g., \"9\")"
        }
    },
    {
        "description": "In your home directory, there is a subdirectory named \"projects\" containing multiple subdirectories, each representing a project. Within each project subdirectory, there might be multiple log files with a \".log\" extension. Your task is to find the total number of lines across all \".log\" files within all project subdirectories that contain the word \"ERROR\". Please write the number of such lines as your answer.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"projects\" directory within your home directory.\n2. Use a combination of `find` and `grep` commands to locate all \".log\" files and count the lines containing the word \"ERROR\".\n3. Sum up these counts to get the total number of lines containing \"ERROR\" across all projects.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\nfind ~/projects -name \"*.log\" -exec grep -H \"ERROR\" {} \\; | wc -l\n```",
        "create": {
            "init": "# Create directories and sample log files\nmkdir -p ~/projects/project1\nmkdir -p ~/projects/project2\n\n# Create sample log files with some content\necho -e \"INFO: Start process\\nERROR: Something went wrong\\nINFO: Process ended\" > ~/projects/project1/app.log\necho -e \"DEBUG: Debugging info\\nERROR: Another error occurred\\nINFO: Finished\\nERROR: Critical failure\" > ~/projects/project2/system.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\nfind ~/projects -name \"*.log\" -exec grep -H \"ERROR\" {} \\; | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory containing multiple log files with \".log\" extension. Each log file contains timestamps and error messages in the format \"YYYY-MM-DD HH:MM:SS - ERROR: Message\". Your task is to count how many unique error messages occurred in each log file and then sum them up to find the total number of unique errors across all files. Provide the final count as the answer.",
        "explanation": "To solve this problem, you need to perform several steps:\n1. Navigate to the \"logfiles\" directory.\n2. Use `grep` or `awk` to extract only the error messages from each log file.\n3. Utilize `sort` and `uniq` commands to find unique error messages per file.\n4. Count these unique entries for each file.\n5. Sum up all unique counts from each file to get the total number of distinct error messages across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the logfiles directory\ncd ~/logfiles\n\n# Extract, sort, and count unique errors in system.log\nunique_system_errors=$(grep 'ERROR' system.log | awk -F 'ERROR:' '{print $2}' | sort | uniq | wc -l)\n\n# Extract, sort, and count unique errors in application.log\nunique_application_errors=$(grep 'ERROR' application.log | awk -F 'ERROR:' '{print $2}' | sort | uniq | wc -l)\n\n# Sum up all unique errors counts from both files\ntotal_unique_errors=$((unique_system_errors + unique_application_errors))\n\n# Output the total number of unique errors\necho $total_unique_errors\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-10-01 12:00:00 - ERROR: Disk full\\n2023-10-01 12:05:00 - ERROR: Network unreachable\\n2023-10-01 12:10:00 - ERROR: Disk full\" > ~/logfiles/system.log\necho -e \"2023-10-01 13:00:00 - ERROR: File not found\\n2023-10-01 13:05:00 - ERROR: Disk full\\n2023-10-01 13:15:00 - ERROR: File not found\" > ~/logfiles/application.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to the logfiles directory\ncd ~/logfiles\n\n# Extract, sort, and count unique errors in system.log\nunique_system_errors=$(grep 'ERROR' system.log | awk -F 'ERROR:' '{print $2}' | sort | uniq | wc -l)\n\n# Extract, sort, and count unique errors in application.log\nunique_application_errors=$(grep 'ERROR' application.log | awk -F 'ERROR:' '{print $2}' | sort | uniq | wc -l)\n\n# Sum up all unique errors counts from both files\ntotal_unique_errors=$((unique_system_errors + unique_application_errors))\n\n# Output the total number of unique errors\necho $total_unique_errors"
        }
    },
    {
        "description": "In your home directory, there is a file named \"system_logs.txt\" containing various log entries. Your task is to find out how many unique IP addresses have accessed the system according to this log file. Assume each log entry is structured with an IP address at the beginning of the line.",
        "explanation": "To solve this problem, you need to extract the IP addresses from each line in the \"system_logs.txt\" file, filter out any duplicates, and count how many unique IP addresses are present. You can use tools like `awk`, `sort`, and `uniq` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{print $1}' ~/system_logs.txt | sort | uniq | wc -l\n```",
        "create": {
            "init": "cat > ~/system_logs.txt <<EOL\n192.168.1.1 - Accessed on 2023-10-01\n192.168.1.2 - Accessed on 2023-10-02\n192.168.1.1 - Accessed on 2023-10-03\n172.16.0.5 - Accessed on 2023-10-04\n192.168.1.3 - Accessed on 2023-10-05\n172.16.0.5 - Accessed on 2023-10-06\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{print $1}' ~/system_logs.txt | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing multiple log files with the \".log\" extension. Each log file contains several lines of text, among which there are lines that include the keyword \"ERROR\". Your task is to count the total number of lines containing the keyword \"ERROR\" across all log files in the \"logs\" directory and provide this count as your answer.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory, use a combination of commands such as `grep` to search for lines containing the keyword \"ERROR\", and then use `wc -l` to count these lines across all files. The command should be executed in such a way that it processes multiple files at once.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p logs\necho -e \"INFO: All systems go\\nERROR: Disk space low\\nWARNING: High memory usage\\nERROR: Network delay detected\" > logs/system1.log\necho -e \"INFO: Running diagnostics\\nINFO: Diagnostics completed\\nERROR: CPU temperature high\" > logs/system2.log\necho -e \"WARNING: Low battery\\nERROR: Battery failed\\nINFO: Charging initiated\" > logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' logs/*.log | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines containing the string \"ERROR\" in all `.log` files within the `/var/logs` directory. Please note that some files may be compressed with `.gz` extension, and you need to include those as well. Ensure your solution is efficient and doesn't produce unnecessary output.",
        "explanation": "To solve this problem, you'll need to perform several steps: \n1. Use `find` to locate all `.log` and `.log.gz` files in the `/var/logs` directory.\n2. Use `zgrep` for compressed files and `grep` for uncompressed files to search for lines containing \"ERROR\".\n3. Count the total number of lines across all files using appropriate shell utilities like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all .log and .log.gz files and search for \"ERROR\"\ntotal_errors=0\n\nfor file in $(find /var/logs -name \"*.log\" -o -name \"*.log.gz\"); do\n  if [[ $file == *.gz ]]; then\n    count=$(zgrep -c \"ERROR\" \"$file\")\n  else\n    count=$(grep -c \"ERROR\" \"$file\")\n  fi\n  \n  # Accumulate counts from each file\n  total_errors=$((total_errors + count))\ndone\n\n# Output the total number of errors found\necho $total_errors\n```",
        "create": {
            "init": "# Create a directory for logs\nmkdir -p /var/logs\n\n# Create some .log files with sample content\necho -e \"INFO: Everything is fine\\nERROR: Something went wrong\\nINFO: Still fine\" > /var/logs/system.log\necho -e \"ERROR: Major issue detected\\nWARNING: High memory usage\" > /var/logs/application.log\n\n# Create a .log.gz file with sample content\necho -e \"INFO: Started successfully\\nERROR: Failed to load module\\nDEBUG: Module retry\" | gzip > /var/logs/service.log.gz"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all .log and .log.gz files and search for \"ERROR\"\ntotal_errors=0\n\nfor file in $(find /var/logs -name \"*.log\" -o -name \"*.log.gz\"); do\n  if [[ $file == *.gz ]]; then\n    count=$(zgrep -c \"ERROR\" \"$file\")\n  else\n    count=$(grep -c \"ERROR\" \"$file\")\n  fi\n  \n  # Accumulate counts from each file\n  total_errors=$((total_errors + count))\ndone\n\n# Output the total number of errors found\necho $total_errors"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with the extension \".log\". Each log file records various system events with timestamps. Your task is to count how many unique IP addresses accessed the system on the date \"2023-10-01\". Assume that each line in the log files follows the format: \"[YYYY-MM-DD HH:MM:SS] IP_ADDRESS ACTION\". You need to find and count unique occurrences of IP addresses for that specific date across all log files.",
        "explanation": "To solve this problem, you should first navigate to the \"logs\" directory. Use tools like `grep` or `awk` to filter out lines corresponding to the date \"2023-10-01\". Then, extract the IP address from each of these lines. After extraction, use `sort` and `uniq` commands to determine and count the number of unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep '2023-10-01' *.log | awk '{print $2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"[2023-10-01 12:00:00] 192.168.1.1 LOGIN\" > ~/logs/access1.log\necho \"[2023-10-01 12:05:00] 192.168.1.2 LOGOUT\" >> ~/logs/access1.log\necho \"[2023-09-30 11:59:59] 192.168.1.1 LOGIN\" > ~/logs/access2.log\necho \"[2023-10-01 13:15:00] 192.168.1.3 LOGIN\" >> ~/logs/access2.log\necho \"[2023-10-01 14:20:00] 192.168.1.4 LOGOUT\" >> ~/logs/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep '2023-10-01' *.log | awk '{print $2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"project_files\" in your home directory, containing various text files. Your task is to identify the three most frequent words across all these files, ignoring case sensitivity and excluding common English stop words like \"the\", \"is\", \"at\", etc. Output the three words sorted by frequency in descending order, each on a new line.",
        "explanation": "To solve this problem, you need to read the content of all text files in the \"project_files\" directory. You can use utilities like `cat` to concatenate file contents and `tr` to transform text (such as converting everything to lowercase). To exclude stop words, you can use `grep` with pattern matching or `awk`. Finally, use `sort`, `uniq`, and other utilities like `head` to count word frequencies and determine the top three most frequent words.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/project_files/*.txt | \ntr '[:upper:]' '[:lower:]' | \ntr -c '[:alnum:]' '[\\n*]' | \ngrep -vE \"^$|^(the|is|at|and|a|to|in)$\" | \nsort | \nuniq -c | \nsort -nr | \nhead -3 | \nawk '{print $2}'\n```",
        "create": {
            "init": "mkdir -p ~/project_files\necho -e \"The quick brown fox jumps over the lazy dog.\\nThe fox is quick and fast.\" > ~/project_files/file1.txt\necho -e \"At noon, the sun is high.\\nThe dog barks at the sun.\" > ~/project_files/file2.txt\necho -e \"Is it sunny today?\\nYes, it is very sunny.\" > ~/project_files/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "cat ~/project_files/*.txt | \ntr '[:upper:]' '[:lower:]' | \ntr -c '[:alnum:]' '[\\n*]' | \ngrep -vE \"^$|^(the|is|at|and|a|to|in)$\" | \nsort | \nuniq -c | \nsort -nr | \nhead -3 | \nawk '{print $2}'"
        }
    },
    {
        "description": "In your home directory, there are multiple subdirectories each representing a different project. Each project directory contains various types of files including text files, image files, and executable scripts. You need to count the total number of executable files (files with execute permissions) across all project directories within your home directory.",
        "explanation": "To solve this problem, you can use the `find` command to search for files with execute permissions in all subdirectories of your home directory. The `-perm` option can be used to filter for executable files. Finally, you can pipe the output to `wc -l` to count the number of matching files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all executable files in all subdirectories of the home directory and count them.\nfind ~ -type f -executable | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create sample directories and files in the user's home directory\nmkdir -p ~/project1 ~/project2 ~/project3\n\n# Create some executable and non-executable files\ntouch ~/project1/script.sh\nchmod +x ~/project1/script.sh\ntouch ~/project1/readme.txt\n\ntouch ~/project2/run.py\nchmod +x ~/project2/run.py\ntouch ~/project2/info.txt\n\ntouch ~/project3/execute.rb\nchmod +x ~/project3/execute.rb\ntouch ~/project3/details.docx\n\n# Additional non-executable file for complexity\ntouch ~/project3/non_exec_file.c"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all executable files in all subdirectories of the home directory and count them.\nfind ~ -type f -executable | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory, which contains multiple log files with the \".log\" extension. Each log file records various events, and each event is timestamped in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique dates are present across all log files in this directory and output the count. Assume that no other files exist in this directory.",
        "explanation": "To solve this problem, you need to use a combination of bash utilities to read the contents of each log file, extract the date portion from each timestamp, and then determine the number of unique dates. Useful commands for this task could include `cat` for reading files, `awk` or `cut` for extracting date information from timestamps, `sort` for sorting data, and `uniq` for identifying unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 Event A\\n2023-10-01 13:30:00 Event B\\n2023-10-02 09:45:00 Event C\" > ~/logs/log1.log\necho -e \"2023-10-02 11:00:00 Event D\\n2023-10-03 14:25:00 Event E\" > ~/logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total size of all files with a \".log\" extension in the \"/var/logs\" directory and its subdirectories. The result should be presented in a human-readable format (e.g., KB, MB).",
        "explanation": "To solve this problem, you can use the \"find\" command to locate all files with the \".log\" extension within the specified directory and its subdirectories. Once these files are identified, you can use the \"du\" command to calculate their sizes. Finally, sum these sizes and convert them into a human-readable format using appropriate options.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files in /var/logs and calculate their total size in human-readable format.\nfind /var/logs -type f -name \"*.log\" -exec du -ch {} + | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "# Create /var/logs directory and some sample log files\nmkdir -p /var/logs/subdir1 /var/logs/subdir2\necho \"Sample log content 1\" > /var/logs/system.log\necho \"Sample log content 2\" > /var/logs/subdir1/application.log\necho \"Sample log content 3\" > /var/logs/subdir2/user.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "# Find all .log files in /var/logs and calculate their total size in human-readable format.\nfind /var/logs -type f -name \"*.log\" -exec du -ch {} + | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "In your home directory, you will find a subdirectory named `projects`. This directory contains multiple subdirectories, each representing a different project. Each project directory contains several files, including text files with a `.txt` extension and binary files with no extension. Your task is to count the total number of lines across all `.txt` files within all subdirectories of the `projects` directory. Ignore any hidden files (those starting with a dot).",
        "explanation": "To solve this problem, you need to navigate to the `projects` directory and recursively search for `.txt` files in its subdirectories. You can use tools like `find` to locate all `.txt` files and then use `xargs` or a loop with `wc -l` to count the lines in each file. Sum up these line counts to get the total number of lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/projects -type f -name '*.txt' | xargs wc -l | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "mkdir -p ~/projects/project1\nmkdir -p ~/projects/project2\necho \"Hello World\" > ~/projects/project1/file1.txt\necho -e \"Line 1\\nLine 2\\nLine 3\" > ~/projects/project1/file2.txt\ndd if=/dev/urandom bs=1024 count=10 of=~/projects/project1/binaryfile\necho \"This is a test file.\" > ~/projects/project2/file3.txt\necho -e \"Another line\\nYet another line\" > ~/projects/project2/file4.txt\ndd if=/dev/urandom bs=512 count=5 of=~/projects/project2/anotherbinaryfile"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/projects -type f -name '*.txt' | xargs wc -l | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory that contains multiple log files with the extension \".log\". Each log file contains timestamped entries. Your task is to find the total number of unique IP addresses recorded across all log files. Assume each IP address is on a separate line in the format \"IP_ADDRESS - TIMESTAMP\".",
        "explanation": "To solve this problem, you need to combine the content of all \".log\" files in the \"logs\" directory, extract all unique IP addresses, and then count them. You can use utilities like `cat`, `grep`, `awk`, `sort`, and `uniq` to accomplish this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 - 2023-10-01 12:00\\n192.168.1.2 - 2023-10-01 12:05\\n192.168.1.1 - 2023-10-01 12:10\" > ~/logs/log1.log\necho -e \"192.168.1.3 - 2023-10-02 13:00\\n192.168.1.2 - 2023-10-02 13:05\\n192.168.1.4 - 2023-10-02 13:10\" > ~/logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"data_files\" in your home directory that contains multiple text files with random data. Each file has some lines starting with the word \"ERROR\". Your task is to find out how many unique ERROR codes exist across all these files. ERROR codes are numeric values that appear immediately after the word \"ERROR\".",
        "explanation": "To solve this problem, you need to iterate through each file in the \"data_files\" directory, extract lines that start with \"ERROR\", and then extract the numeric code following it. Once you have all the codes, you should find the unique ones and count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h \"^ERROR\" ~/data_files/* | awk '{print $2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/data_files\necho -e \"INFO 123\\nERROR 404\\nWARNING 302\\nERROR 500\" > ~/data_files/file1.txt\necho -e \"DEBUG 100\\nERROR 404\\nINFO 200\" > ~/data_files/file2.txt\necho -e \"NOTICE 111\\nERROR 500\\nERROR 503\" > ~/data_files/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h \"^ERROR\" ~/data_files/* | awk '{print $2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory, which contains multiple text files with server log entries. Each log entry consists of a timestamp, severity level (INFO, WARN, ERROR), and a message. Your task is to count how many ERROR entries occurred on the last day present in these logs and output just that number.",
        "explanation": "To solve this problem, you need to:\n1. Identify all files in the \"logfiles\" directory.\n2. Find the latest date present in any of the log files.\n3. Extract entries from that date and filter out those with the severity level ERROR.\n4. Count these ERROR entries and output the result.\n\nHints:\n- Use `grep` or `awk` to filter lines based on patterns.\n- Use `sort` or `date` utilities to determine the latest date.\n- Ensure you handle multiple files by aggregating data across them.\n\nYou can use this command pattern to perform the task:\n\n```bash\nlatest_date=$(cat ~/logfiles/*.txt | awk '{print $1}' | sort | tail -n1)\nerror_count=$(grep \"$latest_date\" ~/logfiles/*.txt | grep 'ERROR' | wc -l)\necho $error_count\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-10-01 12:00:00 INFO Server started\\n2023-10-01 14:23:45 ERROR Disk full\\n2023-10-02 09:15:00 WARN Low memory\\n2023-10-02 11:30:22 INFO User login\\n2023-10-03 08:45:30 ERROR Connection lost\" > ~/logfiles/log1.txt\necho -e \"2023-10-03 09:30:00 INFO Service restarted\\n2023-10-03 12:00:00 ERROR CPU overload\\n2023-10-04 13:05:25 WARN High temperature\\n2023-10-04 14:20:45 ERROR Network failure\" > ~/logfiles/log2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "latest_date=$(cat ~/logfiles/*.txt | awk '{print $1}' | sort | tail -n1)\nerror_count=$(grep \"$latest_date\" ~/logfiles/*.txt | grep 'ERROR' | wc -l)\necho $error_count"
        }
    },
    {
        "description": "You have been provided with a directory named `log_files` containing multiple `.log` files. Each log file contains various entries, some of which are error messages starting with the string \"ERROR\". Your task is to count the total number of error messages across all log files in the `log_files` directory. You may assume that each line in a file contains only one entry.",
        "explanation": "To solve this problem, you need to iterate through each `.log` file in the `log_files` directory and count lines that start with \"ERROR\". You can use utilities like `grep` to filter these lines and `wc -l` to count them efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"^ERROR\" log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p log_files\necho -e \"INFO: Initialization complete\\nERROR: Failed to load module\\nINFO: User logged in\" > log_files/system.log\necho -e \"ERROR: Disk full\\nERROR: Network timeout\" > log_files/network.log\necho -e \"INFO: Application started\\nERROR: Out of memory\" > log_files/application.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"^ERROR\" log_files/*.log | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your current working directory. This directory contains multiple log files with the extension \".log\". Each log file consists of timestamped entries in the format \"YYYY-MM-DD HH:MM:SS Message\". Your task is to determine the total number of unique dates across all log files within the \"logs\" directory. You should interact directly with the shell to compute this value.",
        "explanation": "To solve this problem, you need to extract the date part from each entry in all log files, then find and count the unique dates. You can achieve this by using tools like `awk` to parse out dates, `sort` to order them, and `uniq` to filter out duplicates. Finally, use `wc -l` to count the number of unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{print $1}' logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p logs\necho -e \"2023-10-01 12:00:00 System started\\n2023-10-01 12:30:00 Connection established\\n2023-10-02 09:45:00 User login\" > logs/log1.log\necho -e \"2023-10-02 10:15:00 File uploaded\\n2023-10-03 14:55:00 Error occurred\" > logs/log2.log\necho -e \"2023-10-03 16:25:00 System check\\n2023-10-04 11:05:00 User logout\" > logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{print $1}' logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a file named \"system_logs.txt\" which contains various system log entries in the format \"[YYYY-MM-DD HH:MM:SS] [log_level] message\". Your task is to count how many log entries have the log level \"ERROR\" and occurred in the month of October 2023. Use command-line tools to achieve this.",
        "explanation": "To solve this problem, you need to filter out log entries with the log level \"ERROR\" and check if their timestamp falls within October 2023. You can use tools like `grep` to search for specific text patterns, `awk` or `sed` to parse and process lines, and `wc -l` to count the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"\\[2023\\-10.*\\[ERROR\\]\" ~/system_logs.txt | wc -l\n```",
        "create": {
            "init": "cat <<EOL > ~/system_logs.txt\n[2023-10-01 12:00:00] [INFO] System booted successfully.\n[2023-10-02 09:15:45] [ERROR] Failed to load module x.\n[2023-09-30 23:59:59] [ERROR] Disk write error.\n[2023-10-10 16:23:14] [WARNING] High memory usage detected.\n[2023-10-15 08:45:42] [ERROR] Network connection lost.\n[2023-11-01 00:00:01] [INFO] New month started.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"\\[2023\\-10.*\\[ERROR\\]\" ~/system_logs.txt | wc -l"
        }
    },
    {
        "description": "In the current directory, there is a file named `server_logs.txt` which contains log entries of server access attempts, with each line containing an IP address followed by a timestamp. Your task is to identify and count the number of unique IP addresses that attempted to access the server more than 5 times within a single day. Output just the count of such IP addresses.",
        "explanation": "To solve this problem, you need to parse the log file and process each line to extract the IP address and its corresponding date from the timestamp. Then, track how many times each IP appears on any particular day. Finally, count how many unique IP addresses have more than 5 attempts in a day.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{split($2, datetime, \"T\"); ip_date[$1\" \"datetime[1]]++} END {for (entry in ip_date) {split(entry, parts, \" \"); if (ip_date[entry] > 5) unique_ips[parts[1]]++} print length(unique_ips)}' server_logs.txt\n```",
        "create": {
            "init": "cat > server_logs.txt <<EOL\n192.168.1.1 2023-10-01T09:00:00\n192.168.1.2 2023-10-01T10:15:23\n192.168.1.1 2023-10-01T11:30:45\n192.168.1.3 2023-10-02T12:45:56\n192.168.1.2 2023-10-02T14:00:00\n192.168.1.1 2023-10-02T15:30:22\n192.168.1.2 2023-10-01T16:45:33\n192.168.1.4 2023-10-03T17:00:44\n192.168.1.2 2023-10-01T18:15:55\n192.168.1.5 2023-10-03T19:30:06\n192.168.*.* (additional entries for diverse testing)\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{split($2, datetime, \"T\"); ip_date[$1\" \"datetime[1]]++} END {for (entry in ip_date) {split(entry, parts, \" \"); if (ip_date[entry] > 5) unique_ips[parts[1]]++} print length(unique_ips)}' server_logs.txt"
        }
    },
    {
        "description": "You need to count the total number of lines across all text files (with a .txt extension) in your home directory that contain the word \"Linux\" (case-insensitive).",
        "explanation": "To solve this problem, you can use the `grep` command with the `-i` option to search for \"Linux\" in a case-insensitive manner. Use `find` to locate all .txt files in your home directory and then pipe this to `xargs` to apply the grep command. Finally, use `wc -l` to count the total number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find and count lines containing 'Linux' in all txt files in home directory\nfind ~ -name \"*.txt\" | xargs grep -i 'Linux' | wc -l\n```",
        "create": {
            "init": "# Create some test text files in the student's home directory\necho -e \"This is a Linux tutorial.\\nAnother line.\" > ~/file1.txt\necho -e \"linux is open source.\\nLearning Linux.\" > ~/file2.txt\necho -e \"No mention here.\" > ~/file3.txt\necho -e \"LINUX is powerful.\\nYet another line about Linux.\" > ~/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find and count lines containing 'Linux' in all txt files in home directory\nfind ~ -name \"*.txt\" | xargs grep -i 'Linux' | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" within your home directory, which contains multiple log files. Each log file is named in the format `YYYY-MM-DD.log` and contains lines of text representing system events. Your task is to identify the most common word across all log files in this directory that is longer than five characters. Ignore case while counting words.",
        "explanation": "To solve this problem, you need to read all the files within the \"logs\" directory, extract words longer than five characters from each file, convert them to lowercase for uniformity, and then count their occurrences. Finally, determine which word appears most frequently across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -ohr '\\b\\w\\{6,\\}\\b' ~/logs | tr '[:upper:]' '[:lower:]' | sort | uniq -c | sort -nr | head -n 1 | awk '{print $2}'\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat > ~/logs/2023-10-01.log <<EOL\nSystem booted successfully.\nUser login detected.\nNetwork connection established.\nEOL\n\ncat > ~/logs/2023-10-02.log <<EOL\nApplication error occurred.\nUser login failed.\nDatabase connection error.\nEOL\n\ncat > ~/logs/2023-10-03.log <<EOL\nScheduled backup completed successfully.\nUser logout detected.\nNetwork disconnection observed.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "grep -ohr '\\b\\w\\{6,\\}\\b' ~/logs | tr '[:upper:]' '[:lower:]' | sort | uniq -c | sort -nr | head -n 1 | awk '{print $2}'"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"project_data\" containing several text files. Your task is to find out the total number of unique lines across all these text files. You should ignore case sensitivity when comparing the lines. Provide the total count as your answer.",
        "explanation": "To solve this problem, you need to iterate through each file in the \"project_data\" directory and extract all lines. Then, use a method to store these lines while ignoring case sensitivity, ensuring that duplicates are not counted more than once. Finally, calculate the total number of unique lines and provide that number as your answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/project_data/* | tr '[:upper:]' '[:lower:]' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_data\necho -e \"Hello World\\nhello universe\\nLinux\\nShell Script\" > ~/project_data/file1.txt\necho -e \"HELLO WORLD\\nlinux\\nshell script\\nPython\" > ~/project_data/file2.txt\necho -e \"python\\nJavaScript\\njava script\\nHELLO UNIVERSE\" > ~/project_data/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/project_data/* | tr '[:upper:]' '[:lower:]' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains lines with timestamps followed by messages. Your task is to find out how many unique error messages (case-sensitive) appear across all log files. An error message is defined as any line that starts with the string \"ERROR\". You should count only the unique error messages, not their occurrences.",
        "explanation": "To solve this problem, you need to search through all files in the \"log_files\" directory for lines that start with \"ERROR\". Extract these lines and keep track of only the unique ones. Use tools like `grep` to filter out lines starting with \"ERROR\", and `sort` and `uniq` to identify unique messages. Finally, count these using tools like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all unique error messages across all .log files in 'log_files' directory.\ngrep '^ERROR' ~/log_files/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create the directory and sample log files\nmkdir -p ~/log_files\n\n# Create sample log files with ERROR messages\ncat <<EOL > ~/log_files/system1.log\n2023-10-01 10:00:00 INFO Starting system check\n2023-10-01 10:05:00 ERROR Disk space low on /dev/sda1\n2023-10-01 10:15:00 WARNING High memory usage detected\n2023-10-01 11:00:00 ERROR Disk space low on /dev/sda1\nEOL\n\ncat <<EOL > ~/log_files/system2.log\n2023-10-02 09:00:00 INFO System boot complete\n2023-10-02 09:30:00 ERROR Network unreachable on interface eth0\n2023-10-02 09:45:00 ERROR Disk space low on /dev/sda1\nEOL\n\ncat <<EOL > ~/log_files/system3.log\n2023-10-03 12:20:00 INFO Scheduled backup started\n2023-10-03 12:45:00 ERROR Failed to mount NFS share on /mnt/share1 \nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all unique error messages across all .log files in 'log_files' directory.\ngrep '^ERROR' ~/log_files/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing multiple text files with various server log entries. Each log entry is on a new line and starts with a timestamp followed by the log message. Your task is to find out how many unique IP addresses have accessed the server, across all log files in the \"logs\" directory. Assume each IP address is in standard IPv4 format.",
        "explanation": "To solve this problem, you can use tools like `grep` to extract lines containing potential IP addresses from each file, then use `sed` or `awk` to isolate the IP address itself. After gathering all potential IP addresses, you can use `sort` and `uniq` commands to filter out duplicates and count the number of unique entries. Remember that each line may not necessarily contain an IP address, so be careful when extracting them.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract all lines with potential IPs from all files in logs directory \ngrep -hoE '([0-9]{1,3}\\.){3}[0-9]{1,3}' logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir logs\necho -e \"2023-10-01 10:00:00 192.168.0.1 User login\\n2023-10-01 11:00:00 192.168.0.2 User login\\n2023-10-01 12:00:00 192.168.0.1 File uploaded\" > logs/server1.log\necho -e \"2023-10-02 09:30:00 192.168.0.3 User logout\\n2023-10-02 09:45:00 192.168.0.2 File downloaded\\n2023-10-02 10:15:00 192.168.0.4 User login\" > logs/server2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract all lines with potential IPs from all files in logs directory \ngrep -hoE '([0-9]{1,3}\\.){3}[0-9]{1,3}' logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named `logs` containing various `.log` files that represent server logs. Each log file has entries formatted as \"YYYY-MM-DD HH:MM:SS ErrorMessage\". Your task is to count the total number of error entries across all log files that occurred in the month of January 2023.",
        "explanation": "To solve this problem, you need to iterate through each `.log` file in the `logs` directory and filter out lines corresponding to errors that occurred in January 2023. You can achieve this by using tools like `grep` to search for lines starting with \"2023-01\", which represents January 2023, and then counting these lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^2023-01' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/server1.log\n2023-01-05 12:00:00 Error connecting to database\n2023-02-14 09:15:32 User login failed\n2023-01-20 18:45:12 File not found error\nEOL\n\ncat <<EOL > ~/logs/server2.log\n2022-12-31 23:59:59 Service timeout error\n2023-01-10 04:22:11 Disk quota exceeded\n2023-03-01 07:30:45 Connection reset by peer\nEOL\n\ncat <<EOL > ~/logs/server3.log\n2023-01-15 11:17:29 Out of memory error\n2022-11-25 16:40:50 Network unreachable error\nEOL\n\n# Feel free to add more sample log files if needed."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^2023-01' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "In the current directory, there are multiple text files with varying extensions, including \".log\", \".txt\", and \".data\". You need to count the total number of lines that contain the word \"error\" (case insensitive) across all \".log\" files. Ensure you only consider lines from files directly in the current directory and not from any subdirectories.",
        "explanation": "To solve this problem, you need to use a combination of bash commands. First, list all files with the \".log\" extension in the current directory using `ls` or `find`. Then, use `grep` with the `-i` flag for case-insensitive search to filter lines containing \"error\" within these files. Finally, count the number of matching lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all .log files in the current directory and search for 'error', counting occurrences.\ngrep -i 'error' *.log 2>/dev/null | wc -l\n```",
        "create": {
            "init": "# Create some sample .log files with varying content\necho -e \"This is an error line\\nAnother line\\nError occurred here\" > file1.log\necho -e \"No issues here\\nYet another error line\\nFinal error entry\" > file2.log\necho -e \"All good here\\nNo errors in this log file\" > file3.log\n\n# Create other types of files which should not be considered\necho -e \"This should not be counted as it is a .txt file\\nerror again\" > file4.txt\necho -e \"Some data entries\\nAnother error might be here but it's a .data file\" > file5.data\n\n# Create a subdirectory with a log file which should not be considered\nmkdir logs_subdir\necho -e \"Subdirectory log with an error line\\nShould not be counted\" > logs_subdir/file6.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# List all .log files in the current directory and search for 'error', counting occurrences.\ngrep -i 'error' *.log 2>/dev/null | wc -l"
        }
    },
    {
        "description": "Count the number of unique words across all text files in the current directory that start with a vowel (a, e, i, o, u) and have more than 5 characters. Ignore case sensitivity when counting.",
        "explanation": "To solve this problem, you need to iterate through all text files in the current directory. For each file, extract words that start with a vowel and have more than 5 characters. Convert these words to lowercase to handle case insensitivity and then find unique occurrences across all files. Finally, count these unique words.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Read the contents of each text file in the current directory\ncat *.txt | \n# Extract words starting with vowels and having more than 5 characters\ngrep -o -E '\\b([aeiouAEIOU][a-zA-Z]{5,})\\b' | \n# Convert them to lowercase for case insensitive comparison\ntr '[:upper:]' '[:lower:]' | \n# Get unique words only\nsort | uniq | \n# Count them\nwc -l\n```",
        "create": {
            "init": "# Create sample text files for students to work with\necho \"Elephant is an enormous animal.\" > file1.txt\necho \"Umbrella protects us from rain.\" > file2.txt\necho \"Education is essential.\" > file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Read the contents of each text file in the current directory\ncat *.txt | \n# Extract words starting with vowels and having more than 5 characters\ngrep -o -E '\\b([aeiouAEIOU][a-zA-Z]{5,})\\b' | \n# Convert them to lowercase for case insensitive comparison\ntr '[:upper:]' '[:lower:]' | \n# Get unique words only\nsort | uniq | \n# Count them\nwc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" that contains multiple log files with the \".log\" extension. Each log file contains lines of text with timestamps and messages. Your task is to find the total number of unique IP addresses that appear in all these log files combined. Assume each line in a log file is formatted as \"YYYY-MM-DD HH:MM:SS [IP_ADDRESS] Message\". You should output only the count of unique IP addresses.",
        "explanation": "To solve this problem, you need to read through all the \".log\" files in the \"logfiles\" directory, extract the IP addresses from each line, and then determine how many unique IP addresses there are across all files. You can use tools like `grep` or `awk` to extract the IP addresses and `sort` combined with `uniq` to filter out duplicates.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -hoE '\\[([0-9]{1,3}\\.){3}[0-9]{1,3}\\]' logfiles/*.log | sed 's/\\[//g;s/\\]//g' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p logfiles\necho -e \"2023-10-01 12:00:00 [192.168.0.1] User logged in\\n2023-10-01 12:05:00 [192.168.0.2] User logged out\" > logfiles/access1.log\necho -e \"2023-10-01 13:00:00 [192.168.0.1] User logged in\\n2023-10-01 13:15:00 [192.168.0.3] File uploaded\" > logfiles/access2.log\necho -e \"2023-10-02 14:00:00 [192.168.0.4] Error occurred\\n2023-10-02 14:30:00 [192.168.0.5] Connection established\" > logfiles/access3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -hoE '\\[([0-9]{1,3}\\.){3}[0-9]{1,3}\\]' logfiles/*.log | sed 's/\\[//g;s/\\]//g' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files. Each file contains lines of text with timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to count how many unique dates are present across all the log files combined. Assume that the log files contain entries spanning multiple years.",
        "explanation": "To solve this problem, you need to extract the date part from each line in the log files, which is the first 10 characters of each line. You can use tools like `awk`, `cut`, or `sed` to achieve this. After extracting the dates, you should sort them and use `uniq` to count the number of unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extracting dates and counting unique ones\ncat ~/logs/*.txt | cut -d ' ' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a logs directory in home\nmkdir -p ~/logs\n\n# Create sample log files with timestamps\necho -e \"2023-01-01 12:00:00 Entry 1\\n2023-01-02 13:10:00 Entry 2\\n2023-01-01 14:30:00 Entry 3\" > ~/logs/log1.txt\necho -e \"2023-02-15 09:45:00 Entry A\\n2022-12-31 23:59:59 Entry B\\n2023-01-02 10:15:00 Entry C\" > ~/logs/log2.txt\necho -e \"2021-06-20 08:30:00 Checkpoint X\\n2022-07-21 16:40:55 Checkpoint Y\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extracting dates and counting unique ones\ncat ~/logs/*.txt | cut -d ' ' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory, which contains multiple log files with the \".log\" extension. Each log file contains lines of text, and some lines include the word \"ERROR\". Your task is to count the total number of lines across all these log files that contain the word \"ERROR\", ignoring case sensitivity.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and search for all \".log\" files. You can use tools like `grep` with the `-i` flag to perform a case-insensitive search for lines containing \"ERROR\". Then, use `wc -l` to count the number of matching lines across all files. Summing up these counts will give you the total number of error occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'ERROR' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"This is a test line\\nERROR: Something went wrong\\nAnother line\" > ~/logs/app1.log\necho -e \"Error occurred here\\nRandom text\\nerror: critical failure\" > ~/logs/app2.log\necho -e \"Nothing wrong here\\nYet another line\\nERROR detected again\" > ~/logs/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'ERROR' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing various log files with the \".log\" extension. Each log file contains lines of text, and some lines start with the keyword \"ERROR\". Your task is to count the total number of unique error messages across all log files, where uniqueness is determined by the entire line content following \"ERROR\". Provide this count.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"log_files\" directory.\n2. Use a command to extract lines starting with \"ERROR\" from each \".log\" file.\n3. Remove the \"ERROR\" prefix and consider only the message that follows for uniqueness.\n4. Aggregate all unique messages across all files and count them.\n\nHints: You might find utilities like `grep`, `sed`, `awk`, `sort`, and `uniq` helpful to accomplish these tasks.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/log_files\ngrep \"^ERROR\" *.log | sed 's/^.*: ERROR //' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"INFO Starting process\\nERROR Disk not found\\nWARNING Low memory\\nERROR Disk not found\" > ~/log_files/system.log\necho -e \"INFO User logged in\\nERROR Network timeout\\nERROR Disk not found\\nINFO User logged out\" > ~/log_files/network.log\necho -e \"ERROR Network timeout\\nINFO Backup complete\\nWARNING High CPU usage\" > ~/log_files/backup.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/log_files\ngrep \"^ERROR\" *.log | sed 's/^.*: ERROR //' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines containing the word \"error\" (case-insensitive) across all `.log` files in the `/var/logs/student` directory, and return the count.",
        "explanation": "You should navigate to the `/var/logs/student` directory and use tools like `grep` to search for occurrences of the word \"error\" in a case-insensitive manner within all `.log` files. You can then use `wc -l` to count the number of matching lines. Consider using a combination of commands such as `grep`, `cat`, and pipes to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' /var/logs/student/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs/student\necho -e \"This is an error log.\\nNo issues found here.\" > /var/logs/student/system1.log\necho -e \"ERROR: User not found.\\nConnection established.\" > /var/logs/student/system2.log\necho -e \"Everything is running smoothly.\" > /var/logs/student/notes.txt\necho -e \"Critical ERROR detected.\\nError: Disk space low.\" > /var/logs/student/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' /var/logs/student/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, you will find a directory named \"logs\" containing multiple log files with the \".log\" extension. Each log file contains various system messages, each starting with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to determine which day had the most system messages logged across all these files. You need to provide the date in the format \"YYYY-MM-DD\".",
        "explanation": "To solve this problem, you need to aggregate all log entries across multiple files and then count how many entries occurred on each day. By sorting these counts, you can identify which day had the highest number of messages. Useful commands might include `cat`, `grep`, `awk`, `sort`, and `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-03-01 12:00:01 Message A\\n2023-03-01 12:05:02 Message B\\n2023-03-02 13:00:01 Message C\" > ~/logs/server1.log\necho -e \"2023-03-02 14:00:05 Message D\\n2023-03-01 15:10:06 Message E\\n2023-03-03 16:20:07 Message F\" > ~/logs/server2.log\necho -e \"2023-03-02 17:30:08 Message G\\n2023-03-01 18:40:09 Message H\\n2023-03-04 19:50:10 Message I\" > ~/logs/server3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory, which contains multiple log files with an extension \".log\". Each log file contains timestamps and event messages. Your task is to find out how many unique dates are present across all the log files. Assume each line in a log file starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\".",
        "explanation": "To solve this problem, you need to extract the date part from each line of all the log files, collect these dates, and then determine the number of unique dates. You can use utilities like `cut` to extract dates, `sort` to organize them, `uniq` to filter out duplicates, and `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logfiles/*.log | cut -d' ' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-01-01 12:00:00 Event1\\n2023-01-02 13:15:22 Event2\\n2023-01-01 14:30:45 Event3\" > ~/logfiles/log1.log\necho -e \"2023-01-03 09:10:11 Event4\\n2023-01-02 16:40:00 Event5\" > ~/logfiles/log2.log\necho -e \"2023-01-04 08:30:55 Event6\\n2023-01-03 17:50:33 Event7\" > ~/logfiles/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logfiles/*.log | cut -d' ' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains timestamps, error messages, and some informational messages. Your task is to determine how many unique dates have error messages across all the log files. Consider lines containing the word \"ERROR\" as error messages, and each line starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". You should output only the number of unique dates.",
        "explanation": "To solve this problem, you need to iterate through each \".log\" file in the \"logs\" directory, extract lines containing the word \"ERROR\", then parse out the date from these lines. Collect all unique dates and count them. A combination of utilities like `grep`, `awk`, `cut`, `sort`, and `uniq` can be used to accomplish this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR' ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 INFO Some informational message\\n2023-10-01 13:00:00 ERROR An error occurred\\n2023-10-02 14:00:00 ERROR Another error occurred\\n2023-10-02 15:30:00 INFO Another informational message\" > ~/logs/log1.log\necho -e \"2023-10-02 09:20:00 INFO Starting process\\n2023-10-03 11:45:00 ERROR An unexpected error\\n2023-10-03 12:50:00 ERROR Yet another error occurred\\n2023-10-04 08:30:00 INFO Process finished successfully\" > ~/logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR' ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden folder named `.backup` containing various types of files. Your task is to find the total number of lines of code (LOC) present in all `.py` Python files within this `.backup` directory. You should ignore any commented lines (lines starting with `#`) and empty lines while counting.",
        "explanation": "To solve this problem, you need to navigate to the hidden `.backup` directory in your home folder and list all the Python files using appropriate bash utilities. Then, for each file, filter out any commented or empty lines and count the remaining lines. Tools like `find`, `grep`, and `wc` will be helpful here.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/backup/.backup\nfind . -name \"*.py\" -exec grep -v '^\\s*#' {} \\; | grep -v '^\\s*$' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/backup/.backup\necho -e \"import os\\n\\n# This is a comment\\n\\ndef hello_world():\\n    print('Hello World')\" > ~/backup/.backup/script1.py\necho -e \"# Another comment\\n\\nx = 10\\nprint(x)\" > ~/backup/.backup/script2.py\necho -e \"\\n# Comment line\\ny = 20 # Inline comment\" > ~/backup/.backup/script3.py"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/backup/.backup\nfind . -name \"*.py\" -exec grep -v '^\\s*#' {} \\; | grep -v '^\\s*$' | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, containing multiple subdirectories and files. Each file represents a log file with lines that may include the word \"ERROR\". Your task is to count the total number of lines across all files in the \"logs\" directory that contain the word \"ERROR\", without considering case sensitivity. You need to perform this task directly from the shell.",
        "explanation": "To solve this problem, you need to search through all files within the \"logs\" directory and its subdirectories for lines containing the word \"ERROR\", regardless of case. Use tools like `grep` with appropriate options to perform a case-insensitive search and count the matching lines. The `find` command can be helpful in traversing directories recursively.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Using grep and find to count lines with 'ERROR' irrespective of case sensitivity.\nfind ~/logs -type f -exec grep -i 'ERROR' {} + | wc -l\n```",
        "create": {
            "init": "# Create a sample logs directory with some files\nmkdir -p ~/logs/subdir1\nmkdir -p ~/logs/subdir2\n\n# Create sample log files\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nWARNING: High memory usage\" > ~/logs/log1.txt\necho -e \"DEBUG: Starting process\\nerror: Network disconnected\\nINFO: Process completed\" > ~/logs/log2.txt\necho -e \"WARNING: CPU load high\\nerror: Failure detected\\nINFO: System check passed\" > ~/logs/subdir1/log3.txt\necho -e \"info: Checking logs\\nERROR: Unauthorized access attempt\\ndebugging information\" > ~/logs/subdir2/log4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Using grep and find to count lines with 'ERROR' irrespective of case sensitivity.\nfind ~/logs -type f -exec grep -i 'ERROR' {} + | wc -l"
        }
    },
    {
        "description": "Count the total number of lines of code (including comments and blank lines) in all Python files (.py) within the \"projects\" directory, excluding any files in subdirectories named \"test\". You need to ensure that the count is accurate even if there are symbolic links pointing to Python files.",
        "explanation": "To solve this problem, you need to traverse through the \"projects\" directory and identify all Python files. Use a combination of `find` command with appropriate options to filter out unwanted directories like \"test\" and follow symbolic links when necessary. Then, use tools like `wc -l` to count the lines of each identified file and sum them up for the total count.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind projects -type f -name \"*.py\" ! -path \"*/test/*\" -exec wc -l {} + | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "mkdir -p projects/{module1,module2,test}\necho -e \"#!/usr/bin/env python3\\n# Sample script\\nprint('Hello World')\" > projects/module1/sample.py\necho -e \"\\n\\ndef add(a, b):\\n    return a + b\" > projects/module2/calculations.py\nln -s module2/calculations.py projects/module1/calc_link.py\necho -e \"# Test script\\n# should be ignored by find\\nprint('This is a test')\" > projects/test/test_script.py"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find projects -type f -name \"*.py\" ! -path \"*/test/*\" -exec wc -l {} + | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" containing multiple text files with server logs. Each log entry in these files has the format \"timestamp: error_level: message\". Your task is to count how many entries have an error level of \"ERROR\" across all the files in this directory and provide the total count.",
        "explanation": "To solve this problem, you need to iterate over each file in the \"logfiles\" directory and search for lines containing the string \"ERROR\". You can use tools like `grep` to filter these lines and `wc -l` to count them. Finally, sum up the counts from all files to get the total number of \"ERROR\" entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' logfiles | wc -l\n```",
        "create": {
            "init": "mkdir -p logfiles\necho -e \"2023-01-01 10:00:00: INFO: System started\\n2023-01-01 10:05:00: ERROR: Failed to connect\\n2023-01-01 10:10:00: WARNING: Low disk space\" > logfiles/server1.log\necho -e \"2023-01-02 11:00:00: ERROR: Out of memory\\n2023-01-02 11:05:00: INFO: Process completed\\n2023-01-02 11:10:00: ERROR: Disk failure detected\" > logfiles/server2.log\necho -e \"2023-01-03 12:00:00: INFO Updated configuration\\n2023-01-03 12::05::00 ERROR Service unavailable\" > logfiles/server3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' logfiles | wc -l"
        }
    },
    {
        "description": "You are given a directory named `log_files` containing multiple log files with various extensions. Your task is to count the total number of lines that contain the word \"ERROR\" (case-sensitive) across all `.log` files in this directory and provide the result as an integer.",
        "explanation": "To solve this problem, you should iterate through all `.log` files in the `log_files` directory and search for lines containing the word \"ERROR\". You can use utilities like `grep` to filter these lines and then count them using `wc -l`. Summing up these counts will give you the total number of lines with \"ERROR\".\n\nYou can use this command pattern to perform the task:\n\n```bash\ntotal_lines_with_error=$(grep -r 'ERROR' --include='*.log' ./log_files | wc -l)\necho $total_lines_with_error\n```",
        "create": {
            "init": "mkdir -p log_files\necho \"This is a test log file.\" > log_files/test1.log\necho \"ERROR: Something went wrong.\" >> log_files/test1.log\necho \"All systems operational.\" >> log_files/test1.log\necho \"Another error occurred: ERROR 404.\" >> log_files/test1.log\n\necho \"Logging starts here.\" > log_files/test2.txt\necho \"ERROR: Disk full warning.\" >> log_files/test2.txt\n\necho \"New session started.\" > log_files/session.log\necho \"No issues found.\" >> log_files/session.log\necho \"ERROR detected in module X.\" >> log_files/session.log\n\ntouch log_files/empty_file.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "total_lines_with_error=$(grep -r 'ERROR' --include='*.log' ./log_files | wc -l)\necho $total_lines_with_error"
        }
    },
    {
        "description": "You are given a directory named \"server_logs\" in your home directory, which contains multiple log files with the extension \".log\". Each log file records server access logs in the traditional Apache format. Your task is to determine how many unique IP addresses have accessed the server based on these logs. You should ignore any lines that do not contain a valid IP address. Provide your answer as an integer.",
        "explanation": "To solve this problem, you need to extract the IP addresses from each log file in the \"server_logs\" directory and count the unique occurrences. You can use tools like `grep` to find lines containing valid IP addresses, `awk` or `sed` to extract those IPs, and then `sort` and `uniq` to count distinct ones. Ensure that you only consider valid IPv4 addresses which consist of four sets of numbers separated by periods.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the server_logs directory.\ncd ~/server_logs\n\n# Extract all unique IP addresses from each log file.\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' *.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/server_logs\necho '192.168.1.1 - - [01/Apr/2023:12:00:00 +0000] \"GET /index.html HTTP/1.1\" 200 532' > ~/server_logs/access1.log\necho '10.0.0.2 - - [01/Apr/2023:12:05:00 +0000] \"POST /submit HTTP/1.1\" 404 123' >> ~/server_logs/access1.log\necho 'Invalid log line without an IP address' >> ~/server_logs/access1.log\necho '172.16.0.3 - - [01/Apr/2023:12:10:00 +0000] \"GET /home HTTP/1.0\" 200 1024' > ~/server_logs/access2.log\necho '192.168.1.1 - - [01/Apr/2023:12:15:00 +0000] \"GET /about HTTP/1.0\" 200 2048' >> ~/server_logs/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to the server_logs directory.\ncd ~/server_logs\n\n# Extract all unique IP addresses from each log file.\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' *.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden directory named `.logs` containing multiple log files with the `.log` extension. Each log file contains several lines of text, where each line indicates an event with a timestamp in the format `YYYY-MM-DD HH:MM:SS`. Count how many unique dates (in `YYYY-MM-DD` format) appear across all the log files in this directory. You need to ensure that only non-empty lines are considered.",
        "explanation": "To solve this problem, you should first list all the `.log` files within the hidden `.logs` directory in your home directory. Then, extract and count unique dates from each line of these files using tools such as `grep`, `awk`, or `sed`. Use commands like `sort` and `uniq` to filter out duplicate dates and count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/.logs -type f -name \"*.log\" | xargs cat | grep -oP '^\\d{4}-\\d{2}-\\d{2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/\".logs\"\necho -e \"2023-01-01 12:00:00 Event1\\n2023-01-02 13:00:00 Event2\" > ~/.logs/log1.log\necho -e \"2023-01-02 14:00:00 Event3\\n2023-01-03 15:00:00 Event4\" > ~/.logs/log2.log\necho -e \"\\n2023-01-04 16:00:00 Event5\" > ~/.logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/.logs -type f -name \"*.log\" | xargs cat | grep -oP '^\\d{4}-\\d{2}-\\d{2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named `logs` in your home directory, which contains multiple log files with various extensions. Count how many unique IP addresses have accessed the server according to these log files. Only consider log files with the `.log` extension.",
        "explanation": "To solve this problem, you need to iterate through all files in the `logs` directory that have a `.log` extension. You can use tools like `grep`, `awk`, or `sed` to extract IP addresses from these files. After extracting the IPs, use utilities like `sort` and `uniq` to filter out duplicate entries and count the number of unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | grep -oP '(\\d{1,3}\\.){3}\\d{1,3}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 - - [01/Jan/2023] \\\"GET /index.html HTTP/1.0\\\" 200 2326\\n192.168.1.2 - - [01/Jan/2023] \\\"POST /form HTTP/1.0\\\" 404 342\" > ~/logs/access1.log\necho -e \"192.168.1.1 - - [01/Jan/2023] \\\"GET /home.html HTTP/1.0\\\" 200 1234\\n10.0.0.5 - - [01/Jan/2023] \\\"GET /about.html HTTP/1.0\\\" 200 1337\" > ~/logs/access2.log\necho -e \"172.16.0.3 - - [02/Jan/2023] \\\"GET /contact.html HTTP/1.0\\\" 404 452\\n10.0.0.5 - - [02/Jan/2023] \\\"GET /privacy.html HTTP/1.0\\\" 500 564\" > ~/logs/access3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | grep -oP '(\\d{1,3}\\.){3}\\d{1,3}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" located in your home directory. Inside this directory, there are multiple log files with the \".log\" extension. Some of these files may be empty or contain only whitespace. Your task is to determine how many non-empty log files exist in the \"log_files\" directory. A file is considered non-empty if it contains any characters other than whitespace.",
        "explanation": "To solve this problem, you need to list all the files with a \".log\" extension in the \"log_files\" directory and count how many of them are non-empty. You can use commands like `find` to locate the files, `wc` to check for non-zero content, and `grep` or `awk` to filter out whitespace-only content.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/log_files -type f -name \"*.log\" -exec grep -q '[^[:space:]]' {} \\; -print | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho \"Error: Something went wrong.\" > ~/log_files/error1.log\ntouch ~/log_files/empty.log\necho \"\" > ~/log_files/whitespace.log\necho \"Info: Process started successfully.\" > ~/log_files/info.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/log_files -type f -name \"*.log\" -exec grep -q '[^[:space:]]' {} \\; -print | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_logs\" containing multiple text files. Each file logs the activities and errors of different projects, with each line starting with a timestamp in the format `[YYYY-MM-DD HH:MM:SS]`. Your task is to determine how many unique days have logged activities across all files in this directory. Note that only lines containing timestamps should be considered.",
        "explanation": "To solve this problem, you need to extract the date component from each line's timestamp across all files in the \"project_logs\" directory. You should then collect these dates into a set to ensure uniqueness and finally count the number of unique dates. This involves using bash utilities like `grep`, `awk`, or `cut` to extract dates, and `sort` combined with `uniq` to ensure they are unique.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -hoP '\\[\\d{4}-\\d{2}-\\d{2}' project_logs/*.txt | cut -c 2- | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p project_logs\necho \"[2023-10-01 12:00:00] Started process A\" > project_logs/log1.txt\necho \"[2023-10-01 13:15:45] Error on process B\" >> project_logs/log1.txt\necho \"[2023-10-02 09:30:00] Completed task C\" > project_logs/log2.txt\necho \"[2023-10-02 16:50:00] Error on task D\" >> project_logs/log2.txt\necho \"[2023-10-03 11:22:33] Started job E\" > project_logs/log3.txt\necho \"[2023-10-03 14:40:55] Finished job F\" >> project_logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -hoP '\\[\\d{4}-\\d{2}-\\d{2}' project_logs/*.txt | cut -c 2- | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple text files with server log entries. Each log entry is on a new line, and contains a timestamp followed by a space and an event message. Your task is to count how many times the word \"ERROR\" appears as an event message across all these files. Assume that the word \"ERROR\" is case-sensitive.",
        "explanation": "To solve this problem, you need to search through each file in the \"log_files\" directory, identifying lines where the event message is exactly \"ERROR\". You can use tools like `grep` to filter out matching lines and then count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"^.* ERROR$\" ~/log_files | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-01-01 10:00:00 ERROR\\n2023-01-01 10:05:00 OK\\n2023-01-01 10:10:00 ERROR\" > ~/log_files/log1.txt\necho -e \"2023-01-02 11:00:00 OK\\n2023-01-02 11:05:00 WARNING\\n2023-01-02 11:10:00 ERROR\" > ~/log_files/log2.txt\necho -e \"2023-01-03 12:00:00 ERROR\\n2023-01-03 12:05:00 OK\\n2023-01-03 12:10:00 INFO\" > ~/log_files/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"^.* ERROR$\" ~/log_files | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"data_files\" in your home directory, containing multiple text files with varying extensions. Count the number of unique words across all `.txt` files in this directory. A word is defined as any sequence of characters separated by whitespace or punctuation. Ignore case while counting unique words.",
        "explanation": "To solve this problem, you need to locate all `.txt` files within the \"data_files\" directory. Then, extract the words from these files, normalize them to lowercase to ensure case insensitivity, and use a mechanism (e.g., a set in Python or sort/uniq in bash) to identify and count the unique words.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/data_files -name \"*.txt\" -exec cat {} + | \\\ntr '[:upper:]' '[:lower:]' | tr -c '[:alnum:]' '[\\n*]' | \\\nsort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/data_files\necho \"Hello world! Welcome to the universe.\" > ~/data_files/file1.txt\necho \"The quick brown fox jumps over the lazy dog.\" > ~/data_files/file2.txt\necho \"HELLO again! The world is vast and full of wonders.\" > ~/data_files/file3.txt\necho \"In programming, hello world is often used as a first example.\" > ~/data_files/file4.doc"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/data_files -name \"*.txt\" -exec cat {} + | \\\ntr '[:upper:]' '[:lower:]' | tr -c '[:alnum:]' '[\\n*]' | \\\nsort | uniq | wc -l"
        }
    },
    {
        "description": "You have been given a directory called \"logfiles\" in your home directory, which contains several log files with the extension \".log\". Your task is to find out how many lines contain the word \"ERROR\" (case-sensitive) across all log files in this directory. You should not count lines from any subdirectories.",
        "explanation": "To solve this problem, you can use a combination of `grep`, `wc`, and other command-line utilities to search for the word \"ERROR\" in files within the specified directory. Be sure to restrict your search to files with the \".log\" extension and avoid counting entries from potential subdirectories.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\ngrep 'ERROR' ~/logfiles/*.log | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\nmkdir -p ~/logfiles\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nINFO: User logged in\" > ~/logfiles/system.log\necho -e \"INFO: Backup completed\\nERROR: Network unreachable\\nWARNING: High CPU usage\" > ~/logfiles/network.log\necho -e \"ERROR: Out of memory\\nINFO: New device detected\\nERROR: File not found\" > ~/logfiles/application.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\ngrep 'ERROR' ~/logfiles/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" located in your home directory, which contains multiple log files with extensions \".log\". Each log file contains lines of text, where each line starts with a timestamp followed by a message. Your task is to count the total number of error messages across all log files in this directory. An error message is defined as any line that contains the word \"ERROR\".",
        "explanation": "To solve this problem, you need to iterate over each \".log\" file in the \"log_files\" directory, read its contents, and count how many lines contain the word \"ERROR\". You can use tools like `grep` to search for lines containing \"ERROR\" and then use `wc -l` to count them. Summing up these counts from all files will give you the total number of error messages.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-01-01 12:00:00 INFO Startup complete\\n2023-01-01 12:05:00 ERROR Disk not found\\n2023-01-01 12:10:00 INFO Running smooth\" > ~/log_files/system1.log\necho -e \"2023-01-02 13:00:00 INFO Performing check\\n2023-01-02 13:05:00 ERROR Timeout occurred\\n2023-01-02 13:10:00 ERROR Connection lost\" > ~/log_files/system2.log\necho -e \"2023-01-03 14:00:00 INFO System update\\n2023-01-03 14:05:00 ERROR Memory leak detected\\n2023-01-03 14:10:00 INFO Update complete\" > ~/log_files/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory which contains multiple log files. Each log file records events with timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out the most recent event across all these log files and return its timestamp. Assume that each log file has a consistent format of one event per line.",
        "explanation": "To solve this problem, you need to iterate through all the files in the \"logs\" directory, read each line to extract timestamps, and then compare them to find the most recent one. You can use utilities like `find`, `xargs`, `awk`, and `sort` to efficiently parse and process these logs.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -exec cat {} + | awk '{print $1, $2}' | sort -r | head -n 1\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 14:23:45\\n2023-10-02 09:15:30\" > ~/logs/log1.txt\necho -e \"2023-09-30 22:50:00\\n2023-10-01 08:05:15\" > ~/logs/log2.txt\necho -e \"2023-10-01 18:45:00\\n2023-10-02 11:30:00\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "find ~/logs -type f -exec cat {} + | awk '{print $1, $2}' | sort -r | head -n 1"
        }
    },
    {
        "description": "You are tasked with analyzing disk usage in your home directory. Count the number of files that are larger than 1MB and were modified in the last 7 days. Your answer should be a single integer representing this count.",
        "explanation": "To solve this problem, you can use the `find` command to search for files that meet the specified criteria. The `-size` option will help you find files larger than 1MB, and the `-mtime` option allows you to filter files modified in the last 7 days. You can then use `wc -l` to count these files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to home directory as a starting point for simplicity\ncd ~\n\n# Find and count all files larger than 1MB and modified in the last 7 days within test_directory\nfind test_directory -type f -size +1M -mtime -7 | wc -l\n```",
        "create": {
            "init": "# Create sample files for testing\nmkdir -p ~/test_directory\ntouch ~/test_directory/file1.txt\ndd if=/dev/zero of=~/test_directory/file2.txt bs=1M count=2 # Create a file larger than 1MB\ntouch -d \"3 days ago\" ~/test_directory/file2.txt # Modify the timestamp to within last 7 days\ndd if=/dev/zero of=~/test_directory/file3.txt bs=512K count=1 # Create a file smaller than 1MB\ntouch -d \"10 days ago\" ~/test_directory/file3.txt # Modify timestamp to outside last 7 days"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to home directory as a starting point for simplicity\ncd ~\n\n# Find and count all files larger than 1MB and modified in the last 7 days within test_directory\nfind test_directory -type f -size +1M -mtime -7 | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.secret_data` containing a list of numbers, one per line. Your task is to find the sum of all unique numbers present in this file. Ensure that you ignore any duplicate entries and only consider unique numbers for the summation.",
        "explanation": "To solve this problem, you will need to read the contents of the `.secret_data` file and process it to remove duplicate numbers. Then, calculate the sum of these unique numbers. You can use utilities like `sort`, `uniq`, and `awk` or `paste` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Read the .secret_data file, sort and remove duplicates, then sum them up\nsum=$(sort -n ~/.secret_data | uniq | awk '{sum+=$1} END {print sum}')\necho $sum\n```",
        "create": {
            "init": "# Create a hidden file with random numbers including duplicates\necho -e \"23\\n42\\n15\\n23\\n8\\n42\\n9\" > ~/.secret_data"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Read the .secret_data file, sort and remove duplicates, then sum them up\nsum=$(sort -n ~/.secret_data | uniq | awk '{sum+=$1} END {print sum}')\necho $sum"
        }
    },
    {
        "description": "In your home directory, there are various text files with the extension `.log`. Count the total number of lines across all these `.log` files that contain the string \"ERROR\", ignoring case. You should not use any temporary files to store intermediate results.",
        "explanation": "To solve this problem, you can use a combination of `find`, `grep`, and other text processing utilities. First, use `find` to locate all `.log` files in your home directory. Then, utilize `grep` with the `-i` option to search for lines containing the word \"ERROR\" in a case-insensitive manner. Lastly, count the total number of matching lines using tools like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files and count the lines containing 'ERROR' (case-insensitive)\nfind ~ -name \"*.log\" -exec grep -i \"ERROR\" {} + | wc -l\n```",
        "create": {
            "init": "# Create some example .log files in the home directory\necho -e \"INFO: All systems go\\nERROR: Failed to start service\\nDEBUG: Verbose logging enabled\" > ~/example1.log\necho -e \"error: connection lost\\nINFO: Reconnecting\\nNOTICE: Connection re-established\" > ~/example2.log\necho -e \"WARNING: Low disk space\\nerror: Disk quota exceeded\\nINFO: Cleanup initiated\" > ~/example3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .log files and count the lines containing 'ERROR' (case-insensitive)\nfind ~ -name \"*.log\" -exec grep -i \"ERROR\" {} + | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named 'project_files' containing various text files. Your task is to find and count the number of lines across all files in this directory that contain the word \"Linux\" (case-sensitive). Additionally, only count lines from files that have a \".log\" extension. Present your answer as an integer representing the total line count.",
        "explanation": "To solve this problem, you need to navigate to the 'project_files' directory within your home directory. Use a combination of `find`, `grep`, and `wc` commands. First, use `find` to list all files with a \".log\" extension in the 'project_files' directory. Then, apply `grep` to search for lines containing the word \"Linux\" in those files. Finally, use `wc -l` to count these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all .log files and search for lines containing 'Linux', then count them.\nfind ~/project_files -type f -name \"*.log\" | xargs grep 'Linux' | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create project_files directory in home\nmkdir -p ~/project_files\n\n# Create example .log and other files\necho -e \"Linux is great\\nThis is a test\\nLinux kernel\\nHello Linux\" > ~/project_files/example1.log\necho -e \"No Linux here\\nJust some random text\" > ~/project_files/example2.log\necho -e \"Another file\\nWith more Linux mentions\\nLinux again here\" > ~/project_files/example3.log\necho -e \"This is not counted because it is not a log file.\" > ~/project_files/sample.txt\n\n# Additional log file for complexity\necho -e \"Yet another mention of Linux\\nAnd another Linux line\" > ~/project_files/complex.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all .log files and search for lines containing 'Linux', then count them.\nfind ~/project_files -type f -name \"*.log\" | xargs grep 'Linux' | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing log files from a web server to determine the total number of unique IP addresses that accessed the server on a specific date. The log files are located in the \"/var/log/apache2\" directory, and each file follows the naming pattern \"access.log.YYYY-MM-DD\". Assume today's date is 2023-11-01. You need to find out how many unique IP addresses accessed the server on October 31, 2023.",
        "explanation": "To solve this problem, first navigate to the \"/var/log/apache2\" directory. Use tools like `grep` to filter lines from \"access.log.2023-10-31\" for entries of that specific day. Then use `awk` or `cut` to extract IP addresses from these entries. Finally, use `sort` and `uniq` commands to count unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd /var/log/apache2\ngrep '^[[:digit:].]*' access.log.2023-10-31 | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n# Create the log directory if it doesn't exist\nmkdir -p /var/log/apache2\n\n# Generate a sample log file for October 31, 2023\ncat <<EOL > /var/log/apache2/access.log.2023-10-31\n192.168.1.1 - - [31/Oct/2023:12:00:00 +0000] \"GET /index.html HTTP/1.1\" 200 1043\n192.168.1.2 - - [31/Oct/2023:12:05:00 +0000] \"GET /about.html HTTP/1.1\" 200 2048\n192.168.1.1 - - [31/Oct/2023:12:10:00 +0000] \"GET /contact.html HTTP/1.1\" 200 512\n192.168.1.3 - - [31/Oct/2023:13:00:00 +0000] \"POST /submit-form HTTP/1.1\" 302 -\n192.168.1.4 - - [31/Oct/2023:14:20:00 +0000] \"GET /services.html HTTP/1.0\" 404 -\n192.168.1."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd /var/log/apache2\ngrep '^[[:digit:].]*' access.log.2023-10-31 | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"project_files\" in your home directory containing multiple text files. Each file contains lines of text, and some lines start with the word \"ERROR\". Count how many lines in total across all files in the \"project_files\" directory start with the word \"ERROR\".",
        "explanation": "To solve this problem, you need to navigate to the \"project_files\" directory and use a combination of shell utilities like `grep` to search for lines starting with \"ERROR\", and then `wc -l` to count these lines across all files. You may use wildcard characters to address multiple files at once.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^ERROR' ~/project_files/* | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_files\necho -e \"INFO: This is an info message\\nERROR: First error message\\nDEBUG: Debugging info\\nERROR: Second error detected\" > ~/project_files/file1.txt\necho -e \"WARNING: Be cautious\\nINFO: Another info line\\nERROR: Third error encountered\" > ~/project_files/file2.txt\necho -e \"ERROR: Fourth error found\\nNOTE: Just a note\\nERROR: Fifth error happens here\" > ~/project_files/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^ERROR' ~/project_files/* | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with the extension \".log\". Each log file contains lines of text, and each line starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to calculate how many unique dates (in the format \"YYYY-MM-DD\") are present across all these log files.",
        "explanation": "To solve this problem, you need to extract the date part from each line's timestamp in all \".log\" files within the \"logs\" directory. You can use tools like `cut`, `awk`, or `sed` to isolate the date portion. Once you have extracted all dates, use `sort` and `uniq` to find out how many unique dates there are. This will involve reading from multiple files and processing each line appropriately.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extracting dates from all .log files in the logs directory\ngrep -h '^[0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\}' ~/logs/*.log | cut -d' ' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 12:00:00 Log entry one\\n2023-01-01 13:00:00 Log entry two\\n2023-01-02 14:30:45 Log entry three\" > ~/logs/log1.log\necho -e \"2023-01-02 15:15:15 Another log entry\\n2023-01-03 16:45:30 Yet another log entry\" > ~/logs/log2.log\necho -e \"2023-01-03 17:20:50 More entries\\n2023-01-04 18:35:10 Final log entry\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extracting dates from all .log files in the logs directory\ngrep -h '^[0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\}' ~/logs/*.log | cut -d' ' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "In the current directory, you will find a set of text files named `file1.txt`, `file2.txt`, ..., up to `file10.txt`. Each file contains several lines of text. Your task is to determine how many unique words are present across all these files combined. Note that words are case-insensitive and should not include any punctuation.",
        "explanation": "To solve this problem, you need to read each file, extract words while ignoring punctuation and case differences, and then count the number of unique words across all files. You can use utilities like `tr` to handle punctuation, `tr` or `awk` for case conversion, and `sort` with `uniq` to find unique words.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat file*.txt | tr -d '[:punct:]' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create 10 text files with sample content\nfor i in {1..10}; do\n  echo \"This is a line in file $i. It has some common and some Unique Words!\" > \"file$i.txt\"\ndone"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat file*.txt | tr -d '[:punct:]' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"logs\" containing multiple log files with the extension \".log\". Each log file contains timestamped entries where each line begins with a date in the format YYYY-MM-DD. Your task is to find out which day has the highest number of log entries across all these files. Ensure you provide just the date as your final answer.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"logs\" directory in your home directory.\n2. Concatenate all \".log\" files to process them together.\n3. Extract only the dates from each line.\n4. Count occurrences of each date.\n5. Determine which date appears most frequently and output that date.\n\nHints:\n- Use `cat` or `find` and `xargs` to combine content from all log files.\n- Utilize tools like `awk`, `cut`, or `sed` to extract and manipulate data efficiently.\n- Consider using `sort` and `uniq -c` for counting entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ncat *.log | awk '{print $1}' | sort | uniq -c | sort -nr | head -n 1 | awk '{print $2}'\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 Entry one\\n2023-01-02 Entry two\\n2023-01-01 Entry three\" > ~/logs/log1.log\necho -e \"2023-01-03 Entry four\\n2023-01-02 Entry five\\n2023-01-02 Entry six\" > ~/logs/log2.log\necho -e \"2023-01-03 Entry seven\\n2023-01-03 Entry eight\\n2023-01-04 Entry nine\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "cd ~/logs\ncat *.log | awk '{print $1}' | sort | uniq -c | sort -nr | head -n 1 | awk '{print $2}'"
        }
    },
    {
        "description": "You are given a log file named `system.log` located in your home directory. Each line in this file represents a log entry with a timestamp, log level (INFO, WARNING, ERROR), and a message. Your task is to count the number of ERROR entries that occurred on the current date. Assume the timestamp format is \"YYYY-MM-DD HH:MM:SS\".",
        "explanation": "To solve this problem, you need to filter out lines from the `system.log` file that contain today's date and have the log level \"ERROR\". You can achieve this by using command-line tools such as `grep`, `awk`, or `sed`. First, extract today's date in \"YYYY-MM-DD\" format using the `date` command. Then, use `grep` to find lines with both today's date and \"ERROR\", and finally count those lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ntoday=$(date +%Y-%m-%d)\nerror_count=$(grep \"$today\" ~/system.log | grep -c \"ERROR\")\necho $error_count\n```",
        "create": {
            "init": "cat <<EOL > ~/system.log\n2023-10-20 08:00:01 INFO Starting system check\n2023-10-20 09:00:02 ERROR Disk space low\n2023-10-21 10:00:03 WARNING High memory usage\n2023-10-22 11:00:04 INFO System running smoothly\n2023-11-23 12:00:05 ERROR Network issue detected\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "today=$(date +%Y-%m-%d)\nerror_count=$(grep \"$today\" ~/system.log | grep -c \"ERROR\")\necho $error_count"
        }
    },
    {
        "description": "You have a directory named \"logfiles\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains various system events and timestamps. Your task is to count the total number of unique error messages (lines containing the keyword \"ERROR\") across all these log files. Ensure that your count considers only distinct error messages without any trailing or leading whitespace.",
        "explanation": "To solve this problem, you can utilize a combination of commands like `grep`, `sort`, and `uniq`. First, you need to find all lines containing the word \"ERROR\" from all \".log\" files. Then, sort these lines and use `uniq` to filter out duplicate error messages. Finally, count the number of unique lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR' ~/logfiles/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-10-01 10:00:00 INFO Starting system\\n2023-10-01 10:05:00 ERROR Disk full\\n2023-10-01 11:00:00 ERROR Disk full\" > ~/logfiles/system1.log\necho -e \"2023-10-02 12:00:00 INFO System check\\n2023-10-02 12:30:00 ERROR Network unavailable\\n2023-10-02 13:00:00 ERROR Disk full\" > ~/logfiles/system2.log\necho -e \"2023-10-03 14:15:00 INFO Backup complete\\n2023-10-03 15:40:00 ERROR Network unavailable\\n2023-10-03 16:20:00 ERROR Permission denied\" > ~/logfiles/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR' ~/logfiles/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory which contains various log files. Each log file has multiple lines, and each line begins with a timestamp followed by a message. Your task is to count how many unique dates are present in all the log files combined. Note that the date format in the logs is \"YYYY-MM-DD\".",
        "explanation": "To solve this problem, you need to extract the date part from each line of every log file within the \"log_files\" directory and then determine the number of unique dates. You can use tools like `grep`, `awk`, `sort`, and `uniq` to achieve this.\n\n1. Use `grep` or similar command to extract lines from all files.\n2. Use `awk` or another text processing tool to extract just the date portion (\"YYYY-MM-DD\") from each line.\n3. Use `sort` and `uniq` to find unique dates.\n4. Count these unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/log_files/* | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-10-01 Event A\\n2023-10-02 Event B\\n2023-10-01 Event C\" > ~/log_files/log1.txt\necho -e \"2023-10-03 Event D\\n2023-10-02 Event E\\n2023-10-04 Event F\" > ~/log_files/log2.txt\necho -e \"2023-10-01 Event G\\n2023-10-05 Event H\" > ~/log_files/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/log_files/* | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"log_files\" in your home directory, which contains multiple log files with varying extensions (e.g., .log, .txt, .err). Your task is to identify and count how many unique IP addresses have made requests according to these log files. Consider only the files with a \".log\" extension for this task.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"log_files\" directory.\n2. Use tools like `grep` or `awk` to extract IP addresses from files ending with \".log\".\n3. Utilize `sort` and `uniq` to filter out unique IP addresses.\n4. Finally, count the number of unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Navigate to the log_files directory\ncd ~/log_files\n\n# Extract and count unique IPs from .log files\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' *.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create the log_files directory\nmkdir -p ~/log_files\n\n# Create example log files with various extensions\necho -e \"192.168.1.1 - - [01/Jan/2021:10:00:00] \\\"GET /index.html HTTP/1.0\\\"\\n192.168.1.2 - - [01/Jan/2021:10:05:00] \\\"POST /form HTTP/1.0\\\"\\n192.168.1.3 - - [01/Jan/2021:10:15:00] \\\"GET /about.html HTTP/1.0\\\"\" > ~/log_files/access.log\n\necho -e \"192.168.2.4 error occurred\\n192.168.2.5 another error occurred\" > ~/log_files/error.txt\n\necho -e \"192.168.3.6 failed login attempt\\n192.168.3.7 successful login\" > ~/log_files/security.err\n\necho -e \"192.168.4.8 - [02/Jan/2021] \\\"GET /home.html\\\"\\n192-168-4-9 some random text\\ninvalid entry here\" > ~/log_files/misc.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Navigate to the log_files directory\ncd ~/log_files\n\n# Extract and count unique IPs from .log files\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' *.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines across all `.txt` files located in a directory named `data` within your home directory. Additionally, you need to identify which file has the highest number of lines and report its name along with the line count. Your answer should be formatted as \"filename: line_count\".",
        "explanation": "To solve this problem, navigate to the `data` directory in your home directory. Use bash commands to iterate over each `.txt` file, counting the lines using `wc -l`. Keep track of the total line count as well as which file has the most lines. You can use variables to store running totals and comparisons.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/data\ntotal_lines=0\nmax_lines=0\nmax_file=\"\"\nfor file in *.txt; do\n    line_count=$(wc -l < \"$file\")\n    total_lines=$((total_lines + line_count))\n    if [ \"$line_count\" -gt \"$max_lines\" ]; then\n        max_lines=$line_count\n        max_file=$file\n    fi\ndone\n\necho \"$max_file: $max_lines\"\n```",
        "create": {
            "init": "mkdir -p ~/data\necho \"Line 1\" > ~/data/file1.txt\necho -e \"Line 1\\nLine 2\\nLine 3\" > ~/data/file2.txt\necho -e \"Line 1\\nLine 2\" > ~/data/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "cd ~/data\ntotal_lines=0\nmax_lines=0\nmax_file=\"\"\nfor file in *.txt; do\n    line_count=$(wc -l < \"$file\")\n    total_lines=$((total_lines + line_count))\n    if [ \"$line_count\" -gt \"$max_lines\" ]; then\n        max_lines=$line_count\n        max_file=$file\n    fi\ndone\n\necho \"$max_file: $max_lines\""
        }
    },
    {
        "description": "You are given a directory called `project_files` in your home directory, which contains various text files. Your task is to find out the total number of lines that contain the word \"error\" (case-insensitive) across all these files. Provide just the total count as your answer.",
        "explanation": "To solve this problem, you should navigate to the `project_files` directory and use tools like `grep` to search for occurrences of the word \"error\" in each file. The `-i` option in grep will help with case insensitivity. The output should be piped to `wc -l` to count the number of matching lines across all files. Remember, you only need to provide the total count of lines containing \"error\", not any details about those lines or files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'error' ~/project_files/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_files\necho -e \"This is an error message.\\nNo issues here.\" > ~/project_files/file1.txt\necho \"Another line with Error\" > ~/project_files/file2.txt\necho -e \"Random text\\nCompletely fine\\nERROR at this point\" > ~/project_files/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'error' ~/project_files/*.txt | wc -l"
        }
    },
    {
        "description": "Find the total number of lines across all `.txt` files in your home directory that contain the word \"Linux\" (case-insensitive). Assume that your home directory contains a nested directory structure with multiple `.txt` files.",
        "explanation": "To solve this problem, you'll need to search through all `.txt` files within your home directory and its subdirectories. Use the `find` command to locate these files, and then use `grep` with appropriate flags to perform a case-insensitive search for the word \"Linux\". Finally, count the total number of matching lines using a suitable command like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -name \"*.txt\" -exec grep -i 'Linux' {} + | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/test_dir/sub_dir\necho \"Learning Linux is fun.\" > ~/test_dir/file1.txt\necho \"LINUX is versatile.\" > ~/test_dir/file2.txt\necho \"This file does not mention it.\" > ~/test_dir/file3.txt\necho \"Exploring linux commands.\" > ~/test_dir/sub_dir/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -name \"*.txt\" -exec grep -i 'Linux' {} + | wc -l"
        }
    },
    {
        "description": "You have a directory named `logs` in your home directory containing multiple log files with the `.log` extension. Each log file contains timestamps and various log messages. Your task is to find out how many unique IP addresses have accessed the system, given that each line of the log files follows the format: `[timestamp] [IP address] [message]`. Count the number of unique IP addresses across all log files.",
        "explanation": "To solve this problem, you need to aggregate all IP addresses from each line in all `.log` files within the `logs` directory. You can use tools like `cat`, `awk`, and `sort` in combination. First, concatenate all log files using `cat`, extract the IP address using `awk`, sort them uniquely with `sort -u`, and finally count them with `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $2}' | sort -u | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"[2023-10-01 00:00:01] 192.168.1.1 User login\" > ~/logs/access1.log\necho \"[2023-10-01 00:05:12] 192.168.1.2 File upload\" >> ~/logs/access1.log\necho \"[2023-10-01 00:10:34] 192.168.1.3 Page view\" >> ~/logs/access1.log\necho \"[2023-10-02 00:15:21] 192.168.1.2 File download\" > ~/logs/access2.log\necho \"[2023-10-02 00:20:45] 192.168.1.4 User logout\" >> ~/logs/access2.log\necho \"[2023-10-03 00:25:31] 192.168.1.5 Error report\" >> ~/logs/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $2}' | sort -u | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Each log file contains lines of text, and some lines contain the keyword \"ERROR\". Your task is to interactively find out how many lines across all these log files contain the keyword \"ERROR\". You should not use any temporary files for intermediate processing.",
        "explanation": "To solve this problem, you can use a combination of `grep` and `wc` commands. First, use `grep` to search for the keyword \"ERROR\" in all `.log` files within the \"logs\" directory. Then, pipe the output to `wc -l` to count the number of matching lines. This approach will directly give you the total count without creating any temporary files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"ERROR\" ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nINFO: User login successful\" > ~/logs/system.log\necho -e \"WARNING: High memory usage\\nERROR: Network unreachable\\nERROR: Failed login attempt\" > ~/logs/network.log\necho -e \"INFO: Backup completed\\nERROR: File not found\\nINFO: Shutdown initiated\" > ~/logs/backup.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"ERROR\" ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there are several text files with random numbers in their names (e.g., file1.txt, file20.txt, etc.). Your task is to count the total number of lines across all these text files that contain the word \"Linux\". You should filter out any empty lines before counting. Provide the total count as your answer.",
        "explanation": "To solve this problem, you need to list all the text files in your home directory. Then, for each file, read its contents and filter out any empty lines. Next, search for occurrences of the word \"Linux\" and count how many lines contain it across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script to count lines containing 'Linux'\ngrep -h 'Linux' ~/file*.txt | sed '/^$/d' | wc -l\n```",
        "create": {
            "init": "# Create some example text files in the student's home directory\necho -e \"This is a line about Linux\\nAnother line\\n\\nLinux rocks!\" > ~/file1.txt\necho -e \"Just a simple line\\nYet another one about Linux\" > ~/file2.txt\necho -e \"\\n\\nLinux is popular\\n\" > ~/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script to count lines containing 'Linux'\ngrep -h 'Linux' ~/file*.txt | sed '/^$/d' | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory containing multiple text files. Each file contains server log entries, where each entry is on a new line and consists of a timestamp followed by the log message. Your task is to find out how many unique IP addresses attempted to access the server across all log files in the \"logs\" directory. Assume that every log entry starts with an IP address.",
        "explanation": "To solve this problem, you need to iterate through all the files in the \"logs\" directory, extract the IP addresses from each line (since every log entry starts with an IP address), and then determine how many unique IP addresses there are across all these files. You can achieve this by using tools like `grep`, `awk` or `sed` to extract IP addresses and then use `sort` and `uniq` to count unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.txt | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 - Log entry 1\\n192.168.1.2 - Log entry 2\\n192.168.1.3 - Log entry 3\" > ~/logs/log1.txt\necho -e \"192.168.1.2 - Log entry 4\\n192.168.1.4 - Log entry 5\\n192.168.1.5 - Log entry 6\" > ~/logs/log2.txt\necho -e \"192.168.1.3 - Log entry 7\\n192.168.1.5 - Log entry 8\\n192.168.1.6 - Log entry 9\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.txt | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains timestamped entries of system events. Your task is to find out how many unique IP addresses accessed the system on September 15, 2023. Assume the IP addresses are in the format \"xxx.xxx.xxx.xxx\" and each entry is structured as \"[YYYY-MM-DD HH:MM:SS] Event Description - IP Address\".",
        "explanation": "To solve this problem, you'll need to filter out lines from all \".log\" files that correspond to September 15, 2023. Then, extract the IP addresses from these lines and count how many unique IP addresses there are.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^\\[2023\\-09\\-15' ~/logs/*.log | grep -oP '\\d{1,3}(\\.\\d{1,3}){3}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/system1.log\n[2023-09-14 10:00:01] Login Success - 192.168.0.1\n[2023-09-15 12:00:05] File Accessed - 10.0.0.2\n[2023-09-15 12:30:20] File Accessed - 192.168.0.3\nEOL\n\ncat <<EOL > ~/logs/system2.log\n[2023-09-13 11:25:45] System Boot - 172.16.0.5\n[2023-09-15 14:40:35] Unauthorized Access Attempt - 10.0.0.2\n[2023-09-15 16:50:00] User Logout - 192.168.1.4\nEOL\n\ncat <<EOL > ~/logs/system3.log\n[2023-09-15 08:15:55] Service Restarted - 192.168.1.4\n[2023-09-16 11:30:10] Login Failure - 172.16.0.5\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^\\[2023\\-09\\-15' ~/logs/*.log | grep -oP '\\d{1,3}(\\.\\d{1,3}){3}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"log_files\" in your home directory containing multiple log files with the extension \".log\". Your task is to identify and count how many unique IP addresses have made requests to the server as logged across all these files. Assume each log entry starts with an IP address.",
        "explanation": "To solve this problem, you need to parse through each \".log\" file in the \"log_files\" directory and extract the IP addresses from each line. Utilize tools like `grep` or `awk` to extract these IP addresses, and then use `sort` and `uniq` commands to filter out duplicate IPs. Finally, count the number of unique IPs using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/log_files/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"192.168.0.1 - - [10/Oct/2023:13:55:36 +0000] \\\"GET /index.html HTTP/1.1\\\" 200 1043\\n192.168.0.2 - - [10/Oct/2023:13:56:01 +0000] \\\"POST /form.html HTTP/1.1\\\" 404 523\\n192.168.0.1 - - [10/Oct/2023:13:57:59 +0000] \\\"GET /about.html HTTP/1.1\\\" 200 2048\" > ~/log_files/access.log\necho -e \"192.168.0.3 - - [10/Oct/2023:14:01:02 +0000] \\\"GET /contact.html HTTP/1.1\\\" 301 512\\n192.168.0.4 - - [10/Oct/2023:14:02:45 +0000] \\\"GET /home.html HTTP/1.1\\\" 200 1056\\n192.168.0.2 - - [10/Oct/2023:14:03:29 +0000] \\\"POST /login.html HTTP/1.1\\\" 500 423\" > ~/log_files/error.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/log_files/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" that contains several log files with various file extensions. Your task is to count the total number of lines across all files that have a \".log\" extension within this directory. Assume the \"logfiles\" directory is located in your home directory.",
        "explanation": "To solve this problem, you need to navigate to the \"logfiles\" directory and identify all files with the \".log\" extension. You can use tools like `find` to locate these files and then use `wc -l` to count the number of lines in each file. Finally, sum up the line counts from all matched files to obtain the total.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logfiles -type f -name \"*.log\" -exec wc -l {} + | awk '{s+=$1} END {print s}'\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"This is a test log file.\\nIt has multiple lines.\" > ~/logfiles/test1.log\necho -e \"Another log entry.\\nWith some extra information.\" > ~/logfiles/test2.log\necho -e \"Non-log content here.\" > ~/logfiles/readme.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logfiles -type f -name \"*.log\" -exec wc -l {} + | awk '{s+=$1} END {print s}'"
        }
    },
    {
        "description": "Determine the total number of lines across all `.txt` files in the `/home/student/documents` directory that contain the word \"Linux\", case-insensitive. You may assume there are multiple subdirectories within `/home/student/documents`.",
        "explanation": "To solve this problem, you need to search through all text files within `/home/student/documents` and its subdirectories. Use `grep` with the `-i` flag for a case-insensitive search to find lines containing the word \"Linux\". Then, sum up the line counts for each file. Piping commands can help with counting and summing.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /home/student/documents -type f -name \"*.txt\" | xargs grep -i 'Linux' | wc -l\n```",
        "create": {
            "init": "mkdir -p /home/student/documents/subdir1\nmkdir -p /home/student/documents/subdir2\n\necho -e \"This is a Linux tutorial.\\nAnother line.\" > /home/student/documents/file1.txt\necho -e \"Learning about linux systems.\\nOne more line here.\" > /home/student/documents/subdir1/file2.txt\necho -e \"Linux is great!\\nSomething else.\" > /home/student/documents/subdir2/file3.txt\necho \"No mention of it here.\" > /home/student/documents/not_included.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /home/student/documents -type f -name \"*.txt\" | xargs grep -i 'Linux' | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with a \".log\" extension. Each log file contains records of different server requests, and each record is on a new line. Your task is to find out how many unique IP addresses have made requests across all the log files combined. You should only consider lines that start with an IP address.",
        "explanation": "To solve this problem, you need to read through each \".log\" file in the \"logs\" directory, extract the IP address from each line (only if it starts with an IP address), and maintain a set of unique IP addresses. Finally, count the number of unique entries in this set.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -name \"*.log\" | xargs cat | awk '/^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+/ {print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.0.1 GET /index.html\\n192.168.0.2 POST /form\\n192.168.0.3 GET /about\\n192.168.0.1 GET /contact\" > ~/logs/server1.log\necho -e \"10.0.0.1 GET /home\\n192.168.0.2 GET /services\\n172.16.0.5 POST /login\\n10.0.0.1 GET /profile\" > ~/logs/server2.log\necho -e \"172.16.0 404 Error\\nInvalid Request\\n172 Invalid Entry\" > ~/logs/errors.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -name \"*.log\" | xargs cat | awk '/^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+/ {print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"log_files\" in your home directory. This directory contains multiple text files, each representing server logs with various timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to find out how many unique dates (in the format \"YYYY-MM-DD\") are present across all these log files.",
        "explanation": "To solve this problem, you need to extract the date portion from each timestamp in every file within the \"log_files\" directory. You can use tools like `grep` or `awk` to filter out the dates and then use `sort` and `uniq` to identify unique dates. The final count of these unique entries will give you the answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/log_files -type f -exec awk '{print $1}' {} + | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-01-01 12:00:00\\n2023-01-02 13:00:00\\n2023-01-01 14:00:00\" > ~/log_files/log1.txt\necho -e \"2023-02-01 15:30:00\\n2023-03-05 16:45:00\\n2023-02-01 17:50:00\" > ~/log_files/log2.txt\necho -e \"2023-04-10 18:20:00\\n2023-04-10 19:25:00\\n2023-01-02 20:30:00\" > ~/log_files/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/log_files -type f -exec awk '{print $1}' {} + | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory. Inside this directory, there are multiple log files with the extension \".log\". Each log file contains several lines, and each line starts with a date in the format YYYY-MM-DD. Your task is to calculate how many unique days are represented across all log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to extract the date from each line of every \".log\" file, then determine the unique dates. This can be done by iterating through each file, reading the first 10 characters of each line (which represent the date), and storing these dates in a set to automatically handle uniqueness. Finally, count the number of elements in this set to get the number of unique days.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -name \"*.log\" | xargs cat | cut -c 1-10 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-09-10 Log entry one\\n2023-09-11 Log entry two\" > ~/logs/log1.log\necho -e \"2023-09-12 Log entry three\\n2023-09-10 Log entry four\" > ~/logs/log2.log\necho -e \"2023-09-13 Log entry five\\n2023-09-12 Log entry six\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -name \"*.log\" | xargs cat | cut -c 1-10 | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with the \".log\" extension. Each log file records various system activities, and some lines contain the keyword \"ERROR\". Your task is to count the total number of lines containing the keyword \"ERROR\" across all log files within this directory.",
        "explanation": "To solve this problem, you need to iterate over each \".log\" file in the \"logs\" directory and search for lines that contain the keyword \"ERROR\". You can use tools like `grep` with appropriate options to count occurrences. Summing up these counts will give you the total number of error lines across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: System started\\nERROR: Disk not found\\nINFO: Update completed\" > ~/logs/system1.log\necho -e \"WARNING: Low memory\\nERROR: Network timeout\\nERROR: Unauthorized access\" > ~/logs/system2.log\necho -e \"INFO: User login\\nINFO: File saved\\nERROR: Failed to save settings\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You need to find and count the number of files in your home directory that were modified in the last 7 days and have a size greater than 1MB. Provide only the total count of such files.",
        "explanation": "To solve this problem, you can use the `find` command to search for files within your home directory. The `-mtime` option will help you filter files modified in the last 7 days, while `-size` will allow you to specify those larger than 1MB. Combining these options along with other necessary flags, you can count qualifying files using a subsequent command like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# No initialization is required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_logs\" located in your home directory. This directory contains various log files with the extension \".log\". Your task is to count how many unique IP addresses have made requests, assuming each line in the log file starts with an IP address. You need to consider all \".log\" files within this directory.",
        "explanation": "To solve this problem, you will need to iterate over each \".log\" file in the \"project_logs\" directory and extract unique IP addresses. You can use tools like `grep` or `awk` to extract IP addresses from each line, and then use `sort` and `uniq` to find unique ones. Finally, count these unique IP addresses using a command like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/project_logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"192.168.1.1 Request 1\\n192.168.1.2 Request 2\\n192.168.1.1 Request 3\" > ~/project_logs/log1.log\necho -e \"10.0.0.1 Request 4\\n192.168.1.2 Request 5\\n10.0.0.2 Request 6\" > ~/project_logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/project_logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with the \".log\" extension. Each log file records server access logs with lines of text containing timestamps and status codes (e.g., \"2023-10-21 10:45:32 - 200 OK\"). Your task is to count how many times the status code \"404\" appears across all these log files. Provide this count as your answer.",
        "explanation": "To solve this problem, you will need to use a combination of shell utilities such as `grep`, `find`, and `wc`. First, locate all log files in the \"logs\" directory using `find`. Then, use `grep` to search for lines containing the status code \"404\". Finally, use `wc -l` to count the number of matching lines across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -name \"*.log\" | xargs grep '404' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"2023-10-21 10:45:32 - 200 OK\" > ~/logs/access1.log\necho \"2023-10-21 11:00:00 - 404 Not Found\" >> ~/logs/access1.log\necho \"2023-10-21 11:05:12 - 500 Internal Server Error\" >> ~/logs/access1.log\necho \"2023-10-21 12:15:45 - 404 Not Found\" > ~/logs/access2.log\necho \"2023-10-21 13:30:23 - 200 OK\" >> ~/logs/access2.log\necho \"2023-10-21 14:22:08 - 404 Not Found\" >> ~/logs/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -name \"*.log\" | xargs grep '404' | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" located in your home directory. This directory contains multiple log files with random names. Your task is to count how many unique IP addresses appear across all the log files in the \"logs\" directory. Assume that each line in a log file contains one IP address.",
        "explanation": "To solve this problem, you need to iterate over each log file within the \"logs\" directory and extract IP addresses from each line. You can use tools like `cat`, `awk`, `sort`, and `uniq` to process the files. Specifically, you can concatenate all files, extract the IPs, sort them, and then count unique entries. The key is to ensure that you handle potential duplicates by sorting and using `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/* | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.0.1\\n10.0.0.2\\n192.168.0.1\" > ~/logs/log1.txt\necho -e \"172.16.0.3\\n10.0.0.2\\n172.16.0.3\" > ~/logs/log2.txt\necho -e \"192.168.1.4\\n10.0.5.6\\n192.168.1.4\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/* | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains lines of text, where each line starts with a timestamp in the format \"[YYYY-MM-DD HH:MM:SS]\". Your task is to identify and count the total number of unique dates (in YYYY-MM-DD format) across all log files in this directory. Ignore any lines that do not start with a timestamp.",
        "explanation": "To solve this problem, you should first navigate to the \"log_files\" directory. Then, you can use tools like `grep` or `awk` to extract the lines starting with timestamps. From these lines, parse out the date portion (YYYY-MM-DD) and store them uniquely using `sort` and `uniq`. Finally, count these unique dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/log_files\n\n# Extract lines with timestamps and get unique dates\ngrep -hEo '^\\[[0-9]{4}-[0-9]{2}-[0-9]{2}' *.log | sed 's/^\\[\\(.*\\)/\\1/' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create the 'log_files' directory\nmkdir -p ~/log_files\n\n# Create sample log files with timestamps\necho -e \"[2023-10-01 12:00:00] Log entry 1\\n[2023-10-02 14:23:11] Log entry 2\\nSome irrelevant line\\n[2023-10-01 15:45:30] Log entry 3\" > ~/log_files/log1.log\necho -e \"[2023-10-03 16:20:05] Log entry A\\nAnother irrelevant line\\n[2023-10-02 18:30:00] Log entry B\\n[2023-10-03 20:00:00] Log entry C\" > ~/log_files/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/log_files\n\n# Extract lines with timestamps and get unique dates\ngrep -hEo '^\\[[0-9]{4}-[0-9]{2}-[0-9]{2}' *.log | sed 's/^\\[\\(.*\\)/\\1/' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there are several log files with the \".log\" extension. Each log file contains lines with different severity levels: \"INFO\", \"WARNING\", and \"ERROR\". Count the total number of lines across all log files that contain the severity level \"ERROR\".",
        "explanation": "To solve this problem, you need to search through all files ending with \".log\" in your home directory. You can use `grep` to filter lines containing \"ERROR\" and `wc -l` to count them. The task involves using a combination of command-line tools to complete.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Count the number of lines with ERROR in all .log files in the home directory\ngrep -r 'ERROR' ~/*.log | wc -l\n```",
        "create": {
            "init": "# Create sample log files in the home directory\necho -e \"INFO: This is an info message\\nERROR: This is an error message\\nWARNING: This is a warning message\" > ~/log1.log\necho -e \"ERROR: Another error occurred\\nINFO: Another info message\" > ~/log2.log\necho -e \"WARNING: Yet another warning\\nERROR: Error again\\nERROR: And another error\" > ~/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Count the number of lines with ERROR in all .log files in the home directory\ngrep -r 'ERROR' ~/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_files\" in your home directory. This directory contains various files of different sizes and types. Your task is to determine the total disk space used by all the text files (files with .txt extension) in this directory, including those within any subdirectories. Consider only human-readable sizes for the output.",
        "explanation": "To solve this problem, you should navigate to the \"project_files\" directory and use commands that allow you to find and calculate the size of all .txt files recursively. A combination of `find`, `xargs`, and `du` commands will be useful here. The `find` command can help locate all .txt files, while `du -ch` can provide their cumulative size in a human-readable format.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Find all .txt files and calculate their total size in human-readable format\nfind ~/project_files -type f -name \"*.txt\" -print0 | xargs -0 du -ch | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create a project_files directory in the home directory\nmkdir -p ~/project_files/subdir1 ~/project_files/subdir2\n\n# Create some text files with varying sizes\necho \"Hello World\" > ~/project_files/file1.txt\ndd if=/dev/zero of=~/project_files/file2.txt bs=1024 count=10  # 10KB file\n\necho \"Sample text\" > ~/project_files/subdir1/file3.txt\ndd if=/dev/zero of=~/project_files/subdir1/file4.txt bs=1024 count=5  # 5KB file\n\ntouch ~/project_files/subdir2/file5.doc  # non-txt file"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Find all .txt files and calculate their total size in human-readable format\nfind ~/project_files -type f -name \"*.txt\" -print0 | xargs -0 du -ch | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"logs\" containing multiple log files with the extension \".log\". Your task is to find out the total number of lines across all these log files that contain the word \"ERROR\". Use command-line utilities to achieve this.",
        "explanation": "To solve this problem, you will need to use several command-line tools. Start by listing all the \".log\" files in the \"logs\" directory using a pattern match. Then, use `grep` to search for lines containing the word \"ERROR\" in each file. Finally, count these lines using `wc -l` and sum up the counts from all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -rh 'ERROR' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: Everything is fine\\nERROR: An error occurred\\nINFO: Another info line\" > ~/logs/log1.log\necho -e \"ERROR: Something went wrong\\nERROR: Critical failure\\nINFO: Some info\" > ~/logs/log2.log\necho -e \"DEBUG: This is a debug message\\nINFO: Normal operation\\nERROR: Error found here too\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -rh 'ERROR' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all text files within the directory `/home/student/docs` that contain the word \"Linux\". The count should be case-insensitive and include only `.txt` files. Ensure to handle the situation where some files might be empty or do not contain the word \"Linux\" at all.",
        "explanation": "To solve this problem, you need to search through all `.txt` files in the specified directory for occurrences of the word \"Linux\", regardless of case. You can use `grep` with appropriate flags to search for \"Linux\" in a case-insensitive manner and count the matching lines. Sum up all these counts from each file to get your final answer. Consider using `find` to locate `.txt` files and combine it with `xargs` to apply `grep`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use find with grep to search for 'linux' in a case insensitive way and count lines.\nfind /home/student/docs -name \"*.txt\" | xargs grep -i 'linux' | wc -l\n```",
        "create": {
            "init": "# Create directory structure and example files\nmkdir -p /home/student/docs\n\n# Create sample text files\necho -e \"This is an introduction to Linux.\\nLinux is a powerful OS.\" > /home/student/docs/intro.txt\necho -e \"Many servers run on linux.\\nUnderstanding Linux is crucial.\" > /home/student/docs/server.txt\necho -e \"\" > /home/student/docs/empty.txt\necho -e \"This file does not mention it.\" > /home/student/docs/unrelated.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use find with grep to search for 'linux' in a case insensitive way and count lines.\nfind /home/student/docs -name \"*.txt\" | xargs grep -i 'linux' | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.logfile` that contains timestamps of various events, one per line, in the format `YYYY-MM-DD HH:MM:SS`. Your task is to count how many events happened in the year 2022 and provide that number.",
        "explanation": "To solve this problem, you need to filter out lines from the `.logfile` that contain timestamps from the year 2022. You can use utilities like `grep` to search for lines with \"2022\" and then use `wc -l` to count these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script to count events from the year 2022 in .logfile\n\n# Count lines containing '2022' in ~/.logfile and output the number only.\ngrep '2022' ~/.logfile | wc -l\n```",
        "create": {
            "init": "# Create a hidden .logfile in the user's home directory with sample data\ncat <<EOL > ~/.logfile\n2021-12-31 23:59:59\n2022-01-01 00:00:01\n2022-02-15 13:45:30\n2023-03-10 08:20:17\n2022-07-19 18:22:45\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script to count events from the year 2022 in .logfile\n\n# Count lines containing '2022' in ~/.logfile and output the number only.\ngrep '2022' ~/.logfile | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple subdirectories and files. Some of these files have the extension \".log\". Your task is to find the total size of all \".log\" files that contain the string \"ERROR\" at least once. Report the result as a human-readable size (e.g., KB, MB).",
        "explanation": "To solve this problem, you need to navigate through the \"logs\" directory and its subdirectories to identify all the \".log\" files. Use a combination of `grep` to search for the string \"ERROR\" within these files, and `du` or `find` with `xargs` and `stat` to calculate their sizes. Finally, sum up these sizes and convert them into a human-readable format using `du -h` or similar utilities.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files containing 'ERROR' and calculate their total size.\nfind ~/logs -type f -name \"*.log\" -exec grep -l \"ERROR\" {} \\; | xargs du -ch | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "# Create directories and example log files\nmkdir -p ~/logs/subdir1\nmkdir -p ~/logs/subdir2\n\n# Create some log files with varying content\necho \"INFO: Everything is running smoothly.\" > ~/logs/system1.log\necho \"ERROR: Failed to start service.\" > ~/logs/system2.log\necho \"INFO: Starting backup.\" > ~/logs/system3.log\n\n# Create more log files in subdirectories\necho \"ERROR: Disk space low.\" > ~/logs/subdir1/errors.log\necho \"WARNING: High memory usage.\" > ~/logs/subdir1/warnings.log\n\necho \"ERROR: Network timeout occurred.\" > ~/logs/subdir2/network.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "# Find all .log files containing 'ERROR' and calculate their total size.\nfind ~/logs -type f -name \"*.log\" -exec grep -l \"ERROR\" {} \\; | xargs du -ch | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "You have a directory called \"logs\" in your home directory containing multiple log files. Each log file has lines formatted as \"[timestamp] [log_level] [message]\". Your task is to count how many times the word \"ERROR\" appears in these log files. You should only consider lines where the log level is exactly \"ERROR\".",
        "explanation": "To solve this problem, you need to search through all files in the \"logs\" directory and filter out lines where the second field (log level) is \"ERROR\". Then, count how many such lines contain the word \"ERROR\". You can use tools like `grep`, `awk`, and `wc` to accomplish this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^\\[[^]]*\\]\\s*ERROR\\s.*\\bERROR\\b' ~/logs/* | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"[2023-10-01 12:00:00] INFO Starting process\" > ~/logs/log1.txt\necho \"[2023-10-01 12:05:00] ERROR Process failed\" >> ~/logs/log1.txt\necho \"[2023-10-01 12:10:00] ERROR Error occurred during execution\" >> ~/logs/log1.txt\necho \"[2023-10-01 12:15:00] WARN Low memory warning\" > ~/logs/log2.txt\necho \"[2023-10-01 12:20:00] ERROR Another error happened\" >> ~/logs/log2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^\\[[^]]*\\]\\s*ERROR\\s.*\\bERROR\\b' ~/logs/* | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory containing multiple .log files. Your task is to find out how many unique IP addresses have accessed the system, based on the contents of these log files. Assume each line in a log file represents an access entry and contains an IP address at the start of the line.",
        "explanation": "To solve this problem, you need to extract all the IP addresses from each .log file in the \"log_files\" directory, combine them into one list, and then determine how many unique IP addresses there are. You can use tools like `grep` or `awk` to extract IPs and `sort` with `uniq` to filter out duplicates.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/log_files/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho \"192.168.1.1 - Accessed resource 1\" > ~/log_files/access1.log\necho \"10.0.0.2 - Accessed resource 2\" >> ~/log_files/access1.log\necho \"192.168.1.1 - Accessed resource 3\" >> ~/log_files/access1.log\necho \"172.16.0.3 - Accessed resource 4\" > ~/log_files/access2.log\necho \"10.0.0.2 - Accessed resource 5\" >> ~/log_files/access2.log\necho \"192.168.1.4 - Accessed resource 6\" >> ~/log_files/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/log_files/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"data_logs\" in your home directory containing various log files with the \".log\" extension. Your task is to find the total number of unique IP addresses that have accessed the system, as recorded in these log files. Each log file contains multiple lines, and each line follows the format: \"IP_ADDRESS - TIMESTAMP - ACTION\". You need to count only unique IP addresses across all files in the \"data_logs\" directory.",
        "explanation": "To solve this problem, you need to extract IP addresses from each line of every \".log\" file in the \"data_logs\" directory, combine them into a single list, and then determine how many unique IP addresses exist. A good approach is to use tools like `grep` or `awk` to extract IPs, `sort` and `uniq` to find unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/data_logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/data_logs\necho -e \"192.168.1.1 - 2023-01-01 10:00:00 - LOGIN\\n192.168.1.2 - 2023-01-01 10:05:00 - LOGOUT\\n192.168.1.3 - 2023-01-01 11:00:00 - LOGIN\" > ~/data_logs/access1.log\necho -e \"192.168.1.2 - 2023-02-02 12:00:00 - LOGIN\\n192.168.1.4 - 2023-02-02 12:30:00 - LOGOUT\\n192.168.1.5 - 2023-02-03 14:20:00 - LOGIN\" > ~/data_logs/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/data_logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Each log file contains timestamped entries, one per line, in the format \"YYYY-MM-DD HH:MM:SS Message\". Your task is to find out which log file has the earliest timestamp entry and return the name of that file (along with its relative path from your home directory).",
        "explanation": "To solve this problem, you need to iterate through each log file in the \"logs\" directory and examine the first timestamped entry in each file. Compare these timestamps to determine which one is the earliest. You can make use of utilities like `find`, `head`, `awk`, and `sort` to extract and compare timestamps efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\nearliest_file=$(find ~/logs -name \"*.log\" | while read logfile; do head -1 \"$logfile\"; done | sort | head -1)\nmatching_file=$(grep \"$earliest_file\" ~/logs/*.log | cut -d':' -f1)\necho \"${matching_file#$HOME/}\"\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 System start\\n2023-10-01 12:05:00 User login\" > ~/logs/system.log\necho -e \"2023-09-30 08:00:00 Service restart\\n2023-09-30 08:10:00 Error reported\" > ~/logs/service.log\necho -e \"2023-10-02 09:00:00 Backup started\\n2023-10-02 09:30:00 Backup completed\" > ~/logs/backup.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "earliest_file=$(find ~/logs -name \"*.log\" | while read logfile; do head -1 \"$logfile\"; done | sort | head -1)\nmatching_file=$(grep \"$earliest_file\" ~/logs/*.log | cut -d':' -f1)\necho \"${matching_file#$HOME/}\""
        }
    },
    {
        "description": "You have a directory named \"log_analysis\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains lines beginning with timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to determine how many unique dates are present across all log files in this directory.",
        "explanation": "To solve this problem, you need to interact with the shell to perform several tasks:\n1. Navigate to the \"log_analysis\" directory.\n2. Use a command that reads each \".log\" file and extracts lines starting with timestamps.\n3. From these lines, extract only the date portion (\"YYYY-MM-DD\") from each timestamp.\n4. Gather all unique dates and count them.\n\nHints: Consider using tools such as `grep` to filter lines, `awk` or `cut` for extracting date parts, and `sort` or `uniq` for identifying unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate to the log directory\ncd ~/log_analysis\n\n# Extract unique dates from all log files and count them\ngrep -h '^[0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\}' *.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a \"log_analysis\" directory in the user's home directory\nmkdir -p ~/log_analysis\n\n# Create sample log files with timestamps\necho -e \"2023-04-15 12:00:01 Event1\\n2023-04-15 13:30:00 Event2\\n2023-04-16 09:45:12 Event3\" > ~/log_analysis/log1.log\necho -e \"2023-04-16 10:15:22 Event4\\n2023-04-17 14:20:25 Event5\\n2023-04-17 17:05:33 Event6\" > ~/log_analysis/log2.log\necho -e \"2023-04-18 08:00:00 Event7\\n2023-04-18 11:30:59 Event8\\n2023-04-19 23:59:59 Event9\" > ~/log_analysis/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate to the log directory\ncd ~/log_analysis\n\n# Extract unique dates from all log files and count them\ngrep -h '^[0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\}' *.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with monitoring disk usage. Count the number of files in your home directory that have not been accessed in the last 30 days and whose size is greater than 1MB. You should also ensure these files do not have a \".tmp\" extension.",
        "explanation": "To solve this problem, you can use a combination of `find` commands to search for files based on access time and size criteria. The `-atime` option will help filter files that haven't been accessed in a specified number of days, and the `-size` option will help filter by file size. Additionally, you can use the `! -name \"*.tmp\"` condition to exclude files with the \".tmp\" extension.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find command to locate appropriate files\nfind ~/test_files -type f ! -name \"*.tmp\" -size +1M -atime +30 | wc -l\n```",
        "create": {
            "init": "# Create some sample files for testing\nmkdir -p ~/test_files\ncd ~/test_files\n\n# Creating some test files with different access times and sizes\ntouch -a -d '35 days ago' old_file_1.txt\ndd if=/dev/zero of=old_file_1.txt bs=1024 count=2048  # 2MB file\n\ntouch -a -d '10 days ago' recent_file_2.txt\ndd if=/dev/zero of=recent_file_2.txt bs=1024 count=2048  # 2MB file\n\ntouch -a -d '40 days ago' old_file_3.tmp\ndd if=/dev/zero of=old_file_3.tmp bs=1024 count=2048  # 2MB file\n\ntouch -a -d '50 days ago' old_file_4.log\ndd if=/dev/zero of=old_file_4.log bs=512 count=1024   # 0.5MB file\n\ntouch -a -d '45 days ago' old_large_file.dat\ndd if=/dev/zero of=old_large_file.dat bs=1024 count=4096  # 4MB file"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find command to locate appropriate files\nfind ~/test_files -type f ! -name \"*.tmp\" -size +1M -atime +30 | wc -l"
        }
    },
    {
        "description": "In your home directory, find and count all the text files (.txt) that contain the word \"Linux\", ignoring case sensitivity. The search should be recursive, meaning it should include all subdirectories within your home directory.",
        "explanation": "To solve this problem, you can use the `find` command to locate all `.txt` files in your home directory and its subdirectories. Then, use `grep` with the `-i` option to search for the word \"Linux\" within these files, ignoring case sensitivity. Finally, count the number of occurrences using the `wc -l` command.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files recursively from home directory and search for 'Linux'\nfind ~ -name \"*.txt\" -exec grep -i 'Linux' {} \\; | wc -l\n```",
        "create": {
            "init": "# Create a sample environment with some text files containing the word \"Linux\"\nmkdir -p ~/test_dir/sub_dir1\nmkdir -p ~/test_dir/sub_dir2\n\necho \"This is a Linux file.\" > ~/test_dir/file1.txt\necho \"Another file without keyword.\" > ~/test_dir/file2.txt\necho \"Linux is great!\" > ~/test_dir/sub_dir1/file3.txt\necho \"This file contains linux multiple times: Linux Linux.\" > ~/test_dir/sub_dir2/file4.txt\n\n# Create additional files that do not contain the word 'Linux'\necho \"Just some random content.\" > ~/test_dir/sub_dir2/file5.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files recursively from home directory and search for 'Linux'\nfind ~ -name \"*.txt\" -exec grep -i 'Linux' {} \\; | wc -l"
        }
    },
    {
        "description": "You need to search for all the text files in your home directory and its subdirectories that contain the word \"Linux\". Count the number of unique files that contain this word and provide the total count. The search should be case-insensitive.",
        "explanation": "To solve this problem, you can use the `grep` command with options to perform a case-insensitive search for the word \"Linux\" within text files. Use `find` to identify all `.txt` files recursively in your home directory. Then, pipe this into `xargs` with `grep -il` to list unique file names containing the word \"Linux\". Finally, use `wc -l` or similar utility to count these unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example script to find and count unique text files containing \"Linux\"\nfind ~ -type f -name \"*.txt\" | xargs grep -il \"linux\" | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create some sample text files in various directories within the home directory.\nmkdir -p ~/testdir/subdir\necho \"Welcome to Linux tutorial.\" > ~/testdir/linux_intro.txt\necho \"This is an operating system guide.\" > ~/testdir/guide.txt\necho \"LINUX is versatile.\" > ~/testdir/subdir/linux_versatile.txt\necho \"Learning linux can be fun!\" > ~/linux_learn.txt\necho \"Another file without the keyword.\" > ~/other_file.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example script to find and count unique text files containing \"Linux\"\nfind ~ -type f -name \"*.txt\" | xargs grep -il \"linux\" | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"project_logs\" in your home directory containing multiple log files with the \".log\" extension. Your task is to find out how many unique IP addresses accessed the server, according to these logs. Only consider log entries that contain the word \"ERROR\".",
        "explanation": "To solve this problem, you need to navigate to the \"project_logs\" directory and search through all \".log\" files for lines containing the word \"ERROR\". From those lines, extract any IP addresses present and count how many of them are unique. You may use utilities like `grep` to filter out lines containing \"ERROR\", `awk` or `sed` to extract IP addresses, and `sort` with `uniq` to determine uniqueness.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/project_logs\ngrep 'ERROR' *.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"192.168.0.1 - ERROR Failed login\\n192.168.0.2 - INFO User logged in\\n10.0.0.5 - ERROR Timeout\" > ~/project_logs/log1.log\necho -e \"172.16.0.3 - ERROR Disk full\\n192.168.0.1 - ERROR Connection lost\\n10.0.0.5 - INFO Process started\" > ~/project_logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/project_logs\ngrep 'ERROR' *.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"data_logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains lines of text, where each line is formatted as \"timestamp: message\". Your task is to find out how many unique timestamps are there across all the log files. Assume that timestamps are in the format \"YYYY-MM-DD HH:MM:SS\".",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"data_logs\" directory.\n2. Extract all unique timestamps from each \".log\" file.\n3. Combine the extracted timestamps from all files and count how many unique ones exist.\n\nHints:\n- Use `cat` or `grep` to read and filter lines from files.\n- Utilize `awk` or `cut` to extract timestamps from each line.\n- Employ `sort` and `uniq` to identify unique timestamps.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n# Navigate to the data_logs directory\ncd ~/data_logs\n\n# Extract and count unique timestamps across all .log files\ncat *.log | awk -F\": \" '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\nmkdir -p ~/data_logs\necho -e \"2023-10-01 12:00:00: User login\\n2023-10-01 12:05:00: User logout\\n2023-10-01 12:10:00: System update\" > ~/data_logs/log1.log\necho -e \"2023-10-01 12:05:00: User login\\n2023-10-01 12:15:00: Error detected\\n2023-10-02 09:00:00: Backup started\" > ~/data_logs/log2.log\necho -e \"2023-10-02 09:05:00: Backup completed\\n2023-10-03 07:30:00: User login\\n2023-10-03 08:45:00:System rebooted\" > ~/data_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n# Navigate to the data_logs directory\ncd ~/data_logs\n\n# Extract and count unique timestamps across all .log files\ncat *.log | awk -F\": \" '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with a \".log\" extension. Each log file records user activities in the format of \"timestamp: action\". Your task is to find out how many unique actions have been performed across all log files.",
        "explanation": "To solve this problem, you need to follow these steps:\n1. Change into the \"logs\" directory located in your home directory.\n2. Use `cat` to concatenate all \".log\" files and pipe the output to `cut` to extract only the actions part (assuming actions are after ':').\n3. Use `sort` and `uniq` to filter out unique actions.\n4. Count the number of unique actions using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ncat *.log | cut -d':' -f2 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 10:00:01: login\\n2023-10-01 10:05:02: logout\\n2023-10-01 11:00:03: download\\n2023-10-01 12:00:04: upload\" > ~/logs/activity1.log\necho -e \"2023-10-02 09:15:05: login\\n2023-10-02 09:20:06: upload\\n2023-10-02 09:25:07: download\\n2023-10-02 09:30:08 logout\" > ~/logs/activity2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ncat *.log | cut -d':' -f2 | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.user_activity.log` that logs activities of users in the format `username:timestamp:activity_type`. The file may contain multiple entries for different users. Your task is to count how many unique users have logged at least one activity.",
        "explanation": "To solve this problem, you need to extract the usernames from each entry in the `.user_activity.log` file. You can use tools like `cut` or `awk` to isolate the username field, then use `sort` and `uniq` to filter out duplicates, and finally use `wc -l` to count the number of unique usernames.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract usernames, remove duplicates, and count unique entries\ncut -d ':' -f 1 ~/.user_activity.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a hidden user activity log file with sample data\ncat <<EOL > ~/.user_activity.log\nalice:1625078400:login\nbob:1625078410:view\ncarol:1625078420:edit\nalice:1625078430:logout\ndave:1625078440:create\nbob:1625078450:update\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract usernames, remove duplicates, and count unique entries\ncut -d ':' -f 1 ~/.user_activity.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with a \".log\" extension. Each file contains lines of text, and some lines include timestamps in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to count how many lines contain timestamps from the year 2022. Please note that the logs may contain lines without timestamps or with different years.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and use a combination of tools such as `grep`, `awk`, or `sed` to filter out and count the lines containing timestamps specifically from the year 2022. Use pattern matching to identify these lines accurately.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -E '^2022-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2021-12-31 23:59:59 Event A\\n2022-01-01 00:00:01 Event B\\nNo timestamp line\\n2022-03-15 12:34:56 Event C\\nAnother non-timestamp line\" > ~/logs/log1.log\necho -e \"Some random text\\n2022-06-10 09:08:07 Event D\\nMore random text\\n2023-01-01 01:02:03 Event E\" > ~/logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -E '^2022-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You have been given a log file named \"system.log\" in your home directory, which contains timestamps and various system events. Your task is to count how many times the keyword \"ERROR\" appears in this log file for the current day. You need to assume that the date format in the log file is \"YYYY-MM-DD\".",
        "explanation": "To solve this problem, you should first extract today's date in the \"YYYY-MM-DD\" format. Then, filter entries in \"system.log\" for lines containing both today's date and the keyword \"ERROR\". Finally, count these lines to get the number of errors logged today.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Get today's date formatted as YYYY-MM-DD\ntoday=$(date '+%Y-%m-%d')\n\n# Count lines with today's date and containing \"ERROR\"\ngrep \"$today ERROR\" ~/system.log | wc -l\n```",
        "create": {
            "init": "# Create a sample 'system.log' file with various events including some errors\necho -e \"$(date '+%Y-%m-%d') INFO Boot completed\\n$(date '+%Y-%m-%d') ERROR Disk full\\n$(date '+%Y-%m-%d') ERROR Network down\\n$(date -d 'yesterday' '+%Y-%m-%d') INFO Update successful\\n$(date -d 'yesterday' '+%Y-%m-%d') ERROR High temperature\" > ~/system.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Get today's date formatted as YYYY-MM-DD\ntoday=$(date '+%Y-%m-%d')\n\n# Count lines with today's date and containing \"ERROR\"\ngrep \"$today ERROR\" ~/system.log | wc -l"
        }
    },
    {
        "description": "Count the number of unique words in all text files within the \"documents\" directory, ignoring case sensitivity. You should consider words to be sequences of letters only, treating any non-letter characters as delimiters. Additionally, each word should be counted only once per file.",
        "explanation": "To solve this problem, you need to process each text file in the \"documents\" directory. For each file, extract sequences of letters as words, convert them to lowercase to ensure case insensitivity, and store them in a set (to ensure uniqueness). After processing all files, count the total number of unique words across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Initialize an empty set using associative array for storing unique words.\ndeclare -A unique_words\n\n# Iterate over each file in the 'documents' directory.\nfor file in documents/*.txt; do\n  # Extract words from each file and convert to lowercase.\n  # Using grep with PCRE (-P) to match only sequences of letters (\\w+) and tr for lowercase conversion.\n  for word in $(grep -oP '\\b\\w+\\b' \"$file\" | tr '[:upper:]' '[:lower:]'); do\n    # Add word to associative array.\n    unique_words[\"$word\"]=1\n  done\ndone\n\n# Output the count of unique keys (words) in the associative array.\necho \"${#unique_words[@]}\"\n```",
        "create": {
            "init": "mkdir -p documents\necho \"Hello world! This is a test.\" > documents/file1.txt\necho \"Another test: hello again.\" > documents/file2.txt\necho \"The quick brown fox jumps over the lazy dog.\" > documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Initialize an empty set using associative array for storing unique words.\ndeclare -A unique_words\n\n# Iterate over each file in the 'documents' directory.\nfor file in documents/*.txt; do\n  # Extract words from each file and convert to lowercase.\n  # Using grep with PCRE (-P) to match only sequences of letters (\\w+) and tr for lowercase conversion.\n  for word in $(grep -oP '\\b\\w+\\b' \"$file\" | tr '[:upper:]' '[:lower:]'); do\n    # Add word to associative array.\n    unique_words[\"$word\"]=1\n  done\ndone\n\n# Output the count of unique keys (words) in the associative array.\necho \"${#unique_words[@]}\""
        }
    },
    {
        "description": "You have a directory named `logs` in your home directory containing multiple log files with the `.log` extension. Each log file contains entries in the format `YYYY-MM-DD HH:MM:SS [LEVEL] Message`. Your task is to find out how many unique dates appear across all log files combined, where the log level is `ERROR`.",
        "explanation": "To solve this problem, you need to iterate through each `.log` file in the `logs` directory, extract lines that contain `[ERROR]`, and then capture the date part of these lines (the first 10 characters). Once you have collected all dates from all files, deduplicate them to find out how many unique dates are there.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"\\[ERROR\\]\" ~/logs/*.log | cut -d' ' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 12:00:00 [INFO] Start process\\n2023-01-01 12:05:00 [ERROR] Something went wrong\\n2023-01-02 14:00:00 [ERROR] Another error occurred\" > ~/logs/app1.log\necho -e \"2023-01-03 09:45:00 [WARN] Low memory\\n2023-01-02 15:30:00 [ERROR] Disk full\\n2023-01-04 16:50:00 [INFO] Shutdown\" > ~/logs/app2.log\necho -e \"2023-01-03 10:10:10 [ERROR] Network issue\\n2023-01-04 11:11:11 [ERROR] Database locked\" > ~/logs/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"\\[ERROR\\]\" ~/logs/*.log | cut -d' ' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each file contains lines of text, and some lines include the keyword \"ERROR\". Your task is to count how many unique dates (in YYYY-MM-DD format) have error entries across all these log files. Assume that each error line begins with a timestamp formatted as \"YYYY-MM-DD HH:MM:SS\".",
        "explanation": "To solve this problem, you should first navigate to the \"logs\" directory. You will need to use tools like `grep` to filter out lines containing the keyword \"ERROR\", then extract the date portion from each timestamp using tools such as `awk` or `cut`. Finally, you'll want to use `sort` and `uniq` commands to find out how many unique dates exist among these error entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep 'ERROR' *.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 10:00:00 INFO Something happened\\n2023-01-01 11:00:00 ERROR Something went wrong\\n2023-01-02 09:30:00 ERROR Another issue occurred\" > ~/logs/server1.log\necho -e \"2023-01-02 12:15:00 INFO Routine check\\n2023-01-03 14:45:00 ERROR Critical failure detected\\n2023-01-03 16:20:00 ERROR Minor glitch\" > ~/logs/server2.log\necho -e \"2023-01-04 08:50:00 INFO Startup complete\\n2023-01-04 10:30:00 ERROR Unexpected shutdown\\n2023-01-05 16:40:00 INFO Maintenance scheduled\" > ~/logs/server3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep 'ERROR' *.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing a system log file located at `/var/log/syslog`. Your goal is to determine how many times the word \"error\" (case-insensitive) appears in this log file. Provide the count as an integer.",
        "explanation": "To solve this problem, you need to access and read the `/var/log/syslog` file. Use a combination of command-line utilities like `grep` or `awk` to search for occurrences of the word \"error\" in a case-insensitive manner. Count these occurrences and output the result as an integer.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use grep to count occurrences of \"error\" in any case\ngrep -i -o 'error' /var/log/syslog | wc -l\n```",
        "create": {
            "init": "# Since /var/log/syslog may not be available or contain relevant data on all systems,\n# we create a mock syslog file for the purpose of this exercise.\necho -e \"Error: Could not connect to database\\nINFO: Connection established\\nERROR: Failed login attempt\\nerror: Disk space low\\nWarning: High memory usage\" > /var/log/syslog"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use grep to count occurrences of \"error\" in any case\ngrep -i -o 'error' /var/log/syslog | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing a log file named `system.log` located in your home directory. Your goal is to determine how many unique IP addresses have accessed the system. Consider only IPv4 addresses and ignore any lines that are commented out with a `#` at the beginning.",
        "explanation": "To solve this problem, you need to:\n1. Filter out all lines that start with `#` to ignore comments.\n2. Extract all IPv4 addresses from the remaining lines using pattern matching or regular expressions.\n3. Collect these IP addresses and count the number of unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -v '^#' ~/system.log | grep -oE '([0-9]{1,3}\\.){3}[0-9]{1,3}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "cat <<EOL > ~/system.log\n# This is a comment line\n192.168.1.1 - - [12/Oct/2023:14:55:36 +0000] \"GET /index.html HTTP/1.1\" 200 1043\n10.0.0.5 - - [12/Oct/2023:14:56:02 +0000] \"POST /form HTTP/1.1\" 200 2326\n172.16.254.3 - - [12/Oct/2023:14:57:45 +0000] \"GET /about HTTP/1.1\" 404 -\n192.168.1.1 - - [12/Oct/2023:14:58:22 +0000] \"GET /contact HTTP/1.1\" 200 1892\n10.0.0.5 - - [12/Oct/2023:14:59:11 +0000] \"GET /home HTTP/1.1\" 200 5467\n# Another comment here\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -v '^#' ~/system.log | grep -oE '([0-9]{1,3}\\.){3}[0-9]{1,3}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines across all `.txt` files in your current directory that contain the word \"Linux\", case-insensitively. Ensure no subdirectories are included in your search.",
        "explanation": "To solve this problem, you need to combine several command-line utilities. First, identify all `.txt` files in the current directory using `ls` or `find`. Then, use `grep` with the `-i` option to perform a case-insensitive search for the word \"Linux\" within these files. Finally, count the number of matching lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use find to list all .txt files and grep to find occurrences of 'Linux'.\ngrep -i 'Linux' *.txt | wc -l\n```",
        "create": {
            "init": "# Create some sample text files for testing.\necho -e \"This is a Linux file.\\nAnother line.\" > file1.txt\necho -e \"linux is versatile.\\nLearning Linux is fun.\" > file2.txt\necho -e \"This file does not mention it.\" > file3.txt\necho -e \"LINUX commands are powerful.\" > file4.txt\n\n# Ensure no other .txt files exist by deleting any prior ones.\nrm -f temp_file*.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use find to list all .txt files and grep to find occurrences of 'Linux'.\ngrep -i 'Linux' *.txt | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing various log files with different timestamps. Your task is to count the number of lines across all files that contain the word \"ERROR\" and were modified within the last 7 days. You need to provide only the total count as your answer.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and use a combination of commands to filter files based on their modification time and search for occurrences of the word \"ERROR\". The `find` command can be used to identify files modified in the last 7 days, and then you can use `grep` to search within these files for lines containing \"ERROR\". Finally, by using `wc -l`, you can count these lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\nfind . -type f -mtime -7 | xargs grep -i 'ERROR' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"INFO: System started\" > ~/logs/log1.txt\necho \"ERROR: Failed to load module\" >> ~/logs/log1.txt\necho \"WARN: Deprecated API usage\" >> ~/logs/log1.txt\n\necho \"INFO: User login successful\" > ~/logs/log2.txt\necho \"ERROR: Database connection lost\" >> ~/logs/log2.txt\n\ntouch -d '8 days ago' ~/logs/old_log.txt\necho \"ERROR: Outdated error message\" > ~/logs/old_log.txt\n\ntouch -d '3 days ago' ~/logs/recent_log.log\necho \"ERROR: Recent critical issue detected\" > ~/logs/recent_log.log\n\n# Ensure all recent logs are modified within 7 days from now.\ntouch -m $(find ~/logs/ -type f ! -name 'old_log.txt')"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\nfind . -type f -mtime -7 | xargs grep -i 'ERROR' | wc -l"
        }
    },
    {
        "description": "You have a directory named `log_files` in your home directory containing multiple `.log` files. Each file contains lines of text, and some lines are error messages starting with the word \"ERROR\". Your task is to count the total number of error messages across all these `.log` files and output that number as an integer.",
        "explanation": "To solve this problem, you need to iterate through each `.log` file in the `log_files` directory. For each file, you can use tools like `grep` to filter out lines that start with \"ERROR\" and then count them using `wc -l`. Finally, sum up the counts from all files to get the total number of error messages.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Initialize count variable for total errors\ntotal_errors=0\n\n# Iterate over each .log file in the log_files directory\nfor logfile in ~/log_files/*.log; do\n  # Count lines starting with ERROR and add to total_errors\n  errors_in_file=$(grep '^ERROR' \"$logfile\" | wc -l)\n  total_errors=$((total_errors + errors_in_file))\ndone\n\n# Output the total number of errors as an integer\necho $total_errors\n```",
        "create": {
            "init": "#!/bin/bash\n# Create log_files directory and sample .log files\nmkdir -p ~/log_files\n\n# Create sample log files with random content including error messages\necho -e \"INFO: System started\\nERROR: Disk not found\\nINFO: Performing backup\\nERROR: Backup failed\" > ~/log_files/system.log\necho -e \"WARNING: Low battery\\nINFO: Charging started\\nERROR: Charger malfunction detected\" > ~/log_files/device.log\necho -e \"INFO: Network connection established\\nERROR: Connection timeout\\nINFO: Data received successfully\" > ~/log_files/network.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Initialize count variable for total errors\ntotal_errors=0\n\n# Iterate over each .log file in the log_files directory\nfor logfile in ~/log_files/*.log; do\n  # Count lines starting with ERROR and add to total_errors\n  errors_in_file=$(grep '^ERROR' \"$logfile\" | wc -l)\n  total_errors=$((total_errors + errors_in_file))\ndone\n\n# Output the total number of errors as an integer\necho $total_errors"
        }
    },
    {
        "description": "You have a directory named \"logfiles\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains timestamped entries. Your task is to identify the total number of unique IP addresses that appear across all these log files. The IP addresses follow the standard IPv4 format (e.g., 192.168.1.1). You must also ensure that you only count IP addresses appearing on lines with timestamps from the year 2023.",
        "explanation": "To solve this problem, you need to perform several steps:  \n1. Navigate to the \"logfiles\" directory.\n2. Use a command like `grep` to filter out lines containing timestamps from the year 2023.\n3. Extract the IP addresses from these lines using a tool such as `awk` or `sed`.\n4. Collect all extracted IPs and determine the unique ones using `sort` and `uniq`.\n5. Count these unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logfiles\ngrep '2023' *.log | awk '{print $6}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-01-01 12:00:00 - Connection from 192.168.0.1\\n2022-12-31 11:00:00 - Connection from 172.16.0.1\\n2023-02-15 14:22:10 - Connection from 10.0.0.2\" > ~/logfiles/log1.log\necho -e \"2023-03-05 08:30:45 - Connection from 192.168.0.1\\n2023-03-05 08:35:50 - Connection from 10.0.0.2\\n2023-04-20 09:15:55 - Connection from 172.16.0.2\" > ~/logfiles/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logfiles\ngrep '2023' *.log | awk '{print $6}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory which contains multiple text files with server logs. Each log entry starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\" followed by an error level and message. Your task is to find out how many entries with the error level \"ERROR\" occurred on the date \"2023-10-01\".",
        "explanation": "To solve this problem, you should navigate to the \"log_files\" directory and use grep to filter out lines that contain both the date \"2023-10-01\" and the word \"ERROR\". Then, count how many such lines exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '2023-10-01.*ERROR' ~/log_files/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\ncat <<EOT >> ~/log_files/log1.txt\n2023-10-01 12:00:00 INFO Starting process\n2023-10-01 12:05:00 ERROR Failed to connect to database\n2023-10-01 12:10:00 WARN Low disk space\n2023-10-02 13:00:00 ERROR Network timeout\nEOT\n\ncat <<EOT >> ~/log_files/log2.txt\n2023-10-01 14:30:00 ERROR User authentication failed\n2023-09-30 09:00:00 INFO Process completed successfully\n2023-10-01 15:45:00 ERROR Disk write failure\nEOT\n\ncat <<EOT >> ~/log_files/log3.txt\n2023-10-02 16:20:00 INFO System shutdown initiated\n2023-09-29 08:15:00 ERROR Memory allocation failed\nEOT"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '2023-10-01.*ERROR' ~/log_files/*.txt | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains timestamps and messages. Your task is to find out how many times the word \"ERROR\" (case-sensitive) appears across all log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to use the `grep` command to search for the word \"ERROR\" within all files that have a \".log\" extension inside the \"logs\" directory. You can then use `wc -l` to count the number of occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -o 'ERROR' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-10 12:00:00 INFO Starting process\\n2023-10-10 12:01:00 ERROR Failed to start service\\n2023-10-10 12:02:00 INFO Retrying...\\n2023-10-10 12:03:00 ERROR Service unavailable\" > ~/logs/system.log\necho -e \"2023-10-11 08:30:00 INFO Scheduled task started\\n2023-10-11 08:31:00 ERROR Task failed due to timeout\\n2023-10-11 08:32:00 INFO Task retry successful\" > ~/logs/task.log\necho -e \"2023-10-12 09:15:00 INFO Backup started\\n2023-10-12 09:16:00 ERROR Disk full\\n2023-10-12 09:17:00 WARNING Low disk space\\n2023-10-12 09:18:00 ERROR Backup failed\" > ~/logs/backup.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -o 'ERROR' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, you will find a folder named \"logs\". Your task is to count the number of unique IP addresses in all \".log\" files within this directory. Assume the logs are formatted such that each line starts with an IP address. You need to determine how many distinct IP addresses accessed the system.",
        "explanation": "To solve this problem, you will first need to use a combination of bash commands to read and process each \".log\" file in the \"logs\" directory. The `cat` command can be used to concatenate and display all log files, while `awk` or `cut` would help extract the IPs from each line. Then, using `sort` and `uniq`, you can sort these IPs and filter out duplicates to get the unique set. Finally, use `wc -l` to count these unique IPs.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 accessed\\n192.168.1.2 accessed\\n192.168.1.1 accessed\" > ~/logs/access1.log\necho -e \"10.0.0.1 error\\n192.168.1.3 accessed\\n10.0.0.2 warning\" > ~/logs/access2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with a \".log\" extension. Each log file contains lines of text formatted as \"[timestamp] [log_level] [message]\". Your task is to count the number of lines that contain the log level \"ERROR\" across all log files and provide the total count.",
        "explanation": "To solve this problem, you need to list all the \".log\" files in the \"logs\" directory and then search for lines containing the word \"ERROR\". You can use utilities like `grep` to filter these lines and `wc -l` to count them. Consider using tools like `find` or shell globbing to handle multiple files efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -rh \"ERROR\" ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"[2023-10-01 12:00:00] INFO Starting process\\n[2023-10-01 12:00:01] ERROR Failed to start service\\n[2023-10-01 12:00:02] WARNING Low memory\" > ~/logs/system.log\necho -e \"[2023-10-02 13:00:00] INFO Process running\\n[2023-10-02 13:00:05] ERROR Connection lost\\n[2023-10-02 13:00:07] ERROR Timeout occurred\" > ~/logs/network.log\necho -e \"[2023-10-03 14:30:00] DEBUG Debugging mode enabled\\n[2023-10-03 14:31:22] ERROR Disk full\\n[2023-10-03 14:32:33] INFO Cleanup complete\" > ~/logs/storage.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -rh \"ERROR\" ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains timestamps and various types of log entries. Your task is to find out how many unique IP addresses have accessed the system across all logs. Assume that each line in the log files contains an IP address at the beginning of the line.",
        "explanation": "To solve this problem, you need to traverse through all the \".log\" files in the \"logs\" directory, extract IP addresses from each file, and then count how many unique IP addresses exist across all these files. You can use tools like `cat`, `awk`, `sort`, and `uniq` in combination to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 - Accessed system\\n192.168.1.2 - Failed login\\n192.168.1.3 - Accessed system\" > ~/logs/log1.log\necho -e \"192.168.1.2 - Accessed system\\n192.168.1.4 - Failed login\\n192.168.1.5 - Accessed system\" > ~/logs/log2.log\necho -e \"192.168.1.3 - Failed login\\n192.168.1.6 - Accessed system\\n192.168.1.7 - Accessed system\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" which contains multiple text files with various system logs. Your task is to count the number of unique IP addresses that have accessed the system, where each IP address follows the standard IPv4 format and appears at the beginning of each log entry in these files.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to the \"log_files\" directory.\n2. Extract all IP addresses from each file. You can use tools like `grep` or `awk` to filter out lines and extract IPs.\n3. Use `sort` and `uniq` utilities to identify unique IP addresses across all files.\n4. Count these unique IP addresses using tools such as `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd log_files || exit\n\n# Extract and sort all potential IP addresses from all files, ignoring lines with incorrect formats \ngrep -oP '^\\d{1,3}(\\.\\d{1,3}){3}' *.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir log_files\ncat <<EOL > log_files/access1.log\n192.168.1.1 - Accessed /home page\n10.0.0.1 - Accessed /login page\n192.168.1.2 - Accessed /dashboard page\n192.168.1.1 - Accessed /settings page\nEOL\n\ncat <<EOL > log_files/access2.log\n172.16.0.1 - Accessed /register page\n192.168.1.3 - Accessed /logout page\n10.0.0.2 - Accessed /profile page\n192.168.1.3 - Accessed /contact-us page\nEOL\n\ncat <<EOL > log_files/access3.log\n10.0.0.3 - Accessed /home page\n172.16.0.2 - Accessed /about-us page\n10.0 0 3-Accessed/faqpage   # Invalid format; should be ignored.\n10 000 4-Accessedsupportpage# Invalid format; should be ignored.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd log_files || exit\n\n# Extract and sort all potential IP addresses from all files, ignoring lines with incorrect formats \ngrep -oP '^\\d{1,3}(\\.\\d{1,3}){3}' *.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing multiple log files. Each log file has lines of text where each line starts with a date in the format YYYY-MM-DD, followed by a space and a log message. Your task is to find out how many unique dates appear across all log files in the \"logs\" directory. Consider only dates from the month of September 2023.",
        "explanation": "To solve this problem, you need to iterate over each file in the \"logs\" directory, extract the date from each line, filter out only those dates that belong to September 2023, and then count the number of unique dates. You can use utilities like `grep` to filter lines by date pattern, `cut` or `awk` to extract dates, and `sort` combined with `uniq` to determine unique occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# List all files in the 'logs' directory.\nfor file in logs/*; do\n    # Extract lines with September 2023 dates.\n    grep \"^2023-09-\" \"$file\" | cut -d' ' -f1\ndone | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p logs\necho -e \"2023-09-01 Log entry one\\n2023-09-02 Log entry two\\n2023-08-31 Old log entry\" > logs/log1.txt\necho -e \"2023-09-01 Another entry\\n2023-09-03 Different day entry\" > logs/log2.txt\necho -e \"2023-09-04 A new day\\n2023-10-01 Future log\" > logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# List all files in the 'logs' directory.\nfor file in logs/*; do\n    # Extract lines with September 2023 dates.\n    grep \"^2023-09-\" \"$file\" | cut -d' ' -f1\ndone | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains timestamped entries of various system events. Your task is to determine how many unique error codes appear across all the log files. Each error code is prefixed by the string \"ERROR:\" and followed by a three-digit number (e.g., \"ERROR:404\"). Count only distinct error codes.",
        "explanation": "To solve this problem, you need to search through each log file in the \"logs\" directory for lines containing \"ERROR:\" followed by a three-digit number. You can use tools like `grep` to extract these lines, then use `sed` or `awk` to isolate the error codes. Finally, use `sort` and `uniq` to count distinct error codes.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h -o 'ERROR:[0-9]\\{3\\}' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 INFO: System boot\\n2023-10-01 12:05:00 ERROR:404 File not found\\n2023-10-01 12:10:00 ERROR:500 Internal server error\" > ~/logs/system1.log\necho -e \"2023-10-02 10:30:00 ERROR:403 Forbidden\\n2023-10-02 11:00:00 INFO: User login\\n2023-10-02 11:05:00 ERROR:404 Page missing\" > ~/logs/system2.log\necho -e \"2023-10-03 09:15:00 INFO: Network connected\\n2023-10-03 09:45:00 ERROR:500 Server overload\\n2023-10-03 09:50:00 ERROR:502 Bad gateway\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h -o 'ERROR:[0-9]\\{3\\}' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains multiple log files with the \".log\" extension. Each log file consists of entries with timestamps and error messages. Your task is to determine how many unique error messages occurred across all log files within the last 7 days from today. Assume that each log entry has the format: `[YYYY-MM-DD HH:MM:SS] Error: <error_message>`.",
        "explanation": "To solve this problem, you will need to:\n1. Use the `find` command to locate all `.log` files in the \"logs\" directory.\n2. Utilize `grep` or similar tools to filter entries within the last 7 days.\n3. Extract unique error messages using text processing utilities like `awk`, `sed`, or `cut`.\n4. Count the number of unique error messages using tools like `sort` and `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -name \"*.log\" -exec grep -E \"^\\[20[0-9]{2}-((0[1-9])|(1[0-2]))-[0-9]{2}\" {} + | \\\nawk '$0 >= \"[\" strftime(\"%Y-%m-%d\", systime() - (7 * 24 * 60 * 60))' | \\\nawk -F 'Error:' '{print $2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"[2023-09-29 12:00:00] Error: Disk full\" > ~/logs/app1.log\necho \"[2023-10-01 13:15:45] Error: Network timeout\" >> ~/logs/app1.log\necho \"[2023-10-02 14:30:30] Error: Disk full\" >> ~/logs/app1.log\necho \"[2023-10-03 15:45:15] Error: Permission denied\" > ~/logs/app2.log\necho \"[2023-10-04 16:50:50] Error: Network timeout\" >> ~/logs/app2.log\necho \"[2023-09-28 17:55:25] Error: File not found\" >> ~/logs/app2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -name \"*.log\" -exec grep -E \"^\\[20[0-9]{2}-((0[1-9])|(1[0-2]))-[0-9]{2}\" {} + | \\\nawk '$0 >= \"[\" strftime(\"%Y-%m-%d\", systime() - (7 * 24 * 60 * 60))' | \\\nawk -F 'Error:' '{print $2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory, containing multiple log files with the extension \".log\". Your task is to count the total number of lines across all log files that contain the word \"ERROR\". The search should be case-sensitive.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and use a combination of shell utilities to efficiently count lines containing the specified word. Useful utilities include `grep` for searching within files and `wc` for counting lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ngrep 'ERROR' *.log | wc -l\n```",
        "create": {
            "init": "# Create the logs directory and populate it with example log files\nmkdir -p ~/logs\necho -e \"INFO: System boot\\nERROR: Disk not found\\nINFO: User login\" > ~/logs/system.log\necho -e \"WARNING: Low memory\\nERROR: Out of memory\\nERROR: Network down\" > ~/logs/error.log\necho -e \"INFO: Update complete\\nERROR: Service unavailable\" > ~/logs/update.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ngrep 'ERROR' *.log | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"logs\" in your home directory. This directory contains multiple log files with random names, each containing timestamps and error messages in the format \"[YYYY-MM-DD HH:MM:SS] ERROR: <message>\". Your task is to count the total number of unique error messages across all log files in this directory. Consider different messages with the same content as unique if they appear in different timestamps.",
        "explanation": "To solve this problem, you need to iterate over each log file in the \"logs\" directory, extract all lines containing \"ERROR\", and then filter out unique error messages based on their content. You can use utilities like `grep`, `awk`, or `sed` to extract and process the required data from the logs.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f -exec grep \"ERROR\" {} \\; | awk '{$1=$2=\"\"; sub(/^[ \\t]+/, \"\"); print}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"[2023-10-01 12:00:00] ERROR: Failed to connect to server\" > ~/logs/log1.txt\necho \"[2023-10-01 12:05:00] ERROR: Failed to connect to server\" >> ~/logs/log1.txt\necho \"[2023-10-01 12:10:00] INFO: Connection successful\" >> ~/logs/log1.txt\necho \"[2023-10-01 12:15:00] ERROR: Disk space low\" > ~/logs/log2.txt\necho \"[2023-10-01 12:20:00] ERROR: Failed to connect to server\" >> ~/logs/log2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/logs -type f -exec grep \"ERROR\" {} \\; | awk '{$1=$2=\"\"; sub(/^[ \\t]+/, \"\"); print}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory, which contains multiple `.log` files. Each log file has lines in the format `YYYY-MM-DD HH:MM:SS [LOG_LEVEL] Message`, where `LOG_LEVEL` can be INFO, WARNING, or ERROR. Your task is to count how many lines contain the ERROR level across all log files and return this count.",
        "explanation": "To solve this problem, you need to iterate over each log file in the \"log_files\" directory, extract lines that contain \"[ERROR]\", and count them. You can use tools like `grep` to filter out lines with \"[ERROR]\" and `wc -l` to count the number of such lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"\\[ERROR\\]\" ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-10-01 12:00:00 [INFO] System started\\n2023-10-01 12:01:00 [ERROR] Failed to start service\\n2023-10-01 12:02:00 [WARNING] Low memory\" > ~/log_files/log1.log\necho -e \"2023-10-02 13:00:00 [ERROR] Disk full\\n2023-10-02 13:01:00 [INFO] Disk cleanup started\\n2023-10-02 13:02:00 [ERROR] Unable to delete temp files\" > ~/log_files/log2.log\necho -e \"2023-10-03 14:00:00 [WARNING] Network latency high\\n2023-10-03 14:01:00 [INFO] Monitoring network status\\n2023-10-03 14:02:00 [ERROR] Packet loss detected\" > ~/log_files/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"\\[ERROR\\]\" ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory, which contains multiple log files with the extension \".log\". Each log file records various system events. Your task is to find out how many unique IP addresses have accessed the system across all these log files. Assume each line in the log files follows this format: \"[timestamp] [IP address] [event description]\". You need to count and submit the total number of unique IP addresses.",
        "explanation": "To solve this problem, you can use a combination of commands like `cat` to concatenate all log files, `awk` or `cut` to extract the IP addresses from each line, and `sort` and `uniq` to sort and filter out duplicate IP addresses. Finally, use `wc -l` to count the number of unique lines (IP addresses).\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logfiles/*.log | awk '{print $2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho \"[2023-10-01 14:32:21] 192.168.1.1 User login\" > ~/logfiles/log1.log\necho \"[2023-10-01 14:35:45] 192.168.1.2 User login\" >> ~/logfiles/log1.log\necho \"[2023-10-01 15:00:00] 192.168.1.1 File accessed\" >> ~/logfiles/log2.log\necho \"[2023-10-01 15:05:23] 192.168.1.3 User logout\" > ~/logfiles/log2.log\necho \"[2023-10-01 15:30:12] 192.168.1.4 File deleted\" > ~/logfiles/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logfiles/*.log | awk '{print $2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory, which contains multiple text files. Each file represents the log of a server for a specific day and contains lines in the format: \"timestamp IP_address status_code\". Your task is to count how many unique IP addresses have made requests with a 404 status code across all files in the directory.",
        "explanation": "To solve this problem, you need to iterate through each file in the \"logfiles\" directory, extract lines with a status code of 404, and track unique IP addresses from those lines. You can use tools like `grep` to filter lines by status code and `awk` to extract IP addresses. Finally, use `sort` and `uniq` to count distinct IPs.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '404' ~/logfiles/* | awk '{print $2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\ncat <<EOL > ~/logfiles/server1.log\n2023-10-01T12:00:00 192.168.1.1 200\n2023-10-01T12:05:00 192.168.1.2 404\n2023-10-01T12:10:00 192.168.1.1 404\nEOL\n\ncat <<EOL > ~/logfiles/server2.log\n2023-10-02T08:00:00 192.168.2.1 500\n2023-10-02T08:05:00 192.168.1.3 404\n2023-10-02T08:10:00 192.168.1.2 404\nEOL\n\ncat <<EOL > ~/logfiles/server3.log\n2023-10-03T18:00:00 192.168.2.2 200\n2023-10-03T18:05:00 192.168.2.4 404\n2023-10-03T18:15:00 192.168.1.5 404\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '404' ~/logfiles/* | awk '{print $2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"log_files\" in your home directory, which contains multiple text files with various system logs. Count the total number of unique IP addresses that appear in these log files. Assume each line of the log files could contain an IP address in the format xxx.xxx.xxx.xxx, where xxx is a number from 0 to 255. You need to navigate through each file and extract any IP addresses present.",
        "explanation": "To solve this problem, you need to navigate to the \"log_files\" directory and iterate over each file within it. Use tools like `grep` or `awk` to extract potential IP addresses from each line of the log files. Then, use `sort` and `uniq` to count only unique IP addresses across all files combined.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/log_files\n\n# Extract all potential IPs using grep (allowing for partial matches here)\ngrep -oP '\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b' * | sort | uniq | wc -l\n\n# Expected output is 4 since there are four unique valid full IP addresses: \n# 192.168.1.1, 10.0.0., 172., and 127.\n```",
        "create": {
            "init": "mkdir -p ~/log_files\ncat <<EOL > ~/log_files/log1.txt\n192.168.1.1 - Access granted\n10.0.0.2 - Error occurred\n192.168.1.1 - Access revoked\nEOL\n\ncat <<EOL > ~/log_files/log2.txt\n172.16.0.5 - User login successful\n192.168.1.1 - Attempt failed\n10.0.0.2 - Connection lost\nEOL\n\ncat <<EOL > ~/log_files/log3.txt\n127.0.0.1 - Localhost access recorded\n192.168.100.\n172.\n255.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/log_files\n\n# Extract all potential IPs using grep (allowing for partial matches here)\ngrep -oP '\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b' * | sort | uniq | wc -l\n\n# Expected output is 4 since there are four unique valid full IP addresses: \n# 192.168.1.1, 10.0.0., 172., and 127."
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory that contains multiple log files with the extension \".log\". Each log file contains timestamps and error messages. Your task is to determine how many unique error messages occurred on a specific date across all log files. The date should be provided in the format \"YYYY-MM-DD\". You need to count the number of unique error messages for the date \"2023-01-15\".",
        "explanation": "To solve this problem, you need to search through all \".log\" files in the \"logs\" directory for entries corresponding to the specified date. Extract the error message part of each line and keep track of unique messages using tools like `grep`, `awk`, `sort`, and `uniq`. Specifically, you can first filter lines containing the specified date, then extract the error message portion (assuming it follows a structured pattern), sort them, and finally use `uniq` to count distinct occurrences.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '2023-01-15' ~/logs/*.log | awk -F'Error:' '{print $2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-15 10:00:00 Error: Disk full\\n2023-01-15 11:00:00 Error: Network unreachable\\n2023-01-16 09:00:00 Error: Disk full\\n2023-01-15 12:30:00 Error: Disk full\" > ~/logs/system1.log\necho -e \"2023-01-15 14:20:00 Error: Permission denied\\n2023-01-17 08:45:00 Error: Network unreachable\\n2023-01-15 18:50:00 Error: Disk full\" > ~/logs/system2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '2023-01-15' ~/logs/*.log | awk -F'Error:' '{print $2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" which contains multiple log files. Each log file contains entries in the format: \"timestamp - loglevel - message\". Your task is to count the number of \"ERROR\" level log entries across all files in this directory and provide just the integer count as your answer.",
        "explanation": "To solve this problem, you will need to navigate into the \"logs\" directory and use a combination of commands to search for lines containing \"ERROR\". You can use `grep` to filter these lines and `wc -l` to count them. Make sure that you account for all files in the given directory.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Navigate into the logs directory\ncd logs\n\n# Use grep and wc to find and count error entries across all files\ngrep 'ERROR' *.txt | wc -l\n```",
        "create": {
            "init": "# Create the logs directory and populate it with sample log files\nmkdir -p logs\necho -e \"2023-10-01 12:00:00 - INFO - Starting process\\n2023-10-01 12:01:00 - ERROR - Failed to connect\\n2023-10-01 12:02:00 - INFO - Process completed\" > logs/log1.txt\necho -e \"2023-10-02 13:00:00 - ERROR - Unable to access resource\\n2023-10-02 13:05:00 - WARN - Low memory\\n2023-10-02 13:07:00 - ERROR - Timeout occurred\" > logs/log2.txt\necho -e \"2023-10-03 14:00:00 - INFO - System check\\n2023-10-03 14:30:00 - DEBUG - Checking configuration\\n2023-10-03 14:45:00 - ERROR - Disk full\" > logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Navigate into the logs directory\ncd logs\n\n# Use grep and wc to find and count error entries across all files\ngrep 'ERROR' *.txt | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"project_data\" containing multiple subdirectories and files. You need to determine the total number of lines across all text files (*.txt) within this \"project_data\" directory and its subdirectories, excluding any lines that are comments (lines starting with '#').",
        "explanation": "To solve this problem, you should recursively search through the \"project_data\" directory for all text files. For each text file found, read its contents and count only the lines that do not start with '#'. This involves using utilities like `find` to locate the files, and then processing each file with tools like `grep` or `awk` to exclude comment lines and count the remaining ones.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/project_data -type f -name \"*.txt\" | xargs grep -v '^#' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_data/subdir1 ~/project_data/subdir2\necho -e \"# This is a comment\\nLine 1\\nLine 2\\n# Another comment\" > ~/project_data/file1.txt\necho -e \"Line A\\n# Commented line\\nLine B\" > ~/project_data/subdir1/file2.txt\necho -e \"# Full comment file\\n# Another full comment line\" > ~/project_data/subdir2/file3.txt\necho -e \"Valid Line 1\\nValid Line 2\" > ~/project_data/subdir2/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/project_data -type f -name \"*.txt\" | xargs grep -v '^#' | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"logs\" in your home directory, which contains multiple log files with different extensions. Each file records server request logs with entries that include a timestamp and an HTTP status code. Your task is to count how many requests resulted in a 404 error across all files in the \"logs\" directory. You must search recursively through all subdirectories within \"logs\".",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and recursively search for the string \"404\" in all files within it. You can use utilities like `grep` with the `-r` (recursive) option to search through directories. To get only the count of occurrences, you can pipe the output of `grep` into `wc -l`, which will count the number of lines containing \"404\".\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r '404' ~/logs | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs/subdir1\nmkdir -p ~/logs/subdir2\n\necho -e \"2023-10-01 12:00:01 200\\n2023-10-01 12:01:00 404\\n2023-10-01 12:02:30 500\" > ~/logs/log1.txt\necho -e \"2023-10-02 14:00:23 404\\n2023-10-02 14:05:45 302\\n2023-10-02 15:15:36 404\" > ~/logs/subdir1/log2.txt\necho -e \"2023-10-03 16:25:43 200\\n2023-10-03 17:35:50 403\\n2023-10-03 18:45:11 404\" > ~/logs/subdir2/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r '404' ~/logs | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines of code (excluding empty lines and comments) in all Python files (.py) located within your home directory and its subdirectories. Assume comments start with a '#' character and can occur both at the beginning of a line and after code. Present your answer as an integer.",
        "explanation": "To solve this problem, you will need to iterate through all Python files in your home directory and its subdirectories. For each file, read through its lines, count only those that contain actual code (i.e., are not empty or do not solely contain comments). You can use tools like `find` to locate all Python files and `grep` or `awk` to process each file line-by-line.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use find to locate all .py files in the home directory recursively.\nfiles=$(find ~/ -type f -name \"*.py\")\n\n# Initialize a total line count variable.\ntotal_lines=0\n\n# Loop over each found file.\nfor file in $files; do\n  # Count non-empty, non-comment lines using grep.\n  # Add the number of such lines to total_lines.\n  count=$(grep -v '^\\s*$' \"$file\" | grep -v '^\\s*#' | wc -l)\n  total_lines=$((total_lines + count))\ndone\n\n# Output the total line count as the result.\necho $total_lines\n```",
        "create": {
            "init": "# No initialization required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use find to locate all .py files in the home directory recursively.\nfiles=$(find ~/ -type f -name \"*.py\")\n\n# Initialize a total line count variable.\ntotal_lines=0\n\n# Loop over each found file.\nfor file in $files; do\n  # Count non-empty, non-comment lines using grep.\n  # Add the number of such lines to total_lines.\n  count=$(grep -v '^\\s*$' \"$file\" | grep -v '^\\s*#' | wc -l)\n  total_lines=$((total_lines + count))\ndone\n\n# Output the total line count as the result.\necho $total_lines"
        }
    },
    {
        "description": "In your home directory, there are text files named `file1.txt`, `file2.txt`, ..., `file5.txt`. Each file contains several lines of text, and some lines are duplicated across the files. Your task is to find the total number of unique lines present in all these files combined.",
        "explanation": "To solve this problem, you need to read all lines from each file, combine them into a single list, and then determine the unique lines. You can use tools like `cat` to concatenate files, `sort` to sort the lines, and `uniq` to filter out duplicate entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd \"$HOME\"\ncat file1.txt file2.txt file3.txt file4.txt file5.txt | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p \"$HOME\"\ncat <<EOL > \"$HOME/file1.txt\"\napple\nbanana\norange\nEOL\n\ncat <<EOL > \"$HOME/file2.txt\"\nbanana\ngrape\napple\nEOL\n\ncat <<EOL > \"$HOME/file3.txt\"\npear\norange\ngrape\nEOL\n\ncat <<EOL > \"$HOME/file4.txt\"\nkiwi\nbanana\napple\nEOL\n\ncat <<EOL > \"$HOME/file5.txt\"\npeach\nplum\npear\nkiwi\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd \"$HOME\"\ncat file1.txt file2.txt file3.txt file4.txt file5.txt | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.system_logs` containing log entries of various system events. Each line in the file is a single log entry formatted as `YYYY-MM-DD HH:MM:SS [LEVEL] Message`, where `[LEVEL]` can be `INFO`, `WARNING`, or `ERROR`. Your task is to determine how many log entries are of level `ERROR` that occurred on weekends (Saturday and Sunday). You need to submit the count of such entries.",
        "explanation": "To solve this problem, first, you need to filter out all lines from the `.system_logs` file that contain \"ERROR\". Then, for each filtered line, extract the date part and determine whether it falls on a weekend. You can use the `date` command with appropriate flags to determine if a given date is a weekend. Finally, count all the entries that match these criteria.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Filter ERROR entries and check if they occur on weekends.\ngrep '\\[ERROR\\]' ~/.system_logs | while read -r line; do \n    # Extract date from log entry \n    log_date=$(echo $line | cut -d' ' -f1)\n    # Check if this date falls on a weekend using date command \n    day_of_week=$(date -d \"$log_date\" +%u)\n    # If it's Saturday (6) or Sunday (7), then count it\n    if [[ $day_of_week -eq 6 || $day_of_week -eq 7 ]]; then \n        echo $line \n    fi \ndone | wc -l # Count number of lines which are ERRORs on weekends.\n```",
        "create": {
            "init": "# Create .system_logs file with sample data\ncat <<EOL > ~/.system_logs\n2023-10-01 12:00:00 [INFO] System boot complete\n2023-10-02 14:30:22 [ERROR] Failed to connect to database\n2023-10-07 08:45:11 [WARNING] Low disk space\n2023-10-08 09:15:30 [ERROR] Network timeout\n2023-10-08 17:45:55 [ERROR] Authentication failure\n2023-10-09 11:22:33 [INFO] User login successful\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Filter ERROR entries and check if they occur on weekends.\ngrep '\\[ERROR\\]' ~/.system_logs | while read -r line; do \n    # Extract date from log entry \n    log_date=$(echo $line | cut -d' ' -f1)\n    # Check if this date falls on a weekend using date command \n    day_of_week=$(date -d \"$log_date\" +%u)\n    # If it's Saturday (6) or Sunday (7), then count it\n    if [[ $day_of_week -eq 6 || $day_of_week -eq 7 ]]; then \n        echo $line \n    fi \ndone | wc -l # Count number of lines which are ERRORs on weekends."
        }
    },
    {
        "description": "In your home directory, you will find a folder named `project_logs` containing multiple log files. Each log file follows the naming pattern `log_YYYYMMDD.txt`, and each line in the file starts with a timestamp followed by an error message string. Your task is to count how many lines across all log files contain the word \"ERROR\" (case-sensitive) and provide the total count.",
        "explanation": "To solve this problem, you need to iterate over all files in the `project_logs` directory that match the pattern `log_*.txt`. For each file, use tools like `grep` to filter out lines containing the word \"ERROR\". Then, aggregate these results to get a total count of lines with \"ERROR\" across all these files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -rh 'ERROR' ~/project_logs/log_*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"2023-10-01 12:00:00 ERROR: Disk full\\n2023-10-01 12:05:00 INFO: Cleanup started\" > ~/project_logs/log_20231001.txt\necho -e \"2023-10-02 13:00:00 WARNING: Low memory\\n2023-10-02 13:30:00 ERROR: Memory leak detected\" > ~/project_logs/log_20231002.txt\necho -e \"2023-10-03 14:00:00 ERROR: Network unreachable\\n2023-10-03 14:15:00 INFO: Network restored\" > ~/project_logs/log_20231003.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -rh 'ERROR' ~/project_logs/log_*.txt | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files named in the format \"logYYYYMMDD.txt\", where YYYY, MM, and DD represent the year, month, and day respectively. Each log file contains various system logs with timestamps. Your task is to count the number of unique IP addresses that appear across all log files within this directory. You may assume each line in the log files begins with an IP address.",
        "explanation": "To solve this problem, you need to iterate over all the log files within the \"logs\" directory and extract IP addresses from each line. You can use tools like `awk` or `grep` to extract IPs and then use `sort` and `uniq` to filter out duplicates. Finally, count the unique entries using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract all IPs from all log files and count unique entries\ncat ~/logs/log*.txt | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a logs directory in the user's home directory\nmkdir -p ~/logs\n\n# Create sample log files with some example data\necho -e \"192.168.0.1 Log entry 1\\n192.168.0.2 Log entry 2\\n192.168.0.1 Log entry 3\" > ~/logs/log20230101.txt\necho -e \"10.0.0.1 Log entry 4\\n192.168.0.2 Log entry 5\\n10.0.0.2 Log entry 6\" > ~/logs/log20230102.txt\necho -e \"172.16.0.1 Log entry 7\\n10.0.0.2 Log entry 8\\n172.16.0..1 Log entry 9\" > ~/logs/log20230103.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract all IPs from all log files and count unique entries\ncat ~/logs/log*.txt | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, which contains several text files with server log data. Each file's name is in the format \"server-YYYY-MM-DD.log\". Your task is to find out how many unique IP addresses have accessed the server across all log files. Assume each line in a file contains an IP address followed by other information.",
        "explanation": "To solve this problem, you need to read through all the \".log\" files in the \"logs\" directory and extract IP addresses from each line. You can use tools like `grep` or `awk` to extract the IP addresses and `sort` combined with `uniq` to count how many unique ones there are.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 - something\\n192.168.1.2 - something else\\n192.168.1.1 - repeat access\" > ~/logs/server-2023-01-01.log\necho -e \"10.0.0.1 - different network\\n192.168.1.3 - new address\\n192.168.1.2 - repeat access\" > ~/logs/server-2023-01-02.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory called \"logs\" in your home directory. This directory contains multiple log files named in the format \"app-log-YYYY-MM-DD.log\". Your task is to find out which day had the most number of log entries across all files. You should output the date in the format YYYY-MM-DD.",
        "explanation": "To solve this problem, you need to iterate through each log file, count the number of lines (each representing one log entry), and then determine which file has the highest count. The filename of that file will provide you with the date that had the most log entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\nmax_entries=0\nmax_date=\"\"\n\nfor logfile in ~/logs/*.log; do\n  entry_count=$(wc -l < \"$logfile\")\n  if (( entry_count > max_entries )); then\n    max_entries=$entry_count\n    max_date=$(basename \"$logfile\" .log | cut -d'-' -f3,4,5)\n  fi\ndone\n\necho $max_date\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"entry1\\nentry2\\nentry3\" > ~/logs/app-log-2023-10-01.log\necho -e \"entry1\\nentry2\" > ~/logs/app-log-2023-10-02.log\necho -e \"entry1\\nentry2\\nentry3\\nentry4\" > ~/logs/app-log-2023-10-03.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "max_entries=0\nmax_date=\"\"\n\nfor logfile in ~/logs/*.log; do\n  entry_count=$(wc -l < \"$logfile\")\n  if (( entry_count > max_entries )); then\n    max_entries=$entry_count\n    max_date=$(basename \"$logfile\" .log | cut -d'-' -f3,4,5)\n  fi\ndone\n\necho $max_date"
        }
    },
    {
        "description": "You have a directory called \"project_files\" in your home directory containing various files and subdirectories. Some of these files are duplicate copies with different names. Your task is to identify and count the number of unique files based on their content, regardless of their file names or locations within the \"project_files\" directory. You can assume that all files are text-based and not binary.",
        "explanation": "To solve this problem, you need to hash the contents of each file in the \"project_files\" directory recursively using a tool like `md5sum` or `sha256sum`. By storing these hashes, you can identify duplicates by checking for repeated hash values. Count how many unique hashes (and hence unique files) exist.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Navigate to project_files directory\ncd ~/project_files\n\n# Use find to locate all files and compute their hashes\nfind . -type f -exec md5sum {} + | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create project_files directory\nmkdir -p ~/project_files\n\n# Create example files with duplicate content\necho \"Hello World!\" > ~/project_files/file1.txt\necho \"Hello World!\" > ~/project_files/file2.txt\necho \"This is a test.\" > ~/project_files/subdir1/file3.txt\necho \"Another file content.\" > ~/project_files/subdir1/file4.txt\necho \"This is a test.\" > ~/project_files/subdir2/file5.txt\n\n# Duplicate some more files for complexity\nmkdir -p ~/project_files/subdir2/\ncp ~/project_files/file1.txt ~/project_files/subdir2/duplicate_of_file1.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Navigate to project_files directory\ncd ~/project_files\n\n# Use find to locate all files and compute their hashes\nfind . -type f -exec md5sum {} + | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there are several log files with the extension '.log'. Each log file records the activities of a service with timestamps. You need to find out which service has the most number of ERROR entries in its log files. The log files follow the naming convention 'service_name.log'. Count only lines that contain the word \"ERROR\" (case-sensitive). Output just the name of the service with the most ERRORs.",
        "explanation": "To solve this problem, you should:\n1. Identify all '.log' files in your home directory.\n2. For each file, count how many lines contain the word \"ERROR\".\n3. Determine which file has the highest count and extract its service name from its filename.\n4. Output only that service's name.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files and count ERROR occurrences, then determine which has the most errors.\nmax_errors=0\nservice_with_max_errors=\"\"\nfor logfile in ~/*.log; do\n  error_count=$(grep -c \"ERROR\" \"$logfile\")\n  if [ \"$error_count\" -gt \"$max_errors\" ]; then\n    max_errors=$error_count\n    service_with_max_errors=$(basename \"$logfile\" .log)\n  fi\ndone\n\n# Output just the name of the service with most ERRORs.\necho \"$service_with_max_errors\"\n```",
        "create": {
            "init": "# Create sample log files for different services in the user's home directory.\necho -e \"INFO: Service started\\nERROR: Connection failed\\nERROR: Timeout\" > ~/webserver.log\necho -e \"INFO: Backup initiated\\nERROR: Disk full\\nINFO: Backup complete\" > ~/backup.log\necho -e \"ERROR: Out of memory\\nERROR: Process crashed\\nERROR: Restarting process\" > ~/database.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "# Find all .log files and count ERROR occurrences, then determine which has the most errors.\nmax_errors=0\nservice_with_max_errors=\"\"\nfor logfile in ~/*.log; do\n  error_count=$(grep -c \"ERROR\" \"$logfile\")\n  if [ \"$error_count\" -gt \"$max_errors\" ]; then\n    max_errors=$error_count\n    service_with_max_errors=$(basename \"$logfile\" .log)\n  fi\ndone\n\n# Output just the name of the service with most ERRORs.\necho \"$service_with_max_errors\""
        }
    },
    {
        "description": "You are required to find the largest file by size within a directory named \"project_data\" located in your home directory. The directory contains multiple subdirectories and files. You must determine the name of this largest file, excluding directories from consideration.",
        "explanation": "To solve this problem, you need to recursively search through the \"project_data\" directory and its subdirectories for files, while excluding any directories from consideration. Use tools like `find` to list all files with their sizes, and then determine which file has the maximum size using tools like `sort` or `awk`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all files in the project_data directory and sort them by size in descending order,\n# then print the name of the largest one.\nfind ~/project_data -type f -exec du -b {} + | sort -n -r | head -n 1 | awk '{print $2}'\n```",
        "create": {
            "init": "# Create the project_data directory in the user's home\nmkdir -p ~/project_data/subdir1 ~/project_data/subdir2\n\n# Create some test files with different sizes\ndd if=/dev/zero of=~/project_data/file1.txt bs=1K count=10  # 10KB\ndd if=/dev/zero of=~/project_data/subdir1/file2.txt bs=1K count=20  # 20KB\ndd if=/dev/zero of=~/project_data/subdir2/file3.txt bs=1K count=30  # 30KB"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "# Find all files in the project_data directory and sort them by size in descending order,\n# then print the name of the largest one.\nfind ~/project_data -type f -exec du -b {} + | sort -n -r | head -n 1 | awk '{print $2}'"
        }
    },
    {
        "description": "You are given a directory called `logfiles` in your home directory, containing multiple log files with `.log` extension. Each file contains entries with timestamps and messages. Count the total number of unique error messages (lines starting with \"ERROR\") across all log files in this directory.",
        "explanation": "To solve this problem, you need to traverse through each file in the `logfiles` directory, filter out lines that start with \"ERROR\", and then determine the unique error messages from these lines. You can use tools like `grep` to filter lines and `sort` along with `uniq` to find unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^ERROR' ~/logfiles/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\ncat <<EOL > ~/logfiles/log1.log\nINFO 2023-10-01 Initialization complete.\nERROR 2023-10-01 Failed to load module.\nWARNING 2023-10-01 Low memory.\nERROR 2023-10-01 Failed to load module.\nEOL\n\ncat <<EOL > ~/logfiles/log2.log\nINFO 2023-10-02 User logged in.\nERROR 2023-10-02 Network connection lost.\nERROR 2023-10-02 Disk full.\nINFO 2023-10-02 User logged out.\nERROR 2023-10-02 Network connection lost.\nEOL\n\ncat <<EOL > ~/logfiles/log3.log\nWARNING 2023-10-03 Battery low.\nERROR 2023-10-03 Memory leak detected.\nINFO 2023-10-03 System shutting down.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^ERROR' ~/logfiles/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines across all text files in your home directory and its subdirectories that contain the word \"Linux\". You should only consider files with a \".txt\" extension and ignore case while searching for the word.",
        "explanation": "To solve this problem, you can use a combination of `find`, `grep`, and other utilities. First, use `find` to locate all \".txt\" files in your home directory and its subdirectories. Then, use `grep` with the appropriate options to search for lines containing the word \"Linux\", ignoring case. Finally, count these lines using tools like `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .txt files in the home directory and its subdirectories\n# Use grep to search for lines containing the word 'Linux', ignoring case\n# Count these lines\n\nfind ~ -type f -name \"*.txt\" -exec grep -iHn \"Linux\" {} + | wc -l\n```",
        "create": {
            "init": "# No initialization is required as it utilizes existing files in the student's home directory."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all .txt files in the home directory and its subdirectories\n# Use grep to search for lines containing the word 'Linux', ignoring case\n# Count these lines\n\nfind ~ -type f -name \"*.txt\" -exec grep -iHn \"Linux\" {} + | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, containing multiple log files with the extension \".log\". Each log file may contain entries with various error levels: INFO, WARNING, ERROR, and DEBUG. Your task is to count the total number of ERROR entries across all log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to iterate through each \".log\" file in the \"logs\" directory and count the lines that start with \"ERROR\". You can use tools like `grep` to filter these lines and `wc` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^ERROR' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO Start process\\nERROR Failed to start\\nDEBUG Verbose logging enabled\\nERROR Disk full\" > ~/logs/app1.log\necho -e \"WARNING Low memory\\nINFO Process running\\nERROR Network unreachable\\nERROR Timeout occurred\" > ~/logs/app2.log\necho -e \"DEBUG Checking status\\nINFO All systems go\\nWARNING Deprecated API used\" > ~/logs/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^ERROR' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You need to count the total number of lines across all `.txt` files located in the `/var/logs/` directory and its subdirectories without using any recursive flag in your command.",
        "explanation": "To solve this problem, you will need to find a way to traverse the directories and use the cat command to concatenate all text files together, then pipe this output into the wc command to count the lines. You can't use recursive flags like `-r`. Instead, you should explore using commands such as `find` or `xargs` to handle directory traversal.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/logs/ -name \"*.txt\" | xargs cat | wc -l\n```",
        "create": {
            "init": "mkdir -p /var/logs/subdir1 /var/logs/subdir2\necho \"Line 1\" > /var/logs/file1.txt\necho -e \"Line 1\\nLine 2\" > /var/logs/subdir1/file2.txt\necho -e \"Line 1\\nLine 2\\nLine 3\" > /var/logs/subdir2/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find /var/logs/ -name \"*.txt\" | xargs cat | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory, which contains multiple log files with the extension \".log\". Each log file contains various types of messages, including error messages that start with the prefix \"ERROR:\". Your task is to count the total number of unique error messages across all these log files. Note that the same error message may appear multiple times within a file or across different files, but you should only count unique instances.",
        "explanation": "To solve this problem, you need to read through each file in the \"logfiles\" directory and extract lines that start with \"ERROR:\". Use a combination of bash utilities like `grep` to filter these lines and `sort` and `uniq` to identify unique messages. Accumulate all unique error messages from each file into a single list and then determine the total count of distinct entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep \"^ERROR:\" ~/logfiles/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"INFO: System started\\nERROR: Disk failure\\nWARNING: Low memory\\nERROR: Disk failure\" > ~/logfiles/log1.log\necho -e \"ERROR: Network timeout\\nINFO: User login\\nERROR: Disk failure\\nERROR: Network timeout\" > ~/logfiles/log2.log\necho -e \"INFO: Update complete\\nERROR: Disk failure\\nWARNING: High CPU usage\" > ~/logfiles/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep \"^ERROR:\" ~/logfiles/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines across all `.txt` files located in a folder named `documents` within your home directory. Additionally, only count the lines that contain the word \"Linux\" (case-sensitive). You should not use any graphical user interface tools and must perform this task using shell commands.",
        "explanation": "To solve this problem, you need to navigate to the `documents` directory and use a combination of shell utilities. You can utilize `grep` to search for lines containing the word \"Linux\" and then pipe its output to `wc -l` to count those lines. Consider using a loop or a find command combined with xargs or similar utilities to handle multiple files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/documents -name \"*.txt\" -exec grep 'Linux' {} \\; | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/documents\necho -e \"Welcome to Linux.\\nThis is a test file.\" > ~/documents/file1.txt\necho -e \"Linux is great.\\nAnother line.\" > ~/documents/file2.txt\necho -e \"Just another line.\\nWithout Linux word.\" > ~/documents/file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/documents -name \"*.txt\" -exec grep 'Linux' {} \\; | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing the system logs in the `/var/log/` directory on your Linux (Ubuntu) system. Specifically, you need to determine how many unique IP addresses have attempted to access the system by parsing the `auth.log` file. You should consider only the entries that contain \"Failed password\" to count these IP addresses. Ensure that you do not count duplicate IPs more than once.",
        "explanation": "To solve this problem, you will need to:\n1. Locate and read the `auth.log` file within the `/var/log/` directory.\n2. Filter out lines containing \"Failed password\" attempts.\n3. Extract the IP addresses from these lines.\n4. Use a command or series of commands to ensure that each unique IP address is only counted once.\n\nHints:\n- Use `grep` to filter lines with \"Failed password\".\n- Use `awk` or `sed` along with `cut` for extracting IP addresses.\n- Utilize `sort` and `uniq` for counting unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Command sequence to find and count unique IPs attempting failed logins\ngrep \"Failed password\" /var/log/auth.log | awk '{print $11}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# This script simulates an environment where there are some failed login attempts in auth.log\nmkdir -p /var/log/\ncat <<EOL > /var/log/auth.log\nOct 10 10:00:00 ubuntu sshd[12345]: Failed password for invalid user admin from 192.168.0.1 port 22 ssh2\nOct 10 10:01:00 ubuntu sshd[12346]: Failed password for invalid user test from 192.168.0.2 port 22 ssh2\nOct 10 10:02:00 ubuntu sshd[12347]: Failed password for invalid user admin from 192.168.0.1 port 22 ssh2\nOct 10 10:03:00 ubuntu sshd[12348]: Failed password for invalid user guest from 192.168.0.3 port 22 ssh2\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Command sequence to find and count unique IPs attempting failed logins\ngrep \"Failed password\" /var/log/auth.log | awk '{print $11}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"project_files\" in your home directory containing various files and subdirectories. Your task is to find the total number of lines across all `.txt` files within this directory and its subdirectories. You must only count lines from files modified in the last 7 days.",
        "explanation": "To solve this problem, you need to use a combination of `find`, `xargs`, and `wc` commands. Start by using the `find` command to locate all `.txt` files within the \"project_files\" directory that have been modified in the last 7 days. Then, use `xargs` to pass these files to the `wc -l` command to count their lines collectively.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/project_files -name \"*.txt\" -mtime -7 | xargs wc -l | tail -n1 | awk '{print $1}'\n```",
        "create": {
            "init": "mkdir -p ~/project_files/subdir1 ~/project_files/subdir2\necho \"Line 1\\nLine 2\\nLine 3\" > ~/project_files/file1.txt\necho \"Line 1\\nLine 2\" > ~/project_files/file2.txt\necho \"Line 1\\nLine 2\\nLine 3\\nLine 4\" > ~/project_files/subdir1/file3.txt\ntouch -d \"10 days ago\" ~/project_files/subdir2/old_file.txt\necho \"Old line\" > ~/project_files/subdir2/old_file.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/project_files -name \"*.txt\" -mtime -7 | xargs wc -l | tail -n1 | awk '{print $1}'"
        }
    },
    {
        "description": "You need to determine the total number of lines across all text files (.txt) in a directory named \"documents\" located in your home directory. Additionally, filter out any files containing the word \"secret\" and exclude those from your count.",
        "explanation": "To solve this problem, you will need to navigate to the \"documents\" directory and use a combination of commands to identify all .txt files. You'll then read through each file using a command like `grep` to check for the presence of the word \"secret\". If a file does not contain this word, you'll count its lines with `wc -l` and sum up the results for all valid files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/documents\ntotal_lines=0\n\nfor file in *.txt; do\n  if ! grep -q 'secret' \"$file\"; then\n    lines=$(wc -l < \"$file\")\n    total_lines=$((total_lines + lines))\n  fi\ndone\n\necho $total_lines\n```",
        "create": {
            "init": "mkdir -p ~/documents\necho -e \"Hello\\nWorld\" > ~/documents/file1.txt\necho -e \"This is\\na secret document\" > ~/documents/file2.txt\necho -e \"Another\\nfile without secrets\" > ~/documents/file3.txt\necho -e \"Secret\\ninformation here\" > ~/documents/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/documents\ntotal_lines=0\n\nfor file in *.txt; do\n  if ! grep -q 'secret' \"$file\"; then\n    lines=$(wc -l < \"$file\")\n    total_lines=$((total_lines + lines))\n  fi\ndone\n\necho $total_lines"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory, which contains multiple log files with the extension \".log\". Each log file contains multiple lines, and each line represents a log entry that starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to identify the day (YYYY-MM-DD) that has the highest number of log entries across all \".log\" files and output that date. If there is a tie, return any one of the dates.",
        "explanation": "To solve this problem, you should first concatenate all the \".log\" files in the \"logs\" directory. Then, extract just the date portion from each line, tally up occurrences for each date, and identify which date appears most frequently. You can use utilities such as `cat`, `awk`, `sort`, `uniq`, and `head` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOF > ~/logs/log1.log\n2023-10-01 12:00:00 Entry 1\n2023-10-01 13:00:00 Entry 2\n2023-10-02 14:30:00 Entry 3\nEOF\n\ncat <<EOF > ~/logs/log2.log\n2023-10-01 15:45:00 Entry A\n2023-10-03 16:50:00 Entry B\n2023-10-03 17:55:00 Entry C\nEOF\n\ncat <<EOF > ~/logs/log3.log\n2023-10-02 18:15:00 Entry X\n2023-10-02 19:20:00 Entry Y\n2023-10-03 20:25:00 Entry Z\nEOF"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'"
        }
    },
    {
        "description": "You have been given a directory named \"log_files\" in your home directory. This directory contains multiple log files with a \".log\" extension, and each file contains lines of text where some lines contain the word \"ERROR\". Your task is to count the total number of lines across all files in this directory that contain the word \"ERROR\". You should consider case-sensitive matches only.",
        "explanation": "To solve this problem, you can utilize the `grep` command to search for lines containing the word \"ERROR\" in each log file. The `-c` option can be used to count matches per file. Finally, sum up these counts to get the total number of error lines across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -rwc 'ERROR' ~/log_files/*.log | awk -F ':' '{sum += $2} END {print sum}'\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"INFO: System started\\nERROR: Failed to load module\\nINFO: Module loaded successfully\" > ~/log_files/system.log\necho -e \"DEBUG: Initializing\\nERROR: Connection timed out\\nINFO: Connection established\" > ~/log_files/network.log\necho -e \"ERROR: Disk full\\nWARNING: Low memory\\nINFO: Cleanup started\" > ~/log_files/storage.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -rwc 'ERROR' ~/log_files/*.log | awk -F ':' '{sum += $2} END {print sum}'"
        }
    },
    {
        "description": "In your home directory, there is a hidden directory named `.logs` containing various log files with the extension `.log`. Each log file contains multiple lines, some of which start with the word \"ERROR\". Your task is to determine how many unique error messages exist across all log files. For this problem, consider only the text following the first occurrence of \"ERROR\" in each line as the error message. You need to present the count of these unique error messages.",
        "explanation": "To solve this problem, you need to:\n1. Navigate to your home directory and locate the hidden `.logs` directory.\n2. Use a combination of shell commands to read each `.log` file in this directory.\n3. Extract lines that contain \"ERROR\" and isolate the text following it as the error message.\n4. Collect all unique error messages from these files.\n5. Count how many distinct error messages there are.\n\nHints:\n- Use `grep` to filter lines containing \"ERROR\".\n- Use `cut` or `awk` to extract just the part after \"ERROR\".\n- Use `sort` and `uniq` to find distinct messages.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/.logs -type f -name '*.log' | xargs grep 'ERROR' | cut -d' ' -f2- | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/'.logs'\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nWARNING: High memory usage\\nERROR: Disk space low\" > ~/.logs/system1.log\necho -e \"ERROR: Network unreachable\\nINFO: Backup completed\\nERROR: Disk space low\" > ~/.logs/system2.log\necho -e \"WARNING: CPU temperature high\\nERROR: Unauthorized access attempt\\nERROR: Network unreachable\" > ~/.logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/.logs -type f -name '*.log' | xargs grep 'ERROR' | cut -d' ' -f2- | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have been given a directory named `logfiles` in your home directory. This directory contains multiple log files with a `.log` extension. Each log file consists of timestamped entries, and each entry is tagged with either \"ERROR\", \"WARNING\", or \"INFO\". Your task is to count the total number of \"ERROR\" entries across all the log files in the `logfiles` directory and provide the count as your answer.",
        "explanation": "To solve this problem, you need to navigate to the `logfiles` directory and process each `.log` file to count how many lines contain the word \"ERROR\". You can use tools like `grep` to search for occurrences of \"ERROR\" and `wc -l` to count the lines. Summing up these counts from all files will give you the total number of \"ERROR\" entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h 'ERROR' ~/logfiles/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-10-01 12:00:00 INFO Starting process\\n2023-10-01 12:05:00 ERROR Failed to start\\n2023-10-01 12:10:00 INFO Process running\" > ~/logfiles/system1.log\necho -e \"2023-10-02 14:00:00 WARNING Low disk space\\n2023-10-02 14:05:00 ERROR Out of memory\\n2023-10-02 14:15:00 ERROR Disk error\" > ~/logfiles/system2.log\necho -e \"2023-10-03 16:20:00 INFO Connection established\\n2023-10-03 16:25:00 ERROR Timeout occurred\" > ~/logfiles/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h 'ERROR' ~/logfiles/*.log | wc -l"
        }
    },
    {
        "description": "You need to determine how much disk space in total is used by all files with a \".log\" extension located within the \"/var/log\" directory and its subdirectories. Output the total size in human-readable format (e.g., KB, MB).",
        "explanation": "To solve this problem, you can use the `find` command to locate all files with a \".log\" extension within the \"/var/log\" directory and its subdirectories. Then, use the `du` command to calculate their total size and format it in a human-readable way using `-h` flag. You might want to consider piping these commands together efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files in /var/log and its subdirectories, calculate their total size.\nfind /var/log -type f -name \"*.log\" -exec du -ch {} + | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "# No initialization script needed as /var/log is a standard directory on Linux systems."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "# Find all .log files in /var/log and its subdirectories, calculate their total size.\nfind /var/log -type f -name \"*.log\" -exec du -ch {} + | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "You are given a directory named \"project_logs\" in your home directory, which contains multiple log files with the extension \".log\". Each log file contains timestamps and error messages. Find the total number of unique error messages across all log files in this directory. Assume each error message starts with the keyword \"ERROR:\" followed by the message text until the end of the line.",
        "explanation": "To solve this problem, you need to navigate to the \"project_logs\" directory and use various bash commands to extract lines containing error messages from each \".log\" file. Then, you can combine these lines into a single list, remove duplicates using appropriate utilities, and count how many unique messages remain. Tools like `grep`, `sort`, `uniq`, and `wc` will be useful for this task.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'ERROR:' ~/project_logs/*.log | sed 's/.*ERROR://g' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"2023-03-01 12:00:00 INFO: System started\\n2023-03-01 12:05:00 ERROR: Disk not found\\n2023-03-01 12:10:00 ERROR: Network timeout\" > ~/project_logs/server1.log\necho -e \"2023-03-02 13:00:00 INFO: Backup completed\\n2023-03-02 13:15:00 ERROR: Network timeout\\n2023-03-02 13:20:00 ERROR: User authentication failed\" > ~/project_logs/server2.log\necho -e \"2023-03-03 14:00:00 INFO: Maintenance mode enabled\\n2023-03-03 14:30:00 ERROR: Disk not found\\n2023-03-03 14:40:00 ERROR: Low memory warning\" > ~/project_logs/server3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'ERROR:' ~/project_logs/*.log | sed 's/.*ERROR://g' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Determine the total disk usage in human-readable format of all files that have been modified in the last 7 days within a directory named \"weekly_reports\" located in your home directory. You must exclude any subdirectories from this calculation.",
        "explanation": "To solve this problem, you need to use the `find` command to locate files modified within the last 7 days and then use `du` to calculate their disk usage. The `-type f` option with `find` ensures that only files are selected, excluding directories. Finally, use the `-h` option with `du` to display the size in a human-readable format.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script to find and calculate total disk usage of recent files\n\n# Use find command to get list of recently modified files, excluding directories.\nrecent_files=$(find ~/weekly_reports -type f -mtime -7)\n\n# Use du command to calculate total human-readable disk usage of these files.\ndu -ch $recent_files | grep total | awk '{print $1}'\n```",
        "create": {
            "init": "# Create a directory named \"weekly_reports\" in the user's home directory\nmkdir -p ~/weekly_reports\n\n# Create some sample files with modification times within and beyond 7 days\ntouch ~/weekly_reports/file1.txt\ntouch ~/weekly_reports/file2.txt\nsleep 2\ntouch -d '8 days ago' ~/weekly_reports/old_file.txt\n\n# Add some content to change file sizes \necho \"This is a test file.\" > ~/weekly_reports/file1.txt\necho \"Another test file here.\" > ~/weekly_reports/file2.txt\necho \"An old file that should not be counted.\" > ~/weekly_reports/old_file.txt\n\n# Wait for timestamps to ensure proper ordering if needed (not strictly necessary)\nsleep 1"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "# Example solution script to find and calculate total disk usage of recent files\n\n# Use find command to get list of recently modified files, excluding directories.\nrecent_files=$(find ~/weekly_reports -type f -mtime -7)\n\n# Use du command to calculate total human-readable disk usage of these files.\ndu -ch $recent_files | grep total | awk '{print $1}'"
        }
    },
    {
        "description": "You are provided with a directory named \"log_files\" containing multiple log files with different extensions. Your task is to determine the total number of unique IP addresses that have accessed the system by analyzing all the log files in this directory. Restrict your search to files with a \".log\" extension only.",
        "explanation": "To solve this problem, you need to filter out files with the \".log\" extension in the \"log_files\" directory and extract IP addresses from these files. You can use tools like `grep` with regular expressions to find potential IP patterns and `sort` combined with `uniq` to count unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -hoE '[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' log_files/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p log_files\necho -e \"192.168.1.1 - - [10/Oct/2023:13:55:36] \\\"GET /index.html HTTP/1.0\\\"\\n192.168.1.2 - - [10/Oct/2023:13:56:01] \\\"POST /form HTTP/1.0\\\"\\n192.168.1.3 - - [10/Oct/2023:13:56:14] \\\"GET /image.png HTTP/1.0\\\"\\n192.168.1.1 - - [10/Oct/2023:13:57:19] \\\"GET /index.html HTTP/1.0\\\"\" > log_files/access.log\necho -e \"192.168.2.4 - - [11/Oct/2023:09:12:45] \\\"GET /about.html HTTP/1.\\n0\\\"\\n192.168.2.5\\n- 11\\n- 192\\n- 168\\n- 2\\n- 6\\n\" > log_files/error.log\necho \"This file should be ignored as it does not have .log extension\" > log_files/readme.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -hoE '[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' log_files/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"project_files\" which contains various files and subdirectories. Count the total number of lines across all \".txt\" files within this directory and its subdirectories, excluding any lines that contain only whitespace or are blank.",
        "explanation": "To solve this problem, you need to find all \".txt\" files in the \"project_files\" directory recursively. You can use the `find` command to locate these files. Then, for each file, you can use `grep` with a suitable pattern to exclude lines that are blank or contain only whitespace. Finally, sum up the line counts for each file using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/project_files -type f -name \"*.txt\" | xargs grep -v '^\\s*$' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_files/subdir1\nmkdir -p ~/project_files/subdir2\n\necho -e \"Line1\\nLine2\\n\\n  \\nLine3\" > ~/project_files/file1.txt\necho -e \"\\n\\nLine4\\nLine5\\n  \" > ~/project_files/file2.txt\necho -e \"Only one line here\" > ~/project_files/subdir1/file3.txt\necho -e \"\\n   \\nAnother line\\nAnd another one\" > ~/project_files/subdir2/file4.txt\n\ntouch ~/project_files/README.md"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~/project_files -type f -name \"*.txt\" | xargs grep -v '^\\s*$' | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory, which contains multiple text files. Each text file represents application logs with timestamps. Your task is to count the total number of unique dates (in the format YYYY-MM-DD) present across all log files in the \"logfiles\" directory. You are required to use command-line utilities to achieve this.",
        "explanation": "To solve this problem, you need to extract dates from each log file and ensure they are unique before counting them. This can be done by using tools like `grep` or `awk` to extract date patterns, followed by `sort` and `uniq` to filter out duplicates, and finally using `wc -l` to count the unique lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oE '\\b[0-9]{4}-[0-9]{2}-[0-9]{2}\\b' ~/logfiles/* | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho -e \"2023-10-01 12:00:01 Application started\\n2023-10-02 13:05:22 User logged in\\n2023-10-03 14:00:55 Error occurred\" > ~/logfiles/log1.txt\necho -e \"2023-10-02 15:25:33 Task executed\\n2023-10-03 16:45:12 Application stopped\\n2023-10-04 17:35:44 Data saved\" > ~/logfiles/log2.txt\necho -e \"2023-09-30 18:20:11 Backup completed\\n2023-10-01 19:15:41 User logged out\" > ~/logfiles/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oE '\\b[0-9]{4}-[0-9]{2}-[0-9]{2}\\b' ~/logfiles/* | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" containing multiple text files with server logs. Each log entry in these files is on a new line and follows the format: `[timestamp] [log level] [message]`. Your task is to count the number of log entries with the log level \"ERROR\" across all files in the \"logs\" directory. You should only consider files that have a \".log\" extension.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and find all files ending with \".log\". You can use `grep` to search for lines that contain the word \"ERROR\". The `wc -l` command will be useful for counting the number of matching lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind logs -name \"*.log\" -exec grep -c \"ERROR\" {} + | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "mkdir -p logs\necho \"[2023-10-01 10:00:00] INFO Server started\" > logs/server1.log\necho \"[2023-10-01 10:05:00] ERROR Failed to connect to database\" >> logs/server1.log\necho \"[2023-10-01 11:00:00] WARN Disk space low\" >> logs/server1.log\necho \"[2023-10-01 11:30:00] ERROR Timeout reached\" >> logs/server1.log\n\necho \"[2023-10-02 09:15:00] INFO User logged in\" > logs/server2.log\necho \"[2023-10-02 09:20:00] ERROR Access denied for user 'guest'\" >> logs/server2.log\n\necho \"[2023-10-03 14:45:00] INFO Scheduled backup completed\" > logs/backup.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find logs -name \"*.log\" -exec grep -c \"ERROR\" {} + | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "You are given a directory named `logs` in your home directory containing multiple `.log` files. Each file consists of server logs with each line starting with a timestamp in the format `YYYY-MM-DD HH:MM:SS` followed by log details. Your task is to identify which day had the maximum number of log entries across all files in the `logs` directory and output that date in `YYYY-MM-DD` format.",
        "explanation": "To solve this problem, you need to perform several steps:\n1. Navigate to the `logs` directory.\n2. Extract all timestamps from each `.log` file.\n3. Count how many entries belong to each day.\n4. Determine which day has the highest number of entries.\n5. Output that date.\n\nYou can use tools like `grep`, `awk`, or `sed` to extract and manipulate data, and utilities like `sort`, `uniq`, and `cut` for counting and sorting.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\n\n# Extract dates from all log files, count occurrences, sort them numerically, find the max occurrence date.\ngrep -h '^[0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\}' *.log | cut -d' ' -f1 | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/server1.log\n2023-10-01 12:00:01 User login\n2023-10-01 12:05:23 Error occurred\n2023-10-02 13:15:42 File uploaded\n2023-10-02 14:22:11 User logout\nEOL\n\ncat <<EOL > ~/logs/server2.log\n2023-10-01 09:00:00 Service started\n2023-10-03 11:30:59 Disk space low\n2023-10-03 12:45:00 Backup completed\nEOL\n\ncat <<EOL > ~/logs/server3.log\n2023-10-02 08:30:15 System rebooted\n2023-10-02 11:45:33 Network issue resolved\n2023-10-03 17:00:25 User login failed\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "cd ~/logs\n\n# Extract dates from all log files, count occurrences, sort them numerically, find the max occurrence date.\ngrep -h '^[0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\}' *.log | cut -d' ' -f1 | sort | uniq -c | sort -nr | head -n1 | awk '{print $2}'"
        }
    },
    {
        "description": "You have been given a directory named `log_files` that contains multiple `.log` files. Each log file contains lines with timestamps and messages in the format `[YYYY-MM-DD HH:MM:SS] message`. Your task is to find out how many unique dates (in YYYY-MM-DD format) appear across all the log files in this directory.",
        "explanation": "To solve this problem, you need to extract the date part from each line of every `.log` file in the `log_files` directory, collect these dates, and determine the number of unique dates. This can be achieved by using commands like `grep`, `cut`, `sort`, and `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -oP '\\[\\d{4}-\\d{2}-\\d{2}' log_files/*.log | cut -c2- | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p log_files\necho -e \"[2023-10-01 12:00:00] Log entry one\\n[2023-10-01 13:30:00] Log entry two\" > log_files/file1.log\necho -e \"[2023-10-02 09:15:00] Another entry\\n[2023-10-03 11:45:00] Yet another entry\" > log_files/file2.log\necho -e \"[2023-10-03 14:00:00] More logs\\n[2023-10-04 08:20:00] Final log\" > log_files/file3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -oP '\\[\\d{4}-\\d{2}-\\d{2}' log_files/*.log | cut -c2- | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the top three largest files in terms of size within the \"/var/log\" directory and its subdirectories. You must output just their file names, one per line, sorted by size in descending order. Make sure to account for hidden files as well.",
        "explanation": "To solve this problem, you can use a combination of `find` to list all files including those in subdirectories, `du` or `ls` to get their sizes, and `sort` to arrange them by size. Finally, use `head` to select the top three results. Ensure that your command considers both regular and hidden files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind /var/log -type f -exec du -b {} + | sort -nr | head -n 3 | awk '{print $2}'\n```",
        "create": {
            "init": "# Create some log files with varying sizes for testing\nmkdir -p /var/log/test_logs\ndd if=/dev/zero of=/var/log/test_logs/log1.log bs=1M count=2\ndd if=/dev/zero of=/var/log/test_logs/.hidden_log.log bs=1M count=3\ndd if=/dev/zero of=/var/log/test_logs/subdir/log2.log bs=1M count=5\nmkdir -p /var/log/test_logs/subdir\ndd if=/dev/zero of=/var/log/test_logs/subdir/.private_log.log bs=1M count=4"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "find /var/log -type f -exec du -b {} + | sort -nr | head -n 3 | awk '{print $2}'"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.log_records` that contains log entries of various system activities. Each entry is on a new line and starts with a timestamp in the format `YYYY-MM-DD HH:MM:SS`. Your task is to find out how many log entries were made during the month of March 2023.",
        "explanation": "To solve this problem, you need to filter the log entries based on their timestamp. Specifically, you should look for entries where the date matches March 2023 (i.e., the year is 2023 and the month is 03) and then count these filtered entries. You can use tools like `grep`, `awk`, or `sed` to achieve this.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Use grep to filter and wc to count lines matching March 2023\ngrep \"^2023-03\" ~/.log_records | wc -l\n```",
        "create": {
            "init": "# Create a hidden file with sample log data in the user's home directory\ncat <<EOL > ~/.log_records\n2023-03-01 12:00:00 User login\n2023-03-15 14:23:45 System update\n2023-04-10 09:30:22 File accessed\n2022-12-25 18:45:30 User logout\n2023-03-20 07:50:10 Disk cleanup\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Use grep to filter and wc to count lines matching March 2023\ngrep \"^2023-03\" ~/.log_records | wc -l"
        }
    },
    {
        "description": "Find the total number of unique IP addresses that have attempted to access the server and logged in the file `/var/log/server_access.log`. Ignore any IPv6 addresses. You should count only IPv4 addresses.",
        "explanation": "To solve this problem, you need to filter out only the IPv4 addresses from the log file. Since IPv4 addresses consist of four numbers separated by dots (e.g., 192.168.1.1), you can use a regular expression to match these patterns. After extracting these addresses, remove duplicates and count the unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract all IPv4 addresses from the log file, sort them, remove duplicates, and count unique entries.\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' /var/log/server_access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample log file with mixed IP addresses\ncat <<EOL > /var/log/server_access.log\n192.168.1.1 - - [01/Jan/2023:10:00:00 +0000] \"GET / HTTP/1.1\" 200 2326\n2001:0db8:85a3:0000:0000:8a2e:0370:7334 - - [01/Jan/2023:10:05:00 +0000] \"POST /login HTTP/1.1\" 401 4985\n172.16.254.2 - - [01/Jan/2023:10:10:00 +0000] \"GET /dashboard HTTP/1.1\" 200 1234\n203.0.113.44 - - [01/Jan/2023:10:15:00 +0000] \"GET /settings HTTP/1.1\" 404 2345\n198.51.100.23 - - [01/Jan/2023:10:20:00 +0000] \"PUT /upload HTTP/1.1\" 201 6789\n203.0.113.44 - - [01/Jan/2023:10:25:00 +0000] \"DELETE /file.txt HTTP/1.1\" 204 -\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract all IPv4 addresses from the log file, sort them, remove duplicates, and count unique entries.\ngrep -oE '\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b' /var/log/server_access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named \".inventory\" which contains a list of items and their quantities in the format \"item_name:quantity\". Your task is to find out the total number of unique items listed in this file. Assume that item names are case-sensitive.",
        "explanation": "To solve this problem, you need to read the \".inventory\" file located in your home directory and count the number of distinct item names. You can use tools like `cat`, `cut`, `awk`, or `sort` to process the file content and extract unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Read the .inventory file, cut out item names, and find unique entries.\ncat ~/.inventory | cut -d':' -f1 | sort | uniq | wc -l\n```",
        "create": {
            "init": "echo -e \"apple:10\\nbanana:5\\nOrange:7\\napple:3\\ngrapes:12\\nBanana:2\\ncherry:15\" > ~/.inventory"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Read the .inventory file, cut out item names, and find unique entries.\ncat ~/.inventory | cut -d':' -f1 | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"system_logs\" in your home directory containing various log files with a \".log\" extension. Each log file records system events with timestamps. Your task is to find the total number of unique dates on which events were recorded across all log files in this directory. Assume each line in the log files begins with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". You need to count how many distinct dates are present.",
        "explanation": "To solve this problem, you need to extract the date part from each line's timestamp in the log files, collect all unique dates, and then count them. You can use tools like `awk` or `cut` to extract the date, `sort` and `uniq` for finding unique entries, and `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract dates from all logs, find unique ones, and count them.\nfind ~/system_logs -type f -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create system_logs directory and some sample log files with timestamps.\nmkdir -p ~/system_logs\necho -e \"2023-10-01 12:00:00 Event1\\n2023-10-01 13:45:23 Event2\" > ~/system_logs/log1.log\necho -e \"2023-10-02 09:15:47 Event3\\n2023-10-01 17:30:00 Event4\" > ~/system_logs/log2.log\necho -e \"2023-10-03 11:00:22 Event5\\n2023-10-02 14:05:55 Event6\" > ~/system_logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract dates from all logs, find unique ones, and count them.\nfind ~/system_logs -type f -name \"*.log\" | xargs cat | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You need to calculate the total size of all \".log\" files in the \"/var/log\" directory and its subdirectories, and output the result in human-readable format (e.g., 3MB or 3072KB).",
        "explanation": "To solve this problem, you should use the `find` command to locate all \".log\" files within \"/var/log\" and its subdirectories. Then, use `du` with appropriate flags to calculate and sum up their sizes in human-readable format. Finally, use tools like `awk` or `sort` if needed to adjust the output format.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all .log files and calculate their total size.\nfind /var/log -type f -name \"*.log\" -exec du -ch {} + | grep total$ | awk '{print $1}'\n```",
        "create": {
            "init": "# No initialization is required for this problem."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "# Find all .log files and calculate their total size.\nfind /var/log -type f -name \"*.log\" -exec du -ch {} + | grep total$ | awk '{print $1}'"
        }
    },
    {
        "description": "You have been given a directory named \"log_files\" in your home directory that contains multiple log files. Each log file has entries in the format: \"YYYY-MM-DD HH:MM:SS [LOG_LEVEL] Message\". Your task is to count how many times the log level \"ERROR\" appears across all the files in this directory. Assume each line contains only one log entry.",
        "explanation": "To solve this problem, you need to iterate over each file in the \"log_files\" directory and search for lines containing \"[ERROR]\". You can use tools like `grep` to filter these lines and then use `wc -l` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r \"\\[ERROR\\]\" ~/log_files | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-10-01 12:00:00 [INFO] Application started\\n2023-10-01 12:05:00 [ERROR] Failed to load configuration\\n2023-10-01 12:10:00 [DEBUG] Debugging mode on\" > ~/log_files/log1.txt\necho -e \"2023-10-02 14:00:00 [ERROR] Connection timeout\\n2023-10-02 14:05:00 [INFO] Retrying connection\\n2023-10-02 14:15:00 [ERROR] Connection failed again\" > ~/log_files/log2.txt\necho -e \"2023-10-03 16:20:00 [WARN] Low memory\\n2023-10-03 16:25:00 [ERROR] Memory allocation failed\\n2023-10-03 16:30:00 [INFO] Resource cleanup initiated\" > ~/log_files/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r \"\\[ERROR\\]\" ~/log_files | wc -l"
        }
    },
    {
        "description": "You are given a directory named `logs` in your home directory, which contains multiple text files with various log entries. Each log entry starts with a timestamp in the format `[YYYY-MM-DD HH:MM:SS]`. Your task is to find the number of unique dates (in YYYY-MM-DD format) across all log files that contain at least one entry with the word \"ERROR\". Assume all logs are properly formatted.",
        "explanation": "To solve this problem, you need to perform several steps:\n1. Navigate to the `logs` directory within your home directory.\n2. Use a combination of `grep` to search for lines containing \"ERROR\" and extract their timestamps.\n3. Extract only the date part from these timestamps.\n4. Sort and count unique dates using utilities like `sort`, `uniq`, or similar.\n\nHints:\n- You can use `grep` with appropriate flags to extract lines containing \"ERROR\".\n- Consider piping commands together to streamline filtering and processing.\n- Use tools like `awk`, `cut`, or regular expressions to isolate the date component.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h \"ERROR\" ~/logs/*.txt | grep -oP '\\[\\K\\d{4}-\\d{2}-\\d{2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/log1.txt\n[2023-10-01 10:00:00] INFO Starting process\n[2023-10-01 10:05:00] ERROR Failed operation\n[2023-10-02 11:00:00] INFO Process running\nEOL\n\ncat <<EOL > ~/logs/log2.txt\n[2023-10-02 12:00:00] ERROR Connection lost\n[2023-10-03 13:30:00] INFO Process stopped\nEOL\n\ncat <<EOL > ~/logs/log3.txt\n[2023-10-01 14:15:00] WARN Low memory\n[2023-10-03 15:45:00] ERROR Disk full\n[2023-10-04 16:50:00] INFO Backup completed\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h \"ERROR\" ~/logs/*.txt | grep -oP '\\[\\K\\d{4}-\\d{2}-\\d{2}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the \".log\" extension. Each log file contains lines formatted as \"YYYY-MM-DD HH:MM:SS [LOG_LEVEL] Message\". Your task is to count how many error messages (\"[ERROR]\") are recorded across all log files in the \"logs\" directory and submit this count.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory and use a combination of command-line utilities such as `grep` to search for lines containing \"[ERROR]\", then `wc -l` to count these lines. This requires understanding of file pattern matching and text processing tools available in Linux.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Count the number of '[ERROR]' occurrences across all .log files in 'logs'\ngrep -r '\\[ERROR\\]' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create 'logs' directory in the user's home directory\nmkdir -p ~/logs\n\n# Create sample log files with various entries\ncat <<EOL > ~/logs/system1.log\n2023-10-01 12:00:01 [INFO] System booted successfully.\n2023-10-01 12:05:15 [ERROR] Failed to load module.\n2023-10-01 12:10:20 [WARN] Low memory detected.\n2023-10-01 12:15:30 [ERROR] Device not responding.\nEOL\n\ncat <<EOL > ~/logs/system2.log\n2023-10-02 11:00:01 [INFO] Scheduled job started.\n2023-10-02 11:05:15 [DEBUG] Debugging mode enabled.\n2023-10-02 11:15:30 [ERROR] Disk read error occurred.\nEOL\n\ncat <<EOL > ~/logs/system3.log\n2023-10-03 09:00:01 [INFO] Backup completed successfully.\n2023-10-03 09:05:20 [ERROR] Network connection lost.\n2023-10-03 09:15:45 [ERROR] Out of memory.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Count the number of '[ERROR]' occurrences across all .log files in 'logs'\ngrep -r '\\[ERROR\\]' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the total number of lines of code in all Python (.py) files within a directory named \"projects\" and its subdirectories. You must exclude any lines that are comments (lines starting with #) or empty. Navigate through the directories, count the relevant lines, and provide the final count.",
        "explanation": "To solve this problem, you need to recursively search through the \"projects\" directory for all Python files. Use tools like `find` to locate these files, then use `grep` or `awk` to filter out comment and empty lines while counting the remaining lines. Summing up these counts will give you the total line count.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind projects -name '*.py' | xargs grep -v '^\\s*#' | grep -v '^\\s*$' | wc -l\n```",
        "create": {
            "init": "mkdir -p projects/subdir1 projects/subdir2\necho -e \"# This is a comment\\nprint('Hello World')\\n\\n# Another comment\" > projects/file1.py\necho -e \"import os\\n\\n# Comment line\\nprint('OS module imported')\" > projects/subdir1/file2.py\necho -e \"# Full comment file\\n# Another comment\" > projects/subdir2/file3.py"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find projects -name '*.py' | xargs grep -v '^\\s*#' | grep -v '^\\s*$' | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing numerous log files with the extension \".log\". Each log file contains multiple entries, each with a timestamp followed by a message. Your task is to count how many unique messages appear in these log files within the last 24 hours. You should consider timestamps in the format \"YYYY-MM-DD HH:MM:SS\" and assume that all timestamps are in UTC.",
        "explanation": "To solve this problem, you need to:\n1. Find the current date and time using `date` command.\n2. Calculate the date and time for 24 hours ago.\n3. Iterate through each log file in the \"logs\" directory.\n4. Extract entries from each log file that fall within the last 24 hours based on their timestamp.\n5. Collect and count unique messages from these entries.\n\nHint: You can make use of tools like `awk` or `sed` to parse timestamps and filter logs, as well as `sort` and `uniq` to find unique messages.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncurrent_time=$(date -u +\"%Y-%m-%d %H:%M:%S\")\npast_time=$(date -u --date=\"24 hours ago\" +\"%Y-%m-%d %H:%M:%S\")\ngrep_pattern=\"$(echo $past_time | awk '{print $1}')|$(echo $current_time | awk '{print $1}')\"\nfind ~/logs -name \"*.log\" | xargs cat | awk -v start=\"$past_time\" -v end=\"$current_time\" '\n{\n    if ($0 >= start && $0 <= end) {\n        sub(/^[0-9:-]+\\s/, \"\", $0);\n        print $0;\n    }\n}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-02 14:00:01 User logged in\\n2023-10-02 15:00:01 User logged out\\n2023-10-03 12:30:00 User logged in again\" > ~/logs/log1.log\necho -e \"2023-10-03 13:00:00 System rebooted\\n2023-10-03 14:45:30 Error occurred\\n2023-10-03 15:00:01 User logged out\" > ~/logs/log2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "current_time=$(date -u +\"%Y-%m-%d %H:%M:%S\")\npast_time=$(date -u --date=\"24 hours ago\" +\"%Y-%m-%d %H:%M:%S\")\ngrep_pattern=\"$(echo $past_time | awk '{print $1}')|$(echo $current_time | awk '{print $1}')\"\nfind ~/logs -name \"*.log\" | xargs cat | awk -v start=\"$past_time\" -v end=\"$current_time\" '\n{\n    if ($0 >= start && $0 <= end) {\n        sub(/^[0-9:-]+\\s/, \"\", $0);\n        print $0;\n    }\n}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.process_logs` that contains multiple lines of process information in the format \"PID USER TIME COMMAND\". You need to find out how many unique users have processes running that have been active for more than 10 minutes. Note: The time is represented in the format \"MM:SS\" or \"HH:MM:SS\".",
        "explanation": "To solve this problem, you need to:\n1. Filter out lines where the TIME exceeds 10 minutes.\n2. Extract the USER field from those lines.\n3. Determine the number of unique users from this filtered list.\n\nHints:\n- Use tools like `awk` or `grep` to filter and extract information.\n- Use `sort` and `uniq` to find unique entries.\n- Time conversion may be necessary for accurate filtering.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk '{split($3, t, \":\"); if ((length(t) == 2 && int(t[1]) > 10) || (length(t) == 3 && (int(t[1]) > 0 || int(t[2]) > 10))) print $2}' ~/.process_logs | sort | uniq | wc -l\n```",
        "create": {
            "init": "echo -e \"1234 alice 00:05:30 /usr/bin/python\\n5678 bob 00:12:45 /bin/bash\\n9101 charlie 00:09:15 /usr/bin/java\\n1123 alice 01:02:30 /usr/bin/perl\\n1456 dave 00:11:00 /usr/sbin/sshd\" > ~/.process_logs"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk '{split($3, t, \":\"); if ((length(t) == 2 && int(t[1]) > 10) || (length(t) == 3 && (int(t[1]) > 0 || int(t[2]) > 10))) print $2}' ~/.process_logs | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Your task is to identify and count the number of unique IP addresses that have accessed the server, as recorded across all these log files. Consider only the lines that contain HTTP status code 200.",
        "explanation": "To solve this problem, you need to:\n1. Search through all \".log\" files in the \"logs\" directory.\n2. Extract lines that contain HTTP status code 200.\n3. Parse these lines to extract IP addresses.\n4. Count the number of unique IP addresses.\n\nHints: You can use utilities like `grep` to filter lines with status code 200, `awk` or `sed` to extract IP addresses, and `sort | uniq` to find unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep 'HTTP.*200' ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 - - [10/Oct/2023:13:55:36 +0000] \\\"GET /index.html HTTP/1.0\\\" 200 2326\\n192.168.1.2 - - [10/Oct/2023:14:00:12 +0000] \\\"GET /home.html HTTP/1.0\\\" 404 7218\\n192.168.1.3 - - [10/Oct/2023:14:05:19 +0000] \\\"GET /about.html HTTP/1.0\\\" 200 1024\" > ~/logs/access_1.log\necho -e \"192.168.1.2 - - [11/Oct/2023:09:15:45 +0000] \\\"POST /submit HTTP/1.0\\\" 500 316\\n192.168.1.4 - - [11/Oct/2023:09:20:30 +0000] \\\"GET /contact.html HTTP/1.0\\\" 200 2048\\n192.168.1.5 - - [11/Oct/2023:09:25:44 +0000] \\\"GET /services.html HTTP/1.0\\\" 302 -\" > ~/logs/access_2.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep 'HTTP.*200' ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.config_data`. This file contains several lines of key-value pairs in the format `key=value`. Your task is to identify how many unique keys are present in this file. Note that some keys might appear multiple times with different values, but you should count each key only once.",
        "explanation": "To solve this problem, you need to read the `.config_data` file and extract all the keys. You can do this by using command-line tools like `awk` or `cut` to parse the lines and extract the part before the equal sign. Then, using tools like `sort` and `uniq`, you can find out how many unique keys are present.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk -F'=' '{print $1}' ~/.config_data | sort | uniq | wc -l\n```",
        "create": {
            "init": "echo -e \"username=admin\\npassword=secret\\nhost=localhost\\nport=8080\\nusername=root\\ndatabase=mydb\" > ~/.config_data"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk -F'=' '{print $1}' ~/.config_data | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have been tasked with finding the total number of lines in all text files within your home directory and its subdirectories that contain the word \"Linux\". You should ignore case when searching for the word \"Linux\".",
        "explanation": "To solve this problem, you will need to use a combination of bash commands to recursively search through files in your home directory. Use the `find` command to locate all text files, and then use `grep` with the `-i` option to search for \"Linux\" while ignoring case. Finally, count the number of lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all text files in the home directory and its subdirectories,\n# search for lines containing \"Linux\" ignoring case, and count them.\nfind ~ -type f -name \"*.txt\" -exec grep -i \"Linux\" {} + | wc -l\n```",
        "create": {
            "init": "# No initialization required for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all text files in the home directory and its subdirectories,\n# search for lines containing \"Linux\" ignoring case, and count them.\nfind ~ -type f -name \"*.txt\" -exec grep -i \"Linux\" {} + | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing the log files in the `/var/log` directory on your Ubuntu system. Specifically, you need to find all occurrences of the word \"error\" (case insensitive) across all `.log` files and count how many times it appears. Exclude any subdirectories from this search and focus only on direct files within `/var/log`.",
        "explanation": "To solve this problem, you can use a combination of `grep` to search for occurrences of the word \"error\" in a case-insensitive manner and `wc -l` to count the number of lines that contain this word. Make sure you restrict your search to `.log` files within `/var/log` and exclude any directories.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i \"error\" /var/log/*.log 2>/dev/null | wc -l\n```",
        "create": {
            "init": "# No initialization script is needed as we assume logs are present in /var/log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i \"error\" /var/log/*.log 2>/dev/null | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" containing multiple log files with various extensions (e.g., .log, .txt, .out). Your task is to find the total number of unique IP addresses that appear in all the log files within this directory. Assume the log files contain lines formatted as: \"timestamp - IP address - message\". You should ignore any non-log file and ensure not to double-count IP addresses that appear in multiple files.",
        "explanation": "To solve this problem, you need to traverse through all the files in the \"logfiles\" directory, filter out only those with specific extensions like .log, .txt, or .out. Then extract the IP addresses from each of these filtered log files. Finally, keep track of unique IPs using a data structure like a set which automatically handles duplicates.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all relevant files and extract unique IPs into a set.\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' logfiles/*.{log,txt,out} | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p logfiles\necho \"2023-10-01 12:00:00 - 192.168.0.1 - User login\" > logfiles/access.log\necho \"2023-10-01 12:05:00 - 192.168.0.2 - User logout\" >> logfiles/access.log\necho \"2023-10-01 13:00:00 - 192.168.0.1 - User login\" > logfiles/secure.txt\necho \"2023-10-01 14:00:00 - 192.168.0.3 - Error occurred\" >> logfiles/secure.txt\necho \"Some random text\" > logfiles/randomfile.out"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find all relevant files and extract unique IPs into a set.\ngrep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}' logfiles/*.{log,txt,out} | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Each log file consists of multiple entries where each entry starts with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\" followed by a log level (INFO, ERROR, WARNING) and then the message. Your task is to count how many ERROR log entries exist across all log files in this directory.",
        "explanation": "To solve this problem, you need to iterate through each \".log\" file in the \"logs\" directory, extract lines that contain the word \"ERROR\", and count these lines. You can use tools like `grep` to filter out ERROR entries and `wc` to count them. The command should be executed within the shell without writing a script.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-01-01 12:00:00 INFO Starting process\\n2023-01-01 12:05:00 ERROR Failed to connect\\n2023-01-01 12:10:00 INFO Process running\" > ~/logs/log1.log\necho -e \"2023-02-02 13:00:00 WARNING Disk space low\\n2023-02-02 13:05:00 ERROR Out of memory\\n2023-02-02 13:10:00 ERROR Unable to allocate resources\" > ~/logs/log2.log\necho -e \"2023-03-03 14:00:00 INFO User logged in\\n2023-03-03 14:05:00 WARNING High CPU usage\\n2023-03-03 14:10:00 INFO User logged out\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing a large log file named \"system.log\" located in your home directory. Your goal is to determine the total number of unique IP addresses that have accessed the system, as listed in this log file. Each line in the log contains an IP address followed by other data. You need to extract these IP addresses and count how many distinct ones there are.",
        "explanation": "To solve this problem, you need to read through \"system.log\", extract the IP addresses from each line, and then count how many unique IP addresses exist. You can use tools such as `awk`, `sort`, and `uniq` to achieve this task:\n1. Use `awk` to extract the field containing the IP address.\n2. Use `sort` to sort these addresses.\n3. Use `uniq` to filter out duplicates and count unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example script to find the number of unique IP addresses in 'system.log'\nawk '{print $1}' ~/system.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample 'system.log' file with random IP addresses for testing\necho -e \"192.168.1.1 user login\\n192.168.1.2 user logout\\n172.16.0.5 access denied\\n192.168.1.1 failed attempt\\n10.0.0.3 user login\" > ~/system.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example script to find the number of unique IP addresses in 'system.log'\nawk '{print $1}' ~/system.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are tasked with finding the top three largest files in your home directory, including all subdirectories. Count their combined size in kilobytes (KB) and submit this total size as your answer.",
        "explanation": "To solve this problem, you can use the `find` command to list all files within the home directory and its subdirectories. Then, use `du` or `ls` to get the sizes of these files. Sort the list based on file size and select the top three entries. Finally, sum their sizes to get the total size in KB.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find all files, sort them by size in descending order,\n# take the top 3 largest ones, and sum their sizes.\nfind ~ -type f -exec du -k {} + | sort -nrk 1 | head -n 3 | awk '{sum += $1} END {print sum}'\n```",
        "create": {
            "init": "# No initialization is needed for this task."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/size-match.py"
                }
            ],
            "example": "# Find all files, sort them by size in descending order,\n# take the top 3 largest ones, and sum their sizes.\nfind ~ -type f -exec du -k {} + | sort -nrk 1 | head -n 3 | awk '{sum += $1} END {print sum}'"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory, which contains various log files with a \".log\" extension. Your task is to find out how many unique IP addresses have accessed the system based on these logs. Each log file records access entries, where each line starts with an IP address followed by other details. Count the total number of unique IP addresses across all log files.",
        "explanation": "To solve this problem, you need to read through all the log files within the \"logs\" directory, extract the IP addresses from each line, and determine the unique ones. You can use tools like `cat`, `awk`, or `grep` to extract IP addresses and `sort` along with `uniq` to filter out duplicate entries and count unique ones.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"192.168.1.1 UserA\\n192.168.1.2 UserB\\n192.168.1.3 UserC\" > ~/logs/access1.log\necho -e \"192.168.1.2 UserD\\n192.168.1.4 UserE\\n192.168.1.5 UserF\" > ~/logs/access2.log\necho -e \"192.168.1.6 UserG\\n192.168.1.4 UserH\\n192.168.1.7 UserI\" > ~/logs/access3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"project_logs\" in your home directory containing multiple log files. Each log file follows the naming pattern \"log-yyyy-mm-dd.txt\" and contains timestamps in the format \"HH:MM:SS\". Your task is to determine how many unique days have logs recorded for them, i.e., count the number of distinct dates based on the filenames. Assume all files follow the correct naming pattern.",
        "explanation": "To solve this problem, you need to list all files in the \"project_logs\" directory, extract the date part from each filename, and then identify unique dates. You can use tools like `ls`, `cut`, `awk`, or `sed` to manipulate and process text data. The key is to focus on extracting the substring that represents the date (yyyy-mm-dd) and then using a method to identify unique entries, such as with `sort` and `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/project_logs\nls | awk -F'-' '{print $2\"-\"$3\"-\"$4}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\ntouch ~/project_logs/log-2023-10-01.txt\ntouch ~/project_logs/log-2023-10-02.txt\ntouch ~/project_logs/log-2023-09-30.txt\ntouch ~/project_logs/log-2023-10-01.txt # Duplicate date for testing uniqueness"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/project_logs\nls | awk -F'-' '{print $2\"-\"$3\"-\"$4}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.myconfig` that contains key-value pairs in the format `key=value`. Some of these keys might have duplicate entries with different values. Your task is to find out how many unique keys exist in this file, regardless of their values.",
        "explanation": "To solve this problem, you need to parse the `.myconfig` file and identify all unique keys. You can use tools like `awk`, `sed`, or `cut` to extract the keys and then use `sort` and `uniq` to filter out duplicates. Finally, count the number of unique keys.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk -F= '{print $1}' ~/.myconfig | sort | uniq | wc -l\n```",
        "create": {
            "init": "cat <<EOL > ~/.myconfig\nusername=admin\npassword=1234\ntimeout=30\nusername=root\nport=22\ntimeout=60\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk -F= '{print $1}' ~/.myconfig | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named `project_logs` within your home directory, containing numerous log files for a large project. Each log file is named in the format `log-YYYYMMDD.txt`. Your task is to find out how many lines contain the word \"ERROR\" across all these log files. You are required to use shell commands to achieve this.",
        "explanation": "To solve this problem, you need to search through all the files in the `project_logs` directory and count occurrences of the word \"ERROR\". You can use tools like `grep` with recursive and counting options, or combine several utilities using pipes to achieve this. Be sure that your approach considers all files in the specified directory.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -rwo 'ERROR' ~/project_logs | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/project_logs\necho -e \"INFO: All systems operational\\nERROR: Disk space low\\nINFO: Backup completed\" > ~/project_logs/log-20231001.txt\necho -e \"WARNING: High memory usage\\nERROR: Network latency detected\\nERROR: Packet loss\" > ~/project_logs/log-20231002.txt\necho -e \"INFO: System rebooted\\nINFO: Security scan passed\" > ~/project_logs/log-20231003.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -rwo 'ERROR' ~/project_logs | wc -l"
        }
    },
    {
        "description": "You are tasked with analyzing disk usage in your home directory. Count the number of files and directories, ignoring hidden ones, that have been modified in the last 7 days. Provide the total count as your answer.",
        "explanation": "To solve this problem, you need to use a combination of `find`, `ls`, and possibly other commands like `wc` to navigate through your home directory. The key is to use `find` with suitable options to filter out hidden files and directories and those modified in the last 7 days.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\nfind ~ -maxdepth 1 -mtime -7 ! -name '.*' | wc -l\n```",
        "create": {
            "init": "# No specific initialization is required for this question."
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\nfind ~ -maxdepth 1 -mtime -7 ! -name '.*' | wc -l"
        }
    },
    {
        "description": "You are tasked with identifying and counting the number of unique IP addresses accessing a web server. The access logs are stored in a file named `access.log` located in your home directory. Your goal is to determine how many unique IP addresses have accessed the server.",
        "explanation": "To solve this problem, you need to extract all the IP addresses from the `access.log` file, filter out duplicates, and then count the number of unique IPs. The log entries typically start with an IP address, so you can use tools like `awk`, `sort`, and `uniq` to achieve this. Here's a brief plan:\n1. Use `awk` or `grep` to extract IP addresses from each line.\n2. Sort these extracted IPs.\n3. Use `uniq` to filter out duplicate entries.\n4. Count the remaining lines with `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extracting unique IP addresses and counting them\nawk '{print $1}' ~/access.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "# Create a sample access log file in the user's home directory for testing\ncat <<EOL > ~/access.log\n192.168.1.10 - - [10/Oct/2023:13:55:36 +0000] \"GET /index.html HTTP/1.0\" 200 1043\n192.168.1.11 - - [10/Oct/2023:13:56:36 +0000] \"POST /form.html HTTP/1.0\" 404 299\n192.168.1.12 - - [10/Oct/2023:13:57:36 +0000] \"GET /about.html HTTP/1.0\" 200 512\n192.168.1.10 - - [10/Oct/2023:13:58:36 +0000] \"GET /contact.html HTTP/1.0\" 200 2048\n192.168.1.13 - - [11/Oct/2023:14:00:36 +0000] \"GET /home.html HTTP/1.0\" 200 1024\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extracting unique IP addresses and counting them\nawk '{print $1}' ~/access.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"log_files\" in your home directory, containing multiple log files with the extension \".log\". Each log file contains time-stamped entries of various events. Your task is to determine the total number of unique IP addresses that appear in all the log files combined. You should consider only those lines starting with an IP address (in the format XXX.XXX.XXX.XXX) and ignore any other lines.",
        "explanation": "To solve this problem, you need to read through each log file in the \"log_files\" directory, extract lines that start with an IP address, and collect unique IP addresses across all files. You can achieve this by using tools like `grep` to filter lines, `awk` or `sed` to extract IP addresses, and `sort` and `uniq` to count unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/log_files\n\n# Extract lines starting with a valid IP address pattern from all .log files,\n# then extract just the IP addresses, sort them uniquely, and count them.\ngrep -hP '^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}' *.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\ncat > ~/log_files/log1.log <<EOL\n192.168.1.1 - Event A\n172.16.0.5 - Event B\n10.0.0.3 - Event C\n192.168.1.1 - Event D\n192-500-600-700 Some other text without proper format.\nEOL\n\ncat > ~/log_files/log2.log <<EOL\n172.16.0.5 - Event E\n10.0.0.4 - Event F\n10-100-100-100 Text without proper format.\nEOL\n\ncat > ~/log_files/log3.log <<EOL\n192-400-500-600 Another improperly formatted line.\n10.0.0.3 - Event G\n172-300 Text without proper format.\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/log_files\n\n# Extract lines starting with a valid IP address pattern from all .log files,\n# then extract just the IP addresses, sort them uniquely, and count them.\ngrep -hP '^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}' *.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have been given a directory named \"logs\" in your home directory containing multiple log files. Each log file contains entries with timestamps and error levels (INFO, WARNING, ERROR). Your task is to count how many ERROR level logs are there across all files in the \"logs\" directory. You should output only the total number of ERROR entries.",
        "explanation": "To solve this problem, you need to iterate over each log file in the \"logs\" directory, and for each file, you should filter out lines that contain the string \"ERROR\". Count these lines and sum them up across all files to get the total number of ERROR entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\ngrep -r \"ERROR\" ~/logs | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\nmkdir -p ~/logs\necho -e \"[2023-10-01 10:00:00] INFO Starting process\\n[2023-10-01 10:05:00] ERROR Failed to load module\\n[2023-10-01 10:10:00] WARNING Low memory\" > ~/logs/log1.txt\necho -e \"[2023-10-02 11:00:00] INFO Starting process\\n[2023-10-02 11:15:00] ERROR Connection timeout\\n[2023-10-02 11:20:00] INFO Process completed\" > ~/logs/log2.txt\necho -e \"[2023-10-03 12:00:00] WARNING Disk space low\\n[2023-10-03 12:30:00] ERROR Out of memory\\n[2023-10-03 12:45:00] ERROR Unable to save file\" > ~/logs/log3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\ngrep -r \"ERROR\" ~/logs | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with a \".log\" extension. Each log file contains lines of text, some of which include IP addresses in the format \"xxx.xxx.xxx.xxx\". Your task is to count the total number of unique IP addresses across all log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to extract all IP addresses from each log file within the \"logs\" directory, ensure they are unique, and then count them. You can use tools like `grep` to find IP addresses and `sort` along with `uniq` for deduplication. Finally, use `wc -l` to count the number of unique entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -Eo '[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' ~/logs/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"User1 login from 192.168.0.1\\nError at 10.0.0.5\\nUser2 login from 192.168.0.1\" > ~/logs/server1.log\necho -e \"Connection attempt from 172.16.0.2\\nFailed login from 10.0.0.5\\nAccess granted to 172.16.0.3\" > ~/logs/server2.log\necho -e \"User3 logout from 192.168.0.1\\nNetwork error at 172.16.0.2\\nService started on 192.168.1.100\" > ~/logs/server3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -Eo '[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' ~/logs/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logfiles\" in your home directory containing multiple log files with randomly generated data. Each log file is named in the format \"logfile_X.txt\" where X is a number. Your task is to find out how many of these log files contain the word \"ERROR\" at least once. Assume that each line in a log file represents a separate log entry and that the lines can be quite long, so consider efficient ways to process them.",
        "explanation": "To solve this problem, you can use the `grep` command to search for the word \"ERROR\" across all the files in the \"logfiles\" directory. By using options like `-l`, you can list only those files that contain matches. Finally, count the number of such files with tools like `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Use grep to find files containing 'ERROR' and count them\ngrep -l 'ERROR' ~/logfiles/*.txt | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create a logfiles directory\nmkdir -p ~/logfiles\n\n# Generate random log files with some containing 'ERROR'\nfor i in {1..10}; do\n  if (( RANDOM % 2 )); then\n    echo -e \"INFO: Sample Log Entry\\nERROR: An error occurred\\nINFO: Another Log Entry\" > ~/logfiles/logfile_$i.txt\n  else\n    echo -e \"INFO: Sample Log Entry\\nINFO: Another Log Entry\" > ~/logfiles/logfile_$i.txt\n  fi\ndone"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Use grep to find files containing 'ERROR' and count them\ngrep -l 'ERROR' ~/logfiles/*.txt | wc -l"
        }
    },
    {
        "description": "You have been provided with a directory named \"logs\" in your home directory that contains multiple log files with the extension \".log\". Each log file consists of lines representing different types of events occurring in a system, and each line starts with the format \"[YYYY-MM-DD HH:MM:SS] EventType: Message\". Your task is to count the total number of occurrences of an event type specified by the string \"ERROR\" across all these log files. Assume that the event type is always followed immediately by a colon and then the message.",
        "explanation": "To solve this problem, you need to search through all the log files within the \"logs\" directory, filtering out lines that begin with \"[YYYY-MM-DD HH:MM:SS] ERROR:\", and then count how many such lines exist across all files. You can use command-line utilities like `grep` to filter out these lines based on their pattern and `wc` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h '^\\[[0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\} [0-9]\\{2\\}:[0-9]\\{2\\}:[0-9]\\{2\\}\\] ERROR:' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"[2023-10-01 13:00:00] INFO: System started\\n[2023-10-01 13:05:00] ERROR: Failed to load module\\n[2023-10-01 13:07:00] WARNING: Low memory\" > ~/logs/system1.log\necho -e \"[2023-10-02 09:00:00] ERROR: Network connection lost\\n[2023-10-02 09:30:00] INFO: Connection restored\\n[2023-10-02 09:45:00] ERROR: Disk full\" > ~/logs/system2.log\necho -e \"[2023-10-03 11:20:00] INFO: User login successful\\n[2023-10-03 11:25:00] ERROR: Permission denied\\n[2023-10-03 11:30;00] ERROR : Incorrect format test\" > ~/logs/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -h '^\\[[0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\} [0-9]\\{2\\}:[0-9]\\{2\\}:[0-9]\\{2\\}\\] ERROR:' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.student_records` containing a list of student names and their respective scores in the format \"Name: Score\". Your task is to find out how many students scored above 75. Note that names and scores are separated by a colon and a space.",
        "explanation": "To solve this problem, you need to use shell commands to process the lines in the `.student_records` file. You can use `grep` or `awk` to filter out students with scores above 75. This requires reading each line, extracting the score, and performing a conditional check.\n\nYou can use this command pattern to perform the task:\n\n```bash\nawk -F': ' '$2 > 75 {count++} END {print count}' ~/.student_records\n```",
        "create": {
            "init": "echo -e \"Alice: 80\\nBob: 60\\nCharlie: 90\\nDave: 75\\nEve: 85\" > ~/.student_records"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "awk -F': ' '$2 > 75 {count++} END {print count}' ~/.student_records"
        }
    },
    {
        "description": "You have a directory named \"logfiles\" in your home directory containing multiple text files with different extensions. Your task is to count the total number of unique IP addresses found across all \".log\" files in this directory. Ignore any files that do not have a \".log\" extension and any non-IPv4 addresses.",
        "explanation": "To solve this problem, you should first filter out only the \".log\" files from the \"logfiles\" directory. Next, use a combination of utilities such as `grep` to extract potential IP addresses from these files. Ensure you are only considering IPv4 addresses by using an appropriate regex pattern. Finally, use `sort` and `uniq` commands to find and count the unique IP addresses.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -hoE '([0-9]{1,3}\\.){3}[0-9]{1,3}' ~/logfiles/*.log | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logfiles\necho \"192.168.1.1 - - [01/Oct/2023:10:00:00 +0000] \\\"GET /index.html HTTP/1.1\\\" 200 2326\" > ~/logfiles/access.log\necho \"10.0.0.5 - - [01/Oct/2023:10:05:00 +0000] \\\"POST /form HTTP/1.1\\\" 302 34\\n192.168.1.1 - - [01/Oct/2023:10:07:00 +0000] \\\"GET /about.html HTTP/1.1\\\" 404 123\" > ~/logfiles/error.log\necho \"127.0.0.1 localhost\\n::1 localhost6\\nfe80::b9c8:a93d:e5b4%eth0 test-machine\" > ~/logfiles/system.info\necho \"172.16.254.2 - - [01/Oct/2023:11:00:00 +0000] \\\"GET /contact.html HTTP/2\\\" 200 1024\\n192-168-001-001.example.com example-hostname\" > ~/logfiles/security.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -hoE '([0-9]{1,3}\\.){3}[0-9]{1,3}' ~/logfiles/*.log | sort | uniq | wc -l"
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory that contains several log files with the \".log\" extension. Each log file records different events, and each line in a log file begins with a timestamp in the format \"YYYY-MM-DD HH:MM:SS\". Your task is to count the total number of events that occurred on \"2023-10-15\".",
        "explanation": "To solve this problem, you need to search through all the \".log\" files in the \"log_files\" directory for lines that start with the date \"2023-10-15\". You can use tools like `grep` to filter lines by date and then count them using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^2023\\-10\\-15' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-10-14 12:00:01 Event A\\n2023-10-15 09:30:00 Event B\\n2023-10-15 11:45:00 Event C\" > ~/log_files/log1.log\necho -e \"2023-10-14 13:22:05 Event D\\n2023-10-15 14:55:00 Event E\\n2023-10-16 08:00:00 Event F\" > ~/log_files/log2.log\necho -e \"2023-10-15 07:20:33 Event G\\n2023-10-17 09:45:12 Event H\\n2023-10-15 18:30:00 Event I\" > ~/log_files/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^2023\\-10\\-15' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing multiple log files with the extension \".log\". Each log file contains timestamped entries, and some entries contain the word \"ERROR\". Your task is to count how many times the word \"ERROR\" appears across all log files in the \"logs\" directory and return this count.",
        "explanation": "To solve this problem, you need to navigate to the \"logs\" directory in your home folder. Use tools like `grep` to search for occurrences of the word \"ERROR\" in each \".log\" file. The `-o` flag of `grep` will output each occurrence on a new line, and you can then pipe this into `wc -l` to count the lines, which equals the number of occurrences. Summing these counts from all files will give the total number of \"ERROR\" entries.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -roh \"ERROR\" ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"[2023-10-11 10:00] INFO Starting process\\n[2023-10-11 10:01] ERROR Failed to start module\\n[2023-10-11 10:02] INFO Retrying start\\n[2023-10-11 10:03] ERROR Module still not responding\\n\" > ~/logs/log1.log\necho -e \"[2023-10-11 11:00] INFO Checking system health\\n[2023-10-11 11:01] ERROR System health check failed\\n[2023-10-11 11:02] INFO Re-running system health check\\n\" > ~/logs/log2.log\necho -e \"[2023-10-12 09:00] INFO Backup started\\n[2023-10-12 09:01] ERROR Backup failed due to disk error\\n[2023-10-12 09:02] INFO Disk error resolved\\n[2023-10-12 09:03] ERROR Retry backup failed again\\n\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -roh \"ERROR\" ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"logs\" containing multiple log files with the extension \".log\". Your task is to find out which log file contains the most number of error entries and return its filename. An error entry is defined as any line that starts with the word \"ERROR\". Assume that all filenames are unique.",
        "explanation": "To solve this problem, you need to iterate over each \".log\" file in the \"logs\" directory and count how many lines start with \"ERROR\" in each file. Keep track of the maximum count and the corresponding filename. You can use tools like `grep` to filter lines and `wc` to count them.\n\nYou can use this command pattern to perform the task:\n\n```bash\nmax_errors=0\nmax_file=\"\"\nfor file in ~/logs/*.log; do\n  error_count=$(grep -c \"^ERROR\" \"$file\")\n  if (( error_count > max_errors )); then\n    max_errors=$error_count\n    max_file=$(basename \"$file\")\n  fi\ndone\n\n# Output only the filename of the log file with most errors.\necho $max_file\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"INFO: Starting process\\nERROR: Failed to load module\\nINFO: Process completed\" > ~/logs/app1.log\necho -e \"ERROR: Disk full\\nERROR: Network timeout\\nINFO: Retrying connection\" > ~/logs/app2.log\necho -e \"WARNING: Low memory\\nINFO: Operation successful\" > ~/logs/app3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "max_errors=0\nmax_file=\"\"\nfor file in ~/logs/*.log; do\n  error_count=$(grep -c \"^ERROR\" \"$file\")\n  if (( error_count > max_errors )); then\n    max_errors=$error_count\n    max_file=$(basename \"$file\")\n  fi\ndone\n\n# Output only the filename of the log file with most errors.\necho $max_file"
        }
    },
    {
        "description": "In your home directory, there is a hidden log file named \".system.log\" that records various system events with timestamps. Each line contains a timestamp in the format \"YYYY-MM-DD HH:MM:SS\" followed by an event description. Your task is to count how many events occurred on the most recent date mentioned in the file.",
        "explanation": "To solve this problem, you need to follow these steps:\n1. Use `grep` or `awk` to extract all the dates from the log file.\n2. Sort these dates and determine the most recent one.\n3. Count the number of occurrences of this date in the log file using tools like `grep`, `awk`, or `wc`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Extract all unique dates from the log file\ndates=$(awk '{print $1}' ~/.system.log | sort | uniq)\n\n# Find the most recent date\nrecent_date=$(echo \"$dates\" | tail -n 1)\n\n# Count how many times this date appears in the log file\ngrep -c \"^$recent_date\" ~/.system.log\n```",
        "create": {
            "init": "echo -e \"2023-03-15 08:30:00 Event A\\n2023-03-15 09:00:00 Event B\\n2023-03-16 10:15:00 Event C\\n2023-03-16 11:45:00 Event D\\n2023-03-17 14:20:00 Event E\" > ~/.system.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Extract all unique dates from the log file\ndates=$(awk '{print $1}' ~/.system.log | sort | uniq)\n\n# Find the most recent date\nrecent_date=$(echo \"$dates\" | tail -n 1)\n\n# Count how many times this date appears in the log file\ngrep -c \"^$recent_date\" ~/.system.log"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory, containing multiple log files with the \".log\" extension. Each log file contains timestamped entries of events. Your task is to determine how many unique IP addresses have accessed the system across all log files in the \"logs\" directory. You may assume that each line in a log file starts with an IP address followed by the event details.",
        "explanation": "To solve this problem, you need to perform several steps:\n1. Navigate to the \"logs\" directory.\n2. Concatenate all \".log\" files into a single stream.\n3. Extract the IP addresses from each line.\n4. Sort and filter out duplicate IP addresses to find unique ones.\n5. Count the number of unique IP addresses.\n\nHints:\n- Use commands like `cat`, `awk` or `sed` for text processing.\n- For sorting and removing duplicates, consider using `sort` and `uniq`.\n- Finally, count the lines using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Navigate to logs directory\ncd ~/logs\n\n# Find unique IPs across all logs and count them\ncat *.log | awk '{print $1}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create logs directory\nmkdir -p ~/logs\n\n# Generate example log files with dummy data\necho -e \"192.168.1.1 Event A\\n192.168.1.2 Event B\\n192.168.1.3 Event C\" > ~/logs/log1.log\necho -e \"192.168.1.2 Event D\\n192.168.1.4 Event E\\n192.168.1.5 Event F\" > ~/logs/log2.log\necho -e \"192.168.1.3 Event G\\n192.168.1.6 Event H\\n192.168.1.7 Event I\\n192.168  .1 .8   Even t J     \\n      19 2 .16 8 .9 Ev ent K     \\n   10 .0 .0 . 10 Eve nt L     \\n255..255..25...5 E    ve nt M       \\nC o rru pt e d Da t a N O P       \" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Navigate to logs directory\ncd ~/logs\n\n# Find unique IPs across all logs and count them\ncat *.log | awk '{print $1}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are given a directory named `logs` in your home directory containing multiple `.log` files. Each file contains timestamps and log messages. Your task is to find the total number of unique log messages that appear across all the files in the `logs` directory. Only consider the part of each line after a space as the log message, ignoring timestamps.",
        "explanation": "To solve this problem, you need to concatenate all `.log` files, extract only the parts of lines after the first space (which represent log messages), sort them uniquely, and then count these unique entries. You can use tools like `cat`, `awk`, `sort`, and `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncat ~/logs/*.log | awk '{$1=\"\"; print $0}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"2023-10-01 10:00:01 User logged in\" > ~/logs/log1.log\necho \"2023-10-01 10:05:23 File uploaded\" >> ~/logs/log1.log\necho \"2023-10-01 11:00:45 User logged out\" >> ~/logs/log1.log\n\necho \"2023-10-02 09:00:15 User logged in\" > ~/logs/log2.log\necho \"2023-10-02 09:15:22 File deleted\" >> ~/logs/log2.log\necho \"2023-10-02 09:30:33 File uploaded\" >> ~/logs/log2.log\n\necho \"2023-10-03 14:30:05 User logged in\" > ~/logs/log3.log\necho \"2023-10-03 14:35:27 User logged out\" >> ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cat ~/logs/*.log | awk '{$1=\"\"; print $0}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "You are provided with a directory named \"log_files\" in your home directory. Inside this directory, there are multiple log files with the extension \".log\". Count the total number of lines across all these log files that contain the word \"ERROR\", ignoring case. Do not use any loops or write a script; perform this directly in the shell.",
        "explanation": "To solve this problem, you can use a combination of `grep` to search for lines containing \"ERROR\" (ignoring case) and then pipe the result to `wc -l` to count these lines. The `-i` option in `grep` will ignore case, ensuring that both \"error\", \"ERROR\", and any other case variations are matched.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -i 'ERROR' ~/log_files/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"This is a test log file.\\nError occurred here.\\nAnother line.\" > ~/log_files/log1.log\necho -e \"This file contains an error.\\nEverything is fine here.\" > ~/log_files/log2.log\necho -e \"ERROR: something went wrong.\\nAll good.\" > ~/log_files/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -i 'ERROR' ~/log_files/*.log | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a folder named \"logs\" containing multiple log files with the \".log\" extension. Each log file contains space-separated entries where each entry represents a timestamp and an event code. Your task is to count how many times the event code \"ERROR\" appears across all log files in the \"logs\" folder. Present the total count as your answer.",
        "explanation": "To solve this problem, you need to iterate over each \".log\" file within the \"logs\" directory, extract lines that contain the word \"ERROR\", and count them. You can use utilities like `grep` to filter out lines with \"ERROR\" and `wc -l` to count these lines. Summing up these counts from all files will give you the total occurrences of \"ERROR\".\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'ERROR' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho -e \"2023-10-01 12:00:00 INFO\\n2023-10-01 12:05:00 ERROR\\n2023-10-01 12:10:00 WARN\\n2023-10-01 12:15:00 ERROR\" > ~/logs/log1.log\necho -e \"2023-10-02 14:00:00 ERROR\\n2023-10-02 14:05:00 INFO\\n2023-10-02 14:10:00 ERROR\\n2023-10-02 14:15:00 INFO\" > ~/logs/log2.log\necho -e \"2023-10-03 16:00:00 WARN\\n2023-10-03 16:05:00 ERROR\\n2023-10-03 16:10:00 INFO\\n2023-10-03 16:15:00 ERROR\" > ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'ERROR' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You have a directory named \"logs\" in your home directory containing several log files with the \".log\" extension. Each log file contains multiple lines, and each line starts with a timestamp in the format \"[YYYY-MM-DD HH:MM:SS]\". Your task is to find out how many unique dates (i.e., \"YYYY-MM-DD\") are present across all the log files in the \"logs\" directory.",
        "explanation": "To solve this problem, you need to perform several steps:\n1. Navigate to the \"logs\" directory.\n2. Concatenate all log files to process them together.\n3. Extract the date part from each line, focusing only on the first 10 characters (the date portion).\n4. Use `sort` and `uniq` commands to identify unique dates.\n5. Count these unique entries.\n\nHints:\n- You can use `awk` or `cut` to extract specific parts of lines.\n- The combination of `sort | uniq` is useful for finding unique items.\n- Remember that `wc -l` can be used to count lines.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/logs\ncat *.log | awk '{print substr($1,2)}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"[2023-10-01 12:00:00] Log entry 1\" > ~/logs/log1.log\necho \"[2023-10-01 13:00:00] Log entry 2\" >> ~/logs/log1.log\necho \"[2023-10-02 14:00:00] Log entry 3\" > ~/logs/log2.log\necho \"[2023-10-03 15:00:00] Log entry 4\" > ~/logs/log3.log\necho \"[2023-10-03 16:30:00] Log entry 5\" >> ~/logs/log3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "cd ~/logs\ncat *.log | awk '{print substr($1,2)}' | sort | uniq | wc -l"
        }
    },
    {
        "description": "List all the files in your home directory and its subdirectories that have been modified in the last 7 days, then count how many of these files are larger than 1MB.",
        "explanation": "To solve this problem, you can use the `find` command to search for files in your home directory that have been modified within the last 7 days. The `-size` option of `find` can be used to filter out files larger than 1MB. After filtering, count the number of such files using `wc -l`.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find and list all modified files within the last 7 days larger than 1MB, then count them.\nfind ~ -type f -mtime -7 -size +1M | wc -l\n```",
        "create": {
            "init": "# This script creates some sample files with different modification times and sizes for testing purposes.\nmkdir -p ~/test_directory/subdir\ndd if=/dev/zero of=~/test_directory/file1.txt bs=2M count=1 # 2MB file\ndd if=/dev/zero of=~/test_directory/file2.txt bs=512K count=1 # 0.5MB file\ntouch -d \"3 days ago\" ~/test_directory/file1.txt\ntouch -d \"10 days ago\" ~/test_directory/file2.txt\n\ndd if=/dev/zero of=~/test_directory/subdir/file3.txt bs=3M count=1 # 3MB file\ntouch -d \"2 days ago\" ~/test_directory/subdir/file3.txt\n\ndd if=/dev/zero of=~/test_directory/subdir/file4.txt bs=512K count=1 # 0.5MB file\ntouch -d \"8 days ago\" ~/test_directory/subdir/file4.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find and list all modified files within the last 7 days larger than 1MB, then count them.\nfind ~ -type f -mtime -7 -size +1M | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.secret_numbers` containing a list of integers, one per line. You need to find the sum of all even numbers in this file and count how many even numbers there are. Your task is to output the sum followed by the count, separated by a space.",
        "explanation": "To solve this problem, you should first locate the hidden file `.secret_numbers` in your home directory. Use tools like `cat` or `less` to view its contents. Filter out the even numbers using `awk` or a similar tool, then calculate the sum and count of these numbers using command-line utilities such as `awk`, `bc`, or `expr`. Finally, print both results on a single line separated by a space.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Using awk to filter and process even numbers from the .secret_numbers file\n\n# Sum of even numbers\nsum=$(awk 'BEGIN{sum=0} $1%2==0 {sum+=$1} END{print sum}' ~/.secret_numbers)\n\n# Count of even numbers\ncount=$(awk '$1%2==0 {count++} END{print count}' ~/.secret_numbers)\n\n# Output both results\necho \"$sum $count\"\n```",
        "create": {
            "init": "# Create a hidden file with random integers for testing\necho -e \"12\\n15\\n18\\n21\\n24\\n27\\n30\" > ~/.secret_numbers"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "# Using awk to filter and process even numbers from the .secret_numbers file\n\n# Sum of even numbers\nsum=$(awk 'BEGIN{sum=0} $1%2==0 {sum+=$1} END{print sum}' ~/.secret_numbers)\n\n# Count of even numbers\ncount=$(awk '$1%2==0 {count++} END{print count}' ~/.secret_numbers)\n\n# Output both results\necho \"$sum $count\""
        }
    },
    {
        "description": "You have a directory named \"log_files\" in your home directory containing multiple log files with a \".log\" extension. Each log file contains timestamps and various messages, including some that contain the keyword \"ERROR\". Your task is to find the most recent \"ERROR\" message across all these log files and return its timestamp. Assume that each line in the log files starts with a timestamp of the format \"YYYY-MM-DD HH:MM:SS\".",
        "explanation": "To solve this problem, you need to iterate over each \".log\" file in the \"log_files\" directory. For each file, you should search for lines containing the keyword \"ERROR\", extract their timestamps, and keep track of the most recent one. Sort or compare these timestamps to ensure you find the latest one across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -h 'ERROR' ~/log_files/*.log | sort | tail -n1 | awk '{print $1, $2}'\n```",
        "create": {
            "init": "mkdir -p ~/log_files\necho -e \"2023-10-01 12:00:00 INFO Starting process\\n2023-10-01 12:05:00 ERROR Failed to load module\\n2023-10-01 12:10:00 INFO Process completed\" > ~/log_files/system1.log\necho -e \"2023-10-02 08:00:00 INFO Checking system\\n2023-10-02 08:15:00 ERROR Disk not found\\n2023-10-02 08:30:00 INFO System check complete\" > ~/log_files/system2.log\necho -e \"2023-09-30 14:30:00 ERROR Network unreachable\\n2023-09-30 14:35:00 INFO Network restored\\n2023-09-30 14:40:00 ERROR Connection timeout\" > ~/log_files/system3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "grep -h 'ERROR' ~/log_files/*.log | sort | tail -n1 | awk '{print $1, $2}'"
        }
    },
    {
        "description": "You are given a directory named \"project_files\" in your home directory. This directory contains multiple subdirectories and files, some of which are symbolic links. Count the total number of regular files (excluding directories and symbolic links) that have been modified within the last 7 days.",
        "explanation": "To solve this problem, you can use the `find` command with appropriate flags to search for files in the \"project_files\" directory that meet the criteria: being a regular file and having been modified within the last 7 days. Use `-type f` to specify regular files and `-mtime -7` to find files modified in the last 7 days. Finally, use `wc -l` to count these files.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Use find to count regular files modified within last 7 days in 'project_files'\nfind ~/project_files -type f -mtime -7 | wc -l\n```",
        "create": {
            "init": "#!/bin/bash\n\n# Create 'project_files' directory in home if it doesn't exist\nmkdir -p ~/project_files\n\n# Navigate into 'project_files'\ncd ~/project_files\n\n# Create sample files and directories\ntouch file1.txt\ntouch file2.log\nln -s file1.txt symlink_to_file1.txt  # Creating a symbolic link\nmkdir dir1\ntouch dir1/file3.docx\n\n# Adjust modification times for testing purposes\ntouch -d \"2 days ago\" file1.txt    # Modified within 7 days\ntouch -d \"10 days ago\" file2.log   # Modified beyond 7 days\n\n# Create more recent regular files for accurate testing\necho \"Sample text\" > recentfile.txt   # Modified now, so within 7 days"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Use find to count regular files modified within last 7 days in 'project_files'\nfind ~/project_files -type f -mtime -7 | wc -l"
        }
    },
    {
        "description": "In your home directory, there are multiple text files with random names. Each file contains several lines of text, and each line may contain multiple words separated by spaces. Your task is to find out the total number of unique words across all these text files. You should consider words case-insensitively, i.e., \"Word\" and \"word\" should be treated as the same word.",
        "explanation": "To solve this problem, you need to perform the following steps:\n1. List all text files in your home directory.\n2. Extract all the words from these files.\n3. Convert all words to lowercase to ensure case insensitivity.\n4. Identify unique words and count them.\n\nHints:\n- Use `find` or `ls` to list files in your home directory.\n- Use `cat` or `xargs` with a combination of `tr`, `awk`, or `sed` to extract and process words.\n- Use `sort` and `uniq` to identify unique words.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Example solution script\n\ncd ~\n# Concatenate all .txt files, convert to lowercase, extract words,\n# sort them uniquely, then count unique entries.\ncat *.txt | tr ' ' '\\n' | tr '[:upper:]' '[:lower:]' | sort | uniq | wc -l\n```",
        "create": {
            "init": "# This script initializes the environment by creating sample text files in the home directory\n\ncd ~\necho -e \"Hello world\\nThis is a test file\\nAnother Line\" > file1.txt\necho -e \"Sample Text\\nHello Again\\nTest File Content\" > file2.txt\necho -e \"Unique Words Count\\nCount the Words\" > file3.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Example solution script\n\ncd ~\n# Concatenate all .txt files, convert to lowercase, extract words,\n# sort them uniquely, then count unique entries.\ncat *.txt | tr ' ' '\\n' | tr '[:upper:]' '[:lower:]' | sort | uniq | wc -l"
        }
    },
    {
        "description": "Count the total number of lines in all `.txt` files within your home directory and its subdirectories, but exclude any lines that are comments (lines starting with `#`). You should also ignore empty lines and only count lines with actual content.",
        "explanation": "To solve this problem, you need to search for all `.txt` files starting from your home directory using tools like `find`. Once you have the list of files, you can use utilities like `grep` or `awk` to filter out comment lines (lines that start with `#`) and empty lines. Finally, sum up the counts of the remaining lines across all files.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~ -name \"*.txt\" | xargs grep -hvE '^\\s*#|^\\s*$' | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/test_dir/sub_dir\necho -e \"# This is a comment\\nLine 1\\n\\nLine 2\" > ~/test_dir/file1.txt\necho -e \"Line A\\n# Another comment\\nLine B\" > ~/test_dir/sub_dir/file2.txt\ntouch ~/test_dir/empty_file.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "find ~ -name \"*.txt\" | xargs grep -hvE '^\\s*#|^\\s*$' | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden directory named `.logdata` containing several text files. Each file logs system events with timestamps in the format `YYYY-MM-DD HH:MM:SS`. Your task is to determine the most recent event timestamp across all these log files. You should only consider files with a `.txt` extension and ignore any other file types.",
        "explanation": "To solve this problem, you need to list all `.txt` files in the hidden `.logdata` directory, extract timestamps from each file, and then find the latest timestamp. You can use utilities like `find`, `grep`, `awk`, and `sort` to accomplish this task efficiently.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/.logdata -name \"*.txt\" -exec cat {} + | grep -oP '\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}' | sort | tail -n 1\n```",
        "create": {
            "init": "mkdir -p ~/logdata\nmkdir -p ~/.logdata\n\n# Create some sample log files with random timestamps\necho \"2023-09-15 12:00:01 Event A\" > ~/.logdata/event1.txt\necho \"2023-09-16 13:30:00 Event B\" >> ~/.logdata/event1.txt\n\necho \"2023-09-17 14:45:05 Event C\" > ~/.logdata/event2.txt\necho \"2023-08-20 10:00:00 Event D\" >> ~/.logdata/event2.txt\n\necho \"2023-10-01 09:15:30 Event E\" > ~/.logdata/event3.txt\n\n# Add a non-txt file which should be ignored\necho \"This should not be considered.\" > ~/.logdata/ignoreme.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "find ~/.logdata -name \"*.txt\" -exec cat {} + | grep -oP '\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}' | sort | tail -n 1"
        }
    },
    {
        "description": "In your home directory, there are several text files with random content. Your task is to find out the total number of lines across all these text files that contain the word \"Linux\" (case-sensitive).",
        "explanation": "To solve this problem, you need to navigate through your home directory and search for all text files. You can use utilities like `grep` to search for the word \"Linux\" and count the occurrences using `wc -l`. The command should be able to handle multiple text files and accumulate the total line count.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep -r 'Linux' ~/text_files/*.txt | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/text_files\necho \"This is a Linux system.\" > ~/text_files/file1.txt\necho \"Another line without the keyword.\" > ~/text_files/file2.txt\necho \"Linux is a popular open-source operating system.\" > ~/text_files/file3.txt\necho \"Just another random sentence.\" > ~/text_files/file4.txt\necho \"The Linux kernel was created by Linus Torvalds.\" > ~/text_files/file5.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep -r 'Linux' ~/text_files/*.txt | wc -l"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.env_variables` which contains a list of environment variables in the format `KEY=VALUE`, one per line. Your task is to determine how many unique keys (case-insensitive) exist in this file and calculate the total number of characters used by all unique keys combined. Provide the sum of these two numbers as your final answer.",
        "explanation": "To solve this problem, you need to read the `.env_variables` file from your home directory, extract each environment variable's key, and ensure uniqueness by treating them case-insensitively. Count the number of unique keys and then sum the length of each unique key to get the total number of characters used. Finally, add these two values together for your answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\n#!/bin/bash\n\n# Read .env_variables file and extract keys (case-insensitive)\nkeys=$(cut -d '=' -f 1 ~/.env_variables | tr '[:upper:]' '[:lower:]')\n\n# Get unique keys using sort and uniq\nunique_keys=$(echo \"$keys\" | sort | uniq)\n\n# Count number of unique keys\nnum_unique_keys=$(echo \"$unique_keys\" | wc -l)\n\n# Calculate total character count for unique keys\ntotal_chars=0\nwhile read -r key; do\n  total_chars=$((total_chars + ${#key}))\ndone <<< \"$unique_keys\"\n\n# Sum up the number of unique keys and total character count for answer.\nanswer=$((num_unique_keys + total_chars))\necho $answer # This should output 21 for provided example data.\n```",
        "create": {
            "init": "cat <<EOF > ~/.env_variables\nPATH=/usr/local/bin\nHOME=/home/user\nUSER=username\nSHELL=/bin/bash\neditor=vim\npath=/usr/bin\nEditor=nano\nLANG=en_US.UTF-8\nEOF"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "#!/bin/bash\n\n# Read .env_variables file and extract keys (case-insensitive)\nkeys=$(cut -d '=' -f 1 ~/.env_variables | tr '[:upper:]' '[:lower:]')\n\n# Get unique keys using sort and uniq\nunique_keys=$(echo \"$keys\" | sort | uniq)\n\n# Count number of unique keys\nnum_unique_keys=$(echo \"$unique_keys\" | wc -l)\n\n# Calculate total character count for unique keys\ntotal_chars=0\nwhile read -r key; do\n  total_chars=$((total_chars + ${#key}))\ndone <<< \"$unique_keys\"\n\n# Sum up the number of unique keys and total character count for answer.\nanswer=$((num_unique_keys + total_chars))\necho $answer # This should output 21 for provided example data."
        }
    },
    {
        "description": "You have been given a directory named `project_files` in your home directory, which contains various files and subdirectories. Your task is to find out the most recently modified file that is not within any subdirectory and has a `.log` extension. Output the name of this file.",
        "explanation": "To solve this problem, you need to search through the `project_files` directory for files with a `.log` extension. You must exclude any files that are located inside subdirectories. Use commands like `find`, `ls`, or `stat` to identify the modification times, and determine which file was modified most recently. Display only the name of this file.\n\nYou can use this command pattern to perform the task:\n\n```bash\ncd ~/project_files && find . -maxdepth 1 -name \"*.log\" -printf '%T@ %f\\n' | sort -n | tail -n 1 | awk '{print $2}'\n```",
        "create": {
            "init": "mkdir -p ~/project_files/subdir1\nmkdir -p ~/project_files/subdir2\n\ntouch ~/project_files/file1.log\nsleep 1\ntouch ~/project_files/file2.txt\nsleep 1\ntouch ~/project_files/file3.log\nsleep 1\ntouch ~/project_files/subdir1/file4.log\nsleep 1\ntouch ~/project_files/subdir2/file5.log\n\n# Modify one of the log files to ensure it's the most recent.\necho \"Update\" >> ~/project_files/file3.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "cd ~/project_files && find . -maxdepth 1 -name \"*.log\" -printf '%T@ %f\\n' | sort -n | tail -n 1 | awk '{print $2}'"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your current working directory containing multiple log files. Each log file is named in the format \"logYYYYMMDD.txt\" (e.g., log20230101.txt). Your task is to find out how many unique IP addresses made requests on the most recent date available in these log files. Assume each line in a log file starts with an IP address followed by other information.",
        "explanation": "To solve this problem, first identify the most recent date from the filenames of the log files. Then read through the corresponding file and extract all unique IP addresses from it. Count these unique IP addresses to get your answer.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Find the most recent log file based on date in filename\nlatest_log_file=$(ls logs | sort -r | head -n 1)\n\n# Extract unique IP addresses from this file and count them\nunique_ip_count=$(cut -d ' ' -f 1 \"logs/$latest_log_file\" | sort | uniq | wc -l)\n\n# Output only the integer count of unique IPs\necho $unique_ip_count\n```",
        "create": {
            "init": "mkdir -p logs\necho -e \"192.168.1.1 GET /index.html\\n192.168.1.2 POST /form\\n192.168.1.3 GET /about\" > logs/log20231005.txt\necho -e \"192.168.1.2 GET /home\\n192.168.1.3 POST /submit\\n192.168.1.4 GET /contact\\n192.168.1.2 GET /home\" > logs/log20231006.txt\necho -e \"10.0.0.5 GET /index.html\\n10.0.0.6 POST /form\\n10.0.0..7 GET /about\\n192..168..1..4 GET /contact\" > logs/log20231007.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Find the most recent log file based on date in filename\nlatest_log_file=$(ls logs | sort -r | head -n 1)\n\n# Extract unique IP addresses from this file and count them\nunique_ip_count=$(cut -d ' ' -f 1 \"logs/$latest_log_file\" | sort | uniq | wc -l)\n\n# Output only the integer count of unique IPs\necho $unique_ip_count"
        }
    },
    {
        "description": "You are provided with a directory named \"logs\" in your home directory, which contains multiple log files with a \".log\" extension. Each log file contains lines in the format \"TIMESTAMP LEVEL MESSAGE\". Your task is to count how many error messages (LEVEL = ERROR) occurred on the system today. Assume today’s date is 2023-10-05.",
        "explanation": "To solve this problem, you need to filter out lines from all log files that contain the current date and have the level set to ERROR. You can achieve this by using tools like `grep` for filtering and `wc -l` for counting. Make sure to utilize the wildcard character (*) to search within all \".log\" files inside the \"logs\" directory.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '2023-10-05 ERROR' ~/logs/*.log | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat <<EOL > ~/logs/system1.log\n2023-10-05 INFO System started\n2023-10-05 ERROR Failed to load module\n2023-10-04 WARNING Low disk space\n2023-10-05 ERROR Connection lost\nEOL\n\ncat <<EOL > ~/logs/system2.log\n2023-10-03 INFO Backup completed\n2023-10-05 INFO User login successful\n2023-10-05 ERROR Disk read failure\nEOL\n\ncat <<EOL > ~/logs/system3.log\n2023-09-30 INFO Scheduled maintenance complete\n2023-10-05 ERROR Memory leak detected\nEOL"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '2023-10-05 ERROR' ~/logs/*.log | wc -l"
        }
    },
    {
        "description": "You are given a directory named \"logs\" in your home directory containing multiple log files with varying extensions. Each file contains timestamps and messages formatted as \"YYYY-MM-DD HH:MM:SS - Message\". Find the most recent timestamp across all log files and provide the corresponding message. Assume that all timestamps are unique across the files.",
        "explanation": "To solve this problem, you need to iterate through each log file in the \"logs\" directory, extract all timestamps, and compare them to find the most recent one. Once found, you should output the entire line (timestamp and message) corresponding to that timestamp. Consider using tools like `find`, `awk`, or `grep` for searching patterns, and `sort` or custom comparisons for finding the latest timestamp.\n\nYou can use this command pattern to perform the task:\n\n```bash\nfind ~/logs -type f | xargs grep -hE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' | sort | tail -n 1 | awk '{print $0}'\n# The expected output should be:\n# 2023-01-03 08:20:10 - Scheduled maintenance\n```",
        "create": {
            "init": "mkdir -p ~/logs\necho \"2023-01-01 10:00:00 - System started\" > ~/logs/log1.txt\necho \"2023-01-02 12:30:45 - User logged in\" > ~/logs/log2.log\necho \"2023-01-02 15:45:30 - Error occurred\" > ~/logs/log3.txt\necho \"2023-01-03 08:20:10 - Scheduled maintenance\" > ~/logs/log4.log"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/string-match.py"
                }
            ],
            "example": "find ~/logs -type f | xargs grep -hE '^[0-9]{4}-[0-9]{2}-[0-9]{2}' | sort | tail -n 1 | awk '{print $0}'\n# The expected output should be:\n# 2023-01-03 08:20:10 - Scheduled maintenance"
        }
    },
    {
        "description": "In your home directory, there is a hidden file named `.logfiles` that contains a list of filenames (one per line). Each filename corresponds to a file that exists in the `~/logs` directory. Your task is to count how many of these files in the `~/logs` directory have been modified in the last 7 days.",
        "explanation": "To solve this problem, you need to perform the following steps:\n1. Navigate to your home directory and read the `.logfiles` file to get the list of filenames.\n2. For each filename listed in `.logfiles`, check if it exists in the `~/logs` directory and verify if it has been modified within the last 7 days.\n3. Count how many files meet this criteria.\n4. You can use utilities like `find`, `xargs`, and `stat` to filter and check modification dates.\n\nYou can use this command pattern to perform the task:\n\n```bash\n# Read filenames from .logfiles, then use find to check modification time within last 7 days.\ngrep -Ff ~/.logfiles <(find ~/logs -type f -mtime -7) | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ntouch ~/logs/log1.txt ~/logs/log2.txt ~/logs/log3.txt\necho \"log1.txt\" > ~/.logfiles\necho \"log2.txt\" >> ~/.logfiles\necho \"log3.txt\" >> ~/.logfiles\n\n# Modify log1.txt and log3.txt to be within 7 days\ntouch -d '2 days ago' ~/logs/log1.txt\ntouch -d '5 days ago' ~/logs/log3.txt\n\n# Modify log2.txt outside of 7-day window for testing purposes\ntouch -d '10 days ago' ~/logs/log2.txt"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "# Read filenames from .logfiles, then use find to check modification time within last 7 days.\ngrep -Ff ~/.logfiles <(find ~/logs -type f -mtime -7) | wc -l"
        }
    },
    {
        "description": "You have a directory named `logs` in your home directory containing multiple log files with a `.log` extension. Each log file contains various system events and timestamps. Your task is to determine how many unique error messages are present across all the log files. An error message is identified by lines starting with the word \"ERROR\". Count each distinct error message only once, regardless of how many times it appears or in which file it appears.",
        "explanation": "To solve this problem, you can use tools like `grep`, `awk`, and `sort` to extract and count unique error messages. First, use `grep` to filter lines starting with \"ERROR\" from all `.log` files in the `logs` directory. Then, use `awk` or similar text processing tools to isolate the actual error message text (assuming it starts immediately after \"ERROR\"). Finally, sort these extracted messages and count unique entries using tools like `uniq`.\n\nYou can use this command pattern to perform the task:\n\n```bash\ngrep '^ERROR' ~/logs/*.log | awk -F'ERROR:' '{print $2}' | sort | uniq | wc -l\n```",
        "create": {
            "init": "mkdir -p ~/logs\ncat > ~/logs/system1.log <<EOF\nINFO: System booting up\nERROR: Disk space low\nWARNING: High memory usage\nERROR: Network unreachable\nINFO: User login successful\nDEBUG: Initializing modules\nERROR: Disk space low\nEOF\n\ncat > ~/logs/system2.log <<EOF\nINFO: Scheduled maintenance start\nERROR: Network unreachable\nDEBUG: Checking disk health\nINFO: Scheduled maintenance complete\nWARNING: CPU temperature high\nERROR: Authentication failed for user admin\nEOF\n\ncat > ~/logs/system3.log <<EOF\nDEBUG: Running diagnostics toolset \nERROR: Disk space low \nINFO: Diagnostics complete \nWARNING: Low battery warning \nERROR: Network unreachable \nINFO: Charging started \nEOF"
        },
        "evaluation": {
            "check": [
                null,
                {
                    "language": "python",
                    "file": "check/integer-match.py"
                }
            ],
            "example": "grep '^ERROR' ~/logs/*.log | awk -F'ERROR:' '{print $2}' | sort | uniq | wc -l"
        }
    }
]